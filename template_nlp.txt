0	Cluster Name <*>	2130
1	<*>	5964
2	Pod Name <*>	710
3	Namespace <*>	1065
4	Node Name <*>	1420
5	Pod Labels component <*> tier control-plane	150
6	Cluster Uid <*>	2485
7	Tenant Uid <*>	2840
8	Project Uid <*>	3195
9	Cloud Type vsphere	3550
10	Cluster Env cleanup	440
11	Time <*> <*> <*> <*> <*> UTC m <*>	3905
12	...........................................	13240
13	Container Name <*>	3112
14	Image Id <*> <*>	4750
15		28242
16	Pod Events	1871
17	Pod Labels k8s-app <*> <*> <*>	60
18	Watch channel closed by remote <*> recreate watcher ListRoot <*>	186066
19	Terminating main client watcher loop	496
20	Main client watcher loop	498
21	Container Name coredns	88
22	Pod Labels <*> <*> k8s-app <*> <*> <*>	400
23	Pod Labels <*> <*> <*> <*> k8s-app <*>	55
24	Pod Labels k8s-app <*> <*> <*> <*> <*>	80
25	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*>	347098
26	Using autodetected IPv4 address on interface eth0 <*>	388384
27	Pod Labels component etcd tier control-plane	55
28	Container Name etcd	121
29	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/api/etcdhttp <*> OK status code <*>	411719
30	<*> <*> <*> <*> <*> <*> <*> I | etcdserver start to snapshot applied <*> lastsnap <*>	5775
31	<*> <*> <*> <*> <*> <*> <*> I | etcdserver saved snapshot at index <*>	5775
32	<*> <*> <*> <*> <*> <*> <*> I | etcdserver compacted raft log at <*>	5775
33	<*> <*> <*> <*> <*> <*> <*> I | pkg/fileutil purged file <*> successfully	6556
34	<*> <*> <*> <*> <*> <*> <*> I | mvcc store.index compact <*>	13948
35	<*> <*> <*> <*> <*> <*> <*> I | mvcc finished scheduled compaction at <*> took <*>	13948
36	Discovered VM using normal UUID format	3723
37	<*> <*> <*> <*> <*> <*> <*> W | rafthttp the clock difference against peer <*> is too high <*> > <*>	46332
38	parsed scheme <*>	76558
39	ccResolverWrapper sending update to cc https <*> <*> <nil> 0 <nil> <nil> <nil>	76555
40	ClientConn switching balancer to pick_first	81382
41	Error proxying data from backend to client tls use of closed connection	7253
42	Pod Labels app <*> <*> <*> <*> <*> role <*>	5
43	Throttling request took <*> request GET https <*> <*> <*>	40803
44	Error while processing Node <*> failed to allocate cidr from cluster cidr at idx 0 CIDR allocation failed there are no remaining CIDRs left to allocate in the accepted range	2574
45	Event occurred object <*> kind Node apiVersion <*> type Normal reason CIDRNotAvailable message Node <*> status is now CIDRNotAvailable	2574
46	Pod Labels role <*> app <*> <*> <*> <*> <*>	5
47	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*>	14974
48	Auditing failed of request encoding failed <*> Kind DeleteOptions is unstructured and is not suitable for converting to <*>	2640
49	Watch error received from Upstream ListRoot <*> error too old resource version <*> <*>	2681
50	Full resync is required ListRoot <*>	3961
51	Pod Labels app <*> <*> <*> role <*>	5
52	forcing resync	1254
53	Watch close <*> <*> total 0 items received	3531
54	Connecting to unix <*>	1074069
55	Pod Labels <*> <*> <*> <*> role <*> app <*>	5
56	Pod Labels control-plane <*> <*> <*>	20
57	Pod Labels <*> <*> control-plane controller-manager	5
58	Pod Labels <*> infrastructure-vsphere control-plane controller-manager <*> <*>	15
59	Pod Labels app spectro component cluster-management-agent log-regex logrus-text module ally <*> <*> <*> proxy	10
60	Pod Labels control-plane controller-manager <*> <*> <*> <*>	5
61	Pod Labels <*> cluster-api control-plane controller-manager <*> <*>	20
62	Pod Labels <*> <*> <*> <*> <*> infrastructure-metal3 control-plane controller-manager	10
63	Pod Labels <*> <*> broadcastjob-name <*> <*> proxy <*> host <*> skip	90
64	Pod Labels <*> <*> <*> bootstrap-kubeadm control-plane controller-manager	15
65	Pod Labels <*> skip <*> <*> broadcastjob-name <*> <*> proxy <*> host	50
66	Container Name cluster-management-agent	44
67	Pod Labels control-plane controller-manager <*> <*> <*> proxy	10
68	Container Name manager	330
69	Container Name node-agent	539
70	Cached <*> logs as events cluster <*>	5491
71	Pushing <*> cached event s to hubble cluster <*>	4175
72	Starting node agent controller	486
73	Pushed >>> <*> event s cluster <*>	4175
74	Found <*> spectro node tasks to reconcile	487
75	upgrade agent No change in version is required as current version and newVersion is <*> same cluster <*>	999
76	Reconciling <*> spectro node task	488
77	<*> <*> <*> register aws provider <*>	22
78	Running cmd exec task <*>	484
79	<*> <*> <*> register azure provider <*>	22
80	Creating <*> file	557
81	Executing command <*> +x print-logs.sh	484
82	<*> <*> <*> register maas provider <*>	22
83	Executing command <*> print-logs.sh	484
84	>>>>>>> Watching SpectroCluster CRD in <*> namespace cluster <*>	244
85	<*> <*> <*> register vsphere provider	22
86	<*> <*> <*> register gcp provider <*>	22
87	<*> <*> <*> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~	1133
88	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus conditions type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed cluster <*>	286
89	Skipping to post <*> conditions to hubble as there is no difference in cached conditions cluster <*>	486
90	<*> <*> <*> register generic provider	22
91	<*> <*> <*> <*>	3171
92	metrics server is starting to listen addr <*> <*>	110
93	register field index	55
94	<*> <*> <*> register openstack provider	22
95	new clientset registry	55
96	watch in a single namespace namespace <*>	69
97	ExecSync for <*> with command <*> <*> <*> and timeout <*> s	286905
98	setup webhook	55
99	Exec process <*> exits with exit code 0 and error <nil>	326742
100	resync period every <*>	69
101	Finish piping stdout of container exec <*>	326645
102	registering webhook path <*>	1059
103	ExecSync for <*> returns with exit code 0	326884
104	Finish piping stderr of container exec <*>	326592
105	metrics server is starting to listen addr <*>	91
106	Registered webhook handler <*>	770
107	Portforward for <*> port	4180
108	starting manager	114
109	Portforward for <*> returns URL http <*> <*>	4180
110	attempting to acquire leader lease <*>	341
111	Executing port forwarding command <*> <*> TCP4 localhost <*> in network namespace host	4180
112	starting palette metrics server at <*>	34
113	starting metrics server path <*>	194
114	successfully acquired lease <*>	262
115	Starting EventSource controller spectrocluster source Type metadata creationTimestamp null spec clusterProfileTemplate clusterConfig machineManagementConfig machineHealthConfig status	57
116	Applying rbac rules cluster <*>	1075
117	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error EOF stderr	2728
118	Starting EventSource controller pack source Type metadata creationTimestamp null spec packConfigSpec layer packRef layer server name tag status	34
119	<*> items n cluster <*>	1065
120	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error exit status <*> stderr <*> <*> <*> <*> socat <*> E write <*> <*> <*> Broken pipe n	418
121	Starting Controller controller pack	34
122	Starting workers controller pack worker count <*>	34
123	Starting EventSource controller spectrocluster source Type metadata creationTimestamp null spec clusterConfig region endpointAccess status	34
124	Starting EventSource controller spectrocluster source Type metadata creationTimestamp null spec cloudAccountRef null clusterConfig network networkName ipPool nameserver controlPlaneEndpoint placement network networkName ipPool nameserver machinePoolConfig null status nodeImage	34
125	Starting EventSource controller spectrocluster source Type metadata creationTimestamp null spec clusterConfig subscriptionId resourceGroup location sshKey controlPlaneSubnet workerSubnet status vhdImage images	34
126	Starting Controller controller spectrocluster	57
127	ExecSync for <*> with command <*> <*> and timeout <*> s	8008
128	Unable to retrieve pull secret <*> for <*> due to secret <*> not found. The image pull may not succeed.	23424
129	Starting workers controller spectrocluster worker count <*>	57
130	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus conditions type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed cluster <*>	220
131	Summarising 6 dataplane reconciliation loops over <*> avg <*> longest <*> <*>	4204
132	detecting env spectrocluster Namespace <*> Name <*>	40139
133	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady conditions for spectro cluster cluster <*>	220
134	Finish port forwarding for <*> port <*>	814
135	detect env done spectrocluster Namespace <*> Name <*> env cleanup	741
136	reconcile delete target spectrocluster Namespace <*> Name <*>	740
137	reconcileCAPI spectrocluster Namespace <*> Name <*>	11411
138	createCAPISecret spectrocluster Namespace <*> Name <*>	16206
139	deployment ready spectrocluster Namespace <*> Name <*> name <*>	81768
140	deployment ready spectrocluster Namespace <*> Name <*> name cert-manager	11420
141	>>>>>>> Watching event s in <*> namespace cluster <*>	234
142	initialize webhook	55
143	Starting <*>	288
144	reconcileCAPI done spectrocluster Namespace <*> Name <*>	11419
145	Waiting for caches to sync for <*>	257
146	pivot resource back to prepare cleanup spectrocluster Namespace <*> Name <*>	737
147	Starting reflector <*> 0s from <*> <*>	242
148	getForcePivotStatus	737
149	Listing and watching <*> from <*> <*>	25359
150	reconcileTargetKubeClient spectrocluster Namespace <*> Name <*>	737
151	fetching kubeconfig with key spectrocluster Namespace <*> Name <*> key Namespace <*> Name <*>	737
152	reconcileTargetKubeClient done spectrocluster Namespace <*> Name <*>	737
153	target namespace already marked for deletion	737
154	reconcilePivotBack spectrocluster Namespace <*> Name <*>	737
155	start to scale down controller deployments spectrocluster Namespace <*> Name <*>	737
156	scale down controller success spectrocluster Namespace <*> Name <*> <*> <*>	4419
157	Secret <*> added	55
158	ValidatingWebhookConfiguration <*> added	55
159	MutatingWebhookConfiguration <*> added	55
160	CustomResourceDefinition <*> added	110
161	scale down controller deployments done spectrocluster Namespace <*> Name <*>	734
162	caches populated	561
163	pivot move resource spectrocluster Namespace <*> Name <*>	733
164	Caches are synced for <*>	258
165	Reconciler error error failed to pivot move resource back failed to pause capi cluster error updating the pause status for <*> Kind <*> Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused controller spectrocluster name <*> namespace <*>	732
166	Started <*>	192
167	Starting to sync webhook certs and configurations	3828
168	cert is invalid or expiring regenerating a new one	33
169	Secret <*> updated	33
170	Cert writer update secret <*> resourceVersion from <*> to <*>	33
171	cert directory doesn t exist <*>	55
172	cloud setup already done skipping spectrocluster Namespace <*> Name <*>	11375
173	performed write of new data to ts data directoryts <*>	55
174	Find path <*> not in handlers map <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	3828
175	ValidatingWebhookConfiguration <*> updated	66
176	Finished to sync webhook certs and configurations	3828
177	MutatingWebhookConfiguration <*> update	66
178	wait webhook ready	55
179	Starting reflector <*> <*> from <*> <*>	510
180	>>>>>>>>> Watching Namespaces cluster <*>	154
181	Error proxying data from backend to client write tcp <*> <*> <*> write broken pipe	220
182	current pathstarget <*> <*> <*> cert.pem key.pem tls.crt tls.key	3773
183	new pathstarget <*> <*> <*> cert.pem key.pem tls.crt tls.key	3773
184	paths to removetarget <*>	3773
185	Error proxying data from backend to client write tcp <*> <*> <*> write connection reset by peer	22
186	>>>>>>> Watching <*> in <*> namespace cluster <*>	455
187	no update required for target <*>	3773
188	Error proxying data from client to backend tls use of closed connection	66
189	Normal message <*> became leader object kind ConfigMap namespace <*> name <*> uid <*> apiVersion <*> resourceVersion <*> reason LeaderElection	57
190	<*> <*> <*> <*> <*> <*> <*> I | wal segmented wal file <*> is created	869
191	starting webhook server	88
192	Updated current TLS certificate	83
193	serving webhook server host <*> port <*>	55
194	Starting certificate watcher	77
195	setup controllers	55
196	Starting AdvancedCronJob Controller	55
197	Starting EventSource controller <*> source Type metadata creationTimestamp null spec schedule template status	55
198	Starting EventSource controller <*> source Type metadata creationTimestamp null spec template metadata creationTimestamp null spec containers null completionPolicy failurePolicy status active 0 succeeded 0 failed 0 desired 0 phase	110
199	Starting EventSource controller <*> source Type metadata creationTimestamp null spec containers null status	55
200	Starting EventSource controller <*> source Type metadata creationTimestamp null spec status daemonEndpoints kubeletEndpoint Port 0 nodeInfo machineID systemUUID bootID kernelVersion osImage containerRuntimeVersion kubeletVersion kubeProxyVersion operatingSystem architecture	55
201	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result range_response_count <*> size <*> took too long <*> to execute	792
202	custom resource gate not found groupVersionKind <*> Kind StatefulSet in discovery the server could not find the requested resource	55
203	Starting EventSource controller <*> source Type metadata creationTimestamp null spec template metadata creationTimestamp null spec containers null status	55
204	Starting Controller controller <*>	110
205	Starting workers controller <*> worker count <*>	110
206	received request webhook <*> UID <*> kind group <*> version <*> kind BroadcastJob resource group <*> version <*> resource broadcastjobs	110
207	wrote response webhook <*> UID <*> allowed true result metadata code <*>	796
208	wrote response webhook <*> UID <*> allowed true result metadata reason allowed to be admitted code <*>	55
209	<*> has <*> nodes remaining to schedule pods	1988
210	Before broadcastjob reconcile <*> desired <*> active 0 failed 0	139
211	creating pod on node <*>	616
212	Controller <*> created pod <*>	616
213	Normal message Created pod <*> object kind BroadcastJob namespace <*> name <*> uid <*> apiVersion <*> resourceVersion <*> reason SuccessfulCreate	616
214	After broadcastjob reconcile <*> desired <*> active <*> failed 0	1749
215	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active <*> Succeeded 0 Failed 0 Desired <*> Phase running	759
216	Successfully Reconciled controller <*> name <*> namespace <*>	2204
217	Before broadcastjob reconcile <*> desired <*> active <*> failed 0	1694
218	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active <*> Succeeded <*> Failed 0 Desired <*> Phase running	880
219	job <*> is Complete Job completed <*> pods succeeded 0 pods failed	55
220	Job <*> is Complete will be deleted after <*> seconds	55
221	After broadcastjob reconcile <*> desired <*> active 0 failed 0	83
222	Updating job <*> status <*> Conditions <*> <*> Type Complete Status True LastProbeTime <*> Time time.Time wall <*> ext <*> loc time.Location <*> LastTransitionTime <*> Time time.Time wall <*> ext <*> loc time.Location <*> Reason Complete Message Job completed <*> pods succeeded 0 pods failed StartTime <*> <*> CompletionTime <*> <*> Active 0 Succeeded <*> Failed 0 Desired <*> Phase completed	55
223	Normal message Job <*> is completed <*> pods succeeded 0 pods failed object kind BroadcastJob namespace <*> name <*> uid <*> apiVersion <*> resourceVersion <*> reason JobComplete	55
224	<*> <*> <*> <*> Successfully assigned <*> to <*>	18
225	<*> <*> <*> <*> Pulling image <*> <*>	318
226	<*> <*> <*> <*> Successfully pulled image <*> <*> in <*>	271
227	<*> <*> <*> <*> Created container manager	18
228	<*> <*> <*> <*> Started container manager	15
229	<*> <*> <*> <*> Readiness probe failed Get http <*> <*> dial tcp <*> <*> connect connection refused	4
230	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result range_response_count 0 size <*> took too long <*> to execute	198
231	<*> <*> <*> <*> <*> <*> <*> W | etcdserver failed to send out heartbeat on time exceeded the <*> timeout for <*> to <*>	22
232	<*> <*> <*> <*> <*> <*> <*> W | etcdserver server is likely overloaded	22
233	Error proxying data from backend to client read tcp <*> <*> <*> read connection reset by peer	11
234	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error write tcp <*> <*> <*> use of closed network connection stderr	110
235	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error write tcp <*> <*> <*> write broken pipe stderr	88
236	Local endpoint updated id WorkloadEndpoint node <*> orchestrator k8s workload <*> name eth0	28139
237	id <orchestrator_id k8s workload_id <*> endpoint_id eth0 > endpoint <state active name <*> profile_ids <*> profile_ids <*> ipv4_nets <*> >	26225
238	Updating per-endpoint chains. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	27994
239	Queueing update of chain. chainName <*> ipVersion <*> table filter	128150
240	Updating endpoint routes. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	27988
241	Chain became referenced marking it for programming chainName <*>	51340
242	Skipping configuration of interface because it is oper down. ifaceName <*>	8795
243	Re-evaluated workload endpoint status adminUp true failed false known true operUp false status down workloadEndpointID proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	8993
244	Storing endpoint status update ipVersion <*> status down workload proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	8993
245	Trying to connect to netlink	8704
246	Endpoint down for at least one IP version id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0 ipVersion <*> status down	8993
247	Reporting combined status. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0 status down	8993
248	Linux interface addrs changed. addrs set.mapSet ifaceName <*>	14099
249	Linux interface state changed. ifIndex <*> ifaceName <*> state up	8666
250	&intdataplane.ifaceAddrsUpdate Name <*> Addrs set.mapSet	13024
251	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name <*> Addrs set.mapSet	13024
252	&intdataplane.ifaceUpdate Name <*> State up Index <*>	7931
253	Workload interface came up marking for reconfiguration. ifaceName <*>	8719
254	Workload interface state changed marking for status update. ifaceName <*>	8629
255	Applying <*> configuration to interface. ifaceName <*>	27820
256	Re-evaluated workload endpoint status adminUp true failed false known true operUp true status up workloadEndpointID proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	27619
257	Storing endpoint status update ipVersion <*> status up workload proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	27617
258	Endpoint up for at least one IP version id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0 ipVersion <*> status up	27615
259	Reporting combined status. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0 status up	27613
260	Netlink address update. addr fe80 ecee eeff feee eeee exists true ifIndex <*>	5791
261	Linux interface addrs changed. addrs set.mapSet fe80 ecee eeff feee eeee set.empty ifaceName <*>	5910
262	&intdataplane.ifaceAddrsUpdate Name <*> Addrs set.mapSet fe80 ecee eeff feee eeee set.empty	5126
263	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name <*> Addrs set.mapSet fe80 ecee eeff feee eeee set.empty	5126
264	Local endpoint deleted id WorkloadEndpoint node <*> orchestrator k8s workload <*> name eth0	10418
265	id <orchestrator_id k8s workload_id <*> endpoint_id eth0 >	10418
266	Workload removed deleting its chains. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10418
267	Queuing deletion of chain. chainName <*> ipVersion <*> table filter	47826
268	Workload removed deleting old state. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10418
269	Chain no longer referenced marking it for removal chainName <*>	47826
270	Re-evaluated workload endpoint status adminUp false failed false known false operUp false status workloadEndpointID proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10418
271	Storing endpoint status update ipVersion <*> status workload proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10418
272	Removing conntrack flows ip <*>	10506
273	Reporting endpoint removed. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10373
274	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result range_response_count 0 size <*> took too long <*> to execute	44
275	<*> <*> <*> bird KIF Received address message for unknown interface <*>	1001
276	Linux interface state changed. ifIndex <*> ifaceName <*> state down	8277
277	&intdataplane.ifaceUpdate Name <*> State down Index <*>	7909
278	Netlink address update. addr fe80 ecee eeff feee eeee exists false ifIndex <*>	5457
279	Linux interface addrs changed. addrs <nil> ifaceName <*>	8288
280	&intdataplane.ifaceAddrsUpdate Name <*> Addrs set.Set nil	7909
281	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name <*> Addrs set.Set nil	7909
282	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*>	1968
283	Summarising 6 dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*>	220
284	id <name <*> > profile <inbound_rules <action allow rule_id RlLgQRgidk_vSbTC > outbound_rules <action allow rule_id <*> > >	11
285	Queueing update of chain. chainName <*> ipVersion <*> table mangle	9609
286	id <name <*> > profile <>	4425
287	id <name <*> >	8127
288	Queuing deletion of chain. chainName <*> ipVersion <*> table mangle	8083
289	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*>	1258
290	Upgrading palette as current version is <*> and new version is <*> cluster <*>	11
291	Successfully audited via rest Upgrading palette as current version is <*> and new version is <*> Normal cluster <*>	11
292	Pushing 4 cached event s to hubble cluster <*>	75
293	Pushed >>> 4 event s cluster <*>	75
294	Cached 6 logs as events cluster <*>	12
295	Event occurred object <*> kind Deployment apiVersion <*> type Normal reason <*> message Scaled up replica set <*> to <*>	1671
296	Event occurred object <*> kind ReplicaSet apiVersion <*> type Normal reason SuccessfulCreate message Created pod <*>	1917
297	Event occurred object <*> kind Deployment apiVersion <*> type Normal reason <*> message Scaled down replica set <*> to 0	45
298	Event occurred object <*> kind ReplicaSet apiVersion <*> type Normal reason SuccessfulDelete message Deleted pod <*>	45
299	<*> <*> <*> <*> <*> <*> <*> Handling the message <*>	44
300	NATS Received message with key <*> cluster <*>	44
301	Successfully audited Received message with key <*> nats Normal cluster <*>	44
302	Collecting logs on demand cluster <*>	44
303	Cluster Feature Log Fetcher Request noOfLines <*> duration <*> k8sRequest namespace <*> <*> nodeRequest nodeLog <*> <*> cluster <*>	22
304	Successfully audited Started processing log collection request at <*> <*> <*> <*> <*> UTC m <*> log Normal cluster <*>	44
305	Applying crony task controller by getting it from scar cluster <*>	22
306	Creating crony task controller deployment with version <*> cluster <*>	22
307	Fetching manifest of service crony and version <*> for action apply cluster <*>	22
308	Applying manifest with file name <*> cluster <*>	22
309	Applying on demand log fetch spectro node task cluster <*>	44
310	Fetching manifest from service crony and version <*> for action resources with file name <*> cluster <*>	132
311	Applying spectro node task <*> cluster <*>	55
312	Finding spectro node task <*> cluster <*>	55
313	spectro node task <*> is not found cluster <*>	33
314	Creating spectro node task <*> cluster <*>	33
315	Created spectro node task <*> cluster <*>	33
316	Applied spectro node task <*> cluster <*>	55
317	Applied on demand log fetch spectro node task cluster <*>	44
318	Checking for replica to be in running state for deployment <*> in iteration 0 cluster <*>	44
319	Waiting for pod to be in running state for deployment <*> cluster <*>	66
320	Checking for replica to be in running state for deployment <*> in iteration <*> cluster <*>	44
321	Checking for replica to be in running state for deployment <*> in iteration 4 cluster <*>	11
322	Checking for replica to be in running state for deployment <*> in iteration 6 cluster <*>	11
323	Deployment <*> is in running state with <*> replica cluster <*>	33
324	Applying on demand log fetch broadcast job cluster <*>	66
325	Deleting <*> broadcast job cluster <*>	66
326	Deleted <*> broadcast job cluster <*>	66
327	Checking for deletion of all log grep pods in iteration 0 cluster <*>	66
328	Old Log grep pods on all nodes have been deleted successfully in iteration 0 cluster <*>	55
329	Applying <*> broadcast job cluster <*>	66
330	Finding broadcast job <*> cluster <*>	396
331	broadcast job <*> is not found cluster <*>	66
332	Creating <*> broadcast job cluster <*>	66
333	Created <*> broadcast job cluster <*>	44
334	Applied <*> broadcast job cluster <*>	44
335	Applied on demand log fetch broadcast job cluster <*>	44
336	Checking for completed log grep pods in iteration 0 cluster <*>	44
337	Found broadcast job <*> cluster <*>	330
338	Waiting for pod containing node logs to get completed... cluster <*>	275
339	Checking for completed log grep pods in iteration <*> cluster <*>	231
340	Considering pod <*> with phase Running cluster <*>	3465
341	Pod <*> doesn t have any label. Thus skipping to parse logs. cluster <*>	121
342	Considering pod <*> with phase Succeeded cluster <*>	561
343	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error write tcp <*> <*> <*> write connection reset by peer stderr	22
344	topologymanager Topology Admit Handler	1397
345	operationExecutor.VerifyControllerAttachedVolume started for volume <*> UniqueName <*> pod <*> UID <*>	1177
346	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd <*> Started Kubernetes transient mount for <*>	66
347	RunPodsandbox for &PodSandboxMetadata Name <*> Uid <*> Namespace <*> Attempt 0	1027
348	Calico CNI found existing endpoint & WorkloadEndpoint <*> <*> <*> <*> <*> <*> 0 <*> <*> <*> <*> <*> UTC <nil> <nil> map control-plane <*> <*> <*> <*> <*> <*> k8s <*> default map k8s <*> <*> eth0 <*> <*> <*> <*> TCP <*> metrics TCP <*> health TCP <*> ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
349	Extracted identifiers for CmdAddK8s ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
350	Calico CNI IPAM request count IPv4 <*> IPv6 0 ContainerID <*> HandleID <*> Workload <*>	484
351	Auto assigning IP ContainerID <*> HandleID <*> Workload <*> assignArgs ipam.AutoAssignArgs Num4 <*> Num6 0 HandleID string <*> Attrs map string string namespace <*> node <*> pod <*> timestamp <*> <*> <*> <*> <*> UTC Hostname <*> IPv4Pools <*> IPv6Pools <*> MaxBlocksPerHost 0 HostReservedAttrIPv4s ipam.HostReservedAttr nil HostReservedAttrIPv6s ipam.HostReservedAttr nil	66
352	About to acquire host-wide IPAM lock. source ipam_plugin.go <*>	2167
353	Acquired host-wide IPAM lock. source ipam_plugin.go <*>	2167
354	Auto-assign <*> ipv4 0 ipv6 addrs for host <*>	530
355	Looking up existing affinities for host handle <*> host <*>	530
356	Looking up existing affinities for host host <*>	530
357	Trying affinity for <*> host <*>	484
358	Attempting to load block cidr <*> host <*>	530
359	Affinity is confirmed and block has been loaded cidr <*> host <*>	484
360	Attempting to assign <*> addresses from block block <*> handle <*> host <*>	530
361	Creating new handle <*>	530
362	Writing block in order to claim IPs block <*> handle <*> host <*>	530
363	Successfully claimed IPs <*> block <*> handle <*> host <*>	530
364	Auto-assigned <*> out of <*> IPv4s <*> handle <*> host <*>	530
365	Released host-wide IPAM lock. source ipam_plugin.go <*>	2167
366	Calico CNI IPAM assigned addresses IPv4 <*> IPv6 ContainerID <*> HandleID <*> Workload <*>	484
367	Populated endpoint ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string control-plane <*> <*> <*> <*> <*> <*> k8s <*> default Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC Ports <*> <*> Name <*> Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name metrics Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name health Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*>	66
368	Calico CNI using IPs <*> ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
369	Setting the host side veth name to <*> ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
370	Disabling IPv4 forwarding ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
371	<*> <*> <*> Oct <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_UP <*> link is not ready	22
372	<*> <*> <*> Oct <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_UP eth0 link is not ready	22
373	<*> <*> <*> Oct <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_CHANGE eth0 link becomes ready	22
374	<*> <*> <*> Oct <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_CHANGE <*> link becomes ready	22
375	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-udevd <*> link_config autonegotiation is unset or enabled the speed and duplex are not writable.	22
376	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-networkd <*> <*> Link UP	22
377	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-networkd <*> <*> Gained carrier	22
378	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-timesyncd <*> Network configuration changed trying to establish connection.	44
379	<*> <*> <*> Oct <*> <*> <*> <*> <*> <*> <*> WARNING Unknown index <*> <*> <*> interface list	22
380	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string control-plane <*> <*> <*> <*> <*> <*> k8s <*> default Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC a2 <*> <*> f4 <*> 3a Ports <*> <*> Name <*> Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name metrics Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name health Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*>	22
381	Wrote updated endpoint to datastore ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
382	starting signal loop namespace <*> path <*> pid <*>	3094
383	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-timesyncd <*> Synchronized to time server <*> <*> <*> .	44
384	RunPodSandbox for &PodSandboxMetadata Name <*> Uid <*> Namespace <*> Attempt 0 returns sandbox id <*>	1014
385	PullImage <*> <*>	1090
386	ImageUpdate event &ImageUpdate Name <*> <*> Labels map string string <*> managed XXX_unrecognized	2530
387	ImageUpdate event &ImageUpdate Name sha256 <*> Labels map string string <*> managed XXX_unrecognized	1034
388	PullImage <*> <*> returns image reference sha256 <*>	1067
389	CreateContainer within sandbox <*> for container &ContainerMetadata Name manager Attempt 0	66
390	CreateContainer within sandbox <*> for container &ContainerMetadata Name node-agent Attempt 0	924
391	CreateContainer within sandbox <*> for &ContainerMetadata Name node-agent Attempt 0 returns container id <*>	924
392	StartContainer for <*>	1738
393	StartContainer for <*> returns successfully	1749
394	CreateContainer within sandbox <*> for &ContainerMetadata Name manager Attempt 0 returns container id <*>	66
395	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-networkd <*> <*> Gained IPv6LL	22
396	<*> <*> <*> tail can t open <*> No such file or directory	429
397	<*> <*> <*> tail no files	429
398	Failed to run command <*> print-logs.sh with output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~	451
399	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result range_response_count 0 size <*> took too long <*> to execute	539
400	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result range_response_count <*> size <*> took too long <*> to execute	9119
401	<*> <*> <*> <*> <*> <*> <*> W | etcdserver request header <ID <*> username <*> auth_revision <*> > txn <compare <target MOD key <*> mod_revision <*> > success <request_put <key <*> value_size <*> >> failure <>> with result size <*> took too long <*> to execute	11
402	<*> <*> <*> and error exit status <*>	451
403	Failed to run command <*> print-logs.sh . exit status <*>	451
404	Execution failed. Failed to execute command <*> print-logs.sh . exit status <*>	451
405	exit status 1Failed to run ansible task	451
406	Failed to execute task exit status 1Failed to run cmd exec task <*>	451
407	Reconciled successfully	453
408	<*> <*> <*> <*> Created container node-agent	205
409	<*> <*> <*> <*> Started container node-agent	164
410	<*> <*> <*> level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg fullSync is triggered TraceId <*>	209
411	<*> <*> <*> level info time <*> <*> <*> caller <*> <*> msg FullSync start TraceId <*>	209
412	<*> <*> <*> level warn time <*> <*> <*> caller <*> <*> msg could not find any volume which is present in both k8s and in CNS TraceId <*>	209
413	<*> <*> <*> level info time <*> <*> <*> caller <*> <*> msg FullSync fullSyncDeleteVolumes could not find any volume which is not present in k8s and needs to be checked for volume deletion. TraceId <*>	209
414	<*> <*> <*> level info time <*> <*> <*> caller <*> <*> msg FullSync end TraceId <*>	209
415	<*> <*> <*> level warn time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg CSI migration feature state is disabled TraceId <*>	176
416	Pod Labels tier control-plane component <*>	15
417	Cluster Env target	3465
418	Early log level set to info	116
419	Using NODENAME environment for node name <*>	116
420	Determined node name <*>	116
421	Starting node <*> with version <*>	58
422	Checking datastore connection	58
423	Generated self-signed cert in-memory	85
424	Datastore connection verified	58
425	<*> EndpointSlice is deprecated in <*> unavailable in <*> use <*> EndpointSlice	14731
426	Datastore is ready	58
427	Unable to get <*> in <*> Usually fixed by kubectl create rolebinding <*> <*> ROLEBINDING_NAME <*> <*> <*> YOUR_NS YOUR_SA	12
428	<*> <*> <*> Flag <*> has been deprecated see <*> instead.	22
429	Initialize BGP data	46
430	Error looking up in-cluster authentication configuration configmaps <*> is forbidden User system <*> cannot get resource configmaps in API group in the namespace <*>	12
431	Continuing without authentication configuration. This may treat all requests as anonymous.	18
432	Node IPv4 changed will check for conflicts	46
433	To require authentication configuration lookup to succeed set <*> false	19
434	Version <*>	273
435	No AS number configured on node resource using global value	58
436	Starting request-header <*>	64
437	Serving securely on <*> <*>	67
438	Successfully retrieved node IP <*>	32
439	Setting NetworkUnavailable to False	58
440	Detected node IP <*>	20
441	Starting <*> <*>	66
442	Starting <*> <*> <*> <*>	113
443	found <*> <*> in the kubeadm config map	58
444	Unknown proxy mode assuming iptables proxy	38
445	Starting RequestHeaderAuthRequestController	22
446	Waiting for caches to sync for <*> <*> <*> <*>	117
447	Pod Labels <*> <*> broadcastjob-name <*> log-regex klog <*> proxy	5
448	<*> <*> <*> WARNING Deprecated <*> capnslog flag is set use <*> zap flag instead	22
449	<*> running in <*> mode IPv4-primary	26
450	Pod Labels <*> proxy <*> <*> broadcastjob-name <*> log-regex klog	5
451	Pod Labels <*> <*> <*> <*> <*> <*>	5
452	found v6 in the kubeadm config map	58
453	Pod Labels log-regex klog <*> proxy <*> <*> broadcastjob-name <*>	15
454	Waiting for caches to sync for RequestHeaderAuthRequestController	25
455	Pod Labels <*> host <*> skip <*> <*> broadcastjob-name <*> <*> proxy	35
456	<*> <*> <*> <*> <*> <*> <*> I | etcdmain etcd Version <*>	11
457	Using iptables Proxier.	44
458	<*> is false through environment variable	58
459	Using node name <*>	58
460	<*> <*> <*> <*> <*> <*> <*> I | etcdmain Git SHA <*>	11
461	creating dualStackProxier for iptables.	32
462	Caches are synced for <*> <*> <*> <*>	92
463	<*> set to ClusterCIDR but no IPv6 cluster CIDR defined defaulting to <*> detect-local for IPv6	35
464	Releasing all IPs with handle <*>	3667
465	<*> <*> <*> <*> <*> <*> <*> I | etcdmain Go Version <*>	11
466	Pod Labels <*> proxy <*> host <*> skip <*> <*> broadcastjob-name <*>	25
467	<*> <*> <*> <*> <*> <*> <*> I | etcdmain Go <*> linux/amd64	11
468	Assign a new tunnel address type ipipTunnelAddress	46
469	Trace <*> Call conversion webhook custom-resource-definition <*> desired-api-version <*> object-count <*> UID <*> <*> <*> <*> <*> total time <*>	2512
470	<*> <*> <*> Trace <*> <*> <*> END	4114
471	Trace <*> List etcd3 key <*> resourceVersion resourceVersionMatch limit <*> continue <*> <*> <*> <*> total time <*>	2494
472	Release any old tunnel addresses IP type ipipTunnelAddress	46
473	Set sysctl <*> to <*>	115
474	<*> <*> <*> <*> <*> <*> <*> I | etcdmain setting maximum number of CPUs to <*> total number of available CPUs is <*>	11
475	Setting nf_conntrack_max to <*>	59
476	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Tenant conversion webhook for <*> Kind Tenant failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused reinitializing...	1609
477	Assign new tunnel address IP type ipipTunnelAddress	46
478	Setting conntrack hashsize to <*>	45
479	<*> <*> <*> <*> <*> <*> <*> I | embed peerTLS cert <*> key <*> <*> <*> <*> true crl-file	11
480	error retrieving resource lock <*> <*> <*> is forbidden User system <*> cannot get resource leases in API group <*> in the namespace <*>	12
481	Starting Orchestration Executor	14
482	Set sysctl net/netfilter/nf_conntrack_tcp_timeout_established to <*>	59
483	Caches are synced for RequestHeaderAuthRequestController	24
484	<*> <*> <*> <*> <*> <*> <*> I | embed name <*>	11
485	Pod Labels <*> <*> control-plane controller-manager <*> <*>	15
486	Starting cluster management agent...	15
487	<*> <*> <*> <*> <*> <*> <*> I | embed data dir <*>	11
488	Pod Labels control-plane controller-manager <*> <*>	15
489	Event occurred object <*> kind Lease apiVersion <*> type Normal reason LeaderElection message <*> became leader	23
490	Starting service config controller	58
491	Waited for <*> due to <*> throttling not priority and fairness request GET https <*> <*> <*>	27
492	Setting hubble ip to <*> and port to	16
493	<*> <*> <*> <*> <*> <*> <*> I | embed member dir <*>	11
494	Starting endpoint slice config controller	56
495	unable to get all supported resources from server unable to retrieve the complete list of server APIs <*> the server is currently unable to handle the request	11
496	Ran out of existing affine blocks for host host <*>	46
497	Looking for <*> config map in namespace <*>	17
498	<*> <*> <*> <*> <*> <*> <*> I | embed heartbeat <*>	11
499	Waiting for caches to sync for service config	57
500	No more affine blocks but need to claim more block <*> allocate another block host <*>	46
501	WARNING vsphere built-in cloud provider is now deprecated. The vSphere provider is deprecated and will be removed in a future release	34
502	Found cluster id as <*> cluster name as <*> tenant id as <*> project uid as <*> and is system false	18
503	<*> <*> <*> <*> <*> <*> <*> I | embed election <*>	11
504	Initializing hubble client with URI <*> cluster <*>	19
505	Looking for an unclaimed block host <*>	46
506	Waiting for caches to sync for endpoint slice config	55
507	create attach manifest files	14971
508	SecretName and/or SecretNamespace is not provided. VCP will use username and password from config file	12
509	One or more endpoints uses a profile that doesn t exist generating <*> profile. This can happen transiently when a Kubernetes namespace is deleted. profileID <*>	660
510	Initializing nats connection cluster <*>	20
511	<*> <*> <*> <*> <*> <*> <*> I | embed snapshot count <*>	11
512	Found free block <*>	46
513	<*> <*> <*> <*> <*> <*> <*> I | embed advertise client URLs https <*> <*>	11
514	Waiting for caches to sync for tokens	23
515	fetch process output object complete	13079
516	id <name <*> > profile <inbound_rules <action <*> rule_id <*> > outbound_rules <action <*> rule_id <*> > >	638
517	Successfully fetched Nats configuration <*> cluster <*>	21
518	Found unclaimed block host <*> subnet <*>	46
519	<*> <*> <*> <*> <*> <*> <*> I | etcdserver starting member <*> in cluster <*>	11
520	Successfully fetched Nats credentials <*> cluster <*>	22
521	Trying to create affinity in pending state host <*> subnet <*>	46
522	Started serviceaccount	23
523	Auditing failed of request encoding failed authentication.TokenRequest is not suitable for converting to <*> in scheme <*> <*>	3581
524	Caches are synced for service config	52
525	id <orchestrator_id k8s workload_id <*> endpoint_id eth0 > endpoint <state active name <*> profile_ids kns.brighteon profile_ids <*> ipv4_nets <*> >	1848
526	<*> <*> <*> <*> <*> <*> <*> INFO <*> switched to configuration voters	11
527	Initializing Nats connection with url tls <*> <*> <*> tls <*> <*> <*> tls <*> <*> <*> cluster <*>	11
528	Successfully created pending affinity for block host <*> subnet <*>	46
529	<*> is set but cloud provider does not support routes. Will not configure cloud provider routes.	12
530	Caches are synced for endpoint slice config	51
531	<*> <*> <*> <*> <*> <*> <*> INFO <*> became <*> at term 0	11
532	<*> <*> <*> <*> <*> <*> <*> http TLS handshake error from <*> <*> remote error tls bad certificate	53944
533	Initialized Nats connection.. cluster <*>	23
534	Skipping route	23
535	<*> <*> <*> <*> <*> <*> <*> INFO newRaft <*> peers term 0 commit 0 applied 0 lastindex 0 lastterm 0	11
536	<*> <*> <*> <*> <*> <*> <*> W | auth simple token is not cryptographically signed	11
537	<*> <*> <*> register IPAM metal3io	11
538	process status output complete	9350
539	The referenced block doesn t exist trying to create it cidr <*> host <*>	46
540	id <namespace default name <*> >	13288
541	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started HTTP pipelining with peer <*>	44
542	Starting service account controller	23
543	<*> <*> <*> <*> <*> <*> <*> no error handler specified with the subscriber. going with default error handler	11
544	reconciled manifest service status for pack pack permission-manager	891
545	<*> <*> <*> <*> <*> <*> <*> I | rafthttp starting peer <*>	33
546	Wrote affinity as pending cidr <*> host <*>	46
547	Waiting for caches to sync for service account	23
548	pack readiness status pack permission-manager status true	891
549	<*> <*> <*> <*> <*> <*> <*> Listening on <*>	11
550	reconcile charts atop Namespace <*> Name <*>	3751
551	Attempting to claim the block cidr <*> host <*>	46
552	ExecSync for <*> with command sh <*> <*> <*> and timeout 6 s	5610
553	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started streaming with peer <*> writer	66
554	Subscribed to msg channel <*> cluster <*>	23
555	Attempting to create a new block host <*> subnet <*>	46
556	ExecSync for <*> with command sh <*> <*> <*> and timeout <*> s	5610
557	Starting PV protection controller	23
558	Successfully created block	46
559	Waiting for caches to sync for PV protection	23
560	Started job	23
561	Confirming affinity host <*> subnet <*>	46
562	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started peer <*>	33
563	ExecSync for <*> with command sh <*> <*> bash <*> n# If the node is starting up wait for the cluster to be ready request params wait_for_status green&timeout <*> n# Once it has started only check that the node itself is responding nSTART_FILE <*> n n# Disable nss cache to avoid filling dentry cache when calling curl n# This is required with Elasticsearch Docker using nss < <*> nexport NSS_SDB_USE_CACHE no n nhttp n local path $ <*> n local args $ <*> n set <*> <*> <*> n n if $args ! then n set <*> $@ $args n fi n n if <*> $ ELASTIC_USERNAME && <*> $ ELASTIC_PASSWORD then n set <*> $@ <*> $ ELASTIC_USERNAME $ ELASTIC_PASSWORD n fi n n curl <*> <*> <*> $@ http <*> <*> path n n nif <*> $ START_FILE then n echo Elasticsearch is already running lets check the node is healthy n HTTP_CODE $ http <*> <*> % http_code n RC $? n if $ RC <*> 0 then n echo curl <*> <*> <*> <*> <*> <*> % http_code $ BASIC_AUTH http <*> <*> failed with RC $ RC n exit $ RC n fi n # ready if HTTP code <*> <*> is tolerable if ES version is <*> n if $ HTTP_CODE <*> then n exit 0 n elif $ HTTP_CODE <*> && <*> 6 then n exit 0 n else n echo curl <*> <*> <*> <*> <*> <*> % http_code $ BASIC_AUTH http <*> <*> failed with HTTP code $ HTTP_CODE n exit <*> n fi n nelse n echo Waiting for elasticsearch cluster to become ready request params wait_for_status green&timeout <*> n if http <*> green&timeout <*> <*> then n touch $ START_FILE n exit 0 n else n echo Cluster is not yet ready request params wait_for_status green&timeout <*> n exit <*> n fi nfi n and timeout <*> s	6028
564	Starting job controller	23
565	Successfully confirmed affinity host <*> subnet <*>	46
566	Block <*> has <*> free ips which is more than <*> ips required. host <*> subnet <*>	46
567	STARTUP Running start up task cluster <*>	20
568	Starting EventSource controller vspherecluster source Type metadata creationTimestamp null spec cloudProviderConfiguration global network disk workspace labels providerConfig controlPlaneEndpoint host port 0 status	13
569	starting manager version	53
570	Waiting for caches to sync for job	23
571	<*> <*> <*> <*> <*> <*> <*> I | rafthttp added peer <*>	33
572	STARTUP Syncing capi machine s with hubble cluster <*>	19
573	Starting EventSource controller haproxyloadbalancer source Type metadata creationTimestamp null spec virtualMachineConfiguration template network devices null status	13
574	Started replicaset	23
575	Starting EventSource controller vspheremachine source Type metadata creationTimestamp null spec template network devices null status ready false	13
576	<*> <*> <*> <*> <*> <*> <*> I | etcdserver starting server... version <*> cluster version to_be_decided	11
577	Initializing shutdown hooks... cluster <*>	18
578	Starting Controller controller vspherecluster	13
579	Starting replicaset controller	23
580	Error updating resource Key KubeControllersConfiguration default Name default Resource KubeControllersConfigurations Value <*> TypeMeta <*> Kind KubeControllersConfiguration APIVersion <*> ObjectMeta <*> Name default GenerateName Namespace SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string nil Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> LogSeverityScreen Info HealthChecks Enabled EtcdV3CompactionPeriod <*> <*> PrometheusMetricsPort int <*> Controllers <*> Node <*> <*> Policy <*> <*> WorkloadEndpoint v3.WorkloadEndpointControllerConfig <*> ServiceAccount v3.ServiceAccountControllerConfig <*> Namespace <*> <*> Status <*> RunningConfig <*> LogSeverityScreen Info HealthChecks Enabled EtcdV3CompactionPeriod <*> <*> PrometheusMetricsPort int nil Controllers <*> Node <*> <*> Policy <*> nil WorkloadEndpoint v3.WorkloadEndpointControllerConfig nil ServiceAccount v3.ServiceAccountControllerConfig nil Namespace <*> nil EnvironmentVars map string string DATASTORE_TYPE kubernetes ENABLED_CONTROLLERS node error etcdserver leader changed	9
581	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started streaming with peer <*> stream Message reader	33
582	reconcileCAPICluster spectrocluster Namespace <*> Name <*>	10676
583	STARTUP task executed cluster <*>	16
584	Waiting for caches to sync for ReplicaSet	23
585	Starting workers controller vspherecluster worker count <*>	13
586	unable to perform status update on KubeControllersConfiguration default error etcdserver leader changed	8
587	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started streaming with peer <*> stream MsgApp <*> reader	33
588	Starting EventSource controller kubeadmcontrolplane source Type metadata creationTimestamp null spec version infrastructureTemplate kubeadmConfigSpec status initialized false ready false	12
589	>>>>>>> Scheduling polling of event s after every <*> seconds cluster <*>	15
590	looking for releases filter <*> namespace default	7502
591	Starting Controller controller vspheremachine	13
592	Assigned tunnel address to node IP <*> type ipipTunnelAddress	46
593	Started disruption	23
594	Error getting cluster information config ClusterInformation default error etcdserver request timed out	7
595	<*> <*> <*> <*> <*> <*> <*> I | embed ClientTLS cert <*> key <*> <*> <*> <*> true crl-file	11
596	Starting EventSource controller kubeadmcontrolplane source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	12
597	>>>>>>> Scheduling log monitor service cluster <*>	14
598	Failed to verify datastore error etcdserver request timed out	6
599	found release releases	9262
600	Starting EventSource controller kubeadmconfig source Type metadata creationTimestamp null spec status	12
601	Starting disruption controller	23
602	Starting Controller controller haproxyloadbalancer	13
603	Successfully audited Acquired all resources to Orchestrate SpectroCluster Acquired all resources Normal cluster <*>	12
604	ExecSync for <*> with command bash <*> # Run the proper check depending on the version n $ mongo <*> | grep MongoDB shell ~ <*> + . <*> + . <*> + && VERSION $ BASH_REMATCH <*> n. <*> nVERSION_MAJOR $ get_sematic_version $VERSION <*> nVERSION_MINOR $ get_sematic_version $VERSION <*> nVERSION_PATCH $ get_sematic_version $VERSION <*> nif $VERSION_MAJOR -ge 4 && $VERSION_MINOR -ge 4 && $VERSION_PATCH -ge <*> then n mongo <*> $TLS_OPTIONS <*> <*> .isWritablePrimary || <*> .secondary | grep <*> true nelse n mongo <*> $TLS_OPTIONS <*> db.isMaster .ismaster || db.isMaster .secondary | grep <*> true nfi n and timeout <*> s	1210
605	Starting EventSource controller kubeadmcontrolplane source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	12
606	Waiting for caches to sync for disruption	23
607	ExecSync for <*> with command mongo <*> <*> db.adminCommand ping and timeout <*> s	1210
608	Starting EventSource controller kubeadmconfig source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	12
609	<*> <*> <*> <*> <*> <*> <*> I | embed listening for metrics on http <*> <*>	11
610	pack has no charts atop Namespace <*> Name <*>	3751
611	Scheduling in target cluster... cluster <*>	12
612	Starting EventSource controller kubeadmconfig source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	12
613	Started csrapproving	23
614	Starting workers controller haproxyloadbalancer worker count <*>	13
615	Starting Controller controller kubeadmcontrolplane	12
616	<*> <*> <*> Calico node started successfully	11
617	Starting EventSource controller machinehealthcheck source Type metadata creationTimestamp null spec clusterName selector unhealthyConditions null status	12
618	<*> <*> <*> <*> <*> <*> <*> I | embed listening for peers on <*> <*>	11
619	reconcile manifests atop Namespace <*> Name <*>	3751
620	reconcile control plane endpoint address for VSphereCluster namespace <*> vsphereCluster <*>	9339
621	Starting workers controller kubeadmcontrolplane worker count <*>	12
622	Starting certificate controller csrapproving	23
623	Starting EventSource controller cluster source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	24
624	<*> <*> <*> <*> <*> <*> <*> I | rafthttp peer <*> became active	33
625	<*> <*> <*> bird Unable to open configuration file <*> No such file or directory	22
626	control plane endpoint is already allocated for the VSphereCluster namespace <*> vsphereCluster <*> vSphereCluster <*>	9339
627	Successfully audited Provisioning in target cluster Normal cluster <*>	12
628	Managed <*> is installed cluster <*>	12
629	<*> chart with name <*> and version <*> is already installed and status is deployed. It was last updated on <*> <*> <*> <*> <*> UTC and revision count is <*> cluster <*>	12
630	Un-managed metrics server test... Getting metrics for node <*> cluster <*>	12
631	Starting pod metrics scrapper cluster <*>	11
632	upgrade agent >>>>>>>>>> Initializing upgrade scheduler cluster <*>	12
633	>>>>>>>>>> Initializing health scheduler cluster <*>	12
634	Syncing spc packs manifests and registries cluster <*>	3884
635	Cluster is deployed and all nodes are running. Applying startup os patch config cluster <*>	11
636	Found spectro node task <*> cluster <*>	22
637	Updating spectro node task <*> cluster <*>	22
638	Updated spectro node task <*> cluster <*>	22
639	Starting EventSource controller machine source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	12
640	ExecSync for <*> with command <*> <*> <*> <*> check_running && <*> <*> check_local_alarms and timeout <*> s	792
641	Starting workers controller vspheremachine worker count <*>	13
642	Starting Controller controller kubeadmconfig	12
643	reconcile IP address for VSphereMachine namespace <*> vsphereMachine <*>	174927
644	Reconcile KubeadmControlPlane cluster <*> kubeadmControlPlane <*> namespace <*>	26465
645	ExecSync for <*> with command <*> <*> <*> <*> ping and timeout <*> s	792
646	VSphereCluster spec or failure domains is not changed spectrocluster Namespace <*> Name <*> name <*>	5894
647	Starting EventSource controller machine source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	12
648	Starting workers controller kubeadmconfig worker count <*>	12
649	Skipping confd config file.	58
650	Scaling up control plane cluster <*> kubeadmControlPlane <*> namespace <*> Desired <*> Existing <*>	165
651	successfully reconciled IP address for VSphereMachine namespace <*> vsphereMachine <*>	163729
652	<*> <*> <*> <*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream Message reader	44
653	Starting EventSource controller machineset source Type metadata creationTimestamp null spec clusterName selector template metadata spec clusterName bootstrap infrastructureRef status	12
654	Starting EventSource controller machinedeployment source Type metadata creationTimestamp null spec clusterName selector template metadata spec clusterName bootstrap infrastructureRef status	36
655	Started ttl	23
656	cloud cluster reconcile done spectrocluster Namespace <*> Name <*>	10681
657	<*> <*> <*> <*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream MsgApp <*> reader	44
658	Refreshing token until the infrastructure has a chance to consume it kind Machine kubeadmconfig Namespace <*> Name <*> name <*> version <*>	6193
659	Starting TTL controller	23
660	Waiting for control plane to pass preflight checks cluster <*> kubeadmControlPlane <*> namespace <*> failures machine <*> does not have APIServerPodHealthy condition machine <*> does not have ControllerManagerPodHealthy condition machine <*> does not have SchedulerPodHealthy condition machine <*> does not have EtcdPodHealthy condition machine <*> does not have EtcdMemberHealthy condition	22
661	Starting EventSource controller machinepool source Type metadata creationTimestamp null spec clusterName template metadata spec clusterName bootstrap infrastructureRef status replicas 0 bootstrapReady false infrastructureReady false	12
662	Starting EventSource controller cluster source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	12
663	Start called	182
664	reconcile cloud level setups spectrocluster Namespace <*> Name <*>	10690
665	<*> <*> <*> <*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream Message writer	44
666	Waiting for caches to sync for TTL	23
667	Checking for lock cluster-name <*> configmap-name <*> namespace <*>	223
668	<*> <*> <*> <*> <*> <*> <*> INFO <*> term 0 received a MsgVote message with higher term from <*> term <*>	11
669	Starting Controller controller cluster	24
670	Sending status update Status <*>	368
671	Caches are synced for TTL	23
672	Starting workers controller cluster worker count <*>	24
673	setting up ipam ip pool for cluster spectrocluster Namespace <*> Name <*>	5894
674	<*> <*> <*> <*> <*> <*> <*> INFO <*> became <*> at term <*>	77
675	Control plane init lock not found it may have been released already cluster-name <*> configmap-name <*> namespace <*>	223
676	Starting main event processing loop	186
677	Starting EventSource controller machinehealthcheck source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	12
678	reconcileCNI start spectrocluster Namespace <*> Name <*>	5894
679	Started tokencleaner	23
680	Failed to delete route error no such process ifaceName <*> ifaceRegex ^cali. ipVersion <*>	22
681	Altering JoinConfiguration.Discovery.BootstrapToken kubeadmconfig <*> APIServerEndpoint <*> <*>	163
682	<*> <*> <*> <*> <*> <*> <*> INFO <*> logterm 0 index 0 vote 0 cast MsgVote for <*> logterm <*> index <*> at term <*>	11
683	pack object digest not changed skip reconcile spectrocluster Namespace <*> Name <*> digest sha256 <*>	11788
684	Starting EventSource controller machinehealthcheck source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	12
685	>>>>>>>>>>>> Starting to watch vsphere machines cluster <*>	12
686	Starting token cleaner controller	23
687	Altering JoinConfiguration.Discovery.BootstrapToken kubeadmconfig <*> Token <*>	163
688	reconcileCSI start spectrocluster Namespace <*> Name <*>	5894
689	Starting Controller controller machinehealthcheck	12
690	Starting to watch statefulsets cluster <*>	11
691	Waiting for caches to sync for token_cleaner	23
692	<*> <*> <*> <*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream MsgApp <*> writer	44
693	Creating BootstrapData for the join control plane kind Machine kubeadmconfig Namespace <*> Name <*> name <*> version <*>	209
694	Sending synced update ListRoot <*>	1241
695	Interface was deleted during operation filtering error error netlink update operation failed ifaceName <*> ifaceRegex ^cali. ipVersion <*>	22
696	Starting workers controller machinehealthcheck worker count <*>	12
697	Caches are synced for token_cleaner	23
698	Starting to watch pods cluster <*>	11
699	<*> <*> <*> <*> <*> <*> <*> INFO raft.node <*> <*> leader <*> at term <*>	33
700	creating or update kubeadm control plane init false	5894
701	Interface missing will retry if it appears. ifaceName <*> ifaceRegex ^cali. ipVersion <*>	1908
702	using os image from mold spectrocluster Namespace <*> Name <*> template <*>	13103
703	Failed to start service controller the cloud provider does not support external load balancers	23
704	Sending status update Status resync	186
705	Received InSync event from one of the watcher caches	1240
706	Starting to watch deployments cluster <*>	11
707	>>>>>>>>>>>> Starting to watch nodes cluster <*>	12
708	<*> <*> <*> <*> <*> <*> <*> I | rafthttp receiving database snapshot index <*> from <*> raft message size <*> kB	11
709	Skipping service	23
710	Reconciling machinehealthcheck <*> namespace <*>	156699
711	create update operations cptemplate 0 kcp 0	5905
712	Started podgc	23
713	<*> <*> <*> <*> <*> <*> <*> I | snap saved database snapshot to disk total bytes <*>	11
714	>>>>>>>>>>>> Starting to watch spectrocluster cluster <*>	12
715	Starting Controller controller machine	12
716	Starting GC controller	23
717	setting machine health check	5905
718	Starting workers controller machine worker count <*>	12
719	waiting for machine controller to set ownerRef on VSphereMachine vspheremachine Namespace <*> Name <*>	147
720	Starting to watch jobs cluster <*>	11
721	Waiting for caches to sync for GC	23
722	Starting EventSource controller machineset source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	24
723	<*> <*> <*> <*> <*> <*> <*> I | rafthttp successfully received and saved database snapshot index <*> from <*> raft message size <*> kB db size <*> MB took <*>	11
724	All watchers have sync d data <*> sending data and final sync	183
725	starting reconcile unhealthy control-plane machines	3476
726	Started daemonset	23
727	<*> <*> <*> <*> <*> <*> <*> INFO log committed 0 applied 0 unstable.offset <*> len unstable.Entries 0 starts to restore snapshot index <*> term <*>	11
728	>>>>>>>>>>>> Starting to watch events cluster <*>	12
729	IPPool <*> is available namespace <*> vsphereMachine <*>	11126
730	<*> <*> <*> <*> <*> <*> <*> INFO <*> switched to configuration voters <*> <*>	22
731	Starting EventSource controller machineset source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	12
732	checking machine machine <*>	10428
733	Starting daemon sets controller	23
734	<*> <*> <*> <*> <*> <*> <*> INFO <*> commit <*> lastindex <*> lastterm <*> restored snapshot index <*> term <*>	11
735	get IPAddress <*> namespace <*> vsphereMachine <*>	11126
736	Starting to watch cronjobs cluster <*>	11
737	Starting Controller controller machineset	12
738	Starting to watch kubeconfig secret cluster <*>	11
739	<*> <*> <*> <*> <*> <*> <*> INFO <*> commit <*> restored snapshot index <*> term <*>	11
740	Waiting for caches to sync for daemon sets	23
741	waiting for IPClaim <*> namespace <*> vsphereMachine <*>	11122
742	<*> <*> <*> <*> <*> <*> <*> I | etcdserver applying snapshot at index 0...	11
743	Starting workers controller machineset worker count <*>	12
744	Starting to watch daemonsets cluster <*>	11
745	<*> <*> <*> <*> <*> <*> <*> I | etcdserver raft applied incoming snapshot at index <*>	11
746	allocate IP <*> namespace <*> vsphereMachine <*>	11122
747	create IPClaim <*> namespace <*> vsphereMachine <*>	147
748	mdelete mdelete	3476
749	Started statefulset	23
750	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering lessor...	11
751	Listing event s in <*> namespace cluster <*>	12
752	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering lessor	11
753	>>>>>>>>>>>> Starting to watch machines cluster <*>	12
754	<*> <*> <*> <*> <*> <*> <*> I | etcdserver restoring mvcc store...	11
755	created IPClaim <*> waiting for IPAddress to be available namespace <*> vsphereMachine <*>	147
756	reconcile unhealthy control-plane machines done	3476
757	Starting stateful set controller	23
758	Starting to watch namespaces cluster <*>	11
759	waiting for IP address to be available for the VSphereMachine namespace <*> vsphereMachine <*>	11122
760	Starting EventSource controller machinedeployment source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	12
761	Starting Controller controller machinedeployment	12
762	controlplane scale up ongoing requeue after <*> minute	3476
763	<*> <*> <*> <*> <*> <*> <*> I | mvcc restore compact to <*>	11
764	id <name <*> > profile <inbound_rules <action allow rule_id <*> > outbound_rules <action allow rule_id <*> > >	3550
765	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config &config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> <*> AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	11
766	Waiting for caches to sync for stateful set	23
767	Current resource version of nodes is <*> cluster <*>	12
768	Starting workers controller machinedeployment worker count <*>	12
769	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished restoring mvcc store	11
770	Resource version for nodes is <*> cluster <*>	12
771	kcp status spec <*> status selector <*> <*> <*> replicas <*> updatedReplicas <*> readyReplicas <*> unavailableReplicas <*> initialized true ready true observedGeneration <*> conditions type Ready status False severity Warning lastTransitionTime <*> <*> <*> reason ScalingUp message Scaling up control plane to <*> replicas actual <*> type Available status True lastTransitionTime <*> <*> <*> type CertificatesAvailable status True lastTransitionTime <*> <*> <*> type ControlPlaneComponentsHealthy status True lastTransitionTime <*> <*> <*> type EtcdClusterHealthyCondition status True lastTransitionTime <*> <*> <*> type MachinesReady status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation @ <*> message <*> of <*> completed type Resized status False severity Warning lastTransitionTime <*> <*> <*> reason ScalingUp message Scaling up control plane to <*> replicas actual <*> version <*>	3476
772	Using internal linux dataplane driver.	58
773	Started persistentvolume-binder	23
774	id <namespace default name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	26543
775	Starting EventSource controller machinepool source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	12
776	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering alarms...	11
777	Calculated iptables mark bits acceptMark <*> endpointMark <*> endpointMarkNonCali 0x0 passMark <*> scratch0Mark <*> scratch1Mark <*>	58
778	Starting persistent volume controller	23
779	Putting Kubeconfig to hubble cluster <*>	113
780	Starting Controller controller machinepool	12
781	id <name <*> > profile <inbound_rules <action allow rule_id aBMQCbsUMESPKGRp > outbound_rules <action allow rule_id <*> > >	627
782	detect env done spectrocluster Namespace <*> Name <*> env target	5876
783	<*> <*> <*> <*> <*> <*> <*> I | etcdserver closing old backend...	11
784	Starting workers controller machinepool worker count <*>	12
785	Waiting for caches to sync for persistent volume	23
786	Current resource version of cluster is <*> cluster <*>	11
787	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> <*> VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	22
788	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering alarms	11
789	reconcile on target spectrocluster Namespace <*> Name <*>	5876
790	Adding watcher on external object cluster <*> namespace <*> GroupVersionKind <*> Kind VSphereCluster	12
791	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> <*> VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	22
792	Starting EventSource controller cluster source Type apiVersion <*> kind VSphereCluster	12
793	reconcilePacks spectrocluster Namespace <*> Name <*>	10672
794	Resource version for cluster is <*> cluster <*>	11
795	Starting EventSource controller machinehealthcheck source	12
796	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering auth store...	11
797	Workload to host packets will be accepted.	58
798	reconcilePacks done spectrocluster Namespace <*> Name <*>	5764
799	Starting TTL after finished controller	22
800	IPClaim <*> already exists skipping creation namespace <*> vsphereMachine <*>	10975
801	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished closing old backend	11
802	reconcile OS Image spectrocluster Namespace <*> Name <*>	10672
803	image ready status spectrocluster Namespace <*> Name <*> err null ready true	10672
804	Adding watcher on external object cluster <*> namespace <*> GroupVersionKind <*> Kind KubeadmControlPlane	12
805	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering auth store	11
806	filter table allowed packets will be accepted immediately.	58
807	Current resource version of vsphere machines is <*> cluster <*>	11
808	Waiting for caches to sync for TTL after finished	22
809	os image is ready spectrocluster Namespace <*> Name <*>	10672
810	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering store v2...	11
811	Starting EventSource controller cluster source Type apiVersion <*> kind KubeadmControlPlane	12
812	mangle table allowed packets will be accepted immediately.	58
813	Resource version for vsphere machines is <*> cluster <*>	11
814	Packets to unknown service IPs will be dropped	58
815	Started endpoint	23
816	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering store <*>	11
817	kube apply success atop Namespace <*> Name <*> file <*>	3751
818	Unable to retrieve machine from node error expecting one machine for node <*> got node <*>	44
819	Determined pod MTU mtu <*>	58
820	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering cluster configuration...	11
821	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/api enabled capabilities for version <*>	11
822	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/membership added member <*> https <*> <*> to cluster <*> from store	22
823	Starting endpoint controller	23
824	reconcile service status atop Namespace <*> Name <*>	3751
825	configured to periodically rescan interfaces. interval <*>	58
826	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> 2a a9 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
827	Starting EventSource controller machine source	12
828	Unable to retrieve machine from node error no matching Machine node <*>	44
829	Waiting for caches to sync for endpoint	23
830	Looked up iptables command backendMode legacy candidates string <*> <*> command <*> ipVersion <*> <*> <*>	348
831	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes scaling up type ControlPlaneReady status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes scaling up type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message <*> ready. <*> ready. istio ready. permission-manager ready. services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name backend ports protocol TCP port <*> host <*> name frontend ports protocol TCP port <*> host <*> name frontend-streaming ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name minio ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> cluster <*>	11
832	Current resource version of capi machines is <*> cluster <*>	11
833	VM Hardware version <*> from node <*> is deprecated. Please consider upgrading virtual machine hardware version to <*> or higher	77
834	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/membership set the cluster version to <*> from store	11
835	Adding watcher on external object machine <*> namespace <*> GroupVersionKind <*> Kind VSphereMachine	12
836	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering cluster configuration	11
837	Starting garbage collector controller	23
838	Resource version for capi machine is <*> cluster <*>	11
839	reconciled chart service status for pack pack <*>	3751
840	Starting EventSource controller machine source Type apiVersion <*> kind VSphereMachine	12
841	Waiting for caches to sync for garbage collector	57
842	GraphBuilder running	23
843	<*> <*> <*> <*> <*> <*> <*> I | etcdserver removing old peers from network...	11
844	Neither <*> nor <*> was specified. Using the inClusterConfig. This might not work.	98
845	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopping peer <*>	11
846	Set Machine s NodeRef machine <*> namespace <*> noderef <*>	23
847	Started garbagecollector	23
848	EVENT <*> Resource machines Event Type ADDED Name <*> InfraType VSphereMachine InfraTypeName <*> status Running cluster <*>	2483
849	Updating detected iptables features features iptables.Features SNATFullyRandom true MASQFullyRandom true RestoreSupportsLock true iptablesVersion <*> kernelVersion <*>	58
850	<*> <*> <*> <*> <*> <*> <*> I | rafthttp closed the TCP streaming connection with peer <*> stream MsgApp <*> writer	11
851	Started deployment	23
852	EVENT <*> Resource machines Type ADDED Name <*> Uid <*> cluster <*>	2515
853	Calculated old-insert detection regex. pattern ? <*> cali-| ? <*> <*> ? <*> <*> ? <*> <*> ? <*> <*> ? <*> <*> ? <*> calipo-| ? <*> felix-	174
854	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> writer	22
855	<*> <*> <*> <*> <*> <*> <*> I | rafthttp closed the TCP streaming connection with peer <*> stream Message writer	11
856	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 4f ba networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
857	Starting controller controller deployment	22
858	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped HTTP pipelining with peer <*>	11
859	Looked up iptables command backendMode legacy candidates string <*> iptables-restore command <*> ipVersion <*> <*> restore	232
860	<*> <*> <*> <*> <*> <*> <*> W | rafthttp <*> the TCP streaming connection with peer <*> stream MsgApp <*> reader	22
861	Waiting for caches to sync for deployment	23
862	Successfully audited Successfully patched os security updates for node <*> at <*> <*> <*> <*> <*> UTC ospatch Normal cluster <*>	308
863	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> stream MsgApp <*> reader	11
864	Updating VsphereMachine <*> and instance state Running in Hubble for cloudConfig <*> and machine pool master-pool. cluster <*>	551
865	Starting certificate controller <*>	92
866	<*> <*> <*> <*> <*> <*> <*> W | rafthttp <*> the TCP streaming connection with peer <*> stream Message reader	22
867	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Reconciliation on ImageCustomization Done Successfully reason ReconciliationDone status True type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes scaling up reason LaunchControlPlaneNode status False type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes scaling up reason LaunchControlPlaneNode status False type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message worker nodes created successfully reason NodeReady status True type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message <*> ready. <*> ready. istio ready. permission-manager ready. reason AddOnDeployed status True type AddOnDeploymentDone conditions for spectro cluster cluster <*>	33
868	reconciled manifest service status for pack pack <*>	3751
869	<*> <*> <*> <*> <*> <*> <*> E | rafthttp failed to read <*> on stream Message context canceled	11
870	Calculated old-insert detection regex. pattern ? <*> cali-| ? <*> <*> ? <*> <*> ? <*> <*> ? <*> <*> ? <*> <*> ? <*> calipo-| ? <*> felix-|-A POSTROUTING . <*> . <*> POSTROUTING <*> tunl0 <*> addrtype ! <*> LOCAL <*> <*> addrtype <*> LOCAL <*> MASQUERADE	58
871	Updated VsphereMachine <*> with uid <*> and instance state Running in Hubble for cloudConfig <*> and machine pool master-pool. cluster <*>	551
872	Starting <*> <*> <*>	106
873	pack readiness status pack <*> status true	3751
874	<*> <*> <*> <*> <*> <*> <*> I | rafthttp peer <*> became inactive message send to peer failed	11
875	STORE Adding cloud machine with uid <*> and capi machine name <*> with status Running in machine pool master-pool	551
876	etcd cluster before remediation cluster <*> kubeadmControlPlane <*> namespace <*> currentMembers <*> <*> currentTotalMembers <*>	132
877	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	22
878	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> stream Message reader	11
879	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped peer <*>	11
880	<*> <*> <*> <*> <*> <*> <*> I | rafthttp removed peer <*>	11
881	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished removing old peers from network	11
882	etcd cluster projected after remediation of <*> cluster <*> kubeadmControlPlane <*> namespace <*> canSafelyRemediate true healthyMembers <*> <*> <*> <*> targetQuorum <*> targetTotalMembers <*> targetUnhealthyMembers 0 unhealthyMembers	132
883	Advertise global service ranges from this node	174
884	Updated host <*> port <*> api endpoints for spectro cluster cluster <*>	13
885	<*> <*> <*> <*> <*> <*> <*> I | etcdserver adding peers from new cluster configuration into network...	11
886	Remediating unhealthy machine cluster <*> kubeadmControlPlane <*> namespace <*> UnhealthyMachine <*>	132
887	Started csrsigning	23
888	Updating VsphereMachine <*> and instance state Running in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	4188
889	Can t enable XDP acceleration. error kernel is too old have <*> but want at least <*>	58
890	Updated VsphereMachine <*> with uid <*> and instance state Running in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	4188
891	Updated with new cluster IP CIDRs	58
892	STORE Adding cloud machine with uid <*> and capi machine name <*> with status Running in machine pool <*>	4190
893	Updated host <*> name istio-ingressgateway ports port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name backend ports port <*> protocol TCP host <*> name frontend ports port <*> protocol TCP host <*> name frontend-streaming ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name minio ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP services for spectro cluster cluster <*>	11
894	Updated with new external IP CIDRs	58
895	Adding watcher on external object machine <*> namespace <*> GroupVersionKind <*> Kind KubeadmConfig	12
896	Caches are synced for tokens	23
897	Starting EventSource controller machine source Type apiVersion <*> kind KubeadmConfig	12
898	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished adding peers from new cluster configuration into network...	11
899	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> dd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
900	Started csrcleaner	23
901	Updated with new Loadbalancer IP CIDRs	58
902	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished applying incoming snapshot at index <*>	11
903	Bootstrap provider is not ready requeuing machine <*> namespace <*>	12
904	Starting CSR cleaner controller	23
905	Infrastructure provider is not ready requeuing machine <*> namespace <*>	1200
906	Posting manifest to hubble cluster <*>	646
907	Cannot reconcile Machine s Node no valid ProviderID yet machine <*> namespace <*>	1200
908	<*> <*> <*> <*> <*> <*> <*> I | etcdserver published Name <*> ClientURLs https <*> <*> to cluster <*>	11
909	Source SourceRouteGenerator readiness changed ready true	58
910	<*> <*> <*> <*> <*> <*> <*> I | embed ready to serve client requests	22
911	Starting PVC protection controller	23
912	bootstrap data secret for KubeadmConfig already exists updating KubeadmConfig <*> secret <*>	71
913	Waiting for caches to sync for PVC protection	23
914	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> dd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
915	Unable to retrieve pull secret the image pull may not succeed. pod <*> secret err secret <*> not found	396
916	<*> <*> <*> <*> <*> <*> <*> I | embed serving client requests on <*> <*>	22
917	Started bootstrapsigner	23
918	Successfully updated kubeconfig file to hubble cluster <*>	113
919	Fetching pack values for layer k8s and field path clientConfig and pack name cluster <*>	113
920	Waiting for caches to sync for bootstrap_signer	23
921	Sending events to api server	45
922	EVENT <*> Resource machines Event Type ADDED Name <*> InfraType VSphereMachine InfraTypeName <*> status Provisioning cluster <*>	12
923	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	11
924	Starting <*> controller	51
925	lock is held by <*> and has not yet expired	153
926	Started cronjob	23
927	Current address is still valid do nothing currentAddr <*> type ipipTunnelAddress	70
928	failed to acquire lease <*>	154
929	Starting cronjob controller <*>	22
930	Waiting for caches to sync for cronjob	22
931	. . . . . VSphereMachine s <*> providerId is empty. Thus skipping to post to hubble. cluster <*>	458
932	Sending events to api server.	104
933	Failed to get node from machine <*> . Failed to find node reference from machine s <*> status as node ref is empty. cluster <*>	362
934	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	11
935	Failed to process health for node from machine <*> Failed to find node reference from machine s <*> status as node ref is empty. cluster <*>	362
936	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> 2a a9 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
937	No Secondary Service CIDR provided. Skipping filtering out secondary service addresses.	23
938	Started nodeipam	23
939	Updated SpectroClusterStatusCondition condition KubeConfigReady reason KubeConfigReady status True message Kubeconfig file is available. cluster <*>	113
940	Starting ipam controller	23
941	Waiting for caches to sync for node	23
942	Updated kubeconfig ready condition <*> cluster <*>	113
943	Caches are synced for node	23
944	>>>>>>> Watching secret with name <*> cluster <*>	101
945	Starting range CIDR allocator	23
946	Source SourceSyncer readiness changed ready true	58
947	Data is now syncd can start rendering templates	58
948	Started attachdetach	23
949	Target config <*> has been updated	348
950	Failed to update statusUpdateNeeded field in actual state of world Failed to set statusUpdateNeeded to needed true because nodeName <*> does not exist	139
951	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 4f ba networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
952	Successfully updated manifest file to hubble cluster <*>	363
953	Running bpftool to look up programs attached to cgroup args string bpftool <*> <*> cgroup show <*>	58
954	Calculated interface name regexp regex ^cali.	58
955	Queueing IP set for creation family inet setID <*> setType hash net	429
956	Calculated interface name regexp regex <*>	58
957	Registering to report health.	58
958	attempted to modprobe nf_conntrack_proto_sctp error exit status <*> output	58
959	Making sure IPv4 forwarding is enabled.	58
960	Queueing update of chain. chainName <*> ipVersion <*> table <*>	685
961	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> da networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
962	BACKUP Skipping update to hubble as manifest data is same cluster <*>	2354
963	Starting attach detach controller	23
964	Waiting for caches to sync for attach detach	23
965	Started persistentvolume-expander	23
966	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> c7 d6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
967	Starting expand controller	23
968	Waiting for caches to sync for expand	23
969	Starting root CA certificate configmap publisher	23
970	Waiting for caches to sync for crt configmap	23
971	Started ephemeral-volume	22
972	Starting ephemeral volume controller	22
973	Waiting for caches to sync for ephemeral	22
974	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> c7 d6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
975	Started endpointslice	23
976	Starting endpoint slice controller	23
977	Waiting for caches to sync for endpoint_slice	23
978	Started horizontalpodautoscaling	23
979	Starting HPA controller	23
980	Waiting for caches to sync for HPA	23
981	Started endpointslicemirroring	23
982	Starting EndpointSliceMirroring controller	23
983	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	11
984	Failed predicate on node <*> node s had taints that the pod didn t tolerate	5471
985	Waiting for caches to sync for endpoint_slice_mirroring	23
986	Job <*> does not fit on node <*>	44
987	QuotaMonitor created object count evaluator for <*>	1696
988	Failed to access interface because it doesn t exist. error Link not found ifaceName <*> ifaceRegex ^cali. ipVersion <*>	1886
989	Failed to get interface it s <*> error Link not found ifaceName <*> ifaceRegex ^cali. ipVersion <*>	1886
990	QuotaMonitor created object count evaluator for limitranges	23
991	Pod does not fit on node <*>	5377
992	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> da networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
993	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	22
994	QuotaMonitor created object count evaluator for jobs.batch	23
995	QuotaMonitor created object count evaluator for ingresses.extensions	23
996	resyncPeriod <*> is smaller than resyncCheckPeriod <*> and the informer has already started. Changing it to <*>	22
997	QuotaMonitor created object count evaluator for serviceaccounts	23
998	IPIP enabled starting thread to keep tunnel configuration in sync.	58
999	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active 0 Succeeded <*> Failed 0 Desired <*> Phase running	27
1000	Connect to the dataplane driver.	58
1001	using resource updates where applicable	58
1002	Created Syncer syncer <*> status 0x0 watcherCaches <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> results chan interface <*> numSynced 0 callbacks calc.SyncerCallbacksDecoupler <*> wgwc sync.WaitGroup nil wgws sync.WaitGroup nil cancel context.CancelFunc nil	58
1003	Starting the datastore Syncer	58
1004	QuotaMonitor created object count evaluator for endpoints	23
1005	Started internal iptables dataplane driver loop	58
1006	Creating calculation graph filtered to hostname <*>	58
1007	QuotaMonitor created object count evaluator for cronjobs.batch	23
1008	Will refresh IP sets on timer interval <*>	58
1009	Registering listener for type model.WorkloadEndpointKey <*> <*>	348
1010	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status Provisioning cluster <*>	164
1011	EVENT <*> Resource machines Type MODIFIED Name <*> Uid <*> cluster <*>	444
1012	Will refresh routes on timer interval <*>	58
1013	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	88
1014	Registering listener for type model.HostEndpointKey <*> <*>	348
1015	IPIP thread started.	58
1016	Registering listener for type model.PolicyKey <*> <*>	116
1017	Registering listener for type model.ProfileRulesKey <*> <*>	58
1018	Registering listener for type model.ProfileLabelsKey <*> <*>	174
1019	Registering listener for type model.ProfileTagsKey <*> <*>	116
1020	<*> <*> <*> Trace <*> <*> Request completed <*> <*> <*> <*>	132
1021	Registering listener for type model.NetworkSetKey <*> <*>	58
1022	Registering listener for type model.HostIPKey <*> <*>	116
1023	Registering listener for type model.IPPoolKey <*> <*>	58
1024	Registering listener for type model.WireguardKey <*> <*>	58
1025	Registering listener for type model.ResourceKey <*> <*>	58
1026	Registering listener for type model.GlobalConfigKey <*> <*>	58
1027	Registering listener for type model.HostConfigKey <*> <*>	116
1028	Registering listener for type model.ReadyFlagKey <*> <*>	58
1029	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	11
1030	Starting AsyncCalcGraph	58
1031	Started the processing graph	58
1032	Watch close <*> <*> total <*> items received	3531
1033	Started internal status report thread	58
1034	Process status reports disabled	58
1035	reconcile charts atop Namespace <*> Name permission-manager	880
1036	Interface monitoring thread started.	58
1037	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	22
1038	Subscribed to netlink updates.	58
1039	Failed to get IPIP tunnel device assuming it isn t present error Link not found	57
1040	<*> <*> <*> Nov <*> <*> <*> <*> <*> CRON <*> root CMD cd <*> && <*> <*> <*>	22
1041	Linux interface state changed. ifIndex <*> ifaceName lo state up	58
1042	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status Deleting cluster <*>	99
1043	Linux interface addrs changed. addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty ifaceName lo	58
1044	Linux interface state changed. ifIndex <*> ifaceName eth0 state up	58
1045	QuotaMonitor created object count evaluator for podtemplates	23
1046	Linux interface addrs changed. addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c <*> set.empty ifaceName eth0	32
1047	&intdataplane.ifaceUpdate Name lo State up Index <*>	11
1048	looking for releases filter permission-manager namespace default	1760
1049	pack has no charts atop Namespace <*> Name permission-manager	880
1050	Started resourcequota	23
1051	&intdataplane.ifaceUpdate Name eth0 State up Index <*>	11
1052	reconcile manifests atop Namespace <*> Name permission-manager	880
1053	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	11
1054	Starting resource quota controller	23
1055	&intdataplane.ifaceAddrsUpdate Name lo Addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty	11
1056	Waiting for caches to sync for resource quota	57
1057	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name lo Addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty	11
1058	EVENT <*> Resource vspheremachines Type DELETED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	11
1059	QuotaMonitor running	23
1060	Queueing IP set for creation family inet setID <*> setType hash ip	352
1061	Started namespace	23
1062	&intdataplane.ifaceAddrsUpdate Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c <*> set.empty	22
1063	Starting namespace controller	23
1064	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c <*> set.empty	22
1065	Failed to get VSphereMachine <*> <*> not found cluster <*>	61
1066	Waiting for caches to sync for namespace	23
1067	Failed to get VsphereMachine data from store using capi machine name <*> Failed to get machine data as couldn t find any matching machine with capi machine name <*> cluster <*>	61
1068	Failed to delete vsphere machine using cached capi machine <*> <*> not found cluster <*>	61
1069	Failed to get VSphereMachine <*> . <*> <*> not found cluster <*>	61
1070	Controller will reconcile labels.	23
1071	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true Restores null cluster <*>	33
1072	Started nodelifecycle	23
1073	AsyncCalcGraph running	58
1074	Failed to process machine event for machine <*> <*> <*> not found cluster <*>	61
1075	config <key CalicoVersion value <*> > config <key ClusterGUID value <*> > config <key ClusterType value k8s bgp kubeadm kdd > config <key DatastoreType value kubernetes > config <key DefaultEndpointToHostAction value ACCEPT > config <key FelixHostname value <*> > config <key HealthEnabled value true > config <key IpInIpEnabled value true > config <key IpInIpMtu value 0 > config <key IpInIpTunnelAddr value <*> > config <key Ipv6Support value false > config <key LogFilePath value None > config <key LogSeverityFile value None > config <key LogSeverityScreen value Info > config <key LogSeveritySys value None > config <key MetadataAddr value None > config <key ReportingIntervalSecs value 0 >	58
1076	Reading from dataplane driver pipe...	58
1077	Starting node controller	23
1078	Waiting for caches to sync for taint	23
1079	Started clusterrole-aggregation	23
1080	Starting ClusterRoleAggregator	23
1081	Waiting for caches to sync for ClusterRoleAggregator	23
1082	Caches are synced for service account	23
1083	Caches are synced for cronjob	22
1084	Caches are synced for GC	23
1085	Caches are synced for stateful set	23
1086	Caches are synced for endpoint	23
1087	Caches are synced for endpoint_slice_mirroring	23
1088	Caches are synced for ephemeral	22
1089	Caches are synced for namespace	23
1090	Caches are synced for daemon sets	23
1091	Caches are synced for TTL after finished	22
1092	Caches are synced for deployment	23
1093	Caches are synced for endpoint_slice	23
1094	Watch close <*> <*> total 4 items received	352
1095	Caches are synced for job	23
1096	No driver process to monitor	58
1097	kube apply success atop Namespace <*> Name permission-manager file <*>	880
1098	Caches are synced for PVC protection	23
1099	Failed to add IPIP tunnel device error exit status <*>	57
1100	reconcile service status atop Namespace <*> Name permission-manager	880
1101	Failed configure IPIP tunnel device retrying... error exit status <*>	57
1102	Caches are synced for ReplicaSet	23
1103	Caches are synced for disruption	23
1104	reconciled chart service status for pack pack permission-manager	880
1105	Global config update GlobalFelixConfig name ClusterGUID <*> <*> <nil> 0s <*>	58
1106	Caches are synced for ClusterRoleAggregator	23
1107	Caches are synced for bootstrap_signer	23
1108	Global config update GlobalFelixConfig name ClusterType k8s bgp kubeadm kdd <*> <nil> 0s <*>	58
1109	Caches are synced for PV protection	23
1110	Caches are synced for HPA	23
1111	Global config update GlobalFelixConfig name CalicoVersion <*> <*> <nil> 0s <*>	58
1112	Caches are synced for taint	23
1113	EVENT <*> Resource machines Event Type DELETED Name <*> InfraType VSphereMachine InfraTypeName <*> status Deleting cluster <*>	19
1114	Initializing eviction metric for zone dycolo   brighteon1	11
1115	EVENT <*> Resource machines Type DELETED Name <*> Uid <*> cluster <*>	19
1116	Missing timestamp for Node <*> Assuming now as a timestamp.	139
1117	Watch close <*> <*> total 6 items received	374
1118	reconcile charts atop Namespace <*> Name istio	880
1119	Controller detected that zone dycolo   brighteon1 is now in state Normal.	11
1120	Starting NoExecuteTaintManager	23
1121	Caches are synced for persistent volume	23
1122	Event occurred object <*> kind Node apiVersion <*> type Normal reason RegisteredNode message Node <*> event Registered Node <*> in Controller	139
1123	Global config update GlobalFelixConfig name LogSeverityScreen Info <*> <nil> 0s <*>	58
1124	Global config update GlobalFelixConfig name IpInIpEnabled true <*> <nil> 0s <*>	58
1125	Caches are synced for expand	23
1126	Global config update GlobalFelixConfig name ReportingIntervalSecs 0 <*> <nil> 0s <*>	58
1127	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	11
1128	looking for releases filter istio namespace default	2640
1129	Caches are synced for attach detach	23
1130	id <*> pool <cidr <*> masquerade true >	58
1131	found release releases name istio-istio-controlplane namespace default revision <*> updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version <*> name <*> namespace default revision <*> updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version	2640
1132	Caches are synced for crt configmap	23
1133	begin helm get manifest namespace default release istio-istio-controlplane	1760
1134	EVENT <*> Resource machines Event Type ADDED Name <*> InfraType VSphereMachine InfraTypeName <*> status cluster <*>	19
1135	Event occurred object <*> kind DaemonSet apiVersion <*> type Normal reason SuccessfulCreate message Created pod <*>	104
1136	Waited for <*> due to <*> throttling not priority and fairness request GET https <*> <*> 500&resourceVersion 0	11
1137	Caches are synced for resource quota	57
1138	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	11
1139	Host config update for this host HostConfig node <*> name IpInIpTunnelAddr <*> <*> <nil> 0s <*>	58
1140	Caches are synced for garbage collector	57
1141	hostname <*> ipv4_addr <*>	537
1142	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status cluster <*>	19
1143	Garbage collector all resource monitors have synced. Proceeding to collect garbage	23
1144	helm get manifest complete namespace default release istio-istio-controlplane	1760
1145	Event occurred object brighteon/backend kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetResourceMetric message failed to get memory utilization unable to get metrics for resource memory no metrics returned from resource metrics API	1252
1146	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	22
1147	Event occurred object brighteon/backend kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetResourceMetric message failed to get cpu utilization unable to get metrics for resource cpu no metrics returned from resource metrics API	1250
1148	failed to compute desired number of replicas based on listed metrics for <*> invalid metrics <*> invalid out of <*> first error is failed to get memory utilization unable to get metrics for resource memory no metrics returned from resource metrics API	1261
1149	Event occurred object brighteon/backend kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedComputeMetricsReplicas message invalid metrics <*> invalid out of <*> first error is failed to get memory utilization unable to get metrics for resource memory no metrics returned from resource metrics API	1249
1150	begin helm get manifest namespace default release <*>	1760
1151	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status Pending cluster <*>	104
1152	helm get manifest complete namespace default release <*>	1760
1153	datadir <*> atop Namespace <*> Name istio	880
1154	begin helm reconcile for release name istio	880
1155	id <namespace <*> name default > labels <key <*> value default >	3938
1156	id <namespace <*> name <*> > labels <key app value istiod > labels <key <*> value istio-controlplane > labels <key <*> value Base > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1157	id <namespace cert-manager name cert-manager > labels <key app value cert-manager > labels <key <*> value controller > labels <key <*> value cert-manager > labels <key <*> value Helm > labels <key <*> value cert-manager > labels <key helm.sh/chart value <*> > labels <key <*> value cert-manager >	256
1158	get chart name for release name istio-istio-controlplane	880
1159	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	11
1160	id <namespace <*> name <*> > labels <key <*> value <*> >	4415
1161	get chart name for release name <*>	2849
1162	id <namespace <*> name <*> > labels <key app value kiali > labels <key <*> value istio-controlplane > labels <key <*> value AddonComponents > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1163	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	11
1164	begin helm inspect chartpath <*>	3729
1165	helm inspect complete output name <*> version <*> apiVersion <*> ChartPath <*>	880
1166	id <namespace cert-manager name <*> > labels <key app value cainjector > labels <key <*> value cainjector > labels <key <*> value cert-manager > labels <key <*> value Helm > labels <key <*> value cainjector > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	256
1167	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	11
1168	id <namespace default name default > labels <key <*> value default >	135
1169	id <namespace <*> name <*> > labels <key <*> value Helm > labels <key <*> value <*> >	22
1170	helm inspect complete output name istio-controlplane version <*> apiVersion <*> appVersion <*> ChartPath <*>	880
1171	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	55
1172	id <namespace <*> name <*> > labels <key app value istio-ingressgateway > labels <key <*> value istio-controlplane > labels <key istio value ingressgateway > labels <key <*> value IngressGateways > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1173	QueryVirtualDiskUuid failed for diskPath <*> <*> . err ServerFaultCode File <*> <*> was not found	11
1174	chart found in release name <*>	2849
1175	id <namespace <*> name <*> > labels <key app value istio-reader > labels <key <*> value istio-controlplane > labels <key <*> value Base > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1176	nothing to upgrade skipping name <*>	2849
1177	id <namespace brighteon name default > labels <key <*> value default >	11
1178	chart found in release name istio-istio-controlplane	880
1179	id <namespace cert-manager name <*> > labels <key app value webhook > labels <key <*> value webhook > labels <key <*> value cert-manager > labels <key <*> value Helm > labels <key <*> value webhook > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	234
1180	nothing to upgrade skipping name istio-istio-controlplane	880
1181	atop helm reconcile complete	2849
1182	helm charts reconciled successfully for pack istio atop Namespace <*> Name istio files <*> <*>	880
1183	reconcile manifests atop Namespace <*> Name istio	880
1184	id <namespace <*> name bootstrap-signer > labels <key <*> value bootstrap-signer >	58
1185	id <namespace <*> name prometheus > labels <key app value prometheus > labels <key <*> value istio-controlplane > labels <key <*> value AddonComponents > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value prometheus > labels <key release value istio >	11
1186	id <namespace <*> name attachdetach-controller > labels <key <*> value attachdetach-controller >	58
1187	id <namespace cert-manager name default > labels <key <*> value default >	190
1188	id <namespace <*> name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	440
1189	id <namespace <*> name <*> > labels <key app value istio-egressgateway > labels <key <*> value istio-controlplane > labels <key istio value egressgateway > labels <key <*> value EgressGateways > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1190	reconcile service status atop Namespace <*> Name istio	880
1191	id <namespace drone name default > labels <key <*> value default >	11
1192	id <namespace elasticsearch name default > labels <key <*> value default >	11
1193	id <name <*> > labels <key <*> value <*> > labels <key <*> value <*> >	264
1194	id <name <*> > labels <key <*> value bootstrap-kubeadm > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value <*> >	44
1195	reconcile status done for pack pack istio release istio-istio-controlplane	880
1196	id <name <*> > labels <key <*> value cluster-api > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value <*> >	44
1197	id <name default > labels <key <*> value default > labels <key <*> value default >	44
1198	id <name <*> > labels <key app value metallb > labels <key <*> value <*> > labels <key <*> value <*> >	44
1199	reconcile status done for pack pack istio release <*>	880
1200	id <name monitoring > labels <key <*> value monitoring > labels <key <*> value monitoring >	11
1201	reconciled chart service status for pack pack istio	880
1202	id <name permission-manager > labels <key <*> value permission-manager > labels <key <*> value permission-manager >	11
1203	id <name <*> > labels <key <*> value <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value <*> >	44
1204	reconciled manifest service status for pack pack istio	880
1205	id <name cert-manager > labels <key <*> value cert-manager > labels <key <*> value cert-manager >	44
1206	id <name <*> > labels <key <*> value Helm > labels <key istio-injection value disabled > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> >	22
1207	pack readiness status pack istio status true	880
1208	id <name mongodb > labels <key <*> value mongodb > labels <key <*> value mongodb >	11
1209	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	11
1210	id <name drone > labels <key <*> value drone > labels <key <*> value drone >	11
1211	id <name elasticsearch > labels <key <*> value elasticsearch > labels <key <*> value elasticsearch >	11
1212	id <name nginx > labels <key <*> value nginx > labels <key <*> value nginx >	11
1213	id <name redis > labels <key <*> value redis > labels <key <*> value redis >	11
1214	id <name brighteon > labels <key <*> value brighteon > labels <key <*> value brighteon >	11
1215	id <name <*> > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value <*> >	187
1216	id <namespace <*> name endpointslice-controller > labels <key <*> value endpointslice-controller >	58
1217	id <namespace <*> name coredns > labels <key <*> value coredns >	80
1218	id <namespace <*> name endpoint-controller > labels <key <*> value endpoint-controller >	124
1219	id <namespace <*> name deployment-controller > labels <key <*> value deployment-controller >	58
1220	id <namespace <*> name endpointslicemirroring-controller > labels <key <*> value endpointslicemirroring-controller >	58
1221	id <namespace <*> name token-cleaner > labels <key <*> value token-cleaner >	58
1222	id <namespace <*> name speaker > labels <key app value metallb > labels <key <*> value speaker >	341
1223	id <namespace permission-manager name <*> > labels <key <*> value <*> >	11
1224	id <namespace <*> name service-controller > labels <key <*> value service-controller >	25
1225	id <namespace <*> name <*> > labels <key k8s-app value <*> > labels <key <*> value <*> >	11
1226	id <namespace permission-manager name default > labels <key <*> value default >	11
1227	id <namespace <*> name controller > labels <key app value metallb > labels <key <*> value controller >	374
1228	id <namespace mongodb name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value mongodb > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	11
1229	id <namespace <*> name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	11
1230	id <namespace redis name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value redis > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	11
1231	id <namespace <*> name statefulset-controller > labels <key <*> value statefulset-controller >	58
1232	id <namespace redis name default > labels <key <*> value default >	11
1233	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes scaling up type ControlPlaneReady status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes scaling up type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message <*> ready. <*> ready. istio ready. permission-manager ready. services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name backend ports protocol TCP port <*> host <*> name frontend ports protocol TCP port <*> host <*> name frontend-streaming ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name minio ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> cluster <*>	22
1234	id <namespace monitoring name default > labels <key <*> value default >	25
1235	Skipping to post <*> api endpoints to hubble as there is no difference in cached api endpoints cluster <*>	790
1236	Skipping to post <*> services to hubble as there is no difference in cached services cluster <*>	768
1237	id <namespace <*> name resourcequota-controller > labels <key <*> value resourcequota-controller >	58
1238	<*> <*> <*> ... dropped <*> logs ...	11
1239	id <namespace nginx name default > labels <key <*> value default >	11
1240	id <namespace <*> name service-account-controller > labels <key <*> value service-account-controller >	58
1241	Datamodel in sync flushing config update	58
1242	Sending config update global map CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 host map IpInIpTunnelAddr <*> .	58
1243	First time we ve been in sync	58
1244	Health of component changed lastReport health.HealthReport Live true Ready false name async_calc_graph newReport &health.HealthReport Live true Ready true	11
1245	Possible config update. global map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 host map string string IpInIpTunnelAddr <*>	58
1246	Merging in config from datastore global map CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0	58
1247	Parsing value for DatastoreType kubernetes from environment variable	116
1248	Finish piping stderr of container <*>	1034
1249	Parsed value for DatastoreType kubernetes from environment variable	116
1250	Finish piping stdout of container <*>	1034
1251	Parsing value for Ipv6Support false from environment variable	116
1252	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> <*> Consumed <*> CPU time	11
1253	Parsed value for Ipv6Support false from environment variable	116
1254	Parsing value for HealthEnabled true from environment variable	116
1255	TaskExit event &TaskExit ContainerID <*> ID <*> Pid <*> ExitStatus <*> ExitedAt <*> <*> <*> <*> <*> UTC XXX_unrecognized	1066
1256	Parsed value for HealthEnabled true from environment variable	116
1257	shim disconnected id <*>	1703
1258	Parsing value for FelixHostname <*> from environment variable	116
1259	RemoveContainer containerID <*>	37
1260	Parsed value for FelixHostname <*> from environment variable	116
1261	Parsing value for DefaultEndpointToHostAction ACCEPT from environment variable	116
1262	Parsed value for DefaultEndpointToHostAction ACCEPT from environment variable	116
1263	Error syncing pod skipping err failed to StartContainer for brighteon-be with CrashLoopBackOff back-off <*> restarting failed container brighteon-be pod <*> <*> pod <*> podUID <*>	6
1264	RemoveContainer for <*>	940
1265	Parsing value for IpInIpMtu 0 from environment variable	116
1266	RemoveContainer for <*> returns successfully	939
1267	Parsed value for IpInIpMtu 0 from environment variable	116
1268	Parsing value for MetadataAddr None from config file	116
1269	Value set to none replacing with zero-value .	464
1270	Parsed value for MetadataAddr from config file	116
1271	Parsing value for LogFilePath None from config file	116
1272	Parsed value for LogFilePath from config file	116
1273	Parsing value for LogSeverityFile None from config file	116
1274	Pushing <*> cached pod metrics s to hubble cluster <*>	11
1275	Pushed >>> <*> node metrics s cluster <*>	11
1276	Pushed >>> <*> pod metrics s cluster <*>	13662
1277	Parsed value for LogSeverityFile from config file	116
1278	Parsing value for LogSeveritySys None from config file	116
1279	Parsed value for LogSeveritySys from config file	116
1280	Parsing value for IpInIpTunnelAddr <*> from datastore per-host	116
1281	Parsed value for IpInIpTunnelAddr <*> from datastore per-host	116
1282	Parsing value for ClusterGUID <*> from datastore global	116
1283	Parsed value for ClusterGUID <*> from datastore global	116
1284	Parsing value for ClusterType k8s bgp kubeadm kdd from datastore global	116
1285	Parsed value for ClusterType k8s bgp kubeadm kdd from datastore global	116
1286	Parsing value for CalicoVersion <*> from datastore global	116
1287	Parsed value for CalicoVersion <*> from datastore global	116
1288	Parsing value for LogSeverityScreen Info from datastore global	116
1289	Parsed value for LogSeverityScreen INFO from datastore global	116
1290	Parsing value for IpInIpEnabled true from datastore global	116
1291	Parsed value for IpInIpEnabled true from datastore global	116
1292	Parsing value for ReportingIntervalSecs 0 from datastore global	116
1293	Parsed value for ReportingIntervalSecs 0s from datastore global	116
1294	Merging in config from datastore per-host map IpInIpTunnelAddr <*>	58
1295	Waiting before first check-in delay <*>	57
1296	Linux interface addrs changed. addrs set.mapSet ifaceName tunl0	57
1297	First flush after becoming in sync sending InSync message.	58
1298	Datastore now in sync.	58
1299	Datastore in sync for first time sending message to status reporter.	58
1300	&intdataplane.ifaceAddrsUpdate Name tunl0 Addrs set.mapSet	11
1301	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name tunl0 Addrs set.mapSet	11
1302	Datastore in sync flushing the dataplane for the first time... timeSinceStart <*>	58
1303	Checking for completed log grep pods in iteration 4 cluster <*>	33
1304	IPAM pools updated refreshing iptables rule ipVersion <*>	58
1305	All-hosts IP set out-of sync refreshing it.	313
1306	Trying to connect to linkClient	57
1307	Public key out of sync or updated ourPublicKey AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA	58
1308	Doing full IP set rewrite family inet numMembersInPendingReplace <*> setID <*>	574
1309	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	171
1310	<*> <*> <*> bird Reconfiguration requested by SIGHUP	110
1311	Target config <*> has been updated due to change in key <*>	438
1312	Completed first update to dataplane. secsSinceStart <*>	58
1313	<*> <*> <*> bird Reconfiguring	110
1314	Health of component changed lastReport health.HealthReport Live true Ready false name <*> newReport &health.HealthReport Live true Ready true	11
1315	Tunnel wasn t admin up enabling it flags 0 mtu <*> tunnelAddr <*>	57
1316	<*> <*> <*> bird <*> Reconfigured	770
1317	Set tunnel admin up mtu <*> tunnelAddr <*>	57
1318	Address wasn t present adding it. addr <*> link tunl0	57
1319	Linux interface state changed. ifIndex <*> ifaceName tunl0 state up	56
1320	Linux interface addrs changed. addrs set.mapSet <*> set.empty ifaceName tunl0	58
1321	&intdataplane.ifaceUpdate Name tunl0 State up Index <*>	11
1322	&intdataplane.ifaceAddrsUpdate Name tunl0 Addrs set.mapSet <*> set.empty	11
1323	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name tunl0 Addrs set.mapSet <*> set.empty	11
1324	<*> <*> <*> bird Reconfigured	110
1325	Doing full IP set rewrite family inet numMembersInPendingReplace 4 setID <*>	123
1326	Netlink address update. addr <*> exists true ifIndex <*>	110
1327	<*> <*> <*> bird <*> Initializing	154
1328	<*> <*> <*> bird <*> Starting	165
1329	<*> <*> <*> bird <*> Connected to table master	165
1330	<*> <*> <*> bird <*> State changed to feed	165
1331	<*> <*> <*> bird <*> State changed to start	121
1332	Target has failed health check marking for remediation message Node failed to report startup in <*> reason NodeStartupTimeout target <*>	77
1333	<*> <*> <*> bird Graceful restart started	22
1334	<*> <*> <*> bird Started	22
1335	<*> <*> <*> bird <*> State changed to up	165
1336	<*> <*> <*> <*> Created container cluster-management-agent	6
1337	<*> <*> <*> <*> Started container cluster-management-agent	5
1338	Deleting Kubernetes Node associated with Machine is not allowed cluster <*> machine <*> namespace <*> cause noderef is nil node null	42
1339	<*> <*> <*> bird Graceful restart done	22
1340	<*> <*> <*> bird <*> State changed to wait	66
1341	Reconciler error error <*> <*> not found controller machine name <*> namespace <*>	7
1342	Overall health status changed newStatus &health.HealthReport Live true Ready true	11
1343	Recompute BGP peerings <*> updated	215
1344	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name network_v4 updated	171
1345	<*> <*> <*> bird Adding protocol <*>	55
1346	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	46
1347	<*> <*> <*>	71
1348	Initial delay complete doing first report	47
1349	Reporting cluster usage/checking for deprecation warnings. alpEnabled false calicoVersion <*> clusterGUID <*> clusterType k8s bgp kubeadm kdd gitRevision <*> kubernetesVersion <*> stats calc.StatsUpdate NumHosts <*> NumWorkloadEndpoints <*> NumHostEndpoints 0 NumPolicies 0 NumProfiles <*> NumALPPolicies 0 version <*>	212
1350	First report done starting ticker	47
1351	Summarising <*> dataplane reconciliation loops over <*> avg 0s longest <*> <*>	44
1352	Netlink address update. addr <*> exists false ifIndex <*>	66
1353	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*>	99
1354	Linux interface addrs changed. addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> fe9c <*> set.empty ifaceName eth0	12
1355	&intdataplane.ifaceAddrsUpdate Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> fe9c <*> set.empty	11
1356	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> fe9c <*> set.empty	11
1357	sync <*> failed with <*> <*> not found	11
1358	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> <*> Consumed <*> <*> CPU time	22
1359	CreateContainer within sandbox <*> for container &ContainerMetadata Name cluster-management-agent Attempt <*>	22
1360	CreateContainer within sandbox <*> for &ContainerMetadata Name cluster-management-agent Attempt <*> returns container id <*>	22
1361	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> Started libcontainer container <*>	198
1362	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/membership added member <*> https <*> <*> to cluster <*>	11
1363	<*> <*> <*> <*> <*> <*> <*> W | etcdserver failed to reach the peerURL https <*> <*> of member <*> Get https <*> <*> dial tcp <*> <*> connect connection refused	11
1364	<*> <*> <*> <*> <*> <*> <*> W | etcdserver cannot get the version of member <*> Get https <*> <*> dial tcp <*> <*> connect connection refused	11
1365	<*> <*> <*> <*> <*> <*> <*> WARN <*> stepped down to <*> since quorum is not active	11
1366	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error context canceled took too long <*> to execute	264
1367	<*> <*> <*> WARNING <*> <*> <*> <*> grpc <*> failed to write status connection error desc transport is closing	341
1368	<*> <*> <*> <*> <*> <*> <*> INFO <*> is starting a new election at term <*>	55
1369	<*> <*> <*> <*> <*> <*> <*> INFO <*> received MsgVoteResp from <*> at term <*>	66
1370	<*> <*> <*> <*> <*> <*> <*> INFO <*> logterm <*> index <*> sent MsgVote request to <*> at term <*>	55
1371	<*> <*> <*> <*> <*> <*> <*> W | etcdserver/api/etcdhttp <*> error no leader status code <*>	11
1372	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error context deadline exceeded took too long <*> to execute	99
1373	<*> <*> <*> <*> <*> <*> <*> INFO <*> became <*> at term 4	11
1374	<*> <*> <*> <*> <*> <*> <*> INFO <*> received MsgVoteResp from <*> at term 4	11
1375	<*> <*> <*> <*> <*> <*> <*> INFO <*> logterm <*> index <*> sent MsgVote request to <*> at term 4	11
1376	<*> <*> <*> <*> <*> <*> <*> W | rafthttp health check for peer <*> could not connect dial tcp <*> <*> connect connection refused	44
1377	<*> <*> <*> <*> <*> <*> <*> INFO <*> is starting a new election at term 4	11
1378	<*> <*> <*> <*> <*> <*> <*> W | etcdserver timed out waiting for read index response local node might have slow network	22
1379	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error etcdserver request timed out took too long <*> to execute	110
1380	<*> <*> <*> <*> <*> <*> <*> INFO <*> became <*> at term 6	11
1381	<*> <*> <*> <*> <*> <*> <*> INFO <*> received MsgVoteResp from <*> at term 6	11
1382	<*> <*> <*> <*> <*> <*> <*> INFO <*> logterm <*> index <*> sent MsgVote request to <*> at term 6	11
1383	<*> <*> <*> <*> <*> <*> <*> INFO <*> is starting a new election at term 6	11
1384	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result error context canceled took too long <*> to execute	22
1385	<*> <*> <*> <*> <*> <*> <*> INFO <*> has received <*> MsgVoteResp votes and 0 vote rejections	11
1386	<*> <*> <*> <*> <*> <*> <*> INFO <*> became leader at term <*>	11
1387	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error etcdserver leader changed took too long <*> to execute	275
1388	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result error etcdserver leader changed took too long <*> to execute	176
1389	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result error etcdserver leader changed took too long <*> to execute	2057
1390	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result error etcdserver leader changed took too long <*> to execute	11
1391	Topology Admit Handler	88
1392	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> Created slice libcontainer container <*>	88
1393	<*> <*> <*> <*> <*> <*> <*> I | rafthttp start to send database snapshot index <*> to <*> size <*> MB ...	11
1394	<*> <*> <*> <*> <*> <*> <*> I | etcdserver wrote database snapshot out total bytes <*>	11
1395	<*> <*> <*> <*> <*> <*> <*> I | rafthttp database snapshot index <*> to <*> sent out successfully	11
1396	<*> <*> <*> <*> <*> <*> <*> W | rafthttp closed an existing TCP streaming connection with peer <*> stream MsgApp <*> writer	11
1397	<*> <*> <*> <*> <*> <*> <*> W | rafthttp closed an existing TCP streaming connection with peer <*> stream Message writer	11
1398	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result error etcdserver request timed out took too long <*> to execute	165
1399	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count <*> size <*> took too long <*> to execute	957
1400	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count 0 size <*> took too long <*> to execute	869
1401	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count 6 size <*> took too long <*> to execute	187
1402	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count 4 size <*> took too long <*> to execute	55
1403	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result range_response_count 6 size <*> took too long <*> to execute	11
1404	Before broadcastjob reconcile <*> desired <*> active 4 failed 0	88
1405	After broadcastjob reconcile <*> desired <*> active 4 failed 0	88
1406	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active 4 Succeeded <*> Failed 0 Desired <*> Phase running	88
1407	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active <*> Succeeded 4 Failed 0 Desired <*> Phase running	88
1408	Container Name mold-manager	33
1409	starting mold manager	23
1410	ImageBuilderPath spectrocluster <*> ImageBuilderPath <*>	12320
1411	NewImageBuilderPath spectrocluster <*> NewImageBuilderPath <*>	12320
1412	########### login to vcenter for soap client ###############	24
1413	########### login to vcenter for rest client ###############	24
1414	found vm with inventory path spectrocluster <*> InventoryPath <*>	12318
1415	No customization needed same base image exists in vcenter spectrocluster <*> imageId https <*>	12254
1416	Condition spectrocluster <*> Condition type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully	12318
1417	Pod Labels <*> <*> name <*> <*> <*>	150
1418	Pod Labels kvdb true operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx	25
1419	Pod Labels name stork <*> <*> tier control-plane	30
1420	Container Name stork	66
1421	Kubernetes watch closed attempting to re-establish	5325
1422	watch re-established	5611
1423	Pod Labels component scheduler <*> <*> tier control-plane	25
1424	Pod Labels <*> <*> tier control-plane component scheduler	5
1425	Pod Labels <*> <*> <*> <*> name <*>	15
1426	Pod Labels name <*> <*> <*> <*> <*>	15
1427	Pod Labels <*> <*> name portworx operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx storage true	100
1428	Pod Labels app <*> <*> <*>	25
1429	Pod Labels operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx storage true <*> <*> name portworx	25
1430	Pod Labels name portworx operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx storage true <*> <*>	35
1431	Pod Labels operator.libopenstorage.org/name portworx storage true <*> <*> name portworx operator.libopenstorage.org/driver portworx	5
1432	Container Name portworx	396
1433	Action <*> data <nil> AttachedOn <*> Driver kernel Error <nil> Function VolumeStateChange ID <*> State VOLUME_STATE_ATTACHED Version <*>	157293
1434	Action <*> data <nil> AttachedOn Driver kernel Error <nil> Function VolumeStateChange ID <*> State VOLUME_STATE_DETACHED Version <*>	56925
1435	Pod Labels name <*> <*> <*>	10
1436	Action 4 data <nil> AttachedOn Driver kernel Error <nil> Function VolumeStateChange ID <*> State VOLUME_STATE_DELETED Version <*>	28490
1437	Pod Labels job-name <*> controller-uid <*>	5
1438	Pod Labels <*> bootstrap-kubeadm control-plane controller-manager <*> <*>	5
1439	Pod Labels app <*> <*> <*> release <*>	10
1440	Pod Labels broadcastjob-name <*> <*> proxy <*> host <*> skip <*> <*>	20
1441	remove_device_from_map <*>	28490
1442	unfreeze <*>	1030
1443	Pod Labels <*> <*> <*> infrastructure-metal3 control-plane controller-manager <*> <*>	5
1444	Volume Name <*> Id <*> Path <*> unmounted successfully	1030
1445	Monitoring storage nodes	6641
1446	Removing backing storage for device <*> pool 0 on <*>	2127
1447	Detaching AbortOnError false AttachedState ATTACH_STATE_INTERNAL_SWITCH Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	2630
1448	Container Name main	22
1449	PVC with name <*> and namespace smoketest for volumeID <*> already deleted. Skipping check for volume bound	1425
1450	delete <*> started	1315
1451	Pod Labels <*> <*> <*> proxy control-plane controller-manager	10
1452	unable to determine resource for scale target reference no matches for kind Deployment in group extensions	8229
1453	delete <*> volume deleted	1315
1454	Delete AbortOnError false AttachedState ATTACH_STATE_INTERNAL_SWITCH Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_DELETED Version <*>	1425
1455	Reconciling StorageCluster file storagecluster.go <*> Request.Name portworx Request.Namespace <*>	445
1456	Pod Labels <*> proxy app spectro component cluster-management-agent log-regex logrus-text module ally <*> <*>	5
1457	process_cdb_update dev <*> rset 0 node <*> curr <*> next <*> new_rset empty remove empty pool_ids 0 new_pool_ids empty	2039
1458	unable to fetch pod metrics for pod <*> no metrics known for pod	6875
1459	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetScale message no matches for kind Deployment in group extensions	8225
1460	delete <*> persistentvolume deleted	1315
1461	StorageCluster Predicates failed on node <*> for storage cluster portworx for reason node s had taints that the pod didn t tolerate file storagecluster.go <*>	2641
1462	process_cdb_update new state dev <*> rset 0 nodes <*> curr <*> new empty rem empty	2039
1463	delete <*> succeeded	1315
1464	StorageCluster Predicates failed on node <*> for storage cluster portworx for reason node s didn t match node selector file storagecluster.go <*>	2613
1465	Pod Labels <*> <*> <*> infrastructure-vsphere control-plane controller-manager	5
1466	6 block_finish_io for dev <*> op_id <*>	353
1467	Volume PV access shared flag false	1424
1468	provision <*> class <*> started	2601
1469	detach AbortOnError false AttachedState ATTACH_STATE_INTERNAL_SWITCH Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_DETACHED Version <*>	2452
1470	Selected domains map map map	1424
1471	Event <*> Kind PersistentVolumeClaim Namespace smoketest Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Provisioning External provisioner is provisioning volume for claim <*>	1314
1472	cos LOW ha <*> aggr <*> pools map zones map racks map domains map exclude map use false force false placement <nil> usage 0	1424
1473	<*> <*> <*> <*> systemd <*> Starting Message of the Day...	363
1474	create volume rep CapacityBytes <*> VolumeId <*> VolumeContext map attached ATTACH_STATE_INTERNAL_SWITCH error parent readonly false secure false shared false sharedv4 false state VOLUME_STATE_DETACHED ContentSource <nil> AccessibleTopology XXX_NoUnkeyedLiteral XXX_unrecognized XXX_sizecache 0	1314
1475	Failed to delete mount path <*> remove <*> operation not permitted	6073
1476	<*> <*> <*> <*> systemd <*> Started Message of the Day.	352
1477	provision region <*> aggr <*> ha <*> selectAll false use false	1424
1478	successfully created PV <*> for PVC <*> and csi volume name <*>	1314
1479	unmount ignoring attached remote error Volume is detached. Using device path <*>	6063
1480	pool <*>	1424
1481	provision <*> class <*> volume <*> provisioned	1314
1482	Volume Name <*> Id <*> Path <*> was not mounted.	6060
1483	attach AbortOnError true AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format FS_TYPE_NONE Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	1424
1484	provision <*> class <*> succeeded	1314
1485	Event <*> Kind PersistentVolumeClaim Namespace smoketest Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason ProvisioningSucceeded Successfully provisioned volume <*>	1314
1486	Fetching manifest with uid <*> for pack dex cluster <*>	3741
1487	update_nodes dev <*> rset 0 curr <*> next <*> next clean empty resync to <*>	1044
1488	Applying additional pack manifests for pack <*> in config map cluster <*>	7482
1489	Device <*> starting repl set start event	2481
1490	Updating <*> with name <*> in namespace <*> cluster <*>	7482
1491	attach_if_mounted dev <*> should be mounted but is not	2481
1492	Formatting... AbortOnError true AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format FS_TYPE_NONE Function fsOps.format ID <*> State VOLUME_STATE_ATTACHED Version <*>	1424
1493	Applied additional pack manifests for pack <*> in config map cluster <*>	7482
1494	format AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	1424
1495	Fetching manifest with uid <*> for pack <*> cluster <*>	7482
1496	Calico CNI releasing IP address ContainerID <*>	1683
1497	CRD watch closed attempting to re-establish	286
1498	Applying additional pack manifests for pack manifests-tkesystem in config map cluster <*>	3741
1499	Updating <*> with name manifests-tkesystem in namespace <*> cluster <*>	3741
1500	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-timesyncd <*> Synchronized to time server <*> <*> <*> .	1265
1501	ExecSync for <*> with command <*> <*> curl http <*> <*> <*> | ngrep <*> .+ n and timeout <*> s	10230
1502	Applied additional pack manifests for pack manifests-tkesystem in config map cluster <*>	3741
1503	Releasing address using handleID ContainerID <*> HandleID <*> Workload <*>	1683
1504	parsed scheme	4833
1505	<*> block_finish_io for dev <*> op_id <*>	2100
1506	Released address using handleID ContainerID <*> HandleID <*> Workload <*>	451
1507	scheme not registered fallback to default scheme	4832
1508	Failed to parse Failed to parse logs for pod <*> in namespace <*> as no suitable regex filter is found cluster <*>	3773
1509	provision <*> class <*> persistentvolume <*> already exists skipping	1287
1510	ccResolverWrapper sending update to cc <*> <nil> 0 <nil> <nil> <nil>	4831
1511	Releasing address using workloadID ContainerID <*> HandleID <*> Workload <*>	1683
1512	Failed to get log lines Failed to parse logs cluster <*>	3773
1513	reconcile charts atop Namespace <*> Name vault	990
1514	Failed to process logs Failed to parse logs cluster <*>	3773
1515	looking for releases filter vault namespace vault	2970
1516	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv4 martian source <*> from <*> on dev <*>	110
1517	Pushed >>> <*> metrics s cluster <*>	3265
1518	blockingPicker the picked transport is not ready loop back to repick	4807
1519	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff d2 <*> a6 f2 0f <*> <*> <*> ........... ..	11
1520	Removing mount path directory <*>	1008
1521	Teardown processing complete. ContainerID <*>	1683
1522	Attach for <*> with tty false and stdin false	154
1523	TearDown network for sandbox <*> successfully	2079
1524	Volume <*> unmounted from path <*>	1008
1525	Attach for <*> returns URL http <*> <*>	154
1526	StopPodSandbox for <*> returns successfully	2079
1527	<*> <*> <*> http2 server error reading preface from client <*> <*> read tcp <*> <*> <*> read connection reset by peer	99
1528	operationExecutor.VerifyControllerAttachedVolume started for volume <*> UniqueName <*> pod temp UID <*>	363
1529	Event occurred object <*> kind StatefulSet apiVersion <*> type Normal reason SuccessfulCreate message create Claim <*> Pod <*> in StatefulSet <*> success	879
1530	StopPodSandbox for <*>	2013
1531	Event occurred object <*> kind PersistentVolumeClaim apiVersion <*> type Normal reason ExternalProvisioning message waiting for a volume to be created either by external provisioner pxd.portworx.com or manually created by system administrator	1426
1532	Attach stream <*> closed	308
1533	Container to stop <*> must be in running or unknown state current state CONTAINER_EXITED	1595
1534	found release releases name <*> namespace vault revision <*> updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version <*>	2970
1535	begin helm get manifest namespace vault release <*>	1980
1536	Starting cloudsnap cleanup for cred <*>	242
1537	Path <*> does not exist	440
1538	Event occurred object <*> kind StatefulSet apiVersion <*> type Normal reason SuccessfulCreate message create Pod <*> in StatefulSet <*> successful	887
1539	TaskExit event &TaskExit ContainerID <*> ID <*> Pid <*> ExitStatus 0 ExitedAt <*> <*> <*> <*> <*> UTC XXX_unrecognized	638
1540	RunPodsandbox for &PodSandboxMetadata Name temp Uid <*> Namespace monitoring Attempt 0	264
1541	Cleaning up netns ContainerID <*>	1661
1542	Attaching pxd volume <*> to host	1057
1543	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Gained IPv6LL	319
1544	helm get manifest complete namespace vault release <*>	1980
1545	Releasing IP address es ContainerID <*>	1661
1546	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-timesyncd <*> Network configuration changed trying to establish connection.	1177
1547	attach AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	1057
1548	datadir <*> atop Namespace <*> Name vault	990
1549	begin helm reconcile for release name vault	990
1550	topologymanager RemoveContainer <*> Container ID <*>	4059
1551	FsResizeRequired false FsckRequiredForResize false scanPolicy Trigger SCAN_TRIGGER_NONE Action SCAN_ACTION_NONE AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function isAutoFsckRequired ID <*> State VOLUME_STATE_ATTACHED Version <*>	1057
1552	Volume Name <*> Id <*> Path <*> mounted successfully.	1057
1553	StopContainer for <*> with timeout <*> s	374
1554	helm inspect complete output name vault version <*> apiVersion <*> appVersion <*> ChartPath <*>	990
1555	Volume <*> mounted on <*>	1057
1556	Asked to release address but it doesn t exist. Ignoring ContainerID <*> HandleID <*> Workload <*>	1232
1557	Stop container <*> with signal terminated	253
1558	operationExecutor.UnmountVolume started for volume <*> UniqueName <*> pod <*> UID <*>	841
1559	UnmountVolume.TearDown succeeded for volume <*> OuterVolumeSpecName <*> pod <*> UID <*> . InnerVolumeSpecName <*> . PluginName <*> VolumeGidValue	693
1560	helm charts reconciled successfully for pack vault atop Namespace <*> Name vault files <*>	990
1561	WorkloadEndpoint does not exist in the datastore moving forward with the clean up ContainerID <*> WorkloadEndpoint <*>	1364
1562	StopContainer for <*> returns successfully	451
1563	reconcile manifests atop Namespace <*> Name vault	990
1564	Error syncing pod <*> <*> <*> skipping failed to StartContainer for <*> with CrashLoopBackOff back-off <*> restarting failed container <*> pod <*> <*>	2640
1565	SYNC Machines in store is in sync with hubble cluster <*>	875
1566	Calico CNI found existing endpoint & WorkloadEndpoint <*> <*> monitoring <*> <*> 0 <*> <*> <*> <*> <*> UTC <nil> <nil> map <*> monitoring <*> k8s <*> default run temp map k8s <*> temp eth0 <*> <*> <*> ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1567	Calico CNI deleting device in netns <*> ContainerID <*>	429
1568	reconcile service status atop Namespace <*> Name vault	990
1569	Extracted identifiers for CmdAddK8s ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1570	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Link DOWN	429
1571	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Lost carrier	429
1572	Auto assigning IP ContainerID <*> HandleID <*> Workload <*> assignArgs ipam.AutoAssignArgs Num4 <*> Num6 0 HandleID string <*> Attrs map string string namespace monitoring node <*> pod temp timestamp <*> <*> <*> <*> <*> UTC Hostname <*> IPv4Pools <*> IPv6Pools <*> MaxBlocksPerHost 0 HostReservedAttrIPv4s ipam.HostReservedAttr nil HostReservedAttrIPv6s ipam.HostReservedAttr nil	264
1573	Volume detached for volume <*> UniqueName <*> on node <*> DevicePath	693
1574	CONTROLLER OnUpdate oldObj <*> PersistentVolumeClaimName <*> SnapshotDataName <*>	17270
1575	CONTROLLER OnUpdate newObj <*> PersistentVolumeClaimName <*> SnapshotDataName <*>	17270
1576	Calico CNI deleted device in netns <*> ContainerID <*>	429
1577	controlplane replica count up to date	2429
1578	kcp status spec <*> status selector <*> <*> <*> replicas <*> updatedReplicas <*> readyReplicas <*> initialized true ready true observedGeneration <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type Available status True lastTransitionTime <*> <*> <*> type CertificatesAvailable status True lastTransitionTime <*> <*> <*> type ControlPlaneComponentsHealthy status True lastTransitionTime <*> <*> <*> type EtcdClusterHealthyCondition status True lastTransitionTime <*> <*> <*> type MachinesReady status True lastTransitionTime <*> <*> <*> type MachinesSpecUpToDate status True lastTransitionTime <*> <*> <*> type Resized status True lastTransitionTime <*> <*> <*> version <*>	933
1579	begin worker reconcile	2429
1580	reconcile status done for pack pack vault release <*>	990
1581	reconciled chart service status for pack pack vault	990
1582	reconciled manifest service status for pack pack vault	990
1583	pack readiness status pack vault status true	990
1584	Populated endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC Ports <*> nil	264
1585	machineDeployment templates are up to date cluster <*> mdNum <*> pool <*>	7193
1586	Calico CNI using IPs <*> ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1587	starting to reconcile update strategy	7193
1588	Setting the host side veth name to <*> ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1589	StatefulSet has been deleted <*>	869
1590	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_UP <*> link is not ready	484
1591	Disabling IPv4 forwarding ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1592	Waiting for pending conntrack deletion to finish ip <*>	1784
1593	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_CHANGE <*> link becomes ready	484
1594	Done waiting for pending conntrack deletion to finish ip <*>	1784
1595	Container <*> not found in pod s containers	748
1596	finish reconcile for machine pool poolName <*>	7088
1597	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Link UP	484
1598	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Gained carrier	484
1599	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> c2 <*> <*> <*> Ports <*> nil	22
1600	<*> <*> <*> Nov <*> <*> <*> <*> <*> <*> <*> WARNING Unknown index <*> <*> <*> interface list	484
1601	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-udevd <*> link_config autonegotiation is unset or enabled the speed and duplex are not writable.	484
1602	Wrote updated endpoint to datastore ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1603	veth does not exist no need to clean up. ContainerID <*> ifName eth0	440
1604	RunPodSandbox for &PodSandboxMetadata Name temp Uid <*> Namespace monitoring Attempt 0 returns sandbox id <*>	264
1605	PullImage <*> latest	605
1606	Trace <*> List etcd3 key <*> resourceVersion resourceVersionMatch limit 0 continue <*> <*> <*> <*> total time <*>	66
1607	finish reconcile for workers	2415
1608	Trace <*> List url <*> user-agent <*> linux/amd64 <*> client <*> <*> <*> <*> <*> total time <*>	44
1609	reconcileAPIEndpoint spectrocluster Namespace <*> Name <*>	2415
1610	<*> <*> <*> Trace <*> <*> Listing from storage done <*> <*> <*> <*>	44
1611	reconcileAPIEndpoint Done spectrocluster Namespace <*> Name <*>	2415
1612	reconcileLoadBalancerService spectrocluster Namespace <*> Name <*>	2415
1613	reconcileLoadBalancerService Done spectrocluster Namespace <*> Name <*>	2415
1614	reconcileInstallPriorityForPacks spectrocluster Namespace <*> Name <*>	2415
1615	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> a9 c7 <*> df Ports <*> nil	11
1616	ImageUpdate event &ImageUpdate Name <*> latest Labels map string string <*> managed XXX_unrecognized	1210
1617	marking addon packs ready for install spectrocluster Namespace <*> Name <*> cluster <*> installPriority 0	2415
1618	reconcileInstallPriorityForPacks done spectrocluster Namespace <*> Name <*>	2415
1619	begin migration on target spectrocluster Namespace <*> Name <*>	2415
1620	PullImage <*> latest returns image reference sha256 <*>	605
1621	podpreset migration already done spectrocluster Namespace <*> Name <*>	2414
1622	CreateContainer within sandbox <*> for container &ContainerMetadata Name temp Attempt 0	385
1623	finished migration on target spectrocluster Namespace <*> Name <*>	2415
1624	CreateContainer within sandbox <*> for &ContainerMetadata Name temp Attempt 0 returns container id <*>	385
1625	reconcile loop done spectrocluster Namespace <*> Name <*>	2415
1626	CreateContainer within sandbox <*> for container &ContainerMetadata Name <*> Attempt <*>	308
1627	healthz check failed checker webhook-ready error Op Get URL https <*> <*> Err Op dial Net tcp Source null Addr IP <*> Port <*> Zone Err Syscall connect Err <*>	33
1628	CreateContainer within sandbox <*> for &ContainerMetadata Name <*> Attempt <*> returns container id <*>	308
1629	healthz check failed statuses	33
1630	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> <*> c2 <*> <*> <*> <*> <*> ..............	22
1631	handleIoPatternChange <*> Resetting DB remote profile	133
1632	DerievedIoProfilerUpdaterOp AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	281
1633	handleIoPatternChange <*> Setting DB remote profile	148
1634	process_cdb_update dev <*> rset 0 node 0 <*> curr 0 <*> next 0 <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	89
1635	process_cdb_update new state dev <*> rset 0 nodes 0 <*> curr 0 <*> new empty rem empty	90
1636	process_cdb_update dev <*> rset 0 node <*> <*> curr <*> <*> next <*> <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	147
1637	process_cdb_update new state dev <*> rset 0 nodes <*> <*> curr <*> <*> new empty rem empty	150
1638	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> <*> a9 c7 <*> df <*> <*> ......VB......	11
1639	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted services name <*> ports protocol TCP port <*> host <*> name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name deviceservice-svc ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-config ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-pagerduty ports protocol TCP port <*> host <*> name tbot-support ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	374
1640	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Reconciliation on ImageCustomization Done Successfully reason ReconciliationDone status True type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes addition done reason LaunchControlPlaneNode status True type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message all control plane nodes are updated reason NodesRunning status True type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message worker nodes created successfully reason NodeReady status True type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message vault ready. dex ready. reason AddOnDeployed status True type AddOnDeploymentDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes deletion done reason DeleteControlPlaneNode status True type ControlPlaneNodeDeletionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Worker nodes deleted reason NodeDeleted status True type WorkerNodeDeletionDone conditions for spectro cluster cluster <*>	528
1641	Pushed >>> 4 metrics s cluster <*>	539
1642	RunPodsandbox for &PodSandboxMetadata Name temp Uid <*> Namespace smoketest Attempt 0	99
1643	Calico CNI found existing endpoint & WorkloadEndpoint <*> <*> smoketest <*> <*> 0 <*> <*> <*> <*> <*> UTC <nil> <nil> map <*> smoketest <*> k8s <*> default run temp map k8s <*> temp eth0 <*> <*> <*> ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	99
1644	Extracted identifiers for CmdAddK8s ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	99
1645	Auto assigning IP ContainerID <*> HandleID <*> Workload <*> assignArgs ipam.AutoAssignArgs Num4 <*> Num6 0 HandleID string <*> Attrs map string string namespace smoketest node <*> pod temp timestamp <*> <*> <*> <*> <*> UTC Hostname <*> IPv4Pools <*> IPv6Pools <*> MaxBlocksPerHost 0 HostReservedAttrIPv4s ipam.HostReservedAttr nil HostReservedAttrIPv6s ipam.HostReservedAttr nil	99
1646	process_cdb_update dev <*> rset 0 node 4 <*> curr 4 <*> next 4 <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	45
1647	process_cdb_update new state dev <*> rset 0 nodes 4 <*> curr 4 <*> new empty rem empty	46
1648	Populated endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC Ports <*> nil	99
1649	Calico CNI using IPs <*> ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	99
1650	Setting the host side veth name to <*> ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	99
1651	Disabling IPv4 forwarding ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	121
1652	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC d6 dd 6a <*> <*> <*> Ports <*> nil	22
1653	Wrote updated endpoint to datastore ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	121
1654	RunPodSandbox for &PodSandboxMetadata Name temp Uid <*> Namespace smoketest Attempt 0 returns sandbox id <*>	121
1655	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC fe <*> 4f c2 a2 bf Ports <*> nil	11
1656	Failed to detach volume. AbortOnError false AttachedState ATTACH_STATE_INTERNAL_SWITCH Driver pxd Error Failed with status device or resource busy Format <*> Function Detaching ID <*> State VOLUME_STATE_ATTACHED Version <*>	176
1657	removeKernelDevice AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	176
1658	detach failed. retry count 0 AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error Volume is busy Format <*> Function detachWithExponentialBackoff ID <*> State VOLUME_STATE_ATTACHED Version <*>	176
1659	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> d3 ee networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1660	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	792
1661	Failed to process watch event EventType 0 Name <*> WatchSource 0 task <*> not found not found	286
1662	Partial failure issuing cadvisor.ContainerInfoV2 partial failures <*> RecentStats unable to find data in memory cache	165
1663	Partial failure issuing cadvisor.ContainerInfoV2 partial failures <*> RecentStats unable to find data in memory cache <*> RecentStats unable to find data in memory cache	22
1664	reconcile charts atop Namespace <*> Name dex	979
1665	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> b1 a5 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1666	looking for releases filter dex namespace dex	2937
1667	found release releases name <*> namespace dex revision 4 updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version <*>	1122
1668	begin helm get manifest namespace dex release <*>	1958
1669	helm get manifest complete namespace dex release <*>	1958
1670	datadir <*> atop Namespace <*> Name dex	979
1671	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> e2 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1672	begin helm reconcile for release name dex	979
1673	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> fc <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1674	helm inspect complete output name dex version <*> apiVersion <*> appVersion <*> ChartPath <*>	979
1675	helm charts reconciled successfully for pack dex atop Namespace <*> Name dex files <*>	979
1676	reconcile manifests atop Namespace <*> Name dex	979
1677	Couldn t get containers partial failures <*> containerDataToContainerInfo unable to find data in memory cache	33
1678	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> Device <*> added with mode 0x0 fastpath 0 npath 0	165
1679	kube apply success atop Namespace <*> Name dex file <*>	979
1680	reconcile service status atop Namespace <*> Name dex	979
1681	<*> <*> <*> <*> systemd <*> Starting Cleanup of Temporary Directories...	176
1682	<*> <*> <*> <*> systemd <*> Started Cleanup of Temporary Directories.	176
1683	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a0 cd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1684	reconcile status done for pack pack dex release <*>	979
1685	reconciled chart service status for pack pack dex	979
1686	reconciled manifest service status for pack pack dex	979
1687	pack readiness status pack dex status true	979
1688	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> af networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1689	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> cd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1690	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a2 c2 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1691	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> d3 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1692	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> c8 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1693	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6d cb networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1694	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> f3 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1695	RemovePodSandbox for <*>	605
1696	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 3a a0 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1697	RemovePodSandbox <*> returns successfully	605
1698	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> ab <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1699	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*> <*>	22
1700	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> ec networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1701	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a9 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1702	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6d f4 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1703	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> c4 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1704	id <name atlascustomerjourney-prd > labels <key <*> value <*> > labels <key <*> value sshirey > labels <key <*> value unknown > labels <key <*> value sanugu > labels <key <*> value <*> > labels <key <*> value > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value atlascustomerjourney-prd >	396
1705	<*> attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...	55
1706	MountVolume.MountDevice succeeded for volume <*> UniqueName <*> pod <*> UID <*> device mount path <*>	55
1707	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active <*> Succeeded 6 Failed 0 Desired <*> Phase running	22
1708	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> <*> <*> mounted filesystem with ordered data mode. Opts discard	55
1709	RunPodsandbox for &PodSandboxMetadata Name <*> Uid <*> Namespace smoketest Attempt 0	55
1710	Calico CNI found existing endpoint & WorkloadEndpoint <*> <*> <*> smoketest <*> <*> 0 <*> <*> <*> <*> <*> UTC <nil> <nil> map app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> map k8s <*> <*> eth0 <*> <*> <*> ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1711	Extracted identifiers for CmdAddK8s ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1712	Auto assigning IP ContainerID <*> HandleID <*> Workload <*> assignArgs ipam.AutoAssignArgs Num4 <*> Num6 0 HandleID string <*> Attrs map string string namespace smoketest node <*> pod <*> timestamp <*> <*> <*> <*> <*> UTC Hostname <*> IPv4Pools <*> IPv6Pools <*> MaxBlocksPerHost 0 HostReservedAttrIPv4s ipam.HostReservedAttr nil HostReservedAttrIPv6s ipam.HostReservedAttr nil	55
1713	Populated endpoint ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC Ports <*> nil	55
1714	Calico CNI using IPs <*> ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1715	Setting the host side veth name to <*> ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1716	Disabling IPv4 forwarding ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1717	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_UP eth0 link is not ready	308
1718	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_CHANGE eth0 link becomes ready	308
1719	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC 3e <*> <*> <*> <*> <*> Ports <*> nil	11
1720	Wrote updated endpoint to datastore ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1721	RunPodSandbox for &PodSandboxMetadata Name <*> Uid <*> Namespace smoketest Attempt 0 returns sandbox id <*>	55
1722	CreateContainer within sandbox <*> for container &ContainerMetadata Name <*> Attempt 0	55
1723	CreateContainer within sandbox <*> for &ContainerMetadata Name <*> Attempt 0 returns container id <*>	55
1724	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> f3 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1725	Failed to watch <*> failed to list <*> the server could not find the requested resource get <*>	18411
1726	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	693
1727	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> c8 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1728	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6d f4 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1729	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> cd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1730	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> d3 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1731	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> c4 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1732	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> ab <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1733	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> ec networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1734	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a2 c2 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1735	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 3a a0 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1736	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> d3 ee networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1737	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a0 cd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1738	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> fc <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1739	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> b1 a5 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1740	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> e2 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1741	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a9 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1742	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> af networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1743	Before broadcastjob reconcile <*> desired <*> active 6 failed 0	66
1744	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6d cb networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1745	After broadcastjob reconcile <*> desired <*> active 6 failed 0	66
1746	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active 6 Succeeded <*> Failed 0 Desired <*> Phase running	22
1747	Kill container <*>	33
1748	id <namespace esim-stage name default > labels <key <*> value default >	209
1749	ContainerStatus for <*> failed error an error occurred when try to find container <*> does not exist	33
1750	id <namespace esim-stage name <*> > labels <key <*> value <*> >	220
1751	ContainerStatus <*> from runtime service failed rpc error code Unknown desc an error occurred when try to find container <*> does not exist	33
1752	pod_container_deletor DeleteContainer returned error for id containerd <*> failed to get container status <*> rpc error code Unknown desc an error occurred when try to find container <*> does not exist	33
1753	Operation for volumeName <*> podName <*> nodeName failed. No retries permitted until <*> <*> <*> <*> <*> UTC m <*> durationBeforeRetry <*> . Error UnmountVolume.TearDown failed for volume <*> UniqueName <*> pod <*> UID <*> <*> mounter.TearDownAt failed rpc error code Internal desc Mount path still exists <*>	138
1754	<*> <*> <*> <*> Readiness probe failed Get http <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	8
1755	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC fa bd <*> f3 c0 <*> Ports <*> nil	22
1756	id <namespace aqua name <*> > labels <key deployedby value <*> > labels <key <*> value <*> >	157
1757	id <namespace aqua name <*> > labels <key <*> value <*> >	146
1758	id <namespace velero name default > labels <key <*> value default >	77
1759	id <namespace velero name velero > labels <key component value velero > labels <key <*> value velero >	77
1760	id <namespace aqua name default > labels <key <*> value default >	91
1761	id <namespace <*> name default >	77
1762	id <namespace <*> name <*> >	88
1763	id <namespace atlascustomerjourney-prd name default > labels <key <*> value default >	154
1764	id <namespace ext-ingress name default > labels <key <*> value default >	165
1765	id <namespace <*> name <*> > labels <key app value strimzi > labels <key <*> value <*> >	143
1766	id <namespace atlascustomerjourney-prd name svc-tke-atlascustomerjourneyprd > labels <key <*> value svc-tke-atlascustomerjourneyprd >	165
1767	id <namespace ext-ingress name <*> > labels <key <*> value admission-webhook > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	165
1768	id <namespace ext-ingress name <*> > labels <key <*> value controller > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	187
1769	id <namespace <*> name <*> > labels <key app value <*> > labels <key <*> value <*> >	165
1770	id <namespace ext-ingress name <*> > labels <key <*> value default-backend > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	187
1771	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-timesyncd <*> Timed out waiting for reply from <*> <*> <*> .	154
1772	id <namespace <*> name <*> > labels <key app value istio-ingressgateway > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key istio value ingressgateway > labels <key <*> value IngressGateways > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	36
1773	id <namespace <*> name <*> > labels <key app value istio-egressgateway > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key istio value egressgateway > labels <key <*> value EgressGateways > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	36
1774	id <namespace <*> name <*> > labels <key app value kiali > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key <*> value AddonComponents > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	36
1775	id <namespace <*> name prometheus > labels <key app value prometheus > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key <*> value AddonComponents > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value prometheus > labels <key release value istio >	36
1776	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> a3 <*> 0a fb 2e Ports <*> nil	22
1777	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> a3 <*> 0a fb 2e <*> <*> ..............	22
1778	id <name dex > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value dex >	47
1779	id <name vault > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value vault >	47
1780	id <name default > labels <key <*> value <*> > labels <key <*> value default >	22
1781	id <name default > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value default >	47
1782	id <name willitconnect > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value willitconnect >	47
1783	id <name <*> > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> > labels <key <*> value <*> >	47
1784	id <name <*> > labels <key app value magtape > labels <key <*> value <*> > labels <key <*> value <*> >	33
1785	id <name smoketest > labels <key <*> value <*> > labels <key <*> value smoketest >	33
1786	id <name collectorforkubernetes > labels <key <*> value <*> > labels <key <*> value collectorforkubernetes >	33
1787	id <name monitoring > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value <*> > labels <key <*> value monitoring >	33
1788	id <name std-ingress > labels <key app value std-ingress > labels <key <*> value <*> > labels <key <*> value std-ingress >	33
1789	id <name <*> > labels <key <*> value <*> >	88
1790	id <name <*> > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value unknown > labels <key <*> value atippar1 > labels <key <*> value <*> > labels <key <*> value > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value <*> >	55
1791	id <name monitoring > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value RMcguir4 > labels <key <*> value <*> > labels <key <*> value monitoring >	187
1792	id <name velero > labels <key component value velero > labels <key <*> value velero >	22
1793	id <name std-ingress > labels <key app value std-ingress > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value TBD > labels <key <*> value std-ingress >	47
1794	id <name velero > labels <key component value velero > labels <key <*> value <*> > labels <key <*> value velero >	11
1795	id <name aqua > labels <key <*> value aqua >	11
1796	id <name velero > labels <key component value velero > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value velero >	11
1797	id <name aqua > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value aqua >	47
1798	id <name <*> > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	246
1799	id <name esim-stage > labels <key istio-injection value enabled > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value abentle1 > labels <key <*> value unknown > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value esim-stage >	88
1800	id <name <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	187
1801	id <name <*> > labels <key app value magtape > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	55
1802	id <name smoketest > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value smoketest >	55
1803	id <name collectorforkubernetes > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value collectorforkubernetes >	69
1804	id <name velero > labels <key component value velero > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value velero >	33
1805	id <name <*> > labels <key app value <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value RMcguir4 > labels <key <*> value proxyman-alerts > labels <key <*> value <*> >	88
1806	id <name <*> > labels <key istio-injection value enabled > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value abentle1 > labels <key <*> value unknown > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value <*> >	88
1807	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> fb <*> <*> <*> <*> Ports <*> nil	22
1808	id <name smoketest > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value smoketest >	22
1809	id <name <*> > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value <*> >	33
1810	id <name <*> > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value unknown > labels <key <*> value cpoojar5 > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value <*> >	88
1811	id <name <*> > labels <key app value magtape > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value <*> >	22
1812	id <name collectorforkubernetes > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value collectorforkubernetes >	11
1813	id <name <*> > labels <key control-plane value controller-manager > labels <key <*> value mesh > labels <key <*> value <*> >	66
1814	Trace <*> Get url <*> user-agent <*> client <*> <*> <*> <*> <*> total time <*>	22
1815	<*> <*> <*> Trace <*> <*> Transformed response object <*> <*> <*> <*>	22
1816	id <name <*> > labels <key app value <*> > labels <key control-plane value controller-manager > labels <key <*> value mesh > labels <key <*> value proxyman-alerts > labels <key <*> value <*> >	33
1817	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> fb <*> <*> <*> <*> <*> <*> <*>	22
1818	id <name <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value <*> >	22
1819	id <name <*> > labels <key app value <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value proxyman-alerts > labels <key <*> value <*> >	11
1820	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> Starting Message of the Day...	44
1821	<*> <*> <*> Nov <*> <*> <*> <*> <*> <*> <*> Super-optimized for small spaces <*> read how we shrank the memory	22
1822	<*> <*> <*> Nov <*> <*> <*> <*> <*> <*> <*> footprint of MicroK8s to make it the smallest full K8s around.	22
1823	<*> <*> <*> Nov <*> <*> <*> <*> <*> <*> <*> https <*>	22
1824	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> Started Message of the Day.	22
1825	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> <*> dc <*> <*> Ports <*> nil	22
1826	Unable to authenticate the request due to an error invalid bearer token <*> error in cryptographic primitive	66
1827	id <name dex > labels <key <*> value <*> > labels <key <*> value dex >	22
1828	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted services name <*> ports protocol TCP port <*> host <*> name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name deviceservice-svc ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-config ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-pagerduty ports protocol TCP port <*> host <*> name tbot-support ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	110
1829	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string control-plane <*> <*> <*> <*> <*> <*> k8s <*> default Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> ce <*> <*> b5 f6 Ports <*> <*> Name <*> Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name metrics Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name health Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*>	22
1830	ImageCreate event &ImageCreate Name <*> <*> Labels map string string <*> managed XXX_unrecognized	1287
1831	ImageCreate event &ImageCreate Name sha256 <*> Labels map string string <*> managed XXX_unrecognized	638
1832	object- <*> <*> <*> Failed to watch <*> failed to list <*> secrets <*> is forbidden User system node <*> cannot list resource secrets in API group in the namespace <*> no relationship found between node <*> and this object	440
1833	Error proxying data from client to backend read tcp <*> <*> <*> read connection reset by peer	22
1834	Successfully Reconciled controller vspheremachine name <*> namespace <*>	94729
1835	Fetching IPAddress objects metal3-ippool Namespace <*> Name <*>	28924
1836	Reconciling VSphereCluster	2885
1837	skipping load balancer reconciliation reason VSphereCluster.Spec.LoadBalancerRef is nil	2885
1838	skipping reconcile when API server is online reason controlPlaneInitialized	2885
1839	API server is online controlPlaneEndpoint <*> <*>	2885
1840	cloud provider config was not specified in VSphereCluster skipping reconciliation of the cloud provider integration	2885
1841	storage config was not specified in VSphereCluster skipping reconciliation of the CSI driver	2885
1842	Successfully Reconciled controller vspherecluster name <*> namespace <*>	2885
1843	vm found by bios uuid vmref Type VirtualMachine Value <*>	30660
1844	unable to encode watch object <*> http2 stream closed <*> writer http2.responseWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	105
1845	powered on	30657
1846	vm <*> biosuuid <*>	30657
1847	VSphereVM is ready	30651
1848	resource patch was not required local-resource-version <*> remote-resource-version <*>	30692
1849	Successfully Reconciled controller vspherevm name <*> namespace <*>	30665
1850	Unable to authenticate the request due to an error invalid bearer token oidc verify token oidc token is expired Token Expiry <*> <*> <*> <*> <*> UTC	33
1851	slow openapi aggregation of <*> <*>	198
1852	Trace <*> Call mutating webhook configuration <*> webhook <*> resource <*> Resource pods subresource operation CREATE UID <*> <*> <*> <*> <*> total time <*>	857
1853	Failed calling webhook failing open <*> failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	73
1854	failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	73
1855	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> client <*> <*> <*> <*> <*> total time <*>	88
1856	<*> <*> <*> Trace <*> <*> Object stored in database <*> <*> <*> <*>	55
1857	error building openapi models for <*> ERROR <*> has invalid property anyOf	135
1858	parsed scheme endpoint	2742
1859	ccResolverWrapper sending new addresses to cc https <*> <*> <nil> 0 <nil>	2743
1860	id <name vault > labels <key <*> value <*> > labels <key <*> value vault >	11
1861	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> <*> <*> <*> <*> total time <*>	65
1862	quota admission added evaluator for <*>	211
1863	Trace <*> Call mutating webhook configuration <*> webhook <*> resource <*> Resource broadcastjobs subresource operation CREATE UID <*> <*> <*> <*> <*> total time <*>	44
1864	Failed calling webhook failing closed <*> failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	820
1865	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted services name <*> ports protocol TCP port <*> host <*> name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name deviceservice-svc ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-config ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-interaction ports protocol TCP port <*> host <*> name tbot-pagerduty ports protocol TCP port <*> host <*> name tbot-support ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	176
1866	Updated host <*> name <*> ports port <*> protocol TCP host <*> name istio-ingressgateway ports port <*> protocol TCP port <*> protocol TCP host <*> name istio-ingressgateway-healthcheck ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name alertmanager-operated ports port <*> protocol TCP host <*> name grafana-monitoring ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name thanos-querier ports port <*> protocol TCP host <*> name thanos-querier ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name deviceservice-svc ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name tbot-config ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name tbot-interaction ports port <*> protocol TCP host <*> name tbot-pagerduty ports port <*> protocol TCP host <*> name tbot-support ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name piris-tools ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name willittrace-all ports port <*> protocol TCP host <*> name willitconnect ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP services for spectro cluster cluster <*>	22
1867	<*> <*> <*> KIF Received address message for unknown interface <*>	11
1868	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted services name <*> ports protocol TCP port <*> host <*> name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name deviceservice-svc ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-config ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-interaction ports protocol TCP port <*> host <*> name tbot-pagerduty ports protocol TCP port <*> host <*> name tbot-support ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	66
1869	Cluster Feature Log Fetcher Request noOfLines <*> duration <*> k8sRequest namespace <*> <*> <*> <*> <*> <*> nodeRequest nodeLog <*> <*> cluster <*>	22
1870	Deployment <*> is in running state with 0 replica cluster <*>	11
1871	Failed to create broadcast job <*> Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused cluster <*>	22
1872	Failed to apply log fetch broadcast manifest crd fileInternal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused cluster <*>	22
1873	Failed to apply log fetch broadcast job Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused cluster <*>	22
1874	Checking for completed log grep pods in iteration 6 cluster <*>	11
1875	Pod Labels operator.libopenstorage.org/name portworx kvdb true operator.libopenstorage.org/driver portworx	5
1876	Pod Labels storage true <*> <*> name portworx operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx	15
1877	Pod Labels <*> <*> app <*>	5
1878	Trace <*> List url <*> user-agent <*> <*> <*> client <*> <*> <*> <*> <*> total time <*>	440
1879	<*> <*> <*> Trace <*> <*> Writing http response done count <*> <*> <*> <*> <*>	440
1880	Pod Labels controller-uid <*> job-name <*>	5
1881	Pod Labels module ally <*> <*> <*> proxy app spectro component cluster-management-agent log-regex logrus-text	5
1882	Pod Labels control-plane controller-manager <*> <*> <*> <*> <*> infrastructure-metal3	5
1883	Removing backing storage for device <*> pool 0 on 4	2079
1884	update_nodes dev <*> rset 0 curr 4 next 4 next clean empty resync to 4	1430
1885	process_cdb_update dev <*> rset 0 node 4 curr 4 next 4 new_rset empty remove empty pool_ids 0 new_pool_ids empty	2189
1886	process_cdb_update new state dev <*> rset 0 nodes 4 curr 4 new empty rem empty	2189
1887	Nodes needing storage pods for storage cluster portworx creating 0 file storagecluster.go <*>	862
1888	Pods to delete for storage cluster portworx deleting 0 file storagecluster.go <*>	865
1889	Checking if relevant fields in pod <*> have changed since <*> file update.go <*>	71
1890	kcp status spec <*> status selector <*> <*> <*> replicas <*> updatedReplicas <*> readyReplicas <*> initialized true ready true observedGeneration <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type Available status True lastTransitionTime <*> <*> <*> type CertificatesAvailable status True lastTransitionTime <*> <*> <*> type ControlPlaneComponentsHealthy status True lastTransitionTime <*> <*> <*> type EtcdClusterHealthyCondition status True lastTransitionTime <*> <*> <*> type MachinesReady status True lastTransitionTime <*> <*> <*> type Resized status True lastTransitionTime <*> <*> <*> version <*>	1496
1891	Getting unavailable numbers file update.go <*>	434
1892	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC ea b5 <*> <*> <*> <*> Ports <*> nil	22
1893	Checking for deletion of all log grep pods in iteration <*> cluster <*>	11
1894	Old Log grep pods on all nodes have been deleted successfully in iteration <*> cluster <*>	11
1895	found release releases name <*> namespace dex revision <*> updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version <*>	1815
1896	Error while calling home node <*> <*> Bad Gateway	11
1897	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC ee <*> b3 a2 ca ae Ports <*> nil	11
1898	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> <*> fe <*> <*> Ports <*> nil	11
1899	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active 6 Succeeded 6 Failed 0 Desired <*> Phase running	44
1900	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC f2 db <*> d4 0f <*> Ports <*> nil	22
1901	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> 0d <*> fc <*> Ports <*> nil	22
1902	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> dd <*> 0a 0f <*> Ports <*> nil	22
1903	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> <*> <*> <*> <*> Ports <*> nil	22
1904	operationExecutor.UnmountDevice started for volume <*> UniqueName <*> on node <*>	22
1905	<*> attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...	22
1906	UnmountDevice succeeded for volume <*> %! EXTRA string UnmountDevice succeeded for volume <*> UniqueName <*> on node <*>	22
1907	<*> <*> <*> 0 Successfully assigned <*> to <*>	9
1908	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> b1 <*> 0b <*> 4d Ports <*> nil	11
1909	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> <*> <*> <*> c4 Ports <*> nil	22
1910	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC de <*> <*> <*> ad <*> Ports <*> nil	22
1911	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> dc <*> <*> <*> fa Ports <*> nil	22
1912	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string control-plane <*> <*> <*> <*> <*> <*> k8s <*> default Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC fe <*> <*> ae <*> <*> Ports <*> <*> Name <*> Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name metrics Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name health Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*>	22
1913	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> dc <*> <*> <*> fa <*> <*> ........lh....	22
1914	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC 6e b5 <*> f2 <*> c2 Ports <*> nil	22
1915	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> a3 <*> <*> cd <*> Ports <*> nil	22
1916	Couldn t get secret <*> failed to sync secret cache timed out waiting for the condition	29
1917	Operation for volumeName <*> podName <*> nodeName failed. No retries permitted until <*> <*> <*> <*> <*> UTC m <*> durationBeforeRetry <*> . Error MountVolume.SetUp failed for volume <*> UniqueName <*> pod <*> UID <*> failed to sync secret cache timed out waiting for the condition	28
1918	PVC <*> failed with Operation cannot be fulfilled on persistentvolumeclaims <*> StorageError invalid object Code 4 Key <*> ResourceVersion 0 AdditionalErrorMsg Precondition failed UID in precondition <*> UID in object meta	11
1919	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC fe <*> <*> <*> f9 <*> Ports <*> nil	22
1920	StopContainer for <*> with timeout 0 s	88
1921	failed to keep alive rest client unauthorized error Unauthorized	11
1922	listening for secure connections address <*>	6
1923	START logs for container cert-manager of pod <*>	4
1924	using <*> certificate generating using CA stored in Secret resource secret_name <*> secret_namespace cert-manager	5
1925	listening for insecure healthz connections address <*>	6
1926	registered pprof handlers	7
1927	Failed to generate initial serving certificate retrying... error failed verifying CA keypair tls failed to find any PEM data in certificate input interval <*>	81
1928	caller level.go <*> event createNDPResponder interface <*> level info msg created NDP responder for interface ts <*> <*> <*>	544
1929	START logs for container speaker of pod <*>	3
1930	branch main caller level.go <*> commit <*> goversion gc <*> <*> <*> amd64 level info msg MetalLB speaker starting commit <*> branch main ts <*> <*> <*> version	6
1931	caller level.go <*> event createARPResponder interface eth0 level info msg created ARP responder for interface ts <*> <*> <*>	9
1932	caller level.go <*> event createNDPResponder interface eth0 level info msg created NDP responder for interface ts <*> <*> <*>	12
1933	caller level.go <*> event createARPResponder interface <*> level info msg created ARP responder for interface ts <*> <*> <*>	538
1934	caller level.go <*> level info msg node event <*> forcing sync node addr <*> node event NodeJoin node name <*> ts <*> <*> <*>	36
1935	caller level.go <*> configmap <*> event configLoaded level info msg config re loaded ts <*> <*> <*>	81
1936	caller level.go <*> event nodeLabelsChanged level info msg Node labels changed resyncing BGP peers ts <*> <*> <*>	28
1937	caller level.go <*> level info msg triggering discovery op memberDiscovery ts <*> <*> <*>	12720
1938	caller level.go <*> level info msg memberlist join succesfully number of other nodes <*> op Member detection ts <*> <*> <*>	11
1939	caller level.go <*> error creating NDP responder for <*> listen ip6 <*> fe80 ecee eeff feee <*> bind cannot assign requested address interface <*> level error msg failed to create NDP responder op createNDPResponder ts <*> <*> <*>	61
1940	caller level.go <*> error <*> error occurred n t Failed to join <*> No installed keys could decrypt the message n n expected <*> joined 0 level error msg partial join op memberDiscovery ts <*> <*> <*>	8986
1941	Trace <*> Reflector ListAndWatch name <*> <*> <*> <*> <*> <*> total time <*>	388
1942	START logs for container controller of pod <*>	5
1943	branch main caller level.go <*> commit <*> goversion gc <*> <*> <*> amd64 level info msg MetalLB controller starting commit <*> branch main ts <*> <*> <*> version	2
1944	Trace <*> <*> <*> END	7305
1945	Failed to watch <*> failed to list <*> Get https <*> <*> metadata.name%3Dconfig limit <*> resourceVersion 0 dial tcp <*> <*> i/o timeout	3
1946	Failed to watch <*> failed to list <*> Get https <*> <*> <*> resourceVersion 0 dial tcp <*> <*> i/o timeout	36
1947	caller level.go <*> event stateSynced level info msg controller synced can allocate IPs now ts <*> <*> <*>	3
1948	END logs for container controller of pod <*>	5
1949	caller level.go <*> error <*> errors occurred n t Failed to join <*> No installed keys could decrypt the message n t Failed to join <*> No installed keys could decrypt the message n n expected <*> joined 0 level error msg partial join op memberDiscovery ts <*> <*> <*>	27
1950	caller level.go <*> event deleteARPResponder interface <*> level info msg deleted ARP responder for interface ts <*> <*> <*>	253
1951	caller level.go <*> event deleteNDPResponder interface <*> level info msg deleted NDP responder for interface ts <*> <*> <*>	253
1952	Health check failed as CertificateSource is unhealthy	3
1953	END logs for container <*> of pod <*>	461
1954	START logs for container <*> of pod <*>	481
1955	Valid token audiences	16
1956	Generating self signed cert as no cert is provided	22
1957	Starting TCP socket on <*> <*>	24
1958	Listening securely on <*> <*>	30
1959	START logs for container manager of pod <*>	47
1960	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfig	10
1961	Registering a validating webhook GVK Group <*> Version <*> Kind KubeadmConfig path <*>	11
1962	conversion webhook enabled object metadata creationTimestamp null spec status	12
1963	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfigList	12
1964	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfigList	12
1965	conversion webhook enabled object metadata items null	61
1966	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfigTemplate	12
1967	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfigTemplate	12
1968	conversion webhook enabled object metadata creationTimestamp null spec template spec	12
1969	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind <*>	11
1970	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind <*>	10
1971	creating controller manager version <*>	10
1972	error opening credentials file error open <*> no such file or directory	10
1973	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereCluster	24
1974	Registering a validating webhook GVK Group <*> Version <*> Kind VSphereCluster path <*>	12
1975	serving webhook server host port <*>	25
1976	END logs for container manager of pod <*>	28
1977	caller net.go <*> component Memberlist level error msg memberlist failed to receive No installed keys could decrypt the message from <*> <*> ts <*> <*> <*>	9074
1978	Registering a mutating webhook GVK Group <*> Version <*> Kind KubeadmControlPlane path <*>	10
1979	Registering a validating webhook GVK Group <*> Version <*> Kind KubeadmControlPlane path <*>	10
1980	END logs for container cert-manager of pod <*>	3
1981	conversion webhook enabled object metadata creationTimestamp null spec cloudProviderConfiguration global network disk workspace labels providerConfig controlPlaneEndpoint host port 0 status	12
1982	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereClusterList	12
1983	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereClusterList	12
1984	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereMachine	24
1985	Registering a validating webhook GVK Group <*> Version <*> Kind VSphereMachine path <*>	12
1986	conversion webhook enabled object metadata creationTimestamp null spec template network devices null status ready false	12
1987	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineList	12
1988	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineList	12
1989	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineTemplate	23
1990	Registering a validating webhook GVK Group <*> Version <*> Kind VSphereMachineTemplate path <*>	12
1991	conversion webhook enabled object metadata creationTimestamp null spec template spec template network devices null	12
1992	END logs for container speaker of pod <*>	3
1993	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineTemplateList	12
1994	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineTemplateList	12
1995	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereVM	12
1996	Registering a validating webhook GVK Group <*> Version <*> Kind VSphereVM path <*>	12
1997	END logs for container upgrade-ipam of pod <*>	33
1998	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereVMList	12
1999	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereVMList	12
2000	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind HAProxyLoadBalancer	12
2001	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind HAProxyLoadBalancer	12
2002	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind HAProxyLoadBalancerList	12
2003	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind HAProxyLoadBalancerList	12
2004	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereCluster	12
2005	conversion webhook enabled object metadata creationTimestamp null spec cloudProviderConfiguration global network disk workspace labels providerConfig status ready false	12
2006	START logs for container upgrade-ipam of pod <*>	18
2007	migrating from host-local to calico-ipam...	20
2008	checking host-local IPAM data dir dir existence...	23
2009	host-local IPAM data dir dir not found no migration necessary successfully exiting...	26
2010	migration from host-local to calico-ipam complete node <*>	29
2011	START logs for container install-cni of pod <*>	36
2012	Running as a Kubernetes pod source install.go <*>	38
2013	Installed <*>	414
2014	Wrote Calico CNI binaries to <*> n	47
2015	CNI plugin version <*> n	47
2016	<*> is not writeable skipping	47
2017	Using CNI config template from CNI_NETWORK_CONFIG environment variable. source install.go <*>	47
2018	Created <*>	47
2019	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereMachine	12
2020	conversion webhook enabled object metadata creationTimestamp null spec template datacenter network devices null status ready false	12
2021	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineTemplate	10
2022	conversion webhook enabled object metadata creationTimestamp null spec template metadata spec template datacenter network devices null	9
2023	starting controller manager	9
2024	name <*>	47
2025	cniVersion <*>	47
2026	plugins	47
2027	type calico	47
2028	log_level info	47
2029	log_file_path <*>	47
2030	datastore_type kubernetes	47
2031	nodename <*>	47
2032	mtu 0	47
2033	ipam	47
2034	type calico-ipam	47
2035	policy	47
2036	type k8s	47
2037	kubernetes	47
2038	kubeconfig <*>	47
2039	type <*>	47
2040	snat true	47
2041	capabilities portMappings true	47
2042	type bandwidth	47
2043	capabilities bandwidth true	47
2044	Done configuring CNI. Sleep false	47
2045	END logs for container install-cni of pod <*>	48
2046	Error getting resource Key GlobalFelixConfig name CalicoVersion Name calicoversion Resource GlobalFelixConfigs error the server could not find the requested resource get <*> calicoversion	11
2047	<*> is true defaulted through environment variable	11
2048	Ensure default IPv4 pool is created. IPIP mode Always VXLAN mode Never	11
2049	Created default IPv4 pool <*> with NAT outgoing true. IPIP mode Always VXLAN mode Never	11
2050	Calico node started successfully	47
2051	bird Unable to open configuration file <*> No such file or directory	85
2052	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	11
2053	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0x0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	11
2054	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0x0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	11
2055	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0x0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	11
2056	Calling CSI driver to discover driver name	30
2057	Attempting to open a gRPC connection with <*>	32
2058	Still connecting to unix <*>	221816
2059	GRPC call <*>	33
2060	GRPC request	36
2061	GRPC response name <*> vendor_version <*>	27
2062	GRPC error <nil>	42
2063	CSI driver name <*>	83
2064	Starting Registration Server at <*>	45
2065	Registration Server started at <*>	45
2066	Skipping healthz server because port set to 0	33
2067	Received GetInfo call InfoRequest	45
2068	Received NotifyRegistrationStatus call RegistrationStatus PluginRegistered true Error	45
2069	level info time <*> <*> <*> caller logger/logger.go <*> msg Setting default log level to PRODUCTION	99
2070	level info time <*> <*> <*> caller <*> <*> msg Version <*> TraceId <*>	55
2071	level info time <*> <*> <*> caller <*> <*> msg Defaulting feature states configmap name to <*> TraceId <*>	55
2072	Error looking up in-cluster authentication configuration the server was unable to return a response in the time allotted but may still be processing the request get configmaps <*>	3
2073	Failed to watch <*> failed to list <*> Get https <*> <*> <*> limit <*> resourceVersion 0 dial tcp <*> <*> connect connection refused	79
2074	Failed to watch <*> failed to list <*> Get https <*> <*> <*> resourceVersion 0 dial tcp <*> <*> connect connection refused	491
2075	Creating new default config for lighthouse	96
2076	START logs for container config-init of pod <*>	1
2077	<*> <*> <*> <*> Get http <*> <*> dial tcp <*> <*> connect connection refused Next retry in <*>	101
2078	level info time <*> <*> <*> caller <*> <*> msg Defaulting feature states configmap namespace to <*> TraceId <*>	55
2079	level info time <*> <*> <*> caller service/service.go <*> msg configured <*> with clusterFlavor VANILLA and mode node TraceId <*>	33
2080	identity service registered	44
2081	node service registered	33
2082	serving endpoint unix <*>	44
2083	level info time <*> <*> <*> caller <*> <*> msg No Net Permissions given in Config. Using default permissions. TraceId <*>	55
2084	level info time <*> <*> <*> caller service/node.go <*> msg Config file provided to node daemonset with zones and regions. Assuming topology aware cluster. TraceId <*>	33
2085	level info time <*> <*> <*> caller <*> <*> msg Defaulting timeout for vCenter Client to <*> minutes TraceId <*>	44
2086	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Initializing defaultVirtualCenterManager... TraceId <*>	44
2087	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully initialized defaultVirtualCenterManager TraceId <*>	44
2088	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully registered VC <*> TraceId <*>	44
2089	level info time <*> <*> <*> caller vsphere/virtualcenter.go <*> msg New session ID for VSPHERE.LOCAL arvind <*> TraceId <*>	44
2090	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Initiating asynchronous datacenter listing with uuid <*> TraceId <*>	99
2091	level info time <*> <*> <*> caller <*> <*> msg Publishing datacenter Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> TraceId <*>	99
2092	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg AsyncGetAllDatacenters with uuid <*> sent a dc Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> TraceId <*>	99
2093	level error time <*> <*> <*> caller <*> <*> msg Couldn t find VM given uuid <*> TraceId <*> stacktrace <*> Datacenter .GetVirtualMachineByUUID n <*> <*> <*> n <*> <*>	33
2094	level warn time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Couldn t find VM given uuid <*> on DC Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> with err virtual machine wasn t found continuing search TraceId <*>	33
2095	level error time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Returning VM not found err for UUID <*> TraceId <*> stacktrace <*> n <*> <*> <*> service .NodeGetInfo n <*> <*> <*> n <*> <*> <*> interceptor .handle n <*> <*> <*> n <*> <*> <*> StoragePlugin .injectContext n <*> <*> <*> n <*> <*> <*> n <*> <*> <*> n <*> <*> <*> Server .processUnaryRPC n <*> <*> <*> Server .handleStream n <*> <*> <*> Server <*> n <*> <*>	33
2096	level error time <*> <*> <*> caller service/node.go <*> msg failed to get nodeVM for uuid <*> err virtual machine wasn t found TraceId <*> stacktrace <*> service .NodeGetInfo n <*> <*> <*> n <*> <*> <*> interceptor .handle n <*> <*> <*> n <*> <*> <*> StoragePlugin .injectContext n <*> <*> <*> n <*> <*> <*> n <*> <*> <*> n <*> <*> <*> Server .processUnaryRPC n <*> <*> <*> Server .handleStream n <*> <*> <*> Server <*> n <*> <*>	33
2097	Error initializing lighthouse config. timed out performing task	11
2098	END logs for container config-init of pod <*>	10
2099	START logs for container px-lighthouse of pod <*>	9
2100	Request log error the server rejected our request for an unknown reason get pods <*>	19
2101	END logs for container px-lighthouse of pod <*>	7
2102	ERROR <*> <*> <*> HINFO read udp <*> <*> <*> i/o timeout	95
2103	START logs for container coredns of pod <*>	3
2104	. <*>	4
2105	INFO <*> Running configuration <*> <*>	5
2106	linux/amd64 <*> <*>	7
2107	Warning option provisioner pxd.portworx.com is deprecated and has no effect	9
2108	feature gates map	12
2109	Building kube configs for running in cluster...	29
2110	caller level.go <*> level info msg node event <*> forcing sync node addr <*> node event NodeLeave node name <*> ts <*> <*> <*>	11
2111	caller level.go <*> error <*> error occurred n t Failed to join <*> dial tcp <*> <*> connect connection refused n n expected <*> joined 0 level error msg partial join op memberDiscovery ts <*> <*> <*>	44
2112	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Found VM VirtualMachine <*> VirtualCenterHost <*> UUID <*> Datacenter Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> given uuid <*> on DC Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> TraceId <*>	66
2113	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Returning VM VirtualMachine <*> VirtualCenterHost <*> UUID <*> Datacenter Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> for UUID <*> TraceId <*>	66
2114	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Found tag DND for object ClusterComputeResource <*> Folder <*> GPU Cluster <nil> TraceId <*>	33
2115	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Found tag az4 for object ClusterComputeResource <*> Folder <*> GPU Cluster <nil> TraceId <*>	33
2116	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Found tag <*> for object Datacenter <*> Folder <*> Datacenter <nil> TraceId <*>	33
2117	level info time <*> <*> <*> caller <*> <*> msg PbmClient wasn t connected ignoring TraceId <*>	33
2118	level info time <*> <*> <*> caller <*> <*> msg CnsClient wasn t connected ignoring TraceId <*>	33
2119	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully unregistered VC <*> TraceId <*>	33
2120	calling CSI driver to discover driver name	44
2121	metrics endpoint will not be started because `metrics-address` was not specified.	65
2122	Serving requests to <*> on <*> <*>	44
2123	Service handler initialized via as DBus type dbus svc portworx.service id <*>	18
2124	START logs for container portworx of pod <*>	13
2125	Input arguments <*> <*> <*> <*> type zeroedthick size <*> <*> <*> -secret_type k8s <*> <*> kubernetes	2
2126	Updated arguments <*> <*> <*> <*> type zeroedthick size <*> <*> <*> -secret_type k8s <*> <*> kubernetes	3
2127	<*> computed version <*>	16
2128	Flag <*> has been deprecated see <*> instead.	7
2129	REAPER Starting ...	17
2130	Activating REST server	19
2131	Locating my container handler	20
2132	> Attempt to use Docker as container handler failed error <*> not a socket-file	21
2133	> Using ContainerD as container handler	22
2134	Detected HostNetwork setting <*> will track portworx status via REST	23
2135	Registering CRDs	7
2136	START logs for container stork of pod <*>	4
2137	error retrieving resource lock <*> Get https <*> <*> <*> <*> request canceled Client.Timeout exceeded while awaiting headers	54
2138	Starting stork version <*>	5
2139	Using driver pxd	6
2140	Failed to discover group <*> error the server is currently unable to handle the request	4
2141	Using http <*> <*> as endpoint for portworx REST API	7
2142	Using <*> <*> as endpoint for portworx gRPC API	8
2143	Starting snapshot controller	21
2144	START logs for container stork-connector of pod <*>	3
2145	Removed env variables AUTOPILOT_PORT <*> <*> <*> <*> AUTOPILOT_SERVICE_HOST AUTOPILOT_SERVICE_PORT AUTOPILOT_SERVICE_PORT_AUTOPILOT CLOUD_CONTROLLER_MANAGER_PORT <*> <*> <*> <*> <*> <*> PATH PORTWORX_API_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_SERVICE_HOST PORTWORX_API_SERVICE_PORT <*> <*> <*> PORTWORX_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_SERVICE_HOST PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> PX_LIGHTHOUSE_PORT <*> <*> <*> <*> <*> <*> <*> <*> PX_LIGHTHOUSE_SERVICE_HOST PX_LIGHTHOUSE_SERVICE_PORT <*> <*> STORK_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> STORK_SERVICE_SERVICE_HOST STORK_SERVICE_SERVICE_PORT <*> <*> VSPHERE_VCENTER_PORT	11
2146	Preparing to download Portworx image...	23
2147	REST Changing install-state ST_UNKNOWN <*> ST_INSTALL	23
2148	error retrieving resource lock <*> Get https <*> <*> <*> stream error stream ID <*> INTERNAL_ERROR Client.Timeout exceeded while awaiting headers	11
2149	Unexpected error when reading response body <*> request canceled Client.Timeout or context cancellation while reading body	11
2150	error retrieving resource lock <*> unexpected error when reading response body. Please retry. Original error <*> request canceled Client.Timeout or context cancellation while reading body	11
2151	Error getting nodes Failed to get nodes for the driver Get http <*> <*> dial tcp <*> <*> connect connection refused	15
2152	<*> <*> <*> <*> failed to create cluster domains status object for driver pxd Failed to get clusterID for the driver Get http <*> <*> dial tcp <*> <*> connect connection refused Next retry in <*>	120
2153	Linux interface addrs changed. addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> feb6 <*> set.empty ifaceName eth0	55
2154	QuotaMonitor created object count evaluator for actionapprovals.autopilot.libopenstorage.org	11
2155	QuotaMonitor created object count evaluator for migrationschedules.stork.libopenstorage.org	12
2156	QuotaMonitor created object count evaluator for migrations.stork.libopenstorage.org	12
2157	QuotaMonitor created object count evaluator for autopilotruleobjects.autopilot.libopenstorage.org	11
2158	QuotaMonitor created object count evaluator for rules.stork.libopenstorage.org	12
2159	QuotaMonitor created object count evaluator for clusterpairs.stork.libopenstorage.org	12
2160	END logs for container stork-connector of pod <*>	1
2161	Detected imagePullPolicy Always	23
2162	Attempting to retrieve latest <*> <*> image pullPolicy Always	23
2163	Using anonymous Docker credentials	23
2164	Remote Portworx image digest identical to current image s digest pull skipped	12
2165	Got requested Portworx image <*> <*> with digest sha256 <*>	23
2166	Installed image digest sha256 <*> same as remote/pulled image s no need to reinstall	12
2167	Installing Portworx OCI service to <*>	23
2168	Prepending computed kubelet directory mount <*> <*> shared	23
2169	Adding computed <*> as volatile mount regex	23
2170	RSYNC Found volatile mount <*> <*>	92
2171	> <*> <*> <*> <*> <*> <*> <*>	115
2172	> Changed mount <*> <*> to <*> <*>	92
2173	RSYNC Found volatile mount <*> <*> ro	23
2174	> Changed mount <*> <*> ro to <*> <*>	23
2175	CPU shares limit NOT passed to Portworx service use <*> <*> param instead	23
2176	> run-host <*> install <*> <*> <*> type zeroedthick size <*> <*> <*> -secret_type k8s <*> <*> kubernetes <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> AUTOPILOT_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> AUTOPILOT_SERVICE_HOST <*> <*> AUTOPILOT_SERVICE_PORT <*> <*> AUTOPILOT_SERVICE_PORT_AUTOPILOT <*> <*> <*> <*> <*> CLOUD_CONTROLLER_MANAGER_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> HTTPS_PROXY http <*> <*> <*> HTTP_PROXY http <*> <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NO_PROXY <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_LIGHTHOUSE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PX_LIGHTHOUSE_SERVICE_HOST <*> <*> PX_LIGHTHOUSE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> USER_NO_PROXY <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX datastore <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_PASSWORD <*> VSPHERE_USER <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> http_proxy http <*> <*> <*> https_proxy http <*> <*> <*> no_proxy <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> <*> PX_IMAGE <*> <*> <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*>	11
2177	Rootfs found at <*>	41
2178	PX binaries found at <*>	41
2179	error retrieving resource lock <*> Get https <*> <*> <*> dial tcp <*> <*> connect connection refused	54
2180	Failed to watch <*> failed to list <*> Get https <*> <*> <*> resourceVersion 0 dial tcp <*> <*> connect no route to host	15
2181	Initializing as version <*> OCI	41
2182	Using http_proxy http <*> <*>	11
2183	Enabling Sharedv4 NFS support ...	41
2184	Setting up NFS service	41
2185	> Initialized service controls via DBus type dbus svc <*> id <*>	41
2186	Fixing <*> mount	36
2187	> Removing mount for <*> <*> rbind rprivate	36
2188	> Adding mount for <*> <*> bind rprivate	36
2189	> <*> <*> <*> <*> already exists	25
2190	Checking mountpoints for following shared directories <*> <*>	39
2191	Found following mountpoints for shared dirs map <*> isMP T Opts shared <*> <*> isMP f Opts shared <*> Parent <*> <*> isMP f Opts shared <*> Parent <*>	39
2192	SPEC UNCHANGED <*> <*>	11
2193	<*> arguments <*> <*> <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	11
2194	<*> mounts <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> proc <*> nosuid noexec nodev <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> sysfs <*> nosuid noexec nodev cgroup <*> nosuid noexec nodev <*> <*> <*> <*> <*> <*> <*> <*> bind <*> <*> <*> <*> shared <*> <*> <*> <*> shared <*> <*> <*> <*> ro <*> <*> <*> <*>	11
2195	<*> env AUTOPILOT_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp AUTOPILOT_SERVICE_HOST <*> AUTOPILOT_SERVICE_PORT <*> AUTOPILOT_SERVICE_PORT_AUTOPILOT <*> <*> <*> CLOUD_CONTROLLER_MANAGER_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> CONTAINER_RUNTIME containerd CSI_ENDPOINT unix <*> GOMAXPROCS <*> GOTRACEBACK crash HOSTNAME <*> HTTPS_PROXY http <*> <*> HTTP_PROXY http <*> <*> KUBELET_DIR <*> KUBERNETES_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBERNETES_SERVICE_HOST <*> KUBERNETES_SERVICE_PORT <*> KUBERNETES_SERVICE_PORT_HTTPS <*> KUBE_DNS_PORT udp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> udp <*> <*> <*> <*> <*> <*> <*> udp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBE_DNS_SERVICE_HOST <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> LVM_USE_HOST <*> NFS_SERVICE <*> NO_PROXY <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> PATH <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_API_SERVICE_HOST <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_SERVICE_SERVICE_HOST <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> PX_IMAGE_DIGEST sha256 <*> PX_LIGHTHOUSE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PX_LIGHTHOUSE_SERVICE_HOST <*> PX_LIGHTHOUSE_SERVICE_PORT <*> <*> <*> <*> <*> PX_LOGLEVEL info PX_RUNC true PX_SHARED <*> shared <*> <*> shared <*> PX_TEMPLATE_VERSION <*> PX_VERSION <*> STORK_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp STORK_SERVICE_SERVICE_HOST <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> TERM xterm USER_NO_PROXY <*> <*> <*> VSPHERE_DATASTORE_PREFIX datastore VSPHERE_INSECURE true VSPHERE_INSTALL_MODE shared VSPHERE_PASSWORD VSPHERE_USER VSPHERE_VCENTER <*> VSPHERE_VCENTER_PORT <*> container oci http_proxy http <*> <*> https_proxy http <*> <*> no_proxy <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*>	11
2196	<*> content unchanged <*> <*>	48
2197	intdataplane.ifaceUpdate Name lo State up Index <*>	47
2198	intdataplane.ifaceUpdate Name eth0 State up Index <*>	47
2199	<*> Name lo Addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty	47
2200	Interface addrs changed. update <*> Name lo Addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty	47
2201	<*> Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> feb6 <*> set.empty	55
2202	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> feb6 <*> set.empty	55
2203	<*> Name tunl0 Addrs set.mapSet	46
2204	Interface addrs changed. update <*> Name tunl0 Addrs set.mapSet	46
2205	Could not enable portworx-reboot error exit status <*> out Failed to connect to bus No data available nFailed to connect to bus No data available n	11
2206	Could create systemd service error Could not enable portworx-reboot exit status <*>	11
2207	runC spec unchanged	11
2208	Portworx service restart required due to missing/invalid <*>	22
2209	Reloading + Restarting portworx service	23
2210	Initializing eviction metric for zone <*>   az4	11
2211	<*> <*> <*> <*> I | etcdmain Go <*> linux/amd64	15
2212	START logs for container etcd of pod <*>	5
2213	WARNING Deprecated <*> capnslog flag is set use <*> zap flag instead	27
2214	<*> <*> <*> <*> I | etcdmain etcd Version <*>	9
2215	<*> <*> <*> <*> I | etcdmain Git SHA <*>	11
2216	<*> <*> <*> <*> I | etcdmain Go Version <*>	13
2217	<*> <*> <*> <*> I | etcdmain setting maximum number of CPUs to <*> total number of available CPUs is <*>	14
2218	<*> <*> <*> <*> I | embed peerTLS cert <*> key <*> <*> <*> <*> true crl-file	22
2219	<*> <*> <*> <*> I | embed name <*>	24
2220	<*> <*> <*> <*> I | embed data dir <*>	25
2221	<*> <*> <*> <*> I | embed member dir <*>	25
2222	<*> <*> <*> <*> I | embed heartbeat <*>	25
2223	<*> <*> <*> <*> I | embed election <*>	25
2224	<*> <*> <*> <*> I | embed snapshot count <*>	25
2225	<*> <*> <*> <*> I | embed advertise client URLs https <*> <*>	25
2226	<*> <*> <*> <*> I | etcdserver starting member <*> in cluster <*>	14
2227	<*> <*> <*> <*> INFO <*> switched to configuration voters	14
2228	<*> <*> <*> <*> INFO <*> became <*> at term 0	14
2229	<*> <*> <*> <*> INFO newRaft <*> peers term 0 commit 0 applied 0 lastindex 0 lastterm 0	14
2230	<*> <*> <*> <*> W | auth simple token is not cryptographically signed	25
2231	<*> <*> <*> <*> I | rafthttp started HTTP pipelining with peer <*>	74
2232	Probing CSI driver for readiness	25
2233	Controller detected that zone <*>   az4 is now in state Normal.	11
2234	Error creating spec for volume <*> pod wordpress <*> <*> error processing PVC wordpress <*> <*> PVC <*> has non-bound phase Pending or empty pvc.Spec.VolumeName	11
2235	Error creating spec for volume data pod wordpress <*> <*> error processing PVC wordpress <*> <*> PVC <*> has non-bound phase Pending or empty pvc.Spec.VolumeName	11
2236	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name speaker GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app metallb component speaker Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations labels app metallb component speaker name speaker namespace <*> spec selector matchLabels app metallb component speaker template metadata annotations <*> <*> <*> true labels app metallb component speaker spec containers args <*> <*> <*> config env name METALLB_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name METALLB_HOST valueFrom fieldRef fieldPath status.hostIP name METALLB_ML_BIND_ADDR valueFrom fieldRef fieldPath status.podIP name METALLB_ML_LABELS value app metallb component speaker name METALLB_ML_NAMESPACE valueFrom fieldRef fieldPath metadata.namespace name METALLB_ML_SECRET_KEY valueFrom secretKeyRef key secretkey name memberlist image <*> main imagePullPolicy Always name speaker ports containerPort <*> name monitoring resources limits cpu <*> memory <*> securityContext allowPrivilegeEscalation false capabilities add NET_ADMIN NET_RAW SYS_ADMIN drop ALL readOnlyRootFilesystem true hostNetwork true nodeSelector <*> linux serviceAccountName speaker terminationGracePeriodSeconds <*> tolerations effect NoSchedule key <*> n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager kubectl Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app metallb component speaker Annotations map string string <*> <*> <*> true OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> nil InitContainers <*> nil Containers <*> <*> Name speaker Image <*> main Command string nil Args string <*> <*> <*> config WorkingDir Ports <*> <*> Name monitoring HostPort <*> ContainerPort <*> Protocol TCP HostIP EnvFrom <*> nil Env <*> <*> Name METALLB_NODE_NAME Value ValueFrom <*> <*> <*> Name METALLB_HOST Value ValueFrom <*> <*> <*> Name METALLB_ML_BIND_ADDR Value ValueFrom <*> <*> <*> Name METALLB_ML_LABELS Value app metallb component speaker ValueFrom <*> nil <*> Name METALLB_ML_NAMESPACE Value ValueFrom <*> <*> <*> Name METALLB_ML_SECRET_KEY Value ValueFrom <*> <*> Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format BinarySI Requests <*> nil VolumeMounts <*> nil VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy Always SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string <*> linux ServiceAccountName speaker DeprecatedServiceAccount speaker AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> nil SchedulerName <*> Tolerations <*> <*> Key <*> Operator Value Effect NoSchedule TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable <*> CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> speaker the object has been modified please apply your changes to the latest version and try again	11
2237	CSI driver supports ControllerPublishUnpublish using real CSI handler	8
2238	Service handler initialized via as DBus type dbus svc portworx-reboot.service id <*>	23
2239	Waited for <*> due to <*> throttling not priority and fairness request GET https <*> <*> <*> resourceVersion 0	11
2240	This node is starting with leadership of the cluster	7
2241	START logs for container kube-vip of pod <*>	4
2242	FLAG <*> false	214
2243	<*> <*> <*> <*> I | rafthttp starting peer <*>	54
2244	Beginning cluster membership namespace <*> lock name <*> id <*>	5
2245	<*> version VERSION	4
2246	Node <*> is assuming leadership of the cluster	23
2247	END logs for container coredns of pod <*>	3
2248	FLAG <*> <*>	622
2249	start dhcp client for ddns	7
2250	waiting for ip from dhcp	8
2251	<*> <*> <*> <*> N | etcdmain the server is already initialized as member before starting as etcd member...	8
2252	<*> <*> <*> <*> eth0 sending Discover	9
2253	FLAG <*>	434
2254	<*> <*> <*> <*> eth0 received Offer	11
2255	Service portworx.service not yet active	22
2256	<*> <*> <*> <*> eth0 sending Request	11
2257	Loaded <*> mutating admission controller s successfully in the following order NamespaceLifecycle LimitRanger ServiceAccount NodeRestriction TaintNodesByCondition AlwaysPullImages PodSecurityPolicy Priority DefaultTolerationSeconds DefaultStorageClass StorageObjectInUseProtection RuntimeClass DefaultIngressClass MutatingAdmissionWebhook.	39
2258	<*> <*> <*> <*> I | rafthttp started streaming with peer <*> writer	108
2259	Flag <*> has been deprecated This flag has no effect now and will be removed in <*>	7
2260	external host was not specified using <*>	9
2261	Starting CSI attacher	11
2262	Got initial config snapshot	7
2263	<*> <*> <*> <*> eth0 received Ack	11
2264	Activating <*>	23
2265	Loaded <*> validating admission controller s successfully in the following order LimitRanger ServiceAccount AlwaysPullImages PodSecurityPolicy Priority PersistentVolumeClaimResize RuntimeClass CertificateApproval CertificateSigning CertificateSubjectRestriction ValidatingAdmissionWebhook ResourceQuota.	43
2266	Loaded configuration from environment config config.Config LogLevel info WorkloadEndpointWorkers <*> ProfileWorkers <*> PolicyWorkers <*> NodeWorkers <*> Kubeconfig DatastoreType kubernetes	3
2267	CRD actionapprovals.autopilot.libopenstorage.org updated successfully. file actionapproval.go <*>	6
2268	Ensuring Calico datastore is initialized	5
2269	START logs for container autopilot of pod <*>	1
2270	Starting autopilot version <*> file main.go <*>	2
2271	using params url http <*> <*> for provider prometheus file main.go <*>	3
2272	CRD autopilotrules.autopilot.libopenstorage.org updated successfully. file rule.go <*>	4
2273	CRD autopilotruleobjects.autopilot.libopenstorage.org updated successfully. file rule.go <*>	5
2274	Using rule engine <*> file rule.go <*>	7
2275	Using cool down period of <*> seconds. file engine.go <*>	8
2276	Using minimum poll period of <*> seconds. file engine.go <*>	9
2277	<*> <*> <*> <*> I | rafthttp started peer <*>	54
2278	<*> <*> <*> <*> I | rafthttp added peer <*>	54
2279	<*> <*> <*> <*> I | etcdserver starting server... version <*> cluster version to_be_decided	14
2280	<*> <*> <*> <*> I | rafthttp started streaming with peer <*> stream MsgApp <*> reader	54
2281	<*> <*> <*> <*> I | rafthttp started streaming with peer <*> stream Message reader	54
2282	<*> <*> <*> <*> I | embed ClientTLS cert <*> key <*> <*> <*> <*> true crl-file	25
2283	<*> <*> <*> <*> I | embed listening for peers on <*> <*>	25
2284	<*> <*> <*> <*> I | rafthttp peer <*> became active	43
2285	Getting initial config snapshot from datastore	6
2286	got ip from dhcp <*>	11
2287	Using http <*> <*> as endpoint for portworx REST API file connection.go <*>	626
2288	Starting status report routine	9
2289	Using <*> <*> as endpoint for portworx gRPC API file connection.go <*>	626
2290	Starting Prometheus metrics server on port <*>	10
2291	Starting controller ControllerType Node	11
2292	Starting Node controller	12
2293	START logs for container cluster-management-agent of pod <*>	2
2294	START logs for container node-agent of pod <*>	1
2295	Generated self-signed cert <*> <*>	3
2296	Initializing Nats connection with url tls <*> <*> <*> tls <*> <*> <*> cluster <*>	11
2297	Portworx service is ACTIVE	23
2298	Running ansible task <*>	5
2299	<*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream MsgApp <*> writer	46
2300	starting the DNS updater for the address <*>	11
2301	REST Changing install-state ST_INSTALL <*> ST_FINISH	23
2302	syncing licenses file portworx.go <*> fn syncLicenses	715
2303	Starting serving-cert <*> <*>	20
2304	Serving securely on <*>	51
2305	settin webhook	9
2306	Registering a mutating webhook GVK Group <*> Version <*> Kind PodPreset path <*>	11
2307	Start tailing portworx.service logs	23
2308	<*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream Message writer	46
2309	grpc addrConn.createTransport failed to connect to https <*> <*> <nil> 0 <nil> . Err connection error desc transport Error while dialing dial tcp <*> <*> connect connection refused . Reconnecting...	36
2310	skipping action approval watcher <*> due to config for provider <*> is not provided. Github SCM provider requires additional configuration. Refer to Autopilot documentation. file main.go <*>	11
2311	Broadcasting ARP update for <*> <*> <*> <*> b6 <*> <*> via eth0	657
2312	<*> <*> <*> <*> I | embed listening for metrics on http <*> <*>	25
2313	> Starting local log-tailer	23
2314	<*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream Message reader	46
2315	verified action approval watcher <*> file main.go <*>	11
2316	setting <*> as an IP	662
2317	Node controller syncer status updated <*>	19
2318	<*> <*> <*> <*> no error handler specified with the subscriber. going with default error handler	12
2319	Registering a validating webhook GVK Group <*> Version <*> Kind PodPreset path <*>	11
2320	Starting http server to serve metrics at port <*> endpoint <*> file server.go <*>	11
2321	END logs for container stork of pod <*>	4
2322	> <*> <*> <*> <*> @ <*> <*> portworx.service <*> portworx-output.service <*> init.scope <*> <*> <*> <*>	22
2323	<*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream MsgApp <*> reader	46
2324	<*> <*> <*> <*> Listening on <*>	12
2325	Executing command chmod +x set-env.sh bash set-env.sh ansible-playbook <*> chroot <*> inventory playbook.yaml in dir <*>	11
2326	Install done <*> MAIN exiting	23
2327	Setting up handler for user defined signal <*> signal file main.go <*>	11
2328	<*> <*> <*> <*> I | embed initial advertise peer URLs https <*> <*>	11
2329	<*> <*> <*> <*> INFO <*> term 0 received a MsgVote message with higher term from <*> term <*>	11
2330	Registering a mutating webhook GVK Group <*> Version <*> Kind ClusterPodPreset path <*>	11
2331	Executing command <*> +x set-env.sh	11
2332	<*> Flushing logs for PID <*> <*> lines <*>	22
2333	<*> <*> <*> <*> I | embed initial cluster	11
2334	Failed to scrape node err Get https <*> <*> true read tcp <*> <*> <*> read connection reset by peer node <*>	2
2335	failed to check if actions <*> <*> are licensed due to Head http <*> <*> AUTCapacityManagement dial tcp <*> <*> connect connection refused file portworx.go <*> fn syncLicenses	715
2336	<*> <*> <*> <*> INFO <*> became <*> at term <*>	127
2337	<*> <*> <*> <*> I | etcdserver recovered store from snapshot at index <*>	11
2338	Executing command <*> set-env.sh	11
2339	<*> Start tailing the logs for portworx.service portworx-output.service init.scope <*>	23
2340	<*> <*> <*> <*> I | mvcc restore compact to <*>	36
2341	actions <*> <*> for feature AUTCapacityManagement are not licensed. file portworx.go <*>	715
2342	<*> name Configure chroot	11
2343	<*> <*> <*> <*> INFO <*> logterm 0 index 0 vote 0 cast MsgVote for <*> logterm <*> index <*> at term <*>	11
2344	<*> portworx <*> found <*>	47
2345	Event occurred object <*> kind Endpoints apiVersion <*> type Warning reason FailedToUpdateEndpoint message Failed to update endpoint <*> Operation cannot be fulfilled on endpoints <*> the object has been modified please apply your changes to the latest version and try again	23
2346	Registering a validating webhook GVK Group <*> Version <*> Kind ClusterPodPreset path <*>	11
2347	Scraping all the objects from the system. file engine.go <*> component <*>	616
2348	<*> <*> <*> <*> I | etcdserver restarting member <*> in cluster <*> at commit index <*>	11
2349	FLAG <*> vsphere	22
2350	<*> portworx <*> Using <*>	23
2351	hosts chroots	11
2352	grpc addrConn.createTransport failed to connect to https <*> <*> <nil> 0 <nil> . Err connection error desc transport authentication handshake failed read tcp <*> <*> <*> read connection reset by peer . Reconnecting...	4
2353	<*> <*> <*> <*> INFO raft.node <*> <*> leader <*> at term <*>	86
2354	Node controller syncer status updated resync	12
2355	<*> <*> <*> <*> INFO <*> switched to configuration voters <*>	33
2356	user root	11
2357	<*> portworx <*> Creating px fs...	23
2358	<*> <*> <*> <*> I | rafthttp receiving database snapshot index <*> from <*> raft message size <*> kB	14
2359	FLAG <*> kubernetes	22
2360	<*> portworx <*> Checking alternate paths please wait...	11
2361	connection chroot	11
2362	Using reconciler lease	14
2363	<*> <*> <*> <*> I | snap saved database snapshot to disk total bytes <*>	14
2364	failed to create node client to check pool expansion status. err error connecting to GRPC server <*> <*> Connection timed out file portworx.go <*>	614
2365	<*> <*> <*> <*> INFO newRaft <*> peers <*> term <*> commit <*> applied <*> lastindex <*> lastterm <*>	11
2366	<*> portworx <*> Failed to build PX filesystem dependency...	11
2367	<*> <*> <*> <*> I | rafthttp successfully received and saved database snapshot index <*> from <*> raft message size <*> kB db size <*> MB took <*>	14
2368	<*> <*> <*> <*> I | etcdserver/api enabled capabilities for version <*>	25
2369	FLAG <*> true	88
2370	<*> portworx <*> Downloading from https <*>	22
2371	vars	11
2372	Failed to scrape all the objects from the system error connecting to GRPC server <*> <*> Connection timed out file engine.go <*> component <*>	613
2373	<*> <*> <*> <*> INFO log committed 0 applied 0 unstable.offset <*> len unstable.Entries 0 starts to restore snapshot index <*> term <*>	14
2374	<*> <*> <*> <*> I | etcdserver/membership added member <*> https <*> <*> to cluster <*> from store	45
2375	apt_distro buster	11
2376	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg Initializing k8sOrchestratorInstance TraceId <*>	11
2377	<*> <*> <*> <*> INFO <*> switched to configuration voters <*> <*>	22
2378	<*> <*> <*> <*> INFO <*> commit <*> lastindex <*> lastterm <*> restored snapshot index <*> term <*>	14
2379	<*> <*> <*> <*> I | etcdserver/membership set the cluster version to <*> from store	25
2380	FLAG <*> 0s	44
2381	Event occurred object <*> kind ReplicaSet apiVersion <*> type Warning reason FailedCreate message Error creating Internal error occurred failed calling webhook <*> Post https <*> <*> <*> EOF	22
2382	<*> portworx <*> checking local archive please wait...	11
2383	successfully synced all hostendpoints	6
2384	<*> <*> <*> <*> INFO <*> commit <*> restored snapshot index <*> term <*>	14
2385	level info time <*> <*> <*> caller <*> <*> msg k8s client using in-cluster config TraceId <*>	33
2386	tasks	11
2387	END logs for container cluster-management-agent of pod <*>	2
2388	got pod namespace <*>	22
2389	<*> portworx <*> Failed to load PX filesystem dependencies for kernel <*>	11
2390	<*> <*> <*> <*> I | etcdserver applying snapshot at index 0...	14
2391	Node controller is now running	5
2392	level info time <*> <*> <*> caller <*> <*> msg Setting client QPS to <*> and Burst to <*> TraceId <*>	33
2393	sync <*> failed with Internal error occurred failed calling webhook <*> Post https <*> <*> <*> EOF	22
2394	<*> name Distribution	22
2395	<*> systemd <*> portworx.service Main process exited code exited status <*>	13
2396	got podpresets podpresetlist kind PodPreset apiVersion <*> metadata name proxy namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	22
2397	<*> <*> <*> <*> I | etcdserver raft applied incoming snapshot at index <*>	14
2398	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg New internal feature states values stored successfully map <*> false TraceId <*>	11
2399	Synchronizing IPAM data	15
2400	<*> <*> <*> <*> I | etcdserver starting server... version <*> cluster version <*>	11
2401	<*> <*> <*> <*> I | etcdserver recovering lessor...	14
2402	ansible_os_family	22
2403	got filtered podpresets filteredpodpreset kind PodPreset apiVersion <*> metadata name proxy namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	22
2404	<*> systemd <*> portworx.service Failed with result exit-code .	13
2405	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg k8sOrchestratorInstance initialized TraceId <*>	11
2406	sync <*> failed with Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	747
2407	<*> <*> <*> <*> I | etcdserver finished recovering lessor	14
2408	namespaced env env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	22
2409	<*> <*> <*> <*> I | etcdserver <*> as single-node fast-forwarding <*> ticks election ticks <*>	11
2410	Node and IPAM data is in sync	14
2411	FLAG <*> 0	66
2412	ansible_distribution	22
2413	<*> <*> <*> <*> I | etcdserver restoring mvcc store...	14
2414	Event occurred object <*> kind ReplicaSet apiVersion <*> type Warning reason FailedCreate message Error creating Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	746
2415	namespaced volumes volumes null	65
2416	<*> systemd <*> Stopping Portworx FIFO logging reader...	15
2417	level info time <*> <*> <*> caller <*> <*> msg Initializing CNS controller TraceId <*>	11
2418	<*> name Distribution version	11
2419	<*> systemd <*> Stopped Portworx FIFO logging reader.	15
2420	ansible_distribution_version	22
2421	<*> <*> <*> <*> I | etcdserver finished restoring mvcc store	14
2422	<*> systemd <*> Closed Portworx logging FIFO.	15
2423	got clusterpodpresets clusterpodpresetlist kind ClusterPodPreset apiVersion <*> metadata name proxy uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> <*> apiVersion <*> kind ClusterPodPreset metadata annotations name proxy spec env metadata merge_strategy append separator type multi name NO_PROXY value <*> localhost <*> kubernetes <*> <*> <*> <*> <*> <*> <*> metadata merge_strategy append separator type multi name no_proxy value <*> localhost <*> kubernetes <*> <*> <*> <*> <*> <*> <*> metadata merge_strategy append separator type multi name USER_NO_PROXY value <*> <*> <*> metadata merge_strategy replace separator type single name HTTP_PROXY value http <*> <*> metadata merge_strategy replace separator type single name http_proxy value http <*> <*> metadata merge_strategy replace separator type single name HTTPS_PROXY value http <*> <*> metadata merge_strategy replace separator type single name https_proxy value http <*> <*> selector matchLabels <*> proxy n managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace	31
2424	<*> name Distribution major version	11
2425	<*> <*> <*> <*> I | etcdserver recovering alarms...	14
2426	<*> <*> <*> <*> I | etcdserver/membership added member <*> https <*> <*> to cluster <*>	14
2427	got filtered clusterpodpreset filteredclusterpodpreset kind ClusterPodPreset apiVersion <*> metadata name proxy uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> <*> apiVersion <*> kind ClusterPodPreset metadata annotations name proxy spec env metadata merge_strategy append separator type multi name NO_PROXY value <*> localhost <*> kubernetes <*> <*> <*> <*> <*> <*> <*> metadata merge_strategy append separator type multi name no_proxy value <*> localhost <*> kubernetes <*> <*> <*> <*> <*> <*> <*> metadata merge_strategy append separator type multi name USER_NO_PROXY value <*> <*> <*> metadata merge_strategy replace separator type single name HTTP_PROXY value http <*> <*> metadata merge_strategy replace separator type single name http_proxy value http <*> <*> metadata merge_strategy replace separator type single name HTTPS_PROXY value http <*> <*> metadata merge_strategy replace separator type single name https_proxy value http <*> <*> selector matchLabels <*> proxy n managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace	30
2428	id <namespace <*> name autopilot-account > labels <key <*> value autopilot-account >	165
2429	<*> <*> <*> <*> I | etcdserver closing old backend...	14
2430	<*> <*> <*> <*> I | etcdserver finished recovering alarms	14
2431	ansible_distribution_major_version	22
2432	<*> systemd <*> <*> Consumed <*> CPU time	143
2433	cluster env env name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append	11
2434	<*> <*> <*> <*> I | etcdserver recovering auth store...	14
2435	cluster volumes volumes null	55
2436	level info time <*> <*> <*> caller volume/manager.go <*> msg Initializing new volume.defaultManager... TraceId <*>	11
2437	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg New feature states values from <*> stored successfully map <*> false TraceId <*>	22
2438	level info time <*> <*> <*> caller node/manager.go <*> msg Initializing node.defaultManager... TraceId <*>	11
2439	level info time <*> <*> <*> caller node/manager.go <*> msg node.defaultManager initialized TraceId <*>	11
2440	level info time <*> <*> <*> caller <*> <*> msg Adding watch on path <*> TraceId <*>	11
2441	<*> name Include amazon os family changes	11
2442	level info time <*> <*> <*> caller service/service.go <*> msg configured <*> with clusterFlavor VANILLA and mode controller TraceId <*>	11
2443	include_tasks <*>	11
2444	<*> <*> <*> <*> I | etcdserver finished recovering auth store	14
2445	Could not retrieve PX node status error Get http <*> <*> dial tcp <*> <*> connect connection refused	724
2446	when ansible_facts distribution Amazon	11
2447	<*> <*> <*> <*> I | etcdserver recovering store v2...	14
2448	controller service registered	11
2449	merged env merged env name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> metadata type multi separator merge_strategy append	11
2450	merged volumes merged volumes null	25
2451	level info time <*> <*> <*> caller node/manager.go <*> msg Successfully registered node <*> with nodeUUID <*> TraceId <*>	33
2452	<*> <*> <*> <*> I | etcdserver/membership removed member <*> from cluster <*>	28
2453	<*> <*> <*> <*> E | etcdserver the member has been permanently removed from the cluster	11
2454	<*> name Include centos/debian os family changes	11
2455	id <namespace <*> name px-account > labels <key <*> value px-account >	132
2456	<*> <*> <*> <*> I | etcdserver finished closing old backend	14
2457	FLAG <*> endpointsleases	22
2458	merged volume mounts merged volume mounts null	24
2459	include_tasks <*> ansible_os_family <*>	11
2460	<*> <*> <*> <*> I | etcdserver finished recovering store <*>	14
2461	<*> <*> <*> <*> I | etcdserver the <*> used by this member must be removed.	10
2462	<*> <*> <*> <*> I | etcdserver aborting publish because server is stopped	9
2463	got pod namespace cert-manager	11
2464	when ansible_facts distribution ! Amazon	11
2465	<*> <*> <*> <*> I | etcdserver recovering cluster configuration...	14
2466	<*> <*> <*> <*> I | rafthttp stopping peer <*>	45
2467	got podpresets podpresetlist kind PodPreset apiVersion <*> metadata name proxy namespace cert-manager uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	11
2468	#data is added with extra tab identation to match identation with playbook.yaml	11
2469	environment	11
2470	got filtered podpresets filteredpodpreset kind PodPreset apiVersion <*> metadata name proxy namespace cert-manager uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	11
2471	<*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> writer	87
2472	http_proxy ansible_env.http_proxy	11
2473	<*> <*> <*> <*> I | rafthttp stopped HTTP pipelining with peer <*>	42
2474	namespaced env env name no_proxy value <*> metadata type multi separator merge_strategy append name NO_PROXY value <*> metadata type multi separator merge_strategy append	11
2475	<*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> stream MsgApp <*> reader	41
2476	HTTP_PROXY ansible_env.HTTP_PROXY	11
2477	level info time <*> <*> <*> caller node/manager.go <*> msg Successfully discovered node with nodeUUID <*> in vm VirtualMachine <*> VirtualCenterHost <*> UUID <*> Datacenter Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> TraceId <*>	33
2478	<*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> stream Message reader	40
2479	HTTPS_PROXY ansible_env.HTTPS_PROXY	11
2480	<*> <*> <*> <*> I | etcdserver finished recovering cluster configuration	14
2481	level info time <*> <*> <*> caller node/manager.go <*> msg Successfully discovered node <*> with nodeUUID <*> TraceId <*>	33
2482	<*> <*> <*> <*> I | rafthttp stopped peer <*>	39
2483	id <name portworx > labels <key <*> value portworx > labels <key <*> value portworx >	33
2484	<*> <*> <*> <*> I | etcdserver removing old peers from network...	14
2485	END logs for container etcd of pod <*>	5
2486	https_proxy ansible_env.https_proxy	11
2487	<*> <*> <*> <*> I | rafthttp closed the TCP streaming connection with peer <*> stream MsgApp <*> writer	37
2488	<*> <*> <*> <*> I | rafthttp closed the TCP streaming connection with peer <*> stream Message writer	37
2489	NO_PROXY ansible_env.NO_PROXY	11
2490	id <namespace <*> name stork-account > labels <key <*> value stork-account >	143
2491	no_proxy ansible_env.no_proxy	11
2492	cluster env env name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace	11
2493	Executing command <*> <*> chroot <*> inventory playbook.yaml	11
2494	<*> <*> <*> <*> W | rafthttp <*> the TCP streaming connection with peer <*> stream MsgApp <*> reader	40
2495	id <namespace portworx name default > labels <key <*> value default >	143
2496	PLAY Configure chroot	11
2497	<*> <*> <*> <*> E | rafthttp failed to read <*> on stream MsgApp <*> context canceled	18
2498	<*> <*> <*> <*> I | rafthttp peer <*> became inactive message send to peer failed	34
2499	merged env merged env name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace	15
2500	TASK Gathering Facts gather_subset all gather_timeout <*>	11
2501	ok <*>	22
2502	ok <*> >	44
2503	msg Debian	11
2504	msg Ubuntu	11
2505	msg <*>	22
2506	TASK Include amazon os family changes <*> <*>	11
2507	skipping <*>	11
2508	TASK Include centos/debian os family changes <*> <*> ansible_os_family <*>	11
2509	<*> <*> <*> <*> W | rafthttp <*> the TCP streaming connection with peer <*> stream Message reader	40
2510	included <*> for <*>	11
2511	File exists <*> Copy over	12
2512	TASK Check version before upgrade <*> lsb_release <*>	11
2513	changed <*>	76
2514	<*> <*> <*> <*> I | rafthttp removed peer <*>	37
2515	the default service ipfamily for this cluster is IPv4	14
2516	TASK Remove <*> if it is installed <*> apt remove <*> <*>	11
2517	Health of component changed lastReport health.HealthReport Live true Ready false name async_calc_graph newReport health.HealthReport Live true Ready true	47
2518	fatal <*> FAILED! > changed true cmd apt remove <*> <*> delta 0 <*> <*> end <*> <*> <*> <*> msg <*> return code rc <*> start <*> <*> <*> <*> stderr nWARNING apt does not have a stable CLI interface. Use with caution in scripts. n nTerminated stderr_lines WARNING apt does not have a stable CLI interface. Use with caution in scripts. Terminated stdout Reading package lists... nBuilding dependency tree... nReading state information... nPackage <*> is not installed so not removed n0 upgraded 0 newly installed 0 to remove and <*> not upgraded. <*> not fully installed or removed. nAfter this operation 0 B of additional disk space will be used. nSetting up rpcbind <*> ... r nSetting up <*> <*> <*> ... r ndebconf unable to initialize frontend Dialog r ndebconf TERM is not set so the dialog frontend is not usable. r ndebconf falling back to frontend Readline r n r nCreating config file <*> with new version r ndebconf unable to initialize frontend Dialog r ndebconf TERM is not set so the dialog frontend is not usable. r ndebconf falling back to frontend Readline r nAdding system user `statd UID <*> ... r nAdding new user `statd UID <*> with group `nogroup ... r nNot creating home directory <*> . r nCreated symlink <*> → <*> r nCreated symlink <*> → <*> r <*> is a disabled or a static unit not starting it. r nSetting up <*> <*> <*> ... r ndebconf unable to initialize frontend Dialog r ndebconf TERM is not set so the dialog frontend is not usable. r ndebconf falling back to frontend Readline r nModified configuration file r <*> r n r nexports A new version <*> of r nconfiguration file <*> is available but the version installed r ncurrently has been locally modified. r n r n <*> install the package maintainer s version r n <*> keep the local version currently installed r n <*> show the differences between the versions r n <*> show a <*> difference between the versions r n <*> start a new shell to examine the situation r n r nWhat do you want to do about modified configuration file exports? stdout_lines Reading package lists... Building dependency tree... Reading state information... Package <*> is not installed so not removed 0 upgraded 0 newly installed 0 to remove and <*> not upgraded. <*> not fully installed or removed. After this operation 0 B of additional disk space will be used. Setting up rpcbind <*> ... Setting up <*> <*> <*> ... debconf unable to initialize frontend Dialog debconf TERM is not set so the dialog frontend is not usable. debconf falling back to frontend Readline Creating config file <*> with new version debconf unable to initialize frontend Dialog debconf TERM is not set so the dialog frontend is not usable. debconf falling back to frontend Readline Adding system user `statd UID <*> ... Adding new user `statd UID <*> with group `nogroup ... Not creating home directory <*> . Created symlink <*> → <*> Created symlink <*> → <*> <*> is a disabled or a static unit not starting it. Setting up <*> <*> <*> ... debconf unable to initialize frontend Dialog debconf TERM is not set so the dialog frontend is not usable. debconf falling back to frontend Readline Modified configuration file <*> exports A new version <*> of configuration file <*> is available but the version installed currently has been locally modified. <*> install the package maintainer s version <*> keep the local version currently installed <*> show the differences between the versions <*> show a <*> difference between the versions <*> start a new shell to examine the situation What do you want to do about modified configuration file exports?	11
2519	...ignoring	33
2520	<*> <*> <*> <*> I | etcdserver finished removing old peers from network	14
2521	level info time <*> <*> <*> caller <*> <*> msg ControllerGetCapabilities called with args XXX_NoUnkeyedLiteral XXX_unrecognized XXX_sizecache 0 TraceId <*>	33
2522	<*> <*> <*> <*> I | etcdserver adding peers from new cluster configuration into network...	14
2523	TASK Remove <*> if it is installed <*> sudo apt-key adv <*> <*> <*> <*>	22
2524	cluster env env name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append	7
2525	<*> <*> <*> <*> I | etcdserver finished adding peers from new cluster configuration into network...	14
2526	<*> <*> <*> <*> I | etcdserver finished applying incoming snapshot at index <*>	14
2527	<*> <*> <*> <*> I | etcdserver published Name <*> ClientURLs https <*> <*> to cluster <*>	14
2528	<*> <*> <*> <*> I | embed ready to serve client requests	28
2529	<*> <*> <*> <*> I | embed serving client requests on <*> <*>	28
2530	<*> <*> <*> <*> I | embed rejected connection from <*> <*> error EOF ServerName	60
2531	fatal <*> FAILED! > changed true cmd sudo apt-key adv <*> <*> <*> <*> delta 0 <*> <*> end <*> <*> <*> <*> msg <*> return code rc <*> start <*> <*> <*> <*> stderr Warning apt-key output should not be parsed stdout is not a terminal ngpg keyserver receive failed Connection timed out stderr_lines Warning apt-key output should not be parsed stdout is not a terminal gpg keyserver receive failed Connection timed out stdout Executing <*> <*> <*> <*> <*> stdout_lines Executing <*> <*> <*> <*> <*>	22
2532	<*> systemd <*> Started libcontainer container <*>	374
2533	Hit error connecting to datastore <*> retry error etcdserver request timed out	11
2534	level info time <*> <*> <*> caller <*> <*> msg Starting container with operation mode METADATA_SYNC TraceId <*>	11
2535	<*> <*> <*> <*> I | mvcc store.index compact <*>	68
2536	<*> <*> <*> <*> I | mvcc finished scheduled compaction at <*> took <*>	68
2537	<*> <*> <*> <*> I | etcdserver/api/etcdhttp <*> OK status code <*>	1983
2538	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result range_response_count 0 size <*> took too long <*> to execute	330
2539	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error context canceled took too long <*> to execute	88
2540	WARNING <*> <*> <*> <*> grpc <*> failed to write status connection error desc transport is closing	143
2541	<*> <*> <*> <*> W | wal sync duration of <*> expected less than <*>	88
2542	<*> <*> <*> <*> INFO <*> logterm <*> index <*> vote <*> ignored MsgVote from <*> logterm <*> index <*> at term <*> lease is not expired remaining ticks <*>	33
2543	<*> <*> <*> <*> INFO <*> is starting a new election at term <*>	44
2544	level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg Initializing MetadataSyncer	11
2545	level info time <*> <*> <*> caller <*> <*> msg k8s client using in-cluster config	22
2546	TASK Make a copy of security repos <*> cat <*> | grep secu > <*>	11
2547	TASK Wait for APT Lock before doing update <*> while fuser <*> <*> 2> <*> do sleep <*> done	11
2548	level info time <*> <*> <*> caller <*> <*> msg Setting client QPS to <*> and Burst to <*>	22
2549	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg Initializing k8sOrchestratorInstance	11
2550	<*> <*> <*> <*> INFO <*> received MsgVoteResp from <*> at term <*>	58
2551	TASK Update apt-get repo and cache update_cache yes force_apt_get yes cache_valid_time <*>	11
2552	<*> <*> <*> <*> INFO <*> logterm <*> index <*> sent MsgVote request to <*> at term <*>	47
2553	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg New internal feature states values stored successfully map <*> false	11
2554	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg k8sOrchestratorInstance initialized	11
2555	level info time <*> <*> <*> caller <*> <*> msg Defaulting timeout for vCenter Client to <*> minutes	11
2556	TASK List upgradable packages <*> apt-get <*> upgrade	11
2557	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Initializing defaultVirtualCenterManager...	11
2558	<*> <*> <*> <*> INFO <*> received MsgVoteResp rejection from <*> at term <*>	33
2559	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully initialized defaultVirtualCenterManager	11
2560	TASK Exclude kubeadm kubelet kubectl packages from upgrades <*> apt-mark hold kubeadm kubectl kubelet <*>	11
2561	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully registered VC <*>	11
2562	<*> <*> <*> <*> INFO <*> has received <*> MsgVoteResp votes and <*> vote rejections	33
2563	Version <*> Format %h	22
2564	<*> <*> <*> <*> INFO <*> term <*> received a MsgVote message with higher term from <*> term <*>	24
2565	level info time <*> <*> <*> caller vsphere/virtualcenter.go <*> msg New session ID for VSPHERE.LOCAL arvind <*>	11
2566	TASK Install security updates <*> apt-get upgrade <*> Dir Etc SourceList <*> <*> Dpkg Options <*> <*> Dpkg Options <*> <*>	11
2567	level info time <*> <*> <*> caller volume/manager.go <*> msg Initializing new volume.defaultManager...	11
2568	ReadCPIConfigYAML failed yaml unmarshal errors	22
2569	<*> <*> <*> <*> INFO <*> logterm <*> index <*> vote 0 cast MsgVote for <*> logterm <*> index <*> at term <*>	24
2570	level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg Adding watch on path <*>	11
2571	<*> systemd <*> <*> Consumed <*> <*> CPU time	11
2572	line <*> cannot unmarshal !!seq into config.CPIConfigYAML	22
2573	level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg Initialized metadata syncer	11
2574	ReadConfig INI succeeded. CPI <*> <*> is deprecated and will be removed in <*> Please use YAML based <*>	22
2575	TASK Check version after upgrade <*> lsb_release <*>	11
2576	level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg fullSync is triggered TraceId <*>	11
2577	Config initialized	44
2578	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result range_response_count <*> size <*> took too long <*> to execute	2542
2579	level info time <*> <*> <*> caller <*> <*> msg FullSync start TraceId <*>	11
2580	ReadNsxtConfig failed user or vmc access token or client cert file must be set	22
2581	level warn time <*> <*> <*> caller <*> <*> msg could not find any volume which is present in both k8s and in CNS TraceId <*>	11
2582	Unmarshal failed yaml unmarshal errors	22
2583	PLAY RECAP	8
2584	level info time <*> <*> <*> caller <*> <*> msg FullSync fullSyncDeleteVolumes could not find any volume which is not present in k8s and needs to be checked for volume deletion. TraceId <*>	11
2585	<*> ok <*> changed <*> unreachable 0 failed 0 skipped <*> rescued 0 ignored <*>	7
2586	level info time <*> <*> <*> caller <*> <*> msg FullSync end TraceId <*>	11
2587	line <*> cannot unmarshal !!seq into config.LBConfigYAML	44
2588	ReadConfigYAML failed yaml unmarshal errors	22
2589	Successfully executed command chmod +x set-env.sh bash set-env.sh ansible-playbook <*> chroot <*> inventory playbook.yaml	5
2590	Executing post execution command cat <*> >> <*>	4
2591	ReadConfig INI succeeded. LoadBalancer <*> <*> is deprecated and will be removed in <*> Please use YAML based <*>	22
2592	<*> <*> <*> <*> W | etcdserver/api/etcdhttp <*> error QGET failed etcdserver request timed out status code <*>	33
2593	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error context deadline exceeded took too long <*> to execute	88
2594	Executed post execution command cat <*> >> <*>	3
2595	END logs for container node-agent of pod <*>	1
2596	Detected CSI driver <*>	11
2597	Supports migration from <*> plugin <*>	11
2598	Using saving PVs to API server in background	13
2599	new leader detected current leader <*>	72
2600	became leader starting	20
2601	Starting provisioner controller <*>	5
2602	Starting <*> volume queue	4
2603	Started provisioner controller <*>	3
2604	ReadRouteConfig failed router path is required	22
2605	loaded serving cert Generated self signed cert <*> serving validServingFor <*> localhost localhost issuer <*> <*> <*> <*> <*> <*> UTC to <*> <*> <*> <*> <*> UTC now <*> <*> <*> <*> <*> UTC	47
2606	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	11
2607	loaded SNI cert <*> self-signed loopback <*> serving validServingFor <*> issuer <*> <*> <*> <*> <*> <*> UTC to <*> <*> <*> <*> <*> UTC now <*> <*> <*> <*> <*> UTC	46
2608	<*> systemd <*> Created slice libcontainer container <*>	99
2609	loaded client CA <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes issuer <self> <*> <*> <*> <*> <*> UTC to <*> <*> <*> <*> <*> UTC now <*> <*> <*> <*> <*> UTC	42
2610	Successfully loaded configuration. GOMAXPROCS 4 builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0xc0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	11
2611	... dropped 4 logs ...	11
2612	Could not construct reference to <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string nil Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> HolderIdentity string nil LeaseDurationSeconds <*> nil AcquireTime <*> nil RenewTime <*> nil LeaseTransitions <*> nil due to no kind is registered for the type <*> in scheme <*> <*> . Will not report event Normal LeaderElection <*> became leader	11
2613	<*> <*> <*> <*> W | etcdserver request header <ID <*> username <*> auth_revision <*> > txn <compare <target MOD key <*> mod_revision 0 > success <request_put <key <*> value_size <*> >> failure <>> with result size <*> took too long <*> to execute	11
2614	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result range_response_count <*> size <*> took too long <*> to execute	93
2615	<*> <*> <*> <*> W | etcdserver request header <ID <*> username <*> auth_revision <*> > txn <compare <target MOD key <*> mod_revision <*> > success <request_put <key <*> value_size <*> >> failure <request_range <key <*> > >> with result size <*> took too long <*> to execute	33
2616	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count 0 size <*> took too long <*> to execute	341
2617	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result range_response_count 0 size <*> took too long <*> to execute	772
2618	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count <*> size <*> took too long <*> to execute	234
2619	Event <*> Kind Endpoints Namespace <*> Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason LeaderElection <*> became leader	11
2620	Health of component changed lastReport health.HealthReport Live true Ready false name <*> newReport health.HealthReport Live true Ready true	47
2621	<*> Name tunl0 Addrs set.mapSet <*> set.empty	47
2622	Interface addrs changed. update <*> Name tunl0 Addrs set.mapSet <*> set.empty	47
2623	intdataplane.ifaceUpdate Name tunl0 State up Index <*>	45
2624	bird <*> Initializing	518
2625	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0xc0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	11
2626	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0xc0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	11
2627	bird <*> Starting	570
2628	bird <*> Connected to table master	531
2629	bird <*> State changed to feed	530
2630	bird Graceful restart started	89
2631	bird Graceful restart done	89
2632	bird Started	87
2633	bird <*> State changed to up	534
2634	Overall health status changed newStatus health.HealthReport Live true Ready true	47
2635	pickfirstBalancer HandleSubConnStateChange <*> CONNECTING <nil>	33
2636	grpc addrConn.createTransport failed to connect to <*> <nil> 0 <nil> . Err connection error desc transport Error while dialing dial tcp <*> connect connection refused . Reconnecting...	11
2637	pickfirstBalancer HandleSubConnStateChange <*> TRANSIENT_FAILURE connection error desc transport Error while dialing dial tcp <*> connect connection refused	11
2638	could not getversion rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> connect connection refused	11
2639	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> <*> AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	11
2640	<*> Name <*> Addrs set.mapSet	1075
2641	Interface addrs changed. update <*> Name <*> Addrs set.mapSet	1075
2642	intdataplane.ifaceUpdate Name <*> State up Index <*>	735
2643	END logs for container kube-vip of pod <*>	4
2644	bird Reconfiguration requested by SIGHUP	333
2645	bird Reconfiguring	320
2646	bird <*> Reconfigured	4385
2647	bird Reconfigured	339
2648	Linux interface state changed. ifIndex 6 ifaceName <*> state up	42
2649	intdataplane.ifaceUpdate Name <*> State up Index 6	42
2650	Skipping API <*> because it has no resources.	104
2651	END logs for container portworx of pod <*>	23
2652	Netlink address update. addr fe80 ecee eeff feee eeee exists true ifIndex 6	31
2653	<*> Name <*> Addrs set.mapSet fe80 ecee eeff feee eeee set.empty	784
2654	Interface addrs changed. update <*> Name <*> Addrs set.mapSet fe80 ecee eeff feee eeee set.empty	784
2655	id <name <*> > labels <key control-plane value reach-manager > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value true >	33
2656	Starting AvailableConditionController	14
2657	Waiting for caches to sync for AvailableConditionController controller	14
2658	Starting OpenAPI AggregationController	14
2659	Starting APIServiceRegistrationController	14
2660	Waiting for caches to sync for APIServiceRegistrationController controller	14
2661	Starting API Priority and Fairness config controller	14
2662	pickfirstBalancer HandleSubConnStateChange <*> READY <nil>	22
2663	APIVersion <*>	11
2664	Adding NSXT secret listener failed %vconfig is not available for NSXT connector manager	11
2665	Starting route	11
2666	Will not configure cloud provider routes for <*> false <*> true.	11
2667	Starting cloud-node	11
2668	Starting autoregister controller	14
2669	Waiting for caches to sync for autoregister controller	14
2670	Starting OpenAPI controller	14
2671	Starting NamingConditionController	14
2672	Starting EstablishingController	14
2673	Starting KubernetesAPIApprovalPolicyConformantConditionController	14
2674	Unable to remove old endpoints from kubernetes service StorageError key not found Code <*> Key <*> ResourceVersion 0 AdditionalErrorMsg	14
2675	Caches are synced for autoregister controller	14
2676	Running API Priority and Fairness config worker	14
2677	Caches are synced for APIServiceRegistrationController controller	14
2678	Linux interface state changed. ifIndex 6 ifaceName <*> state down	11
2679	Started cloud-node	11
2680	Caches are synced for AvailableConditionController controller	14
2681	intdataplane.ifaceUpdate Name <*> State down Index 6	11
2682	all system priority classes are created successfully or already exist.	14
2683	Starting service	11
2684	OpenAPI AggregationController action for item Nothing removed from the queue .	14
2685	The vSphere cloud provider does not support load balancers	11
2686	OpenAPI AggregationController action for item <*> Nothing removed from the queue .	14
2687	Resetting endpoints for master service kubernetes to <*> <*>	11
2688	<*> <*> <*> <*> INFO <*> has received <*> MsgVoteResp votes and 0 vote rejections	13
2689	quota admission added evaluator for endpoints	14
2690	<*> <*> <*> <*> INFO <*> became leader at term <*>	12
2691	Netlink address update. addr fe80 ecee eeff feee eeee exists false ifIndex 6	11
2692	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> context deadline exceeded	59
2693	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error etcdserver leader changed took too long <*> to execute	77
2694	<*> Name <*> Addrs set.Set nil	379
2695	This node <*> is registered without the cloud taint. Will not process.	30
2696	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	319
2697	Interface addrs changed. update <*> Name <*> Addrs set.Set nil	379
2698	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result error etcdserver leader changed took too long <*> to execute	11
2699	Trace <*> <*> About to write a response <*> <*> <*> <*>	1144
2700	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	11
2701	Trace <*> GuaranteedUpdate etcd3 type apiregistration.APIService <*> <*> <*> <*> total time <*>	22
2702	Failed to create govmomi client. err ServerFaultCode Cannot complete login due to an incorrect user name or password.	8
2703	Trace <*> <*> Transaction committed <*> <*> <*> <*>	363
2704	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	143
2705	Trace <*> <*> Object stored in database <*> <*> <*> <*>	532
2706	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> dial tcp <*> <*> i/o timeout	37
2707	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	297
2708	Trace <*> GuaranteedUpdate etcd3 type coordination.Lease <*> <*> <*> <*> total time <*>	165
2709	intdataplane.ifaceUpdate Name <*> State down Index <*>	368
2710	<*> <*> <*> <*> W | etcdserver failed to send out heartbeat on time exceeded the <*> timeout for <*> to <*>	11
2711	<*> <*> <*> <*> W | etcdserver server is likely overloaded	11
2712	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers	58
2713	<*> <*> <*> <*> W | etcdserver timed out waiting for read index response local node might have slow network	11
2714	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result error etcdserver request timed out took too long <*> to execute	77
2715	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error etcdserver request timed out took too long <*> to execute	44
2716	quota admission added evaluator for serviceaccounts	11
2717	loading OpenAPI spec for <*> failed with failed to retrieve openAPI spec http error ResponseCode <*> Body error trying to reach service dial tcp <*> <*> i/o timeout	22
2718	Header map Content-Type text/plain charset utf-8 <*> nosniff	133
2719	OpenAPI AggregationController action for item <*> Rate Limited Requeue.	133
2720	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	77
2721	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	110
2722	Linux interface addrs changed. addrs set.mapSet <*> set.empty fe80 <*> <*> feb6 <*> set.empty ifaceName eth0	66
2723	Linux interface state changed. ifIndex 4 ifaceName <*> state up	11
2724	<*> failed with Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	79
2725	intdataplane.ifaceUpdate Name <*> State up Index 4	11
2726	<*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> feb6 <*> set.empty	66
2727	<*> <*> <*> <*> E | rafthttp failed to read <*> on stream Message context canceled	16
2728	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> feb6 <*> set.empty	66
2729	<*> <*> <*> <*> W | rafthttp rejected the stream from peer <*> since it was removed	87
2730	quota admission added evaluator for namespaces	12
2731	id <name wordpress > labels <key <*> value wordpress > labels <key <*> value wordpress >	33
2732	id <namespace wordpress name default > labels <key <*> value default >	385
2733	Trace <*> <*> Request completed <*> <*> <*> <*>	136
2734	Trace <*> GuaranteedUpdate etcd3 type <*> <*> <*> <*> <*> total time <*>	430
2735	Trace <*> Update url <*> user-agent manager/v0.0.0 linux/amd64 <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2736	Trace <*> List etcd3 key /autopilot.libopenstorage.org/autopilotruleobjects resourceVersion resourceVersionMatch limit <*> continue <*> <*> <*> <*> total time <*>	11
2737	Trace <*> List etcd3 key <*> resourceVersion 0 resourceVersionMatch limit <*> continue <*> <*> <*> <*> total time <*>	165
2738	Trace <*> List url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> as PartialObjectMetadataList g <*> v <*> <*> as PartialObjectMetadataList g <*> v <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	176
2739	Trace <*> <*> Listing from storage done <*> <*> <*> <*>	198
2740	Trace <*> <*> initial value restored <*> <*> <*> <*>	176
2741	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	209
2742	Trace <*> <*> About to apply patch <*> <*> <*> <*>	319
2743	watch of <*> ended with too old resource version <*> <*>	27
2744	END logs for container autopilot of pod <*>	1
2745	bird <*> State changed to start	446
2746	bird <*> State changed to wait	231
2747	watch of <*> ended with an error on the server unable to decode an event from the watch stream http2 client connection <*> has prevented the request from succeeding	37
2748	Trace <*> List etcd3 key /autopilot.libopenstorage.org/autopilotruleobjects resourceVersion 0 resourceVersionMatch limit <*> continue <*> <*> <*> <*> total time <*>	11
2749	Trace <*> List url <*> user-agent manager/v0.0.0 linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2750	Trace <*> Get url <*> user-agent manager/v0.0.0 linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	55
2751	Dataplane updates throttled	17
2752	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2753	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2754	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	77
2755	Dataplane updates no longer throttled	17
2756	Syncing routes found unexpected route ignoring due to grace period. dest <*> ifaceName <*> ifaceRegex ^cali. ipVersion <*>	2178
2757	Interface in cleanup grace period will retry after. ifaceName <*> ifaceRegex ^cali. ipVersion <*>	1089
2758	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> accept <*> as PartialObjectMetadata g <*> v <*> <*> as PartialObjectMetadata g <*> v <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	242
2759	Trace <*> Get url <*> user-agent manager/v0.0.0 linux/amd64 <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	110
2760	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2761	apiserver was unable to write a JSON response http Handler timeout	99
2762	apiserver received an error that is not an <*> <*> s http Handler timeout http Handler timeout	99
2763	apiserver was unable to write a fallback JSON response http Handler timeout	99
2764	apiserver received an error that is not an <*> rpctypes.EtcdError code 0xe desc etcdserver leader changed etcdserver leader changed	77
2765	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	66
2766	apiserver received an error that is not an <*> <*> s context canceled context canceled	44
2767	apiserver received an error that is not an <*> rpctypes.EtcdError code 0xe desc etcdserver request timed out etcdserver request timed out	44
2768	Trace <*> GuaranteedUpdate etcd3 type policy.PodSecurityPolicy <*> <*> <*> <*> total time <*>	11
2769	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2770	Failed to report usage/get deprecation warnings. error Get https <*> false alp_policies 0 <*> <*> guid <*> heps 0 k8s_ver <*> policies 0 profiles <*> rev <*> size <*> type <*> version <*> weps <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	80
2771	Resetting endpoints for master service kubernetes to <*>	11
2772	Auditing failed of request encoding failed policy.Eviction is not suitable for converting to <*> in scheme <*> <*>	417
2773	unable to encode watch object <*> write tcp <*> <*> <*> write connection reset by peer <*> writer http2.responseWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	26
2774	Failed calling webhook failing closed <*> failed calling webhook <*> Post https <*> <*> <*> EOF	22
2775	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	737
2776	timeout or abort while handling POST <*>	11
2777	Linux interface addrs changed. addrs set.mapSet fe80 <*> <*> feb6 <*> set.empty ifaceName eth0	11
2778	<*> Name eth0 Addrs set.mapSet fe80 <*> <*> feb6 <*> set.empty	11
2779	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet fe80 <*> <*> feb6 <*> set.empty	11
2780	bird Adding protocol <*>	116
2781	Trace <*> Get url <*> user-agent <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	132
2782	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> endpoint-controller client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2783	Trace <*> GuaranteedUpdate etcd3 type discovery.EndpointSlice <*> <*> <*> <*> total time <*>	22
2784	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> endpointslice-controller client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2785	bird KIF Received address message for unknown interface <*>	76
2786	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2787	Trace <*> Delete url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2788	Trace <*> <*> Object deleted from database <*> <*> <*> <*>	22
2789	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2790	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> deployment-controller client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2791	Trace <*> Get url <*> user-agent <*> <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	4
2792	Trace <*> <*> Transformed response object <*> <*> <*> <*>	4
2793	Start NewCSISnapshotController with kubeconfig resyncPeriod <*>	33
2794	error retrieving resource lock <*> etcdserver leader changed	11
2795	error retrieving resource lock <*> etcdserver request timed out	22
2796	error retrieving resource lock <*> the server was unable to return a response in the time allotted but may still be processing the request get <*> <*>	22
2797	error retrieving resource lock <*> Get https <*> <*> http2 server sent GOAWAY and closed the connection LastStreamID <*> ErrCode NO_ERROR debug	11
2798	Reconfiguring	17
2799	Remove old route dest <*> ifaceName <*> ifaceRegex ^cali. ipVersion <*> routeProblems string unexpected route	88
2800	bird <*> State changed to stop	139
2801	bird <*> State changed to down	139
2802	failed to establish connection to CSI driver context deadline exceeded	11
2803	register maas provider <*>	25
2804	register aws provider <*>	21
2805	register azure provider <*>	23
2806	register vsphere provider	27
2807	register gcp provider <*>	29
2808	register generic provider	31
2809	register openstack provider	33
2810	detect env done spectrocluster Namespace <*> Name <*> env pilot	33581
2811	reconcile on pilot spectrocluster Namespace <*> Name <*>	4807
2812	downloading pack spectrocluster Namespace <*> Name <*> pack <*>	90
2813	create success spectrocluster Namespace <*> Name <*> <*> Pack name <*>	88
2814	pack downloaded spectrocluster Namespace <*> Name <*> <*> <*>	92
2815	skipping atop reconcile loop atop Namespace <*> Name <*> env pilot	4004
2816	create success spectrocluster Namespace <*> Name <*> name <*> <*> Secret	44
2817	Attempting to reconcile CloudFormation stack spectrocluster Namespace <*> Name <*> name <*>	22
2818	aws Error cloudformation spectrocluster Namespace <*> Name <*> code AccessDenied error AccessDenied User arn aws iam <*> <*> is not authorized to perform cloudformation DescribeStacks on resource arn aws cloudformation <*> <*> <*> with an explicit <*> n tstatus code <*> request id <*> region <*>	308
2819	aws Error cloudformation spectrocluster Namespace <*> Name <*> code ValidationError error ValidationError Stack with id <*> does not exist n tstatus code <*> request id <*> region <*>	44
2820	stack found in region spectrocluster Namespace <*> Name <*> region <*> stack <*>	22
2821	updating AWS CloudFormation stack spectrocluster Namespace <*> Name <*> stack <*>	22
2822	crd version info not found creating spectrocluster Namespace <*> Name <*> key Namespace <*> Name <*>	44
2823	installing crd from scopeDir spectrocluster Namespace <*> Name <*> scopeDir <*>	44
2824	starting clusterrolebinding role repair spectrocluster Namespace <*> Name <*> dir <*>	44
2825	applying dir spectrocluster Namespace <*> Name <*> dir <*>	44
2826	apply crd success spectrocluster Namespace <*> Name <*> provider capi	22
2827	unable to parse crd file continue to next error couldn t get version/kind json parse error json cannot unmarshal array into Go value of type struct APIVersion string json apiVersion omitempty Kind string json kind omitempty spectrocluster Namespace <*> Name <*> failed file <*>	22
2828	error spectrocluster Namespace <*> Name <*> message Warning kubectl apply should be used on resource created by either kubectl create <*> or kubectl apply	22
2829	apply crd success spectrocluster Namespace <*> Name <*> provider aws	22
2830	create AWSManagedCluster success spectrocluster Namespace <*> Name <*> name <*>	22
2831	create success spectrocluster Namespace <*> Name <*> <*> Cluster name <*>	22
2832	reconcileControlPlaneEndpoint spectrocluster Namespace <*> Name <*>	4796
2833	control plane endpoint reconcile done spectrocluster Namespace <*> Name <*>	4796
2834	creating or updating AWSManagedControlPlane spectrocluster Namespace <*> Name <*>	4796
2835	oidcIdentityProvider property value is not present in k8s pack spectrocluster Namespace <*> Name <*> packName <*>	4796
2836	should upgrade version in mcp spectrocluster Namespace <*> Name <*> desired version <*>	22
2837	reconcile mcp subnet tags spectrocluster Namespace <*> Name <*> cluster <*> mcp	22
2838	waiting for subnets in mcp network spec spectrocluster Namespace <*> Name <*>	22
2839	cluster security group not available yet skip ensure <*> port rule spectrocluster Namespace <*> Name <*>	4796
2840	create update operations spectrocluster Namespace <*> Name <*> mcp <*>	22
2841	create is triggered for ManagedControlPlane requeue after one minute	22
2842	AWSManagedCluster spec not changed spectrocluster Namespace <*> Name <*> name <*>	4774
2843	create update operations spectrocluster Namespace <*> Name <*> mcp 0	4774
2844	waiting for managed control plane to be ready spectrocluster Namespace <*> Name <*> name <*> namespace <*>	4774
2845	reconcile managed control plane done	4774
2846	begin reconcile for managed workers	4774
2847	creating or updating managed worker machine pool	4774
2848	creating or updating AWSManagedMachinePool spectrocluster Namespace <*> Name <*>	4774
2849	create success spectrocluster Namespace <*> Name <*> name <*> namespace <*>	22
2850	desired pool size for pool pool <*> size <*>	4774
2851	create update operations mmpOp <*> mpOp <*>	22
2852	create is triggered for worker MachinePool requeue after one minute	22
2853	check if rolling upgrade is required for AWSManagedMachinePool spectrocluster Namespace <*> Name <*> desired kind AWSManagedMachinePool apiVersion <*> metadata name <*> namespace <*> creationTimestamp null labels <*> <*> spec eksNodegroupName <*> availabilityZones <*> <*> <*> <*> subnetIDs <*> <*> additionalTags <*> spectro__tag spectro__ownerUid <*> <*> spectro__tag roleName <*> diskSize <*> instanceType t3.medium scaling minSize <*> maxSize <*> remoteAccess sshKeyName spectro capacityType spot status ready false replicas 0 existing kind AWSManagedMachinePool apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f labels . f <*> f spec . f additionalTags . f <*> f spectro__ownerUid f <*> f amiType f availabilityZones f capacityType f diskSize f eksNodegroupName f instanceType f remoteAccess . f sshKeyName f roleName f scaling . f maxSize f minSize f subnetIDs f status . f ready f replicas spec eksNodegroupName <*> availabilityZones <*> <*> <*> <*> subnetIDs <*> <*> additionalTags <*> spectro__tag spectro__ownerUid <*> <*> spectro__tag roleName <*> amiType <*> diskSize <*> instanceType t3.medium scaling minSize <*> maxSize <*> remoteAccess sshKeyName spectro capacityType spot status ready false replicas 0	22
2854	check if inline upgrade is required for AWSManagedMachinePool spectrocluster Namespace <*> Name <*> name <*> namespace <*>	4752
2855	check upgrade for existing machine pool MachinePool kind MachinePool apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> annotations <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f labels . f <*> f spec . f clusterName f replicas f template . f metadata f spec . f bootstrap . f dataSecretName f clusterName f infrastructureRef . f apiVersion f kind f name f namespace f version f status . f bootstrapReady f infrastructureReady f replicas spec clusterName <*> replicas <*> template metadata spec clusterName <*> bootstrap dataSecretName infrastructureRef kind AWSManagedMachinePool namespace <*> name <*> apiVersion <*> version <*> minReadySeconds 0 status replicas 0 bootstrapReady false infrastructureReady false	22
2856	create update operations mmpOp 0 mpOp 0	4752
2857	waiting for worker MachinePool replicas to reach target count name <*> namespace <*>	22
2858	check if rolling upgrade is required for AWSManagedMachinePool spectrocluster Namespace <*> Name <*> desired kind AWSManagedMachinePool apiVersion <*> metadata name <*> namespace <*> creationTimestamp null labels <*> <*> spec eksNodegroupName <*> availabilityZones <*> <*> <*> <*> subnetIDs <*> <*> additionalTags <*> spectro__tag spectro__ownerUid <*> <*> spectro__tag roleName <*> diskSize <*> instanceType t3.medium scaling minSize <*> maxSize <*> remoteAccess sshKeyName spectro capacityType spot status ready false replicas 0 existing kind AWSManagedMachinePool apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> ownerReferences apiVersion <*> kind MachinePool name <*> uid <*> controller true blockOwnerDeletion true managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f labels . f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f additionalTags . f <*> f spectro__ownerUid f <*> f amiType f availabilityZones f capacityType f diskSize f eksNodegroupName f instanceType f remoteAccess . f sshKeyName f roleName f scaling . f maxSize f minSize f subnetIDs f status . f conditions f ready f replicas spec eksNodegroupName <*> availabilityZones <*> <*> <*> <*> subnetIDs <*> <*> additionalTags <*> spectro__tag spectro__ownerUid <*> <*> spectro__tag roleName <*> amiType <*> diskSize <*> instanceType t3.medium scaling minSize <*> maxSize <*> remoteAccess sshKeyName spectro capacityType spot status ready false replicas 0 conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForEKSControlPlane message 0 of <*> completed type EKSNodegroupReady status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForEKSControlPlane	4730
2859	check upgrade for existing machine pool MachinePool kind MachinePool apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> annotations <*> ownerReferences apiVersion <*> kind Cluster name <*> uid <*> finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f finalizers f labels . f <*> f ownerReferences f spec . f clusterName f replicas f template . f metadata f spec . f bootstrap . f dataSecretName f clusterName f infrastructureRef . f apiVersion f kind f name f namespace f version f status . f bootstrapReady f conditions f infrastructureReady f observedGeneration f phase f replicas spec clusterName <*> replicas <*> template metadata spec clusterName <*> bootstrap dataSecretName infrastructureRef kind AWSManagedMachinePool namespace <*> name <*> apiVersion <*> version <*> minReadySeconds 0 status replicas 0 phase Provisioning bootstrapReady true infrastructureReady false observedGeneration <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForEKSControlPlane message 0 of <*> completed type BootstrapReady status True lastTransitionTime <*> <*> <*> type InfrastructureReady status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForEKSControlPlane message 0 of <*> completed type ReplicasReady status True lastTransitionTime <*> <*> <*>	4730
2860	waiting for worker MachinePool to be ready name <*> namespace <*>	4730
2861	reconcile mcp subnet tags spectrocluster Namespace <*> Name <*> cluster <*> mcp <*>	440
2862	update mcp subnets with lb tags done spectrocluster Namespace <*> Name <*> mcp <*>	440
2863	reconcile mmp tags spectrocluster Namespace <*> Name <*> mmp <*>	440
2864	mmp providerId list is empty skipping reconcile for mmp tags spectrocluster Namespace <*> Name <*> mmp <*>	440
2865	START logs for container mold-manager of pod <*>	12
2866	skipping mold reconcile for managed kubernetes cluster spectrocluster <*> clusterName <*> clusterNamespace <*>	989
2867	END logs for container mold-manager of pod <*>	2
2868	Inside HealthCheck  0m	22139
2869	| <*> <*> <*>  0m| <*> match| <*> GET  0m <*> r <*> 0m	22140
2870	END logs for container willittrace of pod <*>	3
2871	INFO Started server process <*>	4
2872	INFO Waiting for application startup.	4
2873	INFO Application startup complete.	4
2874	INFO Uvicorn running on http <*> <*> Press CTRL+C to quit	4
2875	INFO <*> <*> <*> GET <*> <*> <*> OK	6177
2876	START logs for container willittrace of pod <*>	2
2877	<*> <*> <*> <*>  <*> <*> I <*> <*> http server Running on http <*> <*> 0m	1
2878	START logs for container piris-tools of pod <*>	1
2879	END logs for container piris-tools of pod <*>	1
2880	START logs for container tke-metadata of pod <*>	2
2881	level debug msg updating service cache time <*> <*> <*>	1983
2882	duration_ms <*> level debug msg completed update of Service Cache time <*> <*> <*>	1982
2883	level debug msg updating namespace cache time <*> <*> <*>	1983
2884	duration_ms <*> level debug msg completed update of Namespace Cache time <*> <*> <*>	722
2885	level debug msg updating pod cache time <*> <*> <*>	1974
2886	duration_ms <*> level debug msg completed update of Pod Cache time <*> <*> <*>	1973
2887	level debug msg updating cluster cache time <*> <*> <*>	1983
2888	level debug msg updating node cache time <*> <*> <*>	1983
2889	duration_ms <*> level debug msg completed update of Cluster Cache time <*> <*> <*>	1982
2890	duration_ms <*> level debug msg completed update of Node Cache time <*> <*> <*>	1982
2891	level debug msg updating serviceinstance cache time <*> <*> <*>	1983
2892	duration_ms 0 level debug msg completed update of Statefulset Cache time <*> <*> <*>	1245
2893	level debug msg updating deployment cache time <*> <*> <*>	1982
2894	duration_ms <*> level debug msg completed update of Deployment Cache time <*> <*> <*>	1980
2895	level debug msg updating ingress cache time <*> <*> <*>	1983
2896	duration_ms 4 level debug msg completed update of ingress Cache time <*> <*> <*>	544
2897	level debug msg updating replicaset cache time <*> <*> <*>	1981
2898	duration_ms <*> level debug msg completed update of Replicaset Cache time <*> <*> <*>	1980
2899	level debug msg updating statefulset cache time <*> <*> <*>	1983
2900	duration_ms 6 level debug msg completed update of Statefulset Cache time <*> <*> <*>	722
2901	level debug msg updating overallsummary cache time <*> <*> <*>	1967
2902	level debug msg updating daemonset cache time <*> <*> <*>	1982
2903	duration_ms <*> level debug msg completed update of Daemonset Cache time <*> <*> <*>	1868
2904	level debug msg updating poddisruptions cache time <*> <*> <*>	1983
2905	duration_ms <*> level debug msg completed update of Poddisruption Cache time <*> <*> <*>	1964
2906	duration_ms 6 level debug msg completed update of Namespace Cache time <*> <*> <*>	1260
2907	duration_ms <*> level debug msg completed update of Statefulset Cache time <*> <*> <*>	1996
2908	duration_ms <*> level debug msg completed update of ingress Cache time <*> <*> <*>	1416
2909	duration_ms 6 level debug msg completed update of Daemonset Cache time <*> <*> <*>	113
2910	duration_ms 4 level debug msg completed update of Poddisruption Cache time <*> <*> <*>	18
2911	duration_ms 6 level debug msg completed update of ingress Cache time <*> <*> <*>	22
2912	duration_ms 4 level debug msg completed update of Statefulset Cache time <*> <*> <*>	1
2913	END logs for container tke-metadata of pod <*>	2
2914	START logs for container opa of pod <*>	5
2915	client_addr <*> <*> level info msg Received request. req_id <*> req_method PUT req_path <*> time <*> <*> <*>	5224
2916	client_addr <*> <*> level info msg Sent response. req_id <*> req_method PUT req_path <*> resp_bytes 0 resp_duration <*> resp_status <*> time <*> <*> <*>	2611
2917	client_addr <*> <*> level info msg Received request. req_id <*> req_method GET req_path <*> time <*> <*> <*>	8487
2918	client_addr <*> <*> level info msg Sent response. req_id <*> req_method GET req_path <*> resp_bytes <*> resp_duration <*> resp_status <*> time <*> <*> <*>	8487
2919	client_addr <*> <*> level info msg Received request. req_id <*> req_method PATCH req_path <*> time <*> <*> <*>	161
2920	client_addr <*> <*> level info msg Sent response. req_id <*> req_method PATCH req_path <*> resp_bytes 0 resp_duration <*> resp_status <*> time <*> <*> <*>	161
2921	END logs for container opa of pod <*>	5
2922	Syncing <*>	37791
2923	Sync for <*> failed due to OPA error. Trying again in <*> Reason list the server could not find the requested resource	37744
2924	Sync channel for <*> closed. Restarting immediately.	37
2925	Listed <*> and got <*> resources with resourceVersion <*> Took <*>	41
2926	Loaded <*> resources into OPA. Took <*> Starting watch at resourceVersion <*>	43
2927	Listed <*> and got 0 resources with resourceVersion <*> Took <*>	6
2928	<*> <*> admin <*> <*> <*> <*> <*> GET <*> <*> <*> <*> <*> <*> <*> <*>	25851
2929	<*> <*> admin <*> <*> <*> <*> <*> GET <*> <*> <*> <*> <*> <*> <*>	7208
2930	<*> <*> <*> <*> warn <*> <*> an upstream response is buffered to a temporary file <*> while reading upstream client <*> server request GET <*> <*> upstream http <*> <*> host <*>	387
2931	Cluster <*>	2
2932	Region <*>	2
2933	ZRegion Alpha	2
2934	Zone 4	2
2935	Firewall None	2
2936	Pod <*>	2
2937	Context CDE	2
2938	Datacenter Titan	2
2939	Environment production	2
2940	Opsman <*>	2
2941	Status Active	2
2942	PksAPI https <*>	2
2943	Api <*>	2
2944	NetscalerUrl <*>	2
2945	ClusterType spectrocloud	2
2946	Version of tke metadata in main <*>	1
2947	level error msg could not make http request to opa endpoint http <*> <*> Get http <*> <*> dial tcp <*> <*> connect connection refused time <*> <*> <*>	13
2948	level error msg ClusterStruct is empty! time <*> <*> <*>	4
2949	duration_ms 4 level debug msg completed update of Deployment Cache time <*> <*> <*>	1
2950	addrs http <*> <*> insecure_addr level info msg Initializing server. time <*> <*> <*>	1
2951	client_addr <*> <*> level info msg Received request. req_id 4 req_method GET req_path <*> time <*> <*> <*>	4
2952	client_addr <*> <*> level info msg Sent response. req_id 4 req_method GET req_path <*> resp_bytes <*> resp_duration <*> resp_status <*> time <*> <*> <*>	4
2953	client_addr <*> <*> level info msg Received request. req_id 6 req_method GET req_path <*> time <*> <*> <*>	4
2954	client_addr <*> <*> level info msg Sent response. req_id 6 req_method GET req_path <*> resp_bytes <*> resp_duration <*> resp_status <*> time <*> <*> <*>	4
2955	Registering a mutating webhook GVK Group <*> Version <*> Kind IPPool path <*>	1
2956	Registering a validating webhook GVK Group <*> Version <*> Kind IPPool path <*>	1
2957	Registering a mutating webhook GVK Group <*> Version <*> Kind IPAddress path <*>	1
2958	Registering a validating webhook GVK Group <*> Version <*> Kind IPAddress path <*>	1
2959	Registering a mutating webhook GVK Group <*> Version <*> Kind IPClaim path <*>	1
2960	Registering a validating webhook GVK Group <*> Version <*> Kind IPClaim path <*>	1
2961	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind Cluster	1
2962	conversion webhook enabled object metadata creationTimestamp null spec status infrastructureReady false controlPlaneInitialized false	1
2963	Registering a mutating webhook GVK Group <*> Version <*> Kind Cluster path <*>	1
2964	Registering a validating webhook GVK Group <*> Version <*> Kind Cluster path <*>	1
2965	conversion webhook enabled object metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	1
2966	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind ClusterList	1
2967	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind ClusterList	1
2968	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind Machine	1
2969	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind Machine	1
2970	conversion webhook enabled object metadata creationTimestamp null spec metadata bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	1
2971	Registering a mutating webhook GVK Group <*> Version <*> Kind Machine path <*>	1
2972	Registering a validating webhook GVK Group <*> Version <*> Kind Machine path <*>	1
2973	conversion webhook enabled object metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	1
2974	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind MachineList	1
2975	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind MachineList	1
2976	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind Cluster	1
2977	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind MachineSet	1
2978	conversion webhook enabled object metadata creationTimestamp null spec selector template metadata spec metadata bootstrap infrastructureRef status replicas 0	1
2979	Registering a mutating webhook GVK Group <*> Version <*> Kind MachineSet path <*>	2
2980	Registering a validating webhook GVK Group <*> Version <*> Kind MachineSet path <*>	1
2981	conversion webhook enabled object metadata creationTimestamp null spec clusterName selector template metadata spec clusterName bootstrap infrastructureRef status	2
2982	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind MachineSetList	1
2983	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind MachineSetList	1
2984	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind MachineDeployment	1
2985	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind MachineDeployment	1
2986	conversion webhook enabled object metadata creationTimestamp null spec selector template metadata spec metadata bootstrap infrastructureRef status	1
2987	Registering a mutating webhook GVK Group <*> Version <*> Kind MachineDeployment path <*>	1
2988	Registering a validating webhook GVK Group <*> Version <*> Kind MachineDeployment path <*>	1
2989	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind MachineDeploymentList	1
2990	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind MachineDeploymentList	1
2991	Registering a mutating webhook GVK Group <*> Version <*> Kind MachinePool path <*>	1
2992	Registering a validating webhook GVK Group <*> Version <*> Kind MachinePool path <*>	1
2993	Registering a mutating webhook GVK Group <*> Version <*> Kind ClusterResourceSet path <*>	1
2994	Registering a validating webhook GVK Group <*> Version <*> Kind ClusterResourceSet path <*>	1
2995	Registering a mutating webhook GVK Group <*> Version <*> Kind MachineHealthCheck path <*>	1
2996	Registering a validating webhook GVK Group <*> Version <*> Kind MachineHealthCheck path <*>	1
2997	received request webhook <*> UID <*> kind group <*> version <*> kind VSphereMachine resource group <*> version <*> resource vspheremachines	657
2998	received request webhook <*> UID <*> kind group <*> version <*> kind VSphereVM resource group <*> version <*> resource vspherevms	78
2999	received request webhook <*> UID <*> kind group <*> version <*> kind VSphereMachineTemplate resource group <*> version <*> resource vspheremachinetemplates	6
3000	<*> <*> <*> <*> <*> o <*>	4
3001	<*> <*> <*> ##8 <*> <*> .. <*>	4
3002	<*> o. . oo <*>	4
3003	<*> <*> <*> o <*>	4
3004	#8 <*> o oo8#@##@@@@@@@@@@@#######8 o . ##########	4
3005	#8 oo <*> ##@@ <*> .. ##########	4
3006	oo oo ##@@ <*> o <*> @ <*> o <*> ... .##########	4
3007	oo <*> <*> <*> <*> . <*>	4
3008	o <*> o o8@##8##ooo o <*> o.##@@@@@@@	4
3009	o ###8 o @@@@ oo o <*> #8#### <*> #########	4
3010	o ## @@@ oo <*> o <*> <*>	4
3011	o <*> <*> o ooo o #@@@@@@@@	4
3012	oo @@@ <*> <*> <*> <*>	4
3013	.. .. . oooo oooo#8 <*> <*> . @@@@@@@@##8	4
3014	............ ooo o <*> <*> oo	4
3015	............ o <*> # <*> ooo	4
3016	.............. o <*> <*> oo	4
3017	.............. o o <*> o o <*> o	4
3018	o .......... oo <*> ## 8oo o ..	4
3019	o oo . .... ooo <*> o ooo	4
3020	. o o .... oo <*> <*> oo o	4
3021	... ooo o. oo <*>	4
3022	... ooo o <*>	4
3023	ooo o <*> o	4
3024	o <*> ooo <*> #################@@@@#####@@@@@@@o@# <*>	4
3025	<*> o <*> #@##########8 #@@###@#@@@@8@# <*>	4
3026	o ## o <*> oooo ... ooooo @@@@@@@@@@@@@@@@@@@@@##8	4
3027	o <*> o8 o8 <*> ####8 ooooo oo ###@#@@@@@@@@@@@@@#@####	4
3028	oo <*> o <*> <*> oooooo .... <*>	4
3029	oo <*> o <*> ooooooo .. #####@@@@@@@@@@@@#@@@@##	4
3030	oo <*> o <*> ooooooo . <*>	4
3031	o8 o@@@ <*> <*> o <*> <*>	4
3032	oo o oo#8 <*> o . <*>	4
3033	<*> oo o oo <*> <*> #######8##@@@@@@@@@@@@@@@	4
3034	<*> oo oo oo o ooooo <*> <*> o #########@@@@@@@@@@@@@@@#	4
3035	<*> <*> oo o o oooooooo oo # oo########@@@@@@@@@@@@@@@@@#	4
3036	<*> <*> <*> <*> INFO <*> <*> main w.WillItConnectApplication Starting WillItConnectApplication using Java <*> on <*> with PID <*> <*> started by root in <*>	4
3037	o o o o <*> ooooooo oo . <*>	4
3038	<*> <*> <*> <*> INFO <*> <*> main <*> <*> initialized with port s <*> http	4
3039	o <*> # <*> <*> o o@@@#@@@@@@@@@@@#@@8 <*> <*>	4
3040	<*> <*> <*> <*> INFO <*> <*> main w.WillItConnectApplication No active profile set falling back to default profiles default	4
3041	<*> <*> <*> <*> INFO <*> <*> main <*> Starting service <*>	4
3042	<*> <*> <*> <*> INFO <*> <*> main <*> Root WebApplicationContext initialization completed in <*> ms	4
3043	<*> <*> <*> <*> INFO <*> <*> main <*> Adding welcome page class path resource <*>	4
3044	<*> <*> <*> <*> INFO <*> <*> main <*> Exposing <*> endpoint s beneath base path <*>	4
3045	<*> <*> <*> <*> INFO <*> <*> main <*> <*> started on port s <*> http with context path	4
3046	<*> <*> <*> <*> INFO <*> <*> main w.WillItConnectApplication Started WillItConnectApplication in <*> seconds JVM running for <*>	4
3047	<*> <*> <*> <*> INFO <*> <*> <*> <*> . . <*> Initializing Spring DispatcherServlet dispatcherServlet	4
3048	<*> <*> <*> <*> INFO <*> <*> <*> <*> Initializing Servlet dispatcherServlet	4
3049	<*> <*> <*> <*> INFO <*> <*> <*> <*> Completed initialization in <*> ms	4
3050	<*> <*> <*> <*> INFO <*> <*> main <*> Starting Servlet engine Apache <*>	4
3051	<*> <*> <*> <*> INFO <*> <*> main <*> . . <*> Initializing Spring embedded WebApplicationContext	4
3052	START logs for container willitconnect of pod <*>	1
3053	END logs for container willitconnect of pod <*>	1
3054	<*> <*> <*> INFO handler Starting handler..	1
3055	Listening on <*> ...	1
3056	<*> <*> <*> INFO <*> Generated CA	1
3057	<*> <*> <*> INFO <*> Updated certificate bundle received. Updating certs...	1
3058	<*> <*> <*> INFO handler Request received Method POST URL /mutate?timeout <*>	351
3059	+ cat <*>	3
3060	checksum/config <*>	3
3061	<*> api	3
3062	<*> privileged	3
3063	<*> vaultconfig	3
3064	<*> <*>	11
3065	<*> true	3
3066	<*> injected	3
3067	+ grep agent-inject-status injected <*> <*>	3
3068	+ 0 ! 0	3
3069	+ echo Vault agent injection status verified init finished !	3
3070	<*> true Vault agent injection status verified init finished !	3
3071	> Vault agent started! Log data will stream in below	3
3072	> Vault agent configuration	3
3073	Cgo disabled	3
3074	Log Level info	3
3075	Version Vault <*>	3
3076	Version Sha <*>	3
3077	<*> <*> <*> INFO sink.file creating file sink	3
3078	<*> <*> <*> INFO <*> starting sink server	3
3079	<*> <*> <*> INFO <*> starting template server	3
3080	INFO runner creating new runner dry false once false	6
3081	<*> <*> <*> INFO <*> starting auth handler	3
3082	<*> <*> <*> INFO <*> authenticating	7
3083	WARN clients disabling vault SSL verification	6
3084	INFO runner creating watcher	6
3085	<*> <*> <*> ERROR <*> error authenticating error context deadline exceeded backoff <*>	4
3086	<*> <*> <*> INFO sink.file file sink configured path <*> mode <*>	3
3087	<*> <*> <*> INFO <*> authentication successful sending token to sinks	3
3088	<*> <*> <*> INFO <*> starting renewal process	3
3089	<*> <*> <*> INFO <*> template server received new token	3
3090	INFO runner stopping	6
3091	<*> <*> <*> INFO sink.file token written path <*>	3
3092	<*> <*> <*> INFO <*> sink server stopped	3
3093	<*> <*> <*> INFO sinks finished exiting	3
3094	INFO runner starting	3
3095	<*> <*> <*> INFO <*> renewed auth token	3
3096	INFO runner rendered <*> > <*>	3
3097	<*> <*> <*> INFO <*> template server stopped	3
3098	INFO runner received finish	3
3099	<*> <*> <*> INFO <*> shutdown triggered stopping lifetime watcher	3
3100	<*> <*> <*> INFO <*> auth handler stopped	3
3101	START logs for container dex of pod <*>	3
3102	+ dexOpts <*> <*> <*> <*> <*> <*>	3
3103	+ <*> dex serve <*> <*> <*> <*> <*> <*> <*>	3
3104	config using log level debug	3
3105	config issuer https <*>	3
3106	kubernetes client apiVersion <*>	3
3107	creating custom Kubernetes resources	3
3108	checking if custom resource <*> has been created already...	30
3109	The custom resource <*> already available skipping create	30
3110	config storage kubernetes	3
3111	config static client Spectro Cloud	3
3112	config connector ldap	3
3113	config response types accepted code id_token token	3
3114	config skipping approval screen	3
3115	config using password grant connector ldap	3
3116	listening telemetry on <*> <*>	3
3117	listening http on <*> <*>	3
3118	END logs for container dex of pod <*>	3
3119	performing ldap search DC <*> DC org sub objectClass person sAMAccountName <*>	4
3120	username <*> mapped to entry CN <*> OU Service Accounts DC <*> DC org	4
3121	START logs for container collectorforkubernetes of pod <*>	16
3122	Build date <*> version <*>	16
3123	reading configuration from <*>	35
3124	InstanceID <*> created <*> <*> <*> <*> <*> UTC	16
3125	watching <*> glob match ^ syslog|messages . d+ ?	15
3126	watching <*> glob match ^ w <*> + .log . d <*> + ? | docker	15
3127	license-check kubernetes <*> <*> <*> <*> <*> <*> <*> <*> true true 0	1154
3128	syslog <*> added file <*>	63
3129	logs <*> added file <*>	177
3130	could not access file <*>	11892
3131	<*> <*> watching <*>	376
3132	thread 0 index kubernetes_admin Failed to post. Verify connection. Retrying in few seconds. Post https <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	44
3133	thread 0 index Failed to post. Verify connection. Retrying in few seconds. Post https <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	45
3134	thread 0 index Failed to post. Verify connection. Retrying in few seconds. Post https <*> <*> dial tcp lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout	37
3135	thread 0 index kubernetes_admin Failed to post. Verify connection. Retrying in few seconds. Post https <*> <*> dial tcp lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout	37
3136	thread 0 index kubernetes_admin Successfully posted after 6 retries	1
3137	thread 0 index Successfully posted after 6 retries	2
3138	END logs for container collectorforkubernetes of pod <*>	16
3139	thread 0 index Successfully posted after <*> retries	13
3140	thread 0 index kubernetes_admin Successfully posted after <*> retries	16
3141	<*> 0.log <*> pipeline did not acknowledged latest pos <*> latest ack 0	23
3142	<*> <*> closing <*>	81
3143	<*> 0.log <*> pipeline did not acknowledged latest pos <*> latest ack <*>	3
3144	<*> <*> <*> pipeline did not acknowledged latest pos <*> latest ack <*>	2
3145	thread 0 index tcsp invalid event number 0	9446
3146	thread 0 index tcsp Failed to post statusCode <*> reason Incorrect index code <*> incorrect index tcsp	9446
3147	thread 0 index tcsp Setting target index to default for messages with the index tcsp	9446
3148	syslog <*> removed file <*>	47
3149	syslog <*> closing file <*> after eof	47
3150	syslog <*> file <*> closed after eof	47
3151	thread 0 index tcsp Successfully posted after <*> retries	6
3152	thread 0 index kubernetes Failed to post. Verify connection. Retrying in few seconds. Post https <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	11
3153	thread 0 index kubernetes Successfully posted after <*> retries	9
3154	logs <*> closing file <*> after eof	20
3155	logs <*> file <*> closed after eof	20
3156	logs <*> removed file <*>	20
3157	expired ack position for <*> <*> <*>	101
3158	thread 0 index tcsp Failed to post. Verify connection. Retrying in few seconds. Post https <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	6
3159	thread 0 index tcsp Successfully posted after 4 retries	1
3160	thread 0 index Successfully posted after 4 retries	1
3161	thread 0 index kubernetes_admin Successfully posted after 4 retries	1
3162	thread 0 index Failed to post. Verify connection. Retrying in few seconds. Post https <*> <*> dial tcp <*> <*> i/o timeout Client.Timeout exceeded while awaiting headers	1
3163	thread 0 index kubernetes Successfully posted after 6 retries	1
3164	error while reading next. unexpected EOF	2
3165	error while reading next. read tcp <*> <*> <*> read connection reset by peer	5
3166	error while reading next. read tcp <*> <*> <*> read connection timed out	8
3167	START logs for container magtape-init of pod <*>	3
3168	<*> <*> <*> <*> <*> INFO MagTape Init	3
3169	<*> <*> <*> <*> <*> INFO Starting TLS init process	3
3170	<*> <*> <*> <*> <*> INFO We made it to check_for_byoc	3
3171	<*> <*> <*> <*> <*> INFO Existing TLS cert and key found	3
3172	<*> <*> <*> <*> <*> INFO Days until Cert Expiration <*>	3
3173	<*> <*> <*> <*> <*> INFO Using existing secret magtape-tls in namespace <*>	3
3174	<*> <*> <*> <*> <*> INFO Waiting for race winning pod to startup	3
3175	<*> <*> <*> <*> <*> INFO Still waiting for race winning pod to startup	3
3176	<*> <*> <*> <*> <*> INFO Writing cert and key locally	3
3177	<*> <*> <*> <*> <*> INFO Existing VWC magtape-webhook found	3
3178	<*> <*> <*> <*> <*> INFO Found MagTape webhook defined in the VWC template	3
3179	<*> <*> <*> <*> <*> INFO Comparing existing VWC to template	3
3180	<*> <*> <*> <*> <*> INFO Existing VWC matches template	3
3181	<*> <*> <*> <*> <*> INFO Done	3
3182	END logs for container magtape-init of pod <*>	3
3183	START logs for container magtape of pod <*>	3
3184	<*> <*> <*> <*> <*> <*> INFO Starting gunicorn <*>	3
3185	<*> <*> <*> <*> <*> <*> INFO Listening at https <*> <*> <*>	3
3186	<*> <*> <*> <*> <*> <*> INFO Using worker threads	3
3187	<*> <*> <*> <*> <*> 6 INFO Booting worker with pid 6	3
3188	<*> <*> <*> <*> <*> <*> INFO Booting worker with pid <*>	3
3189	END logs for container magtape of pod <*>	3
3190	addrs <*> <*> http <*> <*> diagnostic-addrs level info msg Initializing server. time <*> <*> <*>	3
3191	client_addr <*> <*> level info msg Sent response. req_id <*> req_method PUT req_path <*> resp_bytes <*> resp_duration <*> resp_status <*> time <*> <*> <*>	2613
3192	First line of log stream.	3
3193	Sync for <*> failed due to OPA error. Trying again in <*> Reason reset Put http <*> <*> dial tcp i/o timeout	4
3194	START logs for container node-exporter of pod <*>	15
3195	Starting node_exporter version <*> branch HEAD revision <*> source node_exporter.go <*>	15
3196	Build context go <*> user <*> date <*> <*> <*> source node_exporter.go <*>	15
3197	Enabled collectors source node_exporter.go <*>	15
3198	<*> arp source node_exporter.go <*>	15
3199	<*> bcache source node_exporter.go <*>	15
3200	<*> bonding source node_exporter.go <*>	15
3201	<*> conntrack source node_exporter.go <*>	15
3202	<*> cpu source node_exporter.go <*>	15
3203	<*> diskstats source node_exporter.go <*>	15
3204	<*> edac source node_exporter.go <*>	15
3205	<*> entropy source node_exporter.go <*>	15
3206	<*> filefd source node_exporter.go <*>	15
3207	<*> filesystem source node_exporter.go <*>	15
3208	<*> hwmon source node_exporter.go <*>	15
3209	<*> infiniband source node_exporter.go <*>	15
3210	<*> ipvs source node_exporter.go <*>	15
3211	<*> loadavg source node_exporter.go <*>	15
3212	<*> mdadm source node_exporter.go <*>	15
3213	<*> meminfo source node_exporter.go <*>	15
3214	<*> netdev source node_exporter.go <*>	15
3215	<*> netstat source node_exporter.go <*>	15
3216	<*> nfsd source node_exporter.go <*>	15
3217	<*> sockstat source node_exporter.go <*>	15
3218	<*> stat source node_exporter.go <*>	15
3219	<*> textfile source node_exporter.go <*>	15
3220	<*> timex source node_exporter.go <*>	15
3221	<*> uname source node_exporter.go <*>	15
3222	<*> vmstat source node_exporter.go <*>	15
3223	<*> wifi source node_exporter.go <*>	15
3224	<*> xfs source node_exporter.go <*>	15
3225	<*> zfs source node_exporter.go <*>	15
3226	Listening on <*> <*> source node_exporter.go <*>	15
3227	<*> time source node_exporter.go <*>	15
3228	<*> <*> <*> <*> http TLS handshake error from <*> <*> tls first record does not look like a TLS handshake	1
3229	END logs for container node-exporter of pod <*>	15
3230	Unable to authenticate the request due to an error Post https <*> <*> read tcp <*> <*> <*> read connection timed out some request body already written	153
3231	<*> nfs source node_exporter.go <*>	15
3232	Starting Prometheus Operator version <*> .	1
3233	Staring insecure server on <*>	1
3234	connection established cluster-version <*>	3
3235	CRD updated crd ThanosRuler	1
3236	CRD updated crd Alertmanager	1
3237	CRD updated crd Prometheus	1
3238	CRD updated crd ServiceMonitor	1
3239	CRD updated crd PodMonitor	1
3240	CRD updated crd PrometheusRule	1
3241	CRD API endpoints ready	3
3242	successfully synced all caches	3
3243	sync alertmanager key monitoring/monitoring	12
3244	sync prometheus key monitoring/mesh	6
3245	sync prometheus key <*>	1
3246	START logs for container telegraf-blackbox of pod <*>	1
3247	<*> <*> <*> I! Starting Telegraf <*>	1
3248	<*> <*> <*> I! Using config file <*>	1
3249	<*> <*> <*> I! Loaded inputs prometheus	1
3250	<*> <*> <*> I! Loaded aggregators	1
3251	<*> <*> <*> I! Loaded processors rename strings	1
3252	<*> <*> <*> I! Loaded outputs influxdb	1
3253	<*> <*> <*> I! Tags enabled context CDE dc Titan environment production metric_source blackbox_exporter platform TKE region <*>	1
3254	<*> <*> <*> I! agent Config Interval <*> Quiet false Hostname <*> Flush Interval <*>	1
3255	END logs for container telegraf-blackbox of pod <*>	1
3256	START logs for container blackbox-exporter of pod <*>	1
3257	Starting blackbox_exporter version version <*> branch HEAD revision <*>	1
3258	Build context <*> <*> <*> <*> <*> MISSING	1
3259	Loaded config file	1
3260	Listening on address address <*>	1
3261	END logs for container blackbox-exporter of pod <*>	1
3262	START logs for container thanos-querier of pod <*>	3
3263	Tracing will be disabled	9
3264	disabled TLS key and cert must be set to enable	8
3265	registering as gRPC StoreAPI and RulesAPI	6
3266	starting query node	2
3267	changing probe status status healthy	9
3268	listening for requests and metrics address <*> <*>	9
3269	changing probe status status ready	13
3270	listening for serving gRPC address <*> <*>	8
3271	adding new storeAPI to query storeset address <*> <*> extLset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*>	10
3272	adding new storeAPI to query storeset address <*> <*> extLset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*> clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*>	4
3273	adding new storeAPI to query storeset address <*> <*> extLset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*> clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*>	4
3274	adding new storeAPI to query storeset address <*> <*> extLset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*>	11
3275	failed to resolve addresses for storeAPIs err <*> errors look IP addresses <*> lookup <*> on <*> <*> no such host lookup SRV records <*> lookup <*> on <*> <*> no such host lookup SRV records <*> lookup <*> on <*> <*> no such host	1
3276	failed to resolve addresses for storeAPIs err look IP addresses <*> lookup <*> on <*> <*> no such host	4
3277	failed to resolve addresses for storeAPIs err <*> errors look IP addresses <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout lookup SRV records <*> lookup <*> on <*> <*> no such host look IP addresses <*> lookup <*> on <*> <*> no such host	1
3278	update of store node failed err getting metadata fetching store info from <*> <*> rpc error code DeadlineExceeded desc latest connection error connection error desc transport Error while dialing dial tcp <*> <*> connect connection refused address <*> <*>	4
3279	update of store node failed err getting metadata fetching store info from <*> <*> rpc error code DeadlineExceeded desc latest balancer error connection error desc transport Error while dialing dial tcp <*> <*> connect connection refused address <*> <*>	193
3280	removing store because it s unhealthy or does not exist address <*> <*> extLset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*>	6
3281	removing store because it s unhealthy or does not exist address <*> <*> extLset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*> clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*>	3
3282	update of store node failed err getting metadata fetching store info from <*> <*> rpc error code DeadlineExceeded desc context deadline exceeded address <*> <*>	2939
3283	END logs for container thanos-querier of pod <*>	3
3284	START logs for container prometheus of pod <*>	5
3285	Starting Prometheus version version <*> branch HEAD revision <*>	5
3286	level info ts <*> <*> <*> caller main.go <*> build_context go <*> user <*> date <*> <*> <*>	7
3287	level info ts <*> <*> <*> caller main.go <*> host_details Linux <*> <*> SMP Mon Jan <*> <*> <*> <*> UTC <*> <*> <*> none	5
3288	level info ts <*> <*> <*> caller main.go <*> fd_limits soft <*> hard <*>	5
3289	level info ts <*> <*> <*> caller main.go <*> vm_limits soft unlimited hard unlimited	5
3290	Starting TSDB ...	5
3291	Start listening for connections address <*> <*>	5
3292	Found healthy block mint <*> maxt <*> ulid <*>	1060
3293	Replaying <*> memory mappable chunks if any	4
3294	<*> memory mappable chunks replay completed duration <*>	4
3295	Replaying WAL this may take a while	4
3296	WAL checkpoint loaded	4
3297	WAL segment loaded segment <*> maxSegment <*>	22
3298	WAL replay completed checkpoint_replay_duration <*> wal_replay_duration <*> total_replay_duration <*>	4
3299	level info ts <*> <*> <*> caller main.go <*> fs_type <*>	5
3300	TSDB started	5
3301	Loading configuration file filename <*>	8
3302	Using pod service account via in-cluster config	53
3303	Completed loading of configuration file filename <*>	8
3304	Server is ready to receive web requests.	5
3305	Error sending alert err Post http <*> <*> context deadline exceeded	351
3306	Evaluating rule failed rule record node_quantile kubelet_pleg_relist_duration_seconds histogram_quantile nexpr histogram_quantile <*> sum by instance le rate <*> <*> on instance group_left node kubelet_node_name job kubelet nlabels n quantile <*> n err found duplicate series for the match group instance <*> <*> on the right <*> of the operation __name__ kubelet_node_name endpoint https-metrics exported_node <*> instance <*> <*> job kubelet namespace <*> node <*> service kubelet __name__ kubelet_node_name endpoint https-metrics exported_node <*> instance <*> <*> job kubelet namespace <*> node <*> service kubelet <*> matching not allowed matching labels must be unique on one side	18
3307	Evaluating rule failed rule alert KubeletPodStartUpLatencyHigh nexpr histogram_quantile <*> sum by instance le rate kubelet_pod_worker_duration_seconds_bucket job kubelet <*> on instance group_left node kubelet_node_name job kubelet > <*> nfor <*> nlabels n severity warning nannotations n description Kubelet Pod startup <*> percentile latency is value seconds on node labels.node . n runbook_url http <*> <*> n summary Kubelet Pod startup latency is too high. n err found duplicate series for the match group instance <*> <*> on the right <*> of the operation __name__ kubelet_node_name endpoint https-metrics exported_node <*> instance <*> <*> job kubelet namespace <*> node <*> service kubelet __name__ kubelet_node_name endpoint https-metrics exported_node <*> instance <*> <*> job kubelet namespace <*> node <*> service kubelet <*> matching not allowed matching labels must be unique on one side	4
3308	Evaluating rule failed rule record node_namespace_pod_container container_memory_working_set_bytes nexpr container_memory_working_set_bytes image! job kubelet on namespace pod group_left node topk by namespace pod <*> max by namespace pod node kube_pod_info node! n err multiple matches for labels grouping labels must ensure unique matches	24
3309	Evaluating rule failed rule record node_namespace_pod_container container_memory_rss nexpr container_memory_rss image! job kubelet on namespace pod group_left node topk by namespace pod <*> max by namespace pod node kube_pod_info node! n err multiple matches for labels grouping labels must ensure unique matches	24
3310	Evaluating rule failed rule record node_namespace_pod_container container_memory_cache nexpr container_memory_cache image! job kubelet on namespace pod group_left node topk by namespace pod <*> max by namespace pod node kube_pod_info node! n err multiple matches for labels grouping labels must ensure unique matches	24
3311	Evaluating rule failed rule record node_namespace_pod_container container_memory_swap nexpr container_memory_swap image! job kubelet on namespace pod group_left node topk by namespace pod <*> max by namespace pod node kube_pod_info node! n err multiple matches for labels grouping labels must ensure unique matches	24
3312	Error sending alert err Post http <*> <*> dial tcp <*> <*> i/o timeout	12
3313	write block mint <*> maxt <*> ulid <*> duration <*>	4
3314	Head GC completed duration <*>	4
3315	Creating checkpoint from_segment <*> to_segment <*> mint <*>	4
3316	WAL checkpoint complete first <*> last <*> duration <*>	4
3317	END logs for container prometheus of pod <*>	5
3318	Starting <*> version <*> .	4
3319	function failed. Retrying in next tick err trigger reload reload request failed Post http <*> <*> dial tcp <*> <*> connect connection refused	6
3320	Prometheus reload triggered cfg_in <*> cfg_out <*> rule_dirs	4
3321	started watching config file and non-recursively rule dirs for changes cfg <*> out <*> dirs	4
3322	<*> <*> <*> <*> Watching directory <*>	6
3323	loading bucket configuration	7
3324	starting sidecar	4
3325	started watching config file and non-recursively rule dirs for changes cfg out dirs	4
3326	failed to get Prometheus flags. Is Prometheus running? Retrying err request config against http <*> <*> Get http <*> <*> dial tcp <*> <*> connect connection refused	4
3327	failed to get Prometheus flags. Is Prometheus running? Retrying err got <*> response code <*> response Service Unavailable	16
3328	successfully loaded prometheus external labels external_labels clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*>	2
3329	upload new block id <*>	4
3330	START logs for container alertmanager of pod <*>	2
3331	Starting Alertmanager version version <*> branch HEAD revision <*>	2
3332	Waiting for gossip to settle... interval <*>	2
3333	Loading configuration file file <*>	2
3334	Completed loading of configuration file file <*>	2
3335	Listening address <*>	2
3336	gossip not settled polls 0 before 0 now <*> elapsed <*>	2
3337	gossip settled proceeding elapsed <*>	2
3338	refresh result failure addr <*> <*> err <*> error occurred n t Failed to join <*> dial tcp <*> <*> i/o timeout n n	181
3339	refresh result failure addr <*> <*> err <*> error occurred n t Failed to resolve <*> <*> lookup <*> on <*> <*> no such host n n	25
3340	Notify attempt failed will retry later attempts <*> err Post <redacted> dial tcp <*> <*> connect connection timed out	82
3341	Notify for alerts failed num_alerts <*> err <*> 0 notify retry canceled after 4 attempts Post <redacted> context deadline exceeded	80
3342	Notify for alerts failed num_alerts <*> err <*> 0 notify retry canceled after 4 attempts Post <redacted> dial tcp <*> <*> i/o timeout	2
3343	Notify attempt failed will retry later attempts <*> err Post <redacted> dial tcp <*> <*> i/o timeout	1
3344	refresh result failure addr <*> <*> err <*> error occurred n t Failed to resolve <*> <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout n n	32
3345	Notify attempt failed will retry later attempts <*> err Post <redacted> dial tcp lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout	88
3346	Notify attempt failed will retry later attempts 4 err Post <redacted> dial tcp lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout	16
3347	Notify attempt failed will retry later attempts 6 err Post <redacted> dial tcp lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout	16
3348	Notify for alerts failed num_alerts <*> err <*> 0 notify retry canceled after <*> attempts Post <redacted> context deadline exceeded	16
3349	END logs for container alertmanager of pod <*>	2
3350	START logs for container grafana of pod <*>	2
3351	Starting Grafana logger server version <*> commit <*> branch HEAD compiled <*> <*> <*>	2
3352	Config loaded from logger settings file <*>	4
3353	Config overridden from command line logger settings arg <*> <*>	8
3354	Config overridden from command line logger settings arg default.log.mode console	2
3355	Config overridden from Environment variable logger settings var GF_PATHS_DATA <*>	2
3356	Config overridden from Environment variable logger settings var GF_PATHS_LOGS <*>	2
3357	Config overridden from Environment variable logger settings var GF_PATHS_PLUGINS <*>	2
3358	Config overridden from Environment variable logger settings var GF_PATHS_PROVISIONING <*>	2
3359	Config overridden from Environment variable logger settings var GF_SERVER_ROOT_URL https <*>	1
3360	Config overridden from Environment variable logger settings var GF_SECURITY_ADMIN_USER admin	1
3361	Config overridden from Environment variable logger settings var GF_SECURITY_ADMIN_PASSWORD	2
3362	Config overridden from Environment variable logger settings var GF_AUTH_ANONYMOUS_ENABLED false	2
3363	Config overridden from Environment variable logger settings var GF_AUTH_LDAP_ENABLED true	1
3364	Config overridden from Environment variable logger settings var <*> <*>	1
3365	Path Home logger settings path <*>	2
3366	Path Data logger settings path <*>	2
3367	Path Logs logger settings path <*>	2
3368	Path Plugins logger settings path <*>	2
3369	Path Provisioning logger settings path <*>	2
3370	App mode production logger settings	2
3371	Connecting to DB logger <*> dbtype <*>	2
3372	Creating SQLite database file logger <*> path <*>	1
3373	Starting DB migrations logger migrator	1
3374	Executing migration logger migrator id create migration_log table	2
3375	Executing migration logger migrator id create user table	2
3376	Executing migration logger migrator id add unique index user.login	2
3377	Executing migration logger migrator id add unique index user.email	2
3378	Executing migration logger migrator id drop index UQE_user_login <*> <*>	2
3379	Executing migration logger migrator id drop index UQE_user_email <*> <*>	2
3380	Executing migration logger migrator id Rename table user to user_v1 <*> <*>	2
3381	Executing migration logger migrator id create user table <*>	2
3382	Executing migration logger migrator id create index UQE_user_login <*> <*>	2
3383	Executing migration logger migrator id create index UQE_user_email <*> <*>	2
3384	Executing migration logger migrator id copy data_source <*> to <*>	4
3385	Executing migration logger migrator id Drop old table user_v1	2
3386	Executing migration logger migrator id Add column help_flags1 to user table	2
3387	Executing migration logger migrator id Update user table charset	2
3388	Executing migration logger migrator id Add last_seen_at column to user	2
3389	Executing migration logger migrator id Add missing user data	2
3390	Executing migration logger migrator id Add is_disabled column to user	2
3391	Executing migration logger migrator id Add index <*>	1
3392	Executing migration logger migrator id create temp user table <*>	2
3393	Executing migration logger migrator id create index <*> <*> <*>	23
3394	Executing migration logger migrator id create index IDX_temp_user_status <*> <*>	3
3395	Executing migration logger migrator id drop index <*> <*> <*>	5
3396	Executing migration logger migrator id Update <*> table charset	2
3397	Executing migration logger migrator id drop index IDX_temp_user_status <*> <*>	1
3398	Executing migration logger migrator id Rename table <*> to <*> <*> <*>	1
3399	Executing migration logger migrator id create <*> <*>	1
3400	Executing migration logger migrator id copy <*> <*> to <*>	1
3401	Executing migration logger migrator id drop <*>	3
3402	Executing migration logger migrator id Set created for temp users that will otherwise prematurely expire	1
3403	Executing migration logger migrator id create star table	2
3404	Executing migration logger migrator id add unique index star.user_id_dashboard_id	2
3405	Executing migration logger migrator id create org table <*>	2
3406	Executing migration logger migrator id create index UQE_org_name <*> <*>	2
3407	Executing migration logger migrator id create org_user table <*>	2
3408	Executing migration logger migrator id create index IDX_org_user_org_id <*> <*>	2
3409	Executing migration logger migrator id create index UQE_org_user_org_id_user_id <*> <*>	2
3410	Executing migration logger migrator id Update org table charset	2
3411	Executing migration logger migrator id Update org_user table charset	2
3412	Executing migration logger migrator id Migrate all Read Only Viewers to Viewers	2
3413	Executing migration logger migrator id create dashboard table	2
3414	Executing migration logger migrator id add index dashboard.account_id	2
3415	Executing migration logger migrator id add unique index dashboard_account_id_slug	2
3416	Executing migration logger migrator id create dashboard_tag table	2
3417	Executing migration logger migrator id add unique index dashboard_tag.dasboard_id_term	2
3418	Executing migration logger migrator id Rename table dashboard to dashboard_v1 <*> <*>	2
3419	Executing migration logger migrator id create dashboard <*>	2
3420	Executing migration logger migrator id copy dashboard <*> to <*>	2
3421	Executing migration logger migrator id drop table dashboard_v1	2
3422	Executing migration logger migrator id alter dashboard.data to mediumtext <*>	2
3423	Executing migration logger migrator id Add column updated_by in dashboard <*> <*>	2
3424	Executing migration logger migrator id Add column created_by in dashboard <*> <*>	2
3425	Executing migration logger migrator id Add column gnetId in dashboard	2
3426	Executing migration logger migrator id Add index for gnetId in dashboard	2
3427	Executing migration logger migrator id Add column plugin_id in dashboard	2
3428	Executing migration logger migrator id Add index for plugin_id in dashboard	2
3429	Executing migration logger migrator id Add index for dashboard_id in dashboard_tag	2
3430	Executing migration logger migrator id Update dashboard table charset	2
3431	Executing migration logger migrator id Update dashboard_tag table charset	2
3432	Executing migration logger migrator id Add column folder_id in dashboard	2
3433	Executing migration logger migrator id Add column isFolder in dashboard	2
3434	Executing migration logger migrator id Add column has_acl in dashboard	2
3435	Executing migration logger migrator id Add column uid in dashboard	2
3436	Executing migration logger migrator id Update uid column values in dashboard	2
3437	Executing migration logger migrator id Add unique index dashboard_org_id_uid	2
3438	Executing migration logger migrator id Remove unique index org_id_slug	2
3439	Executing migration logger migrator id Update dashboard title length	2
3440	Executing migration logger migrator id Add unique index for dashboard_org_id_title_folder_id	2
3441	Executing migration logger migrator id create dashboard_provisioning	2
3442	Executing migration logger migrator id Rename table dashboard_provisioning to dashboard_provisioning_tmp_qwerty <*> <*>	2
3443	Executing migration logger migrator id create dashboard_provisioning <*>	2
3444	Executing migration logger migrator id create index IDX_dashboard_provisioning_dashboard_id <*> <*>	2
3445	Executing migration logger migrator id create index IDX_dashboard_provisioning_dashboard_id_name <*> <*>	2
3446	Executing migration logger migrator id copy dashboard_provisioning <*> to <*>	2
3447	Executing migration logger migrator id drop dashboard_provisioning_tmp_qwerty	2
3448	Executing migration logger migrator id Add check_sum column	2
3449	Executing migration logger migrator id Add index for dashboard_title	1
3450	Executing migration logger migrator id delete tags for deleted dashboards	1
3451	Executing migration logger migrator id delete stars for deleted dashboards	1
3452	Executing migration logger migrator id create data_source table	2
3453	Executing migration logger migrator id add index data_source.account_id	2
3454	Executing migration logger migrator id add unique index data_source.account_id_name	2
3455	Executing migration logger migrator id drop index IDX_data_source_account_id <*> <*>	2
3456	Executing migration logger migrator id drop index UQE_data_source_account_id_name <*> <*>	2
3457	Executing migration logger migrator id Rename table data_source to data_source_v1 <*> <*>	2
3458	Executing migration logger migrator id create index IDX_data_source_org_id <*> <*>	2
3459	Executing migration logger migrator id create index UQE_data_source_org_id_name <*> <*>	2
3460	Executing migration logger migrator id Drop old table data_source_v1 #2	2
3461	Executing migration logger migrator id Add column with_credentials	2
3462	Executing migration logger migrator id Add secure json data column	2
3463	Executing migration logger migrator id Update data_source table charset	2
3464	Executing migration logger migrator id Update initial version to <*>	2
3465	Executing migration logger migrator id Add read_only data column	2
3466	Executing migration logger migrator id Migrate logging ds to loki ds	2
3467	Executing migration logger migrator id Update json_data with nulls	2
3468	Executing migration logger migrator id Add uid column	1
3469	Executing migration logger migrator id Update uid value	1
3470	Executing migration logger migrator id Add unique index datasource_org_id_uid	1
3471	Executing migration logger migrator id add unique index datasource_org_id_is_default	1
3472	Executing migration logger migrator id create api_key table	2
3473	Executing migration logger migrator id add index api_key.account_id	2
3474	Executing migration logger migrator id add index api_key.key	2
3475	Executing migration logger migrator id add index api_key.account_id_name	2
3476	Executing migration logger migrator id drop index IDX_api_key_account_id <*> <*>	2
3477	Executing migration logger migrator id drop index UQE_api_key_key <*> <*>	2
3478	Executing migration logger migrator id drop index UQE_api_key_account_id_name <*> <*>	2
3479	Executing migration logger migrator id Rename table api_key to api_key_v1 <*> <*>	2
3480	Executing migration logger migrator id create api_key table <*>	2
3481	Executing migration logger migrator id create index UQE_api_key_org_id_name <*> <*>	2
3482	Executing migration logger migrator id copy api_key <*> to <*>	2
3483	Executing migration logger migrator id Drop old table api_key_v1	2
3484	Executing migration logger migrator id Update api_key table charset	2
3485	Executing migration logger migrator id Add expires to api_key table	2
3486	Executing migration logger migrator id create dashboard_snapshot table <*>	2
3487	Executing migration logger migrator id drop table <*> <*>	2
3488	Executing migration logger migrator id create dashboard_snapshot table <*> #2	2
3489	Executing migration logger migrator id alter dashboard_snapshot to mediumtext <*>	2
3490	Executing migration logger migrator id Update dashboard_snapshot table charset	2
3491	Executing migration logger migrator id Add column external_delete_url to dashboard_snapshots table	2
3492	Executing migration logger migrator id Add encrypted dashboard json column	1
3493	Executing migration logger migrator id Change dashboard_encrypted column to MEDIUMBLOB	1
3494	Executing migration logger migrator id create quota table <*>	2
3495	Executing migration logger migrator id create index UQE_quota_org_id_user_id_target <*> <*>	2
3496	Executing migration logger migrator id Update quota table charset	2
3497	Executing migration logger migrator id create plugin_setting table	2
3498	Executing migration logger migrator id create data_source table <*>	2
3499	Executing migration logger migrator id Add column plugin_version to plugin_settings	2
3500	Executing migration logger migrator id Update plugin_setting table charset	2
3501	Executing migration logger migrator id create session table	2
3502	Executing migration logger migrator id Drop old table playlist table	2
3503	Executing migration logger migrator id Drop old table playlist_item table	2
3504	Executing migration logger migrator id create playlist table <*>	2
3505	Executing migration logger migrator id create playlist item table <*>	2
3506	Executing migration logger migrator id Update playlist table charset	2
3507	Executing migration logger migrator id Update playlist_item table charset	2
3508	Executing migration logger migrator id drop preferences table <*>	4
3509	Executing migration logger migrator id create index UQE_plugin_setting_org_id_plugin_id <*> <*>	2
3510	Executing migration logger migrator id Update preferences table charset	2
3511	Executing migration logger migrator id Add column team_id in preferences	2
3512	Executing migration logger migrator id create index UQE_api_key_key <*> <*>	2
3513	Executing migration logger migrator id create alert table <*>	2
3514	Executing migration logger migrator id add index alert org_id id	2
3515	Executing migration logger migrator id add index alert state	2
3516	Executing migration logger migrator id add index alert dashboard_id	2
3517	Executing migration logger migrator id Create alert_rule_tag table <*>	3
3518	Executing migration logger migrator id Add unique index alert_rule_tag.alert_id_tag_id	2
3519	Executing migration logger migrator id drop index UQE_alert_rule_tag_alert_id_tag_id <*> <*>	1
3520	Executing migration logger migrator id create preferences table <*>	2
3521	Executing migration logger migrator id create index UQE_alert_rule_tag_alert_id_tag_id <*> Add unique index alert_rule_tag.alert_id_tag_id V2	1
3522	Executing migration logger migrator id copy alert_rule_tag <*> to <*>	1
3523	Executing migration logger migrator id drop table alert_rule_tag_v1	1
3524	Executing migration logger migrator id create alert_notification table <*>	2
3525	Executing migration logger migrator id Add column is_default	2
3526	Executing migration logger migrator id Add column frequency	2
3527	Executing migration logger migrator id Add column send_reminder	2
3528	Executing migration logger migrator id Add column disable_resolve_message	2
3529	Executing migration logger migrator id add index alert_notification org_id name	2
3530	Executing migration logger migrator id Update alert table charset	2
3531	Executing migration logger migrator id Update alert_notification table charset	2
3532	Executing migration logger migrator id Rename table alert_rule_tag to alert_rule_tag_v1 <*> <*>	1
3533	Executing migration logger migrator id add index notification_journal org_id alert_id notifier_id	2
3534	Executing migration logger migrator id drop alert_notification_journal	2
3535	Executing migration logger migrator id create alert_notification_state table <*>	2
3536	Executing migration logger migrator id add index alert_notification_state org_id alert_id notifier_id	2
3537	Executing migration logger migrator id Add for to alert table	2
3538	Executing migration logger migrator id Add column uid in alert_notification	2
3539	Executing migration logger migrator id Update uid column values in alert_notification	2
3540	Executing migration logger migrator id Add unique index alert_notification_org_id_uid	2
3541	Executing migration logger migrator id Remove unique index org_id_name	2
3542	Executing migration logger migrator id Update team_id column values in preferences	2
3543	Executing migration logger migrator id alter alert.settings to mediumtext	1
3544	Executing migration logger migrator id Add column secure_settings in alert_notification	1
3545	Executing migration logger migrator id Add non-unique index alert_rule_tag_alert_id	1
3546	Executing migration logger migrator id Drop old annotation table <*>	2
3547	Executing migration logger migrator id create annotation table <*>	2
3548	Executing migration logger migrator id add index annotation 0 <*>	2
3549	Executing migration logger migrator id add index annotation <*> <*>	6
3550	Executing migration logger migrator id add index annotation 4 <*>	2
3551	Executing migration logger migrator id Update annotation table charset	2
3552	Executing migration logger migrator id Add column region_id to annotation table	2
3553	Executing migration logger migrator id Drop category_id index	2
3554	Executing migration logger migrator id Add non-unique index alert_notification_state_alert_id	1
3555	Executing migration logger migrator id Add column tags to annotation table	2
3556	Executing migration logger migrator id Add unique index annotation_tag.annotation_id_tag_id	2
3557	Executing migration logger migrator id drop index UQE_annotation_tag_annotation_id_tag_id <*> <*>	1
3558	Executing migration logger migrator id Rename table annotation_tag to annotation_tag_v2 <*> <*>	1
3559	Executing migration logger migrator id Create annotation_tag table <*>	3
3560	Executing migration logger migrator id create index UQE_annotation_tag_annotation_id_tag_id <*> Add unique index annotation_tag.annotation_id_tag_id V3	1
3561	Executing migration logger migrator id copy annotation_tag <*> to <*>	1
3562	Executing migration logger migrator id drop table annotation_tag_v2	1
3563	Executing migration logger migrator id Update alert annotations and set TEXT to empty	2
3564	Executing migration logger migrator id Add created time to annotation table	2
3565	Executing migration logger migrator id Add updated time to annotation table	2
3566	Executing migration logger migrator id Add index for created in annotation table	2
3567	Executing migration logger migrator id Add index for updated in annotation table	2
3568	Executing migration logger migrator id Convert existing annotations from seconds to milliseconds	2
3569	Executing migration logger migrator id Add epoch_end column	2
3570	Executing migration logger migrator id Add index for epoch_end	2
3571	Executing migration logger migrator id Make epoch_end the same as epoch	2
3572	Executing migration logger migrator id Move region to single row	2
3573	Executing migration logger migrator id Remove index org_id_epoch from annotation table	2
3574	Executing migration logger migrator id Remove index org_id_dashboard_id_panel_id_epoch from annotation table	2
3575	Executing migration logger migrator id Add index for org_id_dashboard_id_epoch_end_epoch on annotation table	2
3576	Executing migration logger migrator id Add index for org_id_epoch_end_epoch on annotation table	2
3577	Executing migration logger migrator id Remove index org_id_epoch_epoch_end from annotation table	2
3578	Executing migration logger migrator id Add index for alert_id on annotation table	2
3579	Executing migration logger migrator id create test_data table	2
3580	Executing migration logger migrator id create dashboard_version table <*>	2
3581	Executing migration logger migrator id add index dashboard_version.dashboard_id	2
3582	Executing migration logger migrator id add unique index dashboard_version.dashboard_id and dashboard_version.version	2
3583	Executing migration logger migrator id Set dashboard version to <*> where 0	2
3584	Executing migration logger migrator id <*> existing dashboard data in dashboard_version table <*>	2
3585	Executing migration logger migrator id alter dashboard_version.data to mediumtext <*>	2
3586	Executing migration logger migrator id create team table	2
3587	Executing migration logger migrator id add index team.org_id	2
3588	Executing migration logger migrator id add unique index team_org_id_name	2
3589	Executing migration logger migrator id create team member table	2
3590	Executing migration logger migrator id add index team_member.org_id	2
3591	Executing migration logger migrator id add unique index team_member_org_id_team_id_user_id	2
3592	Executing migration logger migrator id add index team_member.team_id	1
3593	Executing migration logger migrator id Add column email to team table	2
3594	Executing migration logger migrator id Add column external to team_member table	2
3595	Executing migration logger migrator id Add column permission to team_member table	2
3596	Executing migration logger migrator id create dashboard acl table	2
3597	Executing migration logger migrator id add index dashboard_acl_dashboard_id	2
3598	Executing migration logger migrator id add unique index dashboard_acl_dashboard_id_user_id	2
3599	Executing migration logger migrator id add unique index <*>	8
3600	Executing migration logger migrator id <*> default acl rules in dashboard_acl table	2
3601	Executing migration logger migrator id delete acl rules for deleted dashboards and folders	1
3602	Executing migration logger migrator id create tag table	2
3603	Executing migration logger migrator id add index tag.key_value	2
3604	Executing migration logger migrator id create login attempt table	2
3605	Executing migration logger migrator id add index login_attempt.username	2
3606	Executing migration logger migrator id drop index IDX_login_attempt_username <*> <*>	2
3607	Executing migration logger migrator id Rename table login_attempt to <*> <*> <*>	2
3608	Executing migration logger migrator id create login_attempt <*>	2
3609	Executing migration logger migrator id create index IDX_login_attempt_username <*> <*>	2
3610	Executing migration logger migrator id copy login_attempt <*> to <*>	2
3611	Executing migration logger migrator id create user auth table	2
3612	Executing migration logger migrator id alter <*> to length <*>	2
3613	Executing migration logger migrator id Add OAuth access token to user_auth	2
3614	Executing migration logger migrator id Add OAuth refresh token to user_auth	2
3615	Executing migration logger migrator id Add OAuth token type to user_auth	2
3616	Executing migration logger migrator id Add OAuth expiry to user_auth	2
3617	Executing migration logger migrator id Add index to user_id column in user_auth	2
3618	Executing migration logger migrator id create server_lock table	2
3619	Executing migration logger migrator id add index server_lock.operation_uid	2
3620	Executing migration logger migrator id create user auth token table	2
3621	Executing migration logger migrator id add index user_auth_token.user_id	1
3622	Executing migration logger migrator id create notification_journal table <*>	2
3623	Executing migration logger migrator id create short_url table <*>	1
3624	Executing migration logger migrator id add index <*>	1
3625	Created default admin logger <*> user admin	1
3626	Created default organization logger <*>	1
3627	Starting plugin search logger plugins	2
3628	Registering plugin logger plugins id input	1
3629	inserting datasource from configuration logger provisioning.datasources name Prometheus uid	1
3630	Failed to read plugin provisioning files from directory logger provisioning.plugins path <*> error open <*> no such file or directory	1
3631	Executing migration logger migrator id create cache_data table	2
3632	HTTP Server Listen logger http.server address <*> protocol http subUrl socket	2
3633	END logs for container grafana of pod <*>	2
3634	Can t read alert notification provisioning files from directory logger provisioning.notifiers path <*> error open <*> no such file or directory	1
3635	Evaluating rule failed rule record node node_num_cpu sum nexpr count by clusterName node sum by node cpu node_cpu_seconds_total job node-exporter on namespace pod group_left node node_namespace_pod kube_pod_info n err found duplicate series for the match group namespace monitoring pod <*> on the right <*> of the operation __name__ node_namespace_pod kube_pod_info namespace monitoring node <*> pod <*> __name__ node_namespace_pod kube_pod_info namespace monitoring node <*> pod <*> <*> matching not allowed matching labels must be unique on one side	9
3636	heartbeat failed err perform GET request against http <*> <*> Get http <*> <*> context deadline exceeded	2
3637	heartbeat failed err expected 2xx response got <*> Body Service Unavailable	1
3638	<*> <*> watch of <*> ended with an error on the server unable to decode an event from the watch stream context canceled has prevented the request from succeeding	1
3639	successfully loaded prometheus external labels external_labels clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*>	2
3640	START logs for container consul of pod <*>	2
3641	> Starting Consul agent...	2
3642	> Consul agent running!	2
3643	Node ID <*>	2
3644	Node name <*>	2
3645	Datacenter <*> Segment	2
3646	Server false Bootstrap false	2
3647	Client Addr <*> HTTP <*> HTTPS <*> gRPC <*> DNS <*>	2
3648	Cluster Addr <*> LAN <*> WAN <*>	2
3649	Encrypt Gossip true TLS-Outgoing false <*> false	2
3650	> Log data will now stream in as it occurs	2
3651	<*> <*> <*> <*> INFO serf EventMemberJoin <*> <*>	55
3652	<*> <*> <*> <*> WARN agent/proxy running as root will not start managed proxies	2
3653	<*> <*> <*> <*> INFO agent Started DNS server <*> <*> udp	2
3654	<*> <*> <*> <*> INFO agent Started DNS server <*> <*> tcp	2
3655	<*> <*> <*> <*> INFO agent Started HTTP server on <*> tcp	2
3656	<*> <*> <*> <*> INFO agent started state syncer	2
3657	<*> <*> <*> <*> INFO agent Retry join LAN is supported for aliyun aws azure digitalocean gce k8s os packet scaleway softlayer triton vsphere	2
3658	<*> <*> <*> <*> INFO agent Joining LAN cluster...	2
3659	<*> <*> <*> <*> WARN manager No servers available	2
3660	<*> <*> <*> <*> ERR agent failed to sync remote state No known Consul servers	2
3661	<*> <*> <*> <*> INFO agent LAN joining <*>	2
3662	<*> <*> <*> <*> WARN memberlist Refuting a suspect message from <*>	2
3663	<*> <*> <*> <*> INFO consul adding server <*> Addr <*> <*> DC <*>	6
3664	<*> <*> <*> <*> INFO agent LAN joined <*> Err <nil>	2
3665	<*> <*> <*> <*> INFO agent Join LAN completed. Synced with <*> initial agents	2
3666	<*> <*> <*> <*> INFO agent Synced service <*>	216
3667	> Failed to check for updates Get https <*> amd64 os linux signature <*> version <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers	2
3668	<*> <*> <*> <*> INFO serf <*> <*> <*>	1
3669	<*> <*> <*> <*> ERR memberlist Conflicting address for <*> Mine <*> <*> Theirs <*> <*>	1
3670	<*> <*> <*> <*> WARN serf Name conflict for <*> both <*> <*> and <*> <*> are claiming	1
3671	END logs for container consul of pod <*>	2
3672	START logs for container thanos of pod <*>	3
3673	maxprocs Leaving GOMAXPROCS <*> CPU quota undefined	1
3674	Max compaction level is <*> than should be current <*> default 4	1
3675	retention policy of <*> samples is enabled duration <*>	1
3676	starting compact node	1
3677	start sync of metas	15
3678	successfully synchronized block metadata duration <*> cached <*> returned <*> partial 0	141
3679	start of GC	15
3680	start of compactions	15
3681	compaction iterations done	14
3682	downsampling was explicitly disabled	14
3683	start optional retention	14
3684	optional retention apply done	14
3685	started cleaning of aborted partial uploads	14
3686	cleaning of aborted partial uploads done	14
3687	started cleaning of blocks marked for deletion	14
3688	cleaning of blocks marked for deletion done	14
3689	block is too fresh for now block <*>	24
3690	compaction available and planned downloading blocks plan <*> <*> <*> <*>	2
3691	downloaded and verified blocks compacting blocks plan <*> <*> <*> <*> duration <*>	2
3692	compact blocks count 4 mint <*> maxt <*> ulid <*> sources <*> <*> <*> <*> duration <*>	2
3693	compacted blocks new <*> blocks <*> <*> <*> <*> duration <*> overlapping_blocks false	2
3694	uploaded file from <*> dst <*> bucket tracing <*>	8
3695	uploaded block result_block <*> duration <*>	2
3696	marking compacted block for deletion old_block <*>	8
3697	block has been marked for deletion block <*>	8
3698	END logs for container thanos of pod <*>	3
3699	Using default resources	1
3700	Using all namespace	1
3701	metric <*> Excluding the following lists that were on <*>	1
3702	Testing communication with server	1
3703	Running with Kubernetes cluster version <*> git version <*> git tree state clean. commit <*> platform linux/amd64	1
3704	Communication with server successful	1
3705	Starting metrics server <*> <*>	1
3706	Autosharding disabled	1
3707	Starting <*> self metrics server <*> <*>	1
3708	Active resources certificatesigningrequests configmaps cronjobs daemonsets deployments endpoints horizontalpodautoscalers ingresses jobs leases limitranges mutatingwebhookconfigurations namespaces networkpolicies nodes persistentvolumeclaims persistentvolumes <*> pods replicasets replicationcontrollers resourcequotas secrets services statefulsets storageclasses validatingwebhookconfigurations volumeattachments	1
3709	maxprocs Updating GOMAXPROCS <*> determined from CPU quota	2
3710	created in-memory index cache maxItemSizeBytes <*> maxSizeBytes <*> maxItems maxInt	2
3711	registering as gRPC StoreAPI	2
3712	starting store node	2
3713	initializing bucket store	2
3714	loading new block id <*>	64
3715	failed to read index-header from disk recreating path <*> err try lock file open <*> no such file or directory	64
3716	built index-header file path <*> elapsed <*>	64
3717	loaded new block elapsed <*> id <*>	64
3718	bucket store ready init_duration <*>	2
3719	Blocks source resolutions blocks <*> MaximumResolution <*> mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*> spans Range <*> Resolution 0	72
3720	stats query processed stats blocksQueried 4 postingsTouched 0 postingsTouchedSizeSum 0 postingsToFetch 0 postingsFetched 0 postingsFetchedSizeSum 0 postingsFetchCount 0 postingsFetchDurationSum 0 cachedPostingsCompressions 0 cachedPostingsCompressionErrors 0 cachedPostingsOriginalSizeSum 0 cachedPostingsCompressedSizeSum 0 cachedPostingsCompressionTimeSum 0 cachedPostingsDecompressions 0 cachedPostingsDecompressionErrors 0 cachedPostingsDecompressionTimeSum 0 seriesTouched 0 seriesTouchedSizeSum 0 seriesFetched 0 seriesFetchedSizeSum 0 seriesFetchCount 0 seriesFetchDurationSum 0 chunksTouched 0 chunksTouchedSizeSum 0 chunksFetched 0 chunksFetchedSizeSum 0 chunksFetchCount 0 chunksFetchDurationSum 0 getAllDuration <*> mergedSeriesCount 0 mergedChunksCount 0 mergeDuration <*> err null	332
3721	stats query processed stats blocksQueried <*> postingsTouched 0 postingsTouchedSizeSum 0 postingsToFetch 0 postingsFetched 0 postingsFetchedSizeSum 0 postingsFetchCount 0 postingsFetchDurationSum 0 cachedPostingsCompressions 0 cachedPostingsCompressionErrors 0 cachedPostingsOriginalSizeSum 0 cachedPostingsCompressedSizeSum 0 cachedPostingsCompressionTimeSum 0 cachedPostingsDecompressions 0 cachedPostingsDecompressionErrors 0 cachedPostingsDecompressionTimeSum 0 seriesTouched 0 seriesTouchedSizeSum 0 seriesFetched 0 seriesFetchedSizeSum 0 seriesFetchCount 0 seriesFetchDurationSum 0 chunksTouched 0 chunksTouchedSizeSum 0 chunksFetched 0 chunksFetchedSizeSum 0 chunksFetchCount 0 chunksFetchDurationSum 0 getAllDuration <*> mergedSeriesCount 0 mergedChunksCount 0 mergeDuration <*> err null	1313
3722	Blocks source resolutions blocks <*> MaximumResolution 0 mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*> spans Range <*> Resolution 0	1024
3723	No block found mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*>	6
3724	stats query processed stats blocksQueried 0 postingsTouched 0 postingsTouchedSizeSum 0 postingsToFetch 0 postingsFetched 0 postingsFetchedSizeSum 0 postingsFetchCount 0 postingsFetchDurationSum 0 cachedPostingsCompressions 0 cachedPostingsCompressionErrors 0 cachedPostingsOriginalSizeSum 0 cachedPostingsCompressedSizeSum 0 cachedPostingsCompressionTimeSum 0 cachedPostingsDecompressions 0 cachedPostingsDecompressionErrors 0 cachedPostingsDecompressionTimeSum 0 seriesTouched 0 seriesTouchedSizeSum 0 seriesFetched 0 seriesFetchedSizeSum 0 seriesFetchCount 0 seriesFetchDurationSum 0 chunksTouched 0 chunksTouchedSizeSum 0 chunksFetched 0 chunksFetchedSizeSum 0 chunksFetchCount 0 chunksFetchDurationSum 0 getAllDuration <*> mergedSeriesCount 0 mergedChunksCount 0 mergeDuration <*> err null	6
3725	Blocks source resolutions blocks 6 MaximumResolution <*> mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*> spans Range <*> Resolution 0	210
3726	Blocks source resolutions blocks 6 MaximumResolution 0 mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*> spans Range <*> Resolution 0	274
3727	Blocks source resolutions blocks 4 MaximumResolution 0 mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*> spans Range <*> Resolution 0	286
3728	stats query processed stats blocksQueried 6 postingsTouched 0 postingsTouchedSizeSum 0 postingsToFetch 0 postingsFetched 0 postingsFetchedSizeSum 0 postingsFetchCount 0 postingsFetchDurationSum 0 cachedPostingsCompressions 0 cachedPostingsCompressionErrors 0 cachedPostingsOriginalSizeSum 0 cachedPostingsCompressedSizeSum 0 cachedPostingsCompressionTimeSum 0 cachedPostingsDecompressions 0 cachedPostingsDecompressionErrors 0 cachedPostingsDecompressionTimeSum 0 seriesTouched 0 seriesTouchedSizeSum 0 seriesFetched 0 seriesFetchedSizeSum 0 seriesFetchCount 0 seriesFetchDurationSum 0 chunksTouched 0 chunksTouchedSizeSum 0 chunksFetched 0 chunksFetchedSizeSum 0 chunksFetchCount 0 chunksFetchDurationSum 0 getAllDuration <*> mergedSeriesCount 0 mergedChunksCount 0 mergeDuration <*> err null	145
3729	failed to resolve addresses for storeAPIs err <*> errors lookup SRV records <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout lookup SRV records <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout	1
3730	level warn ts <*> <*> <*> caller proxy.go <*> err No StoreAPIs matched for this query stores	3
3731	returning partial response	57
3732	removing store because it s unhealthy or does not exist address <*> <*> extLset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*>	7
3733	failed to resolve addresses for storeAPIs err <*> errors lookup SRV records <*> lookup <*> on <*> <*> no such host lookup SRV records <*> lookup <*> on <*> <*> no such host lookup SRV records <*> lookup <*> on <*> <*> no such host	10896
3734	failed to resolve addresses for storeAPIs err <*> errors look IP addresses <*> lookup <*> on <*> <*> no such host lookup SRV records <*> lookup <*> on <*> <*> no such host	1
3735	No block found mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*>	6
3736	Blocks source resolutions blocks <*> MaximumResolution 0 mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*> spans Range <*> Resolution 0	944
3737	Blocks source resolutions blocks 6 MaximumResolution <*> mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*> spans Range <*> Resolution 0	210
3738	Blocks source resolutions blocks 6 MaximumResolution 0 mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*> spans Range <*> Resolution 0	274
3739	Blocks source resolutions blocks 4 MaximumResolution 0 mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*> spans Range <*> Resolution 0	286
3740	Blocks source resolutions blocks <*> MaximumResolution <*> mint <*> maxt <*> lset clusterName <*> context CDE datacenter Titan environment production prometheus <*> prometheus_replica <*> region <*> spans Range <*> Resolution 0	2
3741	stats query processed stats blocksQueried 6 postingsTouched 6 postingsTouchedSizeSum <*> postingsToFetch 0 postingsFetched 6 postingsFetchedSizeSum <*> postingsFetchCount 6 postingsFetchDurationSum <*> cachedPostingsCompressions 0 cachedPostingsCompressionErrors 0 cachedPostingsOriginalSizeSum <*> cachedPostingsCompressedSizeSum 0 cachedPostingsCompressionTimeSum 0 cachedPostingsDecompressions 0 cachedPostingsDecompressionErrors 0 cachedPostingsDecompressionTimeSum 0 seriesTouched 6 seriesTouchedSizeSum <*> seriesFetched 6 seriesFetchedSizeSum <*> seriesFetchCount 6 seriesFetchDurationSum <*> chunksTouched <*> chunksTouchedSizeSum <*> chunksFetched <*> chunksFetchedSizeSum <*> chunksFetchCount 6 chunksFetchDurationSum <*> getAllDuration <*> mergedSeriesCount <*> mergedChunksCount 0 mergeDuration <*> err null	1
3742	failed to resolve addresses for storeAPIs err <*> errors lookup SRV records <*> lookup <*> on <*> <*> no such host lookup SRV records <*> lookup <*> on <*> <*> no such host	15
3743	failed to resolve addresses for storeAPIs err lookup SRV records <*> lookup <*> on <*> <*> no such host	3
3744	adding new storeAPI to query storeset address <*> <*> extLset	1
3745	removing store because it s unhealthy or does not exist address <*> <*> extLset clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*> clusterName <*> context CDE datacenter Titan environment production prometheus monitoring/mesh prometheus_replica <*> region <*>	3
3746	failed to resolve addresses for storeAPIs err <*> errors lookup SRV records <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout lookup SRV records <*> lookup <*> on <*> <*> no such host lookup SRV records <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout	1
3747	failed to resolve addresses for storeAPIs err <*> errors look IP addresses <*> lookup <*> on <*> <*> no such host look IP addresses <*> lookup <*> on <*> <*> no such host	1
3748	failed to resolve addresses for storeAPIs err 4 errors lookup SRV records <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout lookup SRV records <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout lookup SRV records <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout lookup SRV records <*> lookup <*> on <*> <*> read udp <*> <*> <*> i/o timeout	16
3749	error while sending encoded metrics write tcp <*> <*> <*> write broken pipe n source <autogenerated> <*>	1
3750	<*> <*> <*> <*> http proxy error context canceled	1
3751	START logs for container istio-proxy of pod <*>	7
3752	<*> <*> <*> info FLAG <*> 0	14
3753	<*> <*> <*> info FLAG <*> false	23
3754	<*> <*> <*> info FLAG <*> <*>	54
3755	<*> <*> <*> info FLAG <*>	65
3756	<*> <*> <*> info FLAG <*> default info	8
3757	<*> <*> <*> info FLAG <*> default none	8
3758	<*> <*> <*> info FLAG <*> stdout	8
3759	<*> <*> <*> info FLAG <*> misc error	7
3760	<*> <*> <*> info FLAG <*> warning	7
3761	<*> <*> <*> info FLAG <*> istio-egressgateway	3
3762	<*> <*> <*> info FLAG <*> Kubernetes	9
3763	<*> <*> <*> info FLAG <*> GoogleTokenExchange	7
3764	<*> <*> <*> info FLAG <*> cluster.local	9
3765	<*> <*> <*> info Version <*>	7
3766	<*> <*> <*> info Obtained private IP <*> fe80 <*> <*> fe2a <*>	1
3767	<*> <*> <*> info Apply mesh config from file accessLogEncoding TEXT	7
3768	accessLogFile	7
3769	accessLogFormat	7
3770	defaultConfig	8
3771	concurrency <*>	8
3772	configPath <*>	15
3773	connectTimeout <*>	8
3774	controlPlaneAuthPolicy NONE	7
3775	discoveryAddress <*> <*>	15
3776	drainDuration <*>	15
3777	parentShutdownDuration <*>	15
3778	proxyAdminPort <*>	15
3779	proxyMetadata	15
3780	DNS_AGENT	15
3781	serviceCluster istio-proxy	9
3782	tracing	15
3783	zipkin	15
3784	address <*> <*>	15
3785	disableMixerHttpReports true	8
3786	disablePolicyChecks true	8
3787	enablePrometheusMerge false	8
3788	ingressClass istio	8
3789	ingressControllerMode STRICT	8
3790	ingressService istio-ingressgateway	8
3791	protocolDetectionTimeout <*>	8
3792	reportBatchMaxEntries <*>	8
3793	reportBatchMaxTime <*>	8
3794	sdsUdsPath unix <*>	8
3795	trustDomain cluster.local	8
3796	trustDomainAliases null	7
3797	<*> <*> <*> info Effective config binaryPath <*>	7
3798	envoyAccessLogService	8
3799	envoyMetricsService	8
3800	serviceCluster istio-egressgateway	3
3801	statNameLength <*>	8
3802	statusPort <*>	8
3803	<*> <*> <*> info Proxy role model.Proxy ClusterID Type router IPAddresses string <*> fe80 <*> <*> fe2a <*> ID <*> Locality <*> nil DNSDomain <*> ConfigNamespace Metadata model.NodeMetadata nil SidecarScope model.SidecarScope nil PrevSidecarScope model.SidecarScope nil MergedGateway model.MergedGateway nil ServiceInstances model.ServiceInstance nil IstioVersion model.IstioVersion nil ipv6Support false ipv4Support false GlobalUnicastIP XdsResourceGenerator model.XdsResourceGenerator nil Active map string model.WatchedResource nil	1
3804	<*> <*> <*> info JWT policy is <*>	8
3805	<*> <*> <*> info PilotSAN string <*>	7
3806	<*> <*> <*> info MixerSAN string spiffe <*>	7
3807	<*> <*> <*> info serverOptions.CAEndpoint <*> <*>	7
3808	<*> <*> <*> info Using user-configured CA <*> <*>	7
3809	<*> <*> <*> info istiod uses self-issued certificate	7
3810	<*> <*> <*> info the CA cert of istiod is <*> <*>	7
3811	<*> <*> <*> info parsed scheme	7
3812	<*> <*> <*> info scheme not registered fallback to default scheme	7
3813	<*> <*> <*> info ccResolverWrapper sending update to cc <*> <*> <nil> 0 <nil> <nil> <nil>	7
3814	<*> <*> <*> info ClientConn switching balancer to pick_first	7
3815	<*> <*> <*> info Channel switches to new LB policy pick_first	7
3816	<*> <*> <*> info Subchannel Connectivity change to CONNECTING	82
3817	<*> <*> <*> info Skipping gateway SDS	3
3818	<*> <*> <*> info pickfirstBalancer HandleSubConnStateChange <*> CONNECTING <nil>	82
3819	<*> <*> <*> info Subchannel picks a new address <*> <*> to connect	82
3820	<*> <*> <*> info Channel Connectivity change to CONNECTING	82
3821	<*> <*> <*> info sds SDS gRPC server for workload UDS starts listening on <*>	7
3822	<*> <*> <*> info Starting proxy agent	7
3823	<*> <*> <*> info sds Start SDS grpc server	7
3824	<*> <*> <*> info Opening status port <*>	7
3825	<*> <*> <*> info Received new config creating new Envoy epoch 0	7
3826	<*> <*> <*> info Epoch 0 starting	7
3827	<*> <*> <*> info Envoy command <*> <*> <*> 0 <*> <*> <*> <*> <*> istio-egressgateway <*> <*> <*> <*> <*> <*> <*> <*> %l envoy %n %v <*> warning <*> misc error	3
3828	<*> <*> <*> warning envoy config <*> <*> StreamAggregatedResources gRPC config stream closed <*> no healthy upstream	97
3829	<*> <*> <*> warning envoy config <*> <*> Unable to establish new stream	97
3830	<*> <*> <*> warning envoy main <*> <*> there is no configured limit to the number of allowed active connections. Set a limit via the runtime key overload.global_downstream_max_connections	7
3831	<*> <*> <*> info grpc addrConn.createTransport failed to connect to <*> <*> <nil> 0 <nil> . Err connection error desc transport Error while dialing dial tcp i/o timeout . Reconnecting...	43
3832	<*> <*> <*> info Subchannel Connectivity change to TRANSIENT_FAILURE	60
3833	<*> <*> <*> info pickfirstBalancer HandleSubConnStateChange <*> TRANSIENT_FAILURE connection error desc transport Error while dialing dial tcp i/o timeout	43
3834	<*> <*> <*> info Channel Connectivity change to TRANSIENT_FAILURE	60
3835	<*> <*> <*> info sds resource default new connection	45
3836	<*> <*> <*> info sds Skipping waiting for ingress gateway secret	52
3837	<*> <*> <*> error citadelclient Failed to create certificate rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp i/o timeout	223
3838	<*> <*> <*> warn cache resource default request <*> CSR failed with error rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp i/o timeout retry in <*> millisec	194
3839	<*> <*> <*> error cache resource default request <*> CSR retrial timed out rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp i/o timeout	29
3840	<*> <*> <*> error cache resource default failed to generate secret for proxy rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp i/o timeout	29
3841	<*> <*> <*> error sds resource default Close connection. Failed to get secret for proxy <*> from secret cache rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp i/o timeout	29
3842	<*> <*> <*> info sds resource default connection is terminated rpc error code Canceled desc context canceled	31
3843	<*> <*> <*> warning envoy config <*> <*> StreamSecrets gRPC config stream closed <*> connection error desc transport Error while dialing dial tcp i/o timeout	29
3844	<*> <*> <*> warn Envoy proxy is NOT ready config not received from Pilot is Pilot running? cds updates 0 successful 0 rejected lds updates 0 successful 0 rejected	373
3845	<*> <*> <*> info Subchannel Connectivity change to READY	22
3846	<*> <*> <*> info pickfirstBalancer HandleSubConnStateChange <*> READY <nil>	22
3847	<*> <*> <*> info Channel Connectivity change to READY	22
3848	<*> <*> <*> info cache Root cert has changed start rotating root cert for SDS clients	7
3849	<*> <*> <*> info cache GenerateSecret default	14
3850	<*> <*> <*> info sds resource default pushed <*> pair to proxy	14
3851	<*> <*> <*> warning envoy config <*> <*> StreamAggregatedResources gRPC config stream closed <*> upstream connect error or <*> before headers. reset reason connection failure	21
3852	<*> <*> <*> info sds resource ROOTCA new connection	7
3853	<*> <*> <*> info cache Loaded root cert from certificate ROOTCA	7
3854	<*> <*> <*> info sds resource ROOTCA pushed root cert to proxy	7
3855	<*> <*> <*> info Envoy proxy is ready	7
3856	<*> <*> <*> info transport loopyWriter.run returning. connection error desc transport is closing	795
3857	<*> <*> <*> warning envoy config <*> <*> StreamAggregatedResources gRPC config stream closed <*>	13
3858	END logs for container istio-proxy of pod <*>	7
3859	<*> <*> <*> info FLAG <*> istio-ingressgateway	3
3860	<*> <*> <*> info Obtained private IP <*> fe80 <*> dcff feab bccf	1
3861	serviceCluster istio-ingressgateway	3
3862	<*> <*> <*> info Proxy role model.Proxy ClusterID Type router IPAddresses string <*> fe80 <*> dcff feab bccf ID <*> Locality <*> nil DNSDomain <*> ConfigNamespace Metadata model.NodeMetadata nil SidecarScope model.SidecarScope nil PrevSidecarScope model.SidecarScope nil MergedGateway model.MergedGateway nil ServiceInstances model.ServiceInstance nil IstioVersion model.IstioVersion nil ipv6Support false ipv4Support false GlobalUnicastIP XdsResourceGenerator model.XdsResourceGenerator nil Active map string model.WatchedResource nil	1
3863	<*> <*> <*> info Starting gateway SDS	3
3864	<*> <*> <*> warn secretfetcher failed load server cert/key pair from secret grafana server cert or private key is empty	3
3865	<*> <*> <*> warn secretfetcher failed load server cert/key pair from secret kiali server cert or private key is empty	3
3866	<*> <*> <*> info sds SDS gRPC server for ingress gateway controller starts listening on <*>	3
3867	<*> <*> <*> info sds Start SDS grpc server for ingress gateway proxy	3
3868	<*> <*> <*> info Envoy command <*> <*> <*> 0 <*> <*> <*> <*> <*> istio-ingressgateway <*> <*> <*> <*> <*> <*> <*> <*> %l envoy %n %v <*> warning <*> misc error	3
3869	<*> <*> <*> info grpc addrConn.createTransport failed to connect to <*> <*> <nil> 0 <nil> . Err connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout . Reconnecting...	15
3870	<*> <*> <*> info pickfirstBalancer HandleSubConnStateChange <*> TRANSIENT_FAILURE connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	15
3871	level warn ts <*> <*> <*> caller main.go <*> deprecation_notice <*> flag is deprecated use <*> instead.	1
3872	replaying WAL this may take awhile	1
3873	WAL segment loaded segment 0 maxSegment 0	1
3874	error creating new scrape pool err error creating HTTP client unable to load specified CA cert <*> open <*> no such file or directory scrape_pool <*>	30
3875	<*> <*> watch of <*> ended with too old resource version <*> <*>	14
3876	<*> <*> <*> info FLAG <*> istio-proxy	1
3877	<*> <*> <*> info Obtained private IP <*> fe80 dc7a <*> fe82 <*>	1
3878	<*> <*> <*> warn failed to read pod annotations open <*> no such file or directory	1
3879	<*> <*> <*> info Proxy role model.Proxy ClusterID Type sidecar IPAddresses string <*> fe80 dc7a <*> fe82 <*> ID <*> Locality <*> nil DNSDomain <*> ConfigNamespace Metadata model.NodeMetadata nil SidecarScope model.SidecarScope nil PrevSidecarScope model.SidecarScope nil MergedGateway model.MergedGateway nil ServiceInstances model.ServiceInstance nil IstioVersion model.IstioVersion nil ipv6Support false ipv4Support false GlobalUnicastIP XdsResourceGenerator model.XdsResourceGenerator nil Active map string model.WatchedResource nil	1
3880	<*> <*> <*> warn Envoy proxy is NOT ready Get http <*> <*> filter ^ cluster_manager .cds|listener_manager .lds . update_success|update_rejected dial tcp <*> <*> connect connection refused	1
3881	<*> <*> <*> warn failed to read pod labels open <*> no such file or directory	1
3882	<*> <*> <*> info Envoy command <*> <*> <*> 0 <*> <*> <*> <*> <*> istio-proxy <*> <*> <*> <*> <*> <*> <*> <*> %l envoy %n %v <*> warning <*> misc error	1
3883	<*> <*> <*> error citadelclient Failed to create certificate rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	8
3884	<*> <*> <*> error cache resource default request <*> CSR retrial timed out rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	2
3885	<*> <*> <*> error cache resource default failed to generate secret for proxy rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	2
3886	<*> <*> <*> error sds resource default Close connection. Failed to get secret for proxy <*> from secret cache rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	2
3887	<*> <*> <*> warning envoy config <*> <*> StreamSecrets gRPC config stream closed <*> connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	2
3888	<*> <*> <*> warn cache resource default request <*> CSR failed with error rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout retry in <*> millisec	6
3889	<*> <*> <*> warning envoy filter <*> <*> mTLS PERMISSIVE mode is used connection can be either plaintext or TLS and client cert can be omitted. Please consider to upgrade to mTLS STRICT mode for more secure configuration that only allows TLS connection with client cert. See https <*>	4
3890	<*> <*> <*> info grpc addrConn.createTransport failed to connect to <*> <*> <nil> 0 <nil> . Err connection error desc transport Error while dialing dial tcp <*> <*> connect connection refused . Reconnecting...	2
3891	<*> <*> <*> info pickfirstBalancer HandleSubConnStateChange <*> TRANSIENT_FAILURE connection error desc transport Error while dialing dial tcp <*> <*> connect connection refused	2
3892	<*> <*> <*> info Obtained private IP <*> fe80 <*> f4ff fe62 <*>	1
3893	<*> <*> <*> info Proxy role model.Proxy ClusterID Type router IPAddresses string <*> fe80 <*> f4ff fe62 <*> ID <*> Locality <*> nil DNSDomain <*> ConfigNamespace Metadata model.NodeMetadata nil SidecarScope model.SidecarScope nil PrevSidecarScope model.SidecarScope nil MergedGateway model.MergedGateway nil ServiceInstances model.ServiceInstance nil IstioVersion model.IstioVersion nil ipv6Support false ipv4Support false GlobalUnicastIP XdsResourceGenerator model.XdsResourceGenerator nil Active map string model.WatchedResource nil	1
3894	Config overridden from Environment variable logger settings var GF_SECURITY_ADMIN_USER istio-adm	1
3895	Config overridden from Environment variable logger settings var <*> false	1
3896	Config overridden from Environment variable logger settings var GF_AUTH_BASIC_ENABLED true	1
3897	Initializing SqlStore logger server	1
3898	Starting DB migration logger migrator	1
3899	Created default admin logger <*> user istio-adm	1
3900	Initializing HTTPServer logger server	1
3901	Initializing BackendPluginManager logger server	1
3902	Initializing PluginManager logger server	1
3903	Initializing HooksService logger server	1
3904	Initializing OSSLicensingService logger server	1
3905	Initializing InternalMetricsService logger server	1
3906	Initializing RemoteCache logger server	1
3907	Initializing RenderingService logger server	1
3908	Initializing AlertEngine logger server	1
3909	Initializing QuotaService logger server	1
3910	Initializing ServerLockService logger server	1
3911	Initializing UserAuthTokenService logger server	1
3912	Initializing DatasourceCacheService logger server	1
3913	Initializing LoginService logger server	1
3914	Initializing SearchService logger server	1
3915	Initializing TracingService logger server	1
3916	Initializing UsageStatsService logger server	1
3917	Initializing CleanUpService logger server	1
3918	Initializing NotificationService logger server	1
3919	Initializing provisioningServiceImpl logger server	1
3920	inserting datasource from configuration logger provisioning.datasources name Prometheus	1
3921	Backend rendering via phantomJS logger rendering renderer phantomJS	1
3922	phantomJS is deprecated and will be removed in a future release. You should consider migrating from phantomJS to grafana-image-renderer plugin. Read more at https <*> logger rendering renderer phantomJS	1
3923	Initializing Stream Manager	1
3924	<*> <*> <*> info Obtained private IP <*> fe80 <*> <*> <*> e0dd	1
3925	<*> <*> <*> info Proxy role model.Proxy ClusterID Type router IPAddresses string <*> fe80 <*> <*> <*> e0dd ID <*> Locality <*> nil DNSDomain <*> ConfigNamespace Metadata model.NodeMetadata nil SidecarScope model.SidecarScope nil PrevSidecarScope model.SidecarScope nil MergedGateway model.MergedGateway nil ServiceInstances model.ServiceInstance nil IstioVersion model.IstioVersion nil ipv6Support false ipv4Support false GlobalUnicastIP XdsResourceGenerator model.XdsResourceGenerator nil Active map string model.WatchedResource nil	1
3926	START logs for container discovery of pod <*>	2
3927	<*> <*> <*> info FLAG <*> localhost	1
3928	<*> <*> <*> info FLAG <*> true	2
3929	<*> <*> <*> info FLAG <*> authn authz health mixer	1
3930	<*> <*> <*> info mesh configuration	1
3931	proxyListenPort <*>	1
3932	enableTracing true	1
3933	binaryPath <*>	1
3934	outboundTrafficPolicy	1
3935	mode ALLOW_ANY	1
3936	enableAutoMtls true	1
3937	trustDomainAliases	1
3938	defaultServiceExportTo	1
3939	defaultVirtualServiceExportTo	1
3940	defaultDestinationRuleExportTo	1
3941	rootNamespace <*>	1
3942	localityLbSetting	1
3943	enabled true	1
3944	dnsRefreshRate <*>	1
3945	certificates	1
3946	thriftConfig	1
3947	serviceSettings	1
3948	<*> <*> <*> info version <*>	1
3949	<*> <*> <*> info flags	1
3950	<*> <*> <*> info mesh networks configuration	1
3951	networks	1
3952	<*> <*> <*> info No certificates specified skipping K8S DNS certificate controller	1
3953	<*> <*> <*> info CRD controller watching namespaces	1
3954	<*> <*> <*> info Ingress controller watching namespaces	1
3955	<*> <*> <*> warn Config Store <*> cluster.local <*> <*> <*> <*> cannot track distribution in aggregate this SetLedger operation is not supported by kube ingress controller	1
3956	<*> <*> <*> info Adding Kubernetes registry adapter	1
3957	<*> <*> <*> info Service controller watching namespace for services endpoints nodes and pods refresh <*>	1
3958	<*> <*> <*> info Use self-signed certificate as the CA certificate	1
3959	<*> <*> <*> info pkica Load signing key and cert from existing secret <*> <*>	1
3960	<*> <*> <*> info pkica Using existing public key <*> <*>	1
3961	<*> <*> <*> info pkica The Citadel s public key is successfully written into configmap istio-security in namespace <*>	1
3962	<*> <*> <*> info rootcertrotator Set up back off time <*> to start rotator.	1
3963	<*> <*> <*> info rootcertrotator Jitter is enabled wait <*> before starting root cert rotator.	1
3964	<*> <*> <*> info Generating istiod-signed cert for <*> <*> <*>	1
3965	<*> <*> <*> info No plugged-in cert at <*> self-signed cert is used	1
3966	<*> <*> <*> info DNS certificates created in <*>	1
3967	<*> <*> <*> info Setting up HTTPS webhook server for istiod webhooks	1
3968	<*> <*> <*> info validationServer Cert and Key reloaded	1
3969	<*> <*> <*> info validationServer <*> cert 0 <*> Issuer O cluster.local Subject SN <*> NotBefore <*> <*> <*> NotAfter <*> <*> <*>	1
3970	<*> <*> <*> info Setting up event handlers	1
3971	<*> <*> <*> info Starting Secrets controller	1
3972	<*> <*> <*> info Waiting for informer caches to sync	1
3973	<*> <*> <*> info Staring Istiod Server with primary cluster Kubernetes	1
3974	<*> <*> <*> info ControlZ available at <*> <*>	1
3975	<*> <*> <*> info status Starting status <*> controller	1
3976	<*> <*> <*> info Starting Pilot K8S CRD controller	1
3977	<*> <*> <*> info controller <*> is syncing...	1
3978	<*> <*> <*> info attempting to acquire leader lease <*>	5
3979	<*> <*> <*> info ads Starting ADS server	1
3980	<*> <*> <*> info Started <*> <*>	1
3981	<*> <*> <*> info Started DNS <*>	1
3982	<*> <*> <*> info serverca added client certificate authenticator	1
3983	<*> <*> <*> info serverca added K8s JWT authenticator	1
3984	<*> <*> <*> info Istiod CA has started	1
3985	<*> <*> <*> info starting gRPC discovery service at <*>	1
3986	<*> <*> <*> info ads Push debounce stable <*> <*> <*> since last change <*> since last push full true	1173
3987	<*> <*> <*> info ads XDS Pushing <*> <*> <*> Services 0 ConnectedEndpoints 0	1
3988	<*> <*> <*> info ads Full push new service <*>	71
3989	<*> <*> <*> info ads Full push service accounts changed <*>	145
3990	<*> <*> <*> warn unable to get node <*> for pod <*> from cache <nil>	82
3991	<*> <*> <*> warn unable to get node <*> for pod <*> nodes <*> not found	82
3992	<*> <*> <*> info starting secure DNS gRPC discovery service at <*>	1
3993	<*> <*> <*> info All caches have been synced up triggering a push	1
3994	<*> <*> <*> info ads XDS Pushing <*> <*> <*> Services <*> ConnectedEndpoints 0	58
3995	<*> <*> <*> info starting Http service at <*>	1
3996	<*> <*> <*> info ads Push debounce stable 4 <*> <*> since last change <*> since last push full true	1
3997	<*> <*> <*> info ads Push debounce stable 6 <*> <*> since last change <*> since last push full true	1
3998	<*> <*> <*> info ads Push Status	1069
3999	<*> <*> <*> info ads Push debounce stable <*> <*> <*> since last change <*> since last push full false	213
4000	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> ConnectedEndpoints 0	32
4001	<*> <*> <*> info rootcertrotator Jitter complete start rotator.	1
4002	<*> <*> <*> info ads Incremental push service <*> has no endpoints	799
4003	<*> <*> <*> info ads Push debounce stable <*> 6 <*> since last change <*> since last push full true	2
4004	<*> <*> <*> info ads Push debounce stable <*> 4 <*> since last change <*> since last push full false	2
4005	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> <*> <*> ConnectedEndpoints 0	1
4006	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> <*> <*> <*> <*> <*> <*> <*> ConnectedEndpoints 0	1
4007	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> ConnectedEndpoints 0	1
4008	<*> <*> <*> info ads ADS CDS REQ <*> version	4
4009	<*> <*> <*> info ads CDS PUSH for node <*> clusters <*> services <*> version <*> <*> <*>	4256
4010	<*> <*> <*> info ads EDS PUSH for node <*> clusters <*> endpoints <*> empty <*>	2464
4011	<*> <*> <*> info <*> error occurred	1872
4012	gateway omitting listener <*> due to must have more than 0 chains in listener <*> Name <*> Address <*> <*> FilterChains <*> UseOriginalDst wrappers.BoolValue nil PerConnectionBufferLimitBytes <*> nil Metadata <*> nil DeprecatedV1 <*> nil DrainType 0 ListenerFilters <*> nil ListenerFiltersTimeout duration.Duration nil ContinueOnListenerFiltersTimeout false Transparent wrappers.BoolValue nil Freebind wrappers.BoolValue nil SocketOptions <*> nil TcpFastOpenQueueLength <*> nil TrafficDirection <*> UdpListenerConfig <*> nil ApiListener <*> nil ConnectionBalanceConfig envoy_api_v2.Listener_ConnectionBalanceConfig nil ReusePort false AccessLog envoy_config_filter_accesslog_v2.AccessLog nil XXX_NoUnkeyedLiteral struct XXX_unrecognized uint8 nil XXX_sizecache 0	1872
4013	<*> <*> <*> info ads LDS PUSH for node <*> listeners <*>	2492
4014	<*> <*> <*> info ads RDS PUSH for node <*> routes <*>	2492
4015	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> ConnectedEndpoints <*>	13
4016	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> ConnectedEndpoints <*>	124
4017	<*> <*> <*> info ads XDS Pushing <*> <*> <*> Services <*> ConnectedEndpoints <*>	811
4018	<*> <*> <*> info ads Pushing <*>	3866
4019	pilot_eds_no_instances	660
4020	<*> <*> <*> info ads EDS PUSH for node <*> clusters <*> endpoints <*> empty 0	1729
4021	<*> <*> <*> info ads EDS PUSH for node <*> clusters <*> endpoints <*> empty 4	43
4022	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> <*> ConnectedEndpoints <*>	5
4023	<*> <*> <*> info ads EDS PUSH for node <*> clusters <*> endpoints <*> empty 6	20
4024	<*> <*> <*> info ads LDS PUSH for node <*> listeners 0	1764
4025	<*> <*> <*> info ads ADS CDS REQ <*> version <*> <*> <*>	386
4026	<*> <*> <*> info transport closing server transport due to maximum connection age.	376
4027	<*> <*> <*> info transport http2Server.HandleStreams failed to read frame read tcp <*> <*> <*> use of closed network connection	388
4028	<*> <*> <*> info ads ADS <*> <*> <*> terminated rpc error code Canceled desc context canceled	386
4029	END logs for container discovery of pod <*>	2
4030	START logs for container kiali of pod <*>	2
4031	Kiali Version <*> Commit <*>	2
4032	Using authentication strategy login	2
4033	Kiali Console version <*>	2
4034	Server endpoint will start at <*>	2
4035	Server endpoint will serve static content from <*>	2
4036	Starting Metrics Server on <*>	2
4037	Secret is now available.	2
4038	END logs for container kiali of pod <*>	2
4039	<*> <*> <*> info Obtained private IP <*> fe80 <*> deff fef1 <*>	1
4040	<*> <*> <*> info Proxy role model.Proxy ClusterID Type router IPAddresses string <*> fe80 <*> deff fef1 <*> ID <*> Locality <*> nil DNSDomain <*> ConfigNamespace Metadata model.NodeMetadata nil SidecarScope model.SidecarScope nil PrevSidecarScope model.SidecarScope nil MergedGateway model.MergedGateway nil ServiceInstances model.ServiceInstance nil IstioVersion model.IstioVersion nil ipv6Support false ipv4Support false GlobalUnicastIP XdsResourceGenerator model.XdsResourceGenerator nil Active map string model.WatchedResource nil	1
4041	START logs for container jaeger of pod <*>	1
4042	<*> <*> <*> <*> maxprocs Leaving GOMAXPROCS <*> CPU quota undefined	1
4043	level info ts <*> caller <*> <*> msg Mounting metrics handler on admin server route <*>	1
4044	level info ts <*> caller <*> <*> msg Mounting health check on admin server route <*>	1
4045	level info ts <*> caller <*> <*> msg Starting admin HTTP server http-port <*>	1
4046	level info ts <*> caller <*> <*> msg Admin server started http-port <*> <*> unavailable	1
4047	level info ts <*> caller badger/factory.go <*> msg Badger storage configuration configuration Dir <*> ValueDir <*> SyncWrites false TableLoadingMode <*> ValueLogLoadingMode <*> NumVersionsToKeep <*> MaxTableSize <*> LevelSizeMultiplier <*> MaxLevels <*> ValueThreshold <*> NumMemtables <*> NumLevelZeroTables <*> NumLevelZeroTablesStall <*> LevelOneSize <*> ValueLogFileSize <*> ValueLogMaxEntries <*> NumCompactors <*> DoNotCompact false ReadOnly false Truncate false	1
4048	level info ts <*> caller <*> <*> msg Starting <*> TChannel server port <*>	1
4049	level warn ts <*> caller <*> <*> msg TChannel has been deprecated and will be removed in a future release	1
4050	level info ts <*> caller <*> <*> msg Starting <*> gRPC server <*> <*>	1
4051	level info ts <*> caller <*> <*> msg Starting <*> HTTP server http-port <*>	1
4052	level info ts <*> caller <*> <*> msg Agent requested insecure grpc connection to collector s	1
4053	level info ts <*> caller <*> <*> msg Starting agent	1
4054	level info ts <*> caller <*> <*> msg Archive storage not created reason archive storage not supported	1
4055	level info ts <*> caller app/agent.go <*> msg Starting <*> HTTP server http-port <*>	1
4056	level info ts <*> caller <*> <*> msg Archive storage not initialized	1
4057	level info ts <*> caller <*> <*> msg Health Check state change status ready	1
4058	level info ts <*> caller app/server.go <*> msg Starting GRPC server port <*>	1
4059	level info ts <*> caller app/server.go <*> msg Starting HTTP server port <*>	1
4060	level info ts <*> caller app/server.go <*> msg Starting CMUX server port <*>	1
4061	level info ts <*> caller <*> <*> msg Listening for Zipkin HTTP traffic <*> <*>	1
4062	END logs for container jaeger of pod <*>	1
4063	<*> <*> <*> info Obtained private IP <*> fe80 <*> <*> fe96 <*>	1
4064	<*> <*> <*> info Proxy role model.Proxy ClusterID Type router IPAddresses string <*> fe80 <*> <*> fe96 <*> ID <*> Locality <*> nil DNSDomain <*> ConfigNamespace Metadata model.NodeMetadata nil SidecarScope model.SidecarScope nil PrevSidecarScope model.SidecarScope nil MergedGateway model.MergedGateway nil ServiceInstances model.ServiceInstance nil IstioVersion model.IstioVersion nil ipv6Support false ipv4Support false GlobalUnicastIP XdsResourceGenerator model.XdsResourceGenerator nil Active map string model.WatchedResource nil	1
4065	<*> <*> <*> info rootcertrotator Check and rotate root cert.	57
4066	<*> <*> <*> info rootcertrotator Root cert is not about to expire skipping root cert rotation.	57
4067	<*> <*> <*> info ads XDS Pushing <*> <*> <*> Services <*> ConnectedEndpoints 4	255
4068	<*> <*> <*> info ads Push debounce stable <*> 4 <*> since last change <*> since last push full true	5
4069	<*> <*> <*> info ads XDS Pushing <*> <*> <*> Services <*> ConnectedEndpoints 6	58
4070	<*> <*> <*> info ads Push debounce stable <*> 6 <*> since last change <*> since last push full false	1
4071	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> <*> <*> <*> <*> ConnectedEndpoints <*>	1
4072	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> <*> <*> <*> <*> <*> ConnectedEndpoints <*>	1
4073	<*> <*> <*> error error retrieving resource lock <*> Get https <*> <*> context deadline exceeded	2
4074	<*> <*> <*> info failed to renew lease <*> timed out waiting for the condition	2
4075	<*> <*> <*> info leader election lock <*>	2
4076	<*> <*> <*> error Leader election cycle <*> lost. Trying again	2
4077	<*> <*> <*> info successfully acquired lease <*>	3
4078	<*> <*> <*> info Starting validation controller	1
4079	<*> <*> <*> info validationController Reconcile enter initial request to kickstart reconciliation	1
4080	<*> <*> <*> info validationController validatingwebhookconfiguration <*> failurePolicy Fail resourceVersion <*> is <*> No change required.	1
4081	<*> <*> <*> info Starting namespace controller	1
4082	<*> <*> <*> info Namespace controller started	1
4083	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> <*> ConnectedEndpoints 4	2
4084	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> ConnectedEndpoints 4	11
4085	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> <*> <*> <*> <*> <*> <*> ConnectedEndpoints 4	1
4086	<*> <*> <*> info grpc <*> failed to complete security handshake from <*> <*> EOF	1
4087	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> <*> <*> <*> <*> <*> <*> <*> ConnectedEndpoints <*>	1
4088	<*> <*> <*> info Starting ingress controller	1
4089	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> ConnectedEndpoints 6	19
4090	<*> <*> <*> info ads XDS EDSInc Pushing <*> <*> <*> Services map <*> <*> ConnectedEndpoints 6	3
4091	<*> <*> <*> info transport closing server transport due to idleness.	12
4092	START logs for container aqua-agent of pod <*>	12
4093	<*> <*> <*> <*> <*> seagent.cpp <*> Aqua Security <*> commit <*> compiled Jul <*> <*> <*> <*> <*>	12
4094	<*> <*> <*> <*> <*> seagent.cpp <*> Container id <*>	12
4095	<*> <*> <*> <*> <*> seagent.cpp <*> Installation directory <*>	12
4096	<*> <*> <*> <*> <*> seagent.cpp <*> Installation mode service	12
4097	<*> <*> <*> <*> <*> seagent.cpp <*> Host id	12
4098	Host name <*>	12
4099	Host IPS <*> <*>	12
4100	Host MAC <*>	12
4101	<*> <*> <*> <*> <*> acldb.cpp <*> Using Repo Images DB version no. <*>	12
4102	<*> <*> <*> <*> <*> seagent.cpp <*> Core file pattern <*> %p %s %c %d %P %E	11
4103	<*> <*> <*> <*> <*> seagent.cpp <*> Host system	12
4104	Pretty name Ubuntu <*> LTS	12
4105	Short name Ubuntu	12
4106	Id ubuntu	12
4107	Kernel <*>	12
4108	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment <*> bit support is on	12
4109	<*> <*> <*> <*> <*> seagent.cpp <*> AQUA_GW_MODE true	12
4110	<*> <*> <*> <*> <*> seagent.cpp <*> Using node name <*>	12
4111	<*> <*> <*> <*> <*> seagent.cpp <*> AQUA_AUTO_DISCOVERY true	11
4112	<*> <*> <*> <*> <*> seagent.cpp <*> Risk explorer auto discovery is enabled	12
4113	<*> <*> <*> <*> <*> seagent.cpp <*> eBPF is supported	12
4114	<*> <*> <*> <*> <*> seagent.cpp <*> Enforcer will not verify the peer s certificate please set AQUA_TLS_VERIFY true to enable certificate verification	12
4115	<*> <*> <*> <*> <*> seagent.cpp <*> Enforcer is running in OPEN mode.	12
4116	<*> <*> <*> <*> <*> seagent.cpp <*> Enforcer is running in Network CLOSE mode.	12
4117	<*> <*> <*> <*> <*> seagent.cpp <*> Enforcer is running in Ping OPEN mode.	12
4118	<*> <*> <*> <*> <*> seagent.cpp <*> Memory pressure is not configured. No Memory Cap is configured.	12
4119	<*> <*> <*> <*> <*> seagent.cpp <*> Found process kubelet with pid <*>	12
4120	<*> <*> <*> <*> <*> seagent.cpp <*> Found socket <*>	12
4121	<*> <*> <*> <*> <*> seagent.cpp <*> Assuming containerd environment	12
4122	<*> <*> <*> <*> <*> udslite.cpp <*> Increasing socket buffer SO_RCVBUF to <*> bytes	12
4123	<*> <*> <*> <*> <*> udslite.cpp <*> Increased SO_RCVBUF to <*> bytes	12
4124	<*> <*> <*> <*> <*> udslite.cpp <*> Increasing socket buffer SO_SNDBUF to <*> bytes	12
4125	<*> <*> <*> <*> <*> udslite.cpp <*> Increased SO_SNDBUF to <*> bytes	12
4126	<*> <*> <*> <*> <*> seagent.cpp <*> Setting CRI runtime endpoint to <*>	12
4127	<*> <*> <*> <*> <*> seagent.cpp <*> CRI info	12
4128	CRI server version <*>	12
4129	CRI api version <*>	12
4130	<*> <*> <*> <*> <*> seagent.cpp <*> Running on Kubernetes node	12
4131	<*> <*> <*> <*> <*> <*> <*> Runc bundle prefix path <*> bundle suffix path	11
4132	<*> <*> <*> <*> <*> <*> <*> Timeout reached. Exiting.	11
4133	<*> <*> <*> <*> <*> <*> <*> Using runc hardcoded paths	11
4134	<*> <*> <*> <*> <*> <*> <*> Runc root paths <*>	11
4135	<*> <*> <*> <*> <*> seagent.cpp <*> Secrets feature enabled	12
4136	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_OSVERSION_ID ubuntu	12
4137	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_CONTAINER_ID <*>	12
4138	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_RUNTIME_ENGINE containerd	12
4139	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_RUNTIME_ENDPOINT <*>	12
4140	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_RUNC_FANOTIFY_INTERCEPTION true	12
4141	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_RUNC_BUNDLE_PREFIX <*>	12
4142	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_RUNC_PATH <*>	12
4143	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_CONTAINERIZED true	12
4144	<*> <*> <*> <*> <*> runcinterceptor.cpp <*> Using fanotify slkinterceptor-lite	12
4145	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked slkaudit process with id <*>	12
4146	slkaudit <*> <*> <*> <*> slkaudit version <*> commit <*> compiled Jul <*> <*> <*> <*> <*>	12
4147	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked slksysd process with id <*>	12
4148	<*> <*> <*> <*> <*> <*> <*> Systrace mode set to 0	12
4149	<*> <*> <*> <*> <*> runcinterceptor.cpp <*> Runcinterceptor is disabled	12
4150	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked slkocicfg process with id <*>	12
4151	<*> <*> <*> <*> <*> seagent.cpp <*> Set environment variable SLKD_RUNC_ROOT_PATH <*>	12
4152	slkocicfg <*> <*> <*> <*> Runtime Endpoint socket is <*>	12
4153	slkocicfg <*> <*> <*> <*> containerd version is <*>	12
4154	slkocicfg <*> <*> <*> <*> Containerd runs with old version	12
4155	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked slkpkgquery process with id <*>	12
4156	slkpkgquery <*> <*> <*> <*> slkpkgquery version <*> commit <*> compiled Jul <*> <*> <*> <*> <*>	12
4157	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked slkscan process with id <*>	12
4158	slkscan <*> <*> <*> <*> slkscan version <*> commit <*> compiled Jul <*> <*> <*> <*> <*>	12
4159	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked slkhostsecd process with id <*>	12
4160	<*> <*> <*> <*> <*> <*> <*> check system CONFIG_PROC_EVENTS returned e	12
4161	sh can t create <*> Read-only file system	24
4162	<*> <*> <*> <*> <*> slkhostsecd.cpp <*> Failed to set inotify max_user_watches <*>	12
4163	slkocicfg <*> <*> <*> <*> slkocicfg version <*> commit <*> compiled Jul <*> <*> <*> <*> <*>	12
4164	<*> <*> <*> <*> <*> slkhostsecd.cpp <*> Set mntns ok.	12
4165	<*> <*> <*> <*> <*> slkhostsecd.cpp <*> Set netns ok.	12
4166	<*> <*> <*> <*> <*> uxsockhostsec.cpp <*> fanotify is supported	12
4167	<*> <*> <*> <*> <*> filenotify.cpp <*> Capability CAP_LINUX_IMMUTABLE is not supported blocked files may be deleted	12
4168	<*> <*> <*> <*> <*> livenessmodule.cpp <*> livenessProbe is enabled	12
4169	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked <*> process with id <*>	72
4170	<*> <*> <*> <*> <*> <*> <*> Health probe is supported in this environment	12
4171	<*> <*> <*> <*> <*> modulehealthcontroller.cpp <*> Successfully created channel to <*> E2E Sanity Check initiated	12
4172	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked slknetd process with id <*>	12
4173	<*> <*> <*> <*> <*> Health Readiness monitors start listen to <*> <*>	12
4174	<*> <*> <*> <*> <*> netfiltermodule.cpp <*> slknetd pgid <*>	12
4175	<*> <*> <*> <*> <*> <*> version <*> commit <*> compiled Jul <*> <*> <*> <*> <*>	12
4176	<*> <*> <*> <*> <*> contfw.cpp <*> Agent iptables <*> legacy host iptables <*>	12
4177	<*> <*> <*> <*> <*> <*> <*> Process is running in container true	12
4178	<*> <*> <*> <*> <*> <*> <*> Detected <*> core s	12
4179	<*> <*> <*> <*> <*> <*> <*> Number of netfilter threads <*>	12
4180	<*> <*> <*> <*> <*> <*> <*> Configuration	12
4181	host_network_protection 0	12
4182	cont_network_protection 0	12
4183	risk_explorer_mode <*>	12
4184	<*> <*> <*> <*> <*> <*> <*> Block network when netfilter queue is full is disabled	12
4185	<*> <*> <*> <*> <*> <*> <*> Process information in alert event is disabled	12
4186	<*> <*> <*> <*> <*> <*> <*> Host IPs <*> <*> <*>	12
4187	<*> <*> <*> <*> <*> <*> <*> IPv6 support is disabled try modprobe ip6table_raw and enable net protection	24
4188	<*> <*> <*> <*> <*> <*> <*> Initialized Slknetd Lite proxylite engine manger	12
4189	<*> <*> <*> <*> <*> <*> <*> Initialized Slknetd prpc service	12
4190	<*> <*> <*> <*> <*> netfiltermodule.cpp <*> <*> pgid <*>	12
4191	<*> <*> <*> <*> <*> <*> <*> Maximum file descriptor number <*> <*>	12
4192	<*> <*> <*> <*> <*> sedockernet.cpp <*> Completed sync host policies for netfilter module	12
4193	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked Watchdog process with id <*>	12
4194	<*> <*> <*> <*> <*> workloadsgrpchandler.cpp <*> Workloads gRPC handler listening at unix <*>	12
4195	<*> <*> <*> <*> <*> workloadsmicroservice.cpp <*> Initialized workloads microservice.	12
4196	<*> <*> <*> <*> <*> secretsvaultmicroservice.cpp <*> Initialized secrets vault microservice.	12
4197	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked GRPCServer process with id <*>	12
4198	<*> <*> <*> <*> <*> <*> <*> Server listening on unix <*>	12
4199	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked WtmpModule process with id <*>	12
4200	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked ContainerdEvtClient process with id <*>	59
4201	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked CriEvtClient process with id <*>	12
4202	<*> <*> <*> <*> <*> forkmanager.cpp <*> Forked PackageWatcher process with id <*>	12
4203	<*> <*> <*> <*> <*> server_unix.cpp <*> <*> started in container	12
4204	<*> <*> <*> <*> <*> <*> <*> Started GW client process <*>	591
4205	<*> <*> <*> <*> <*> proxyserver.cpp <*> Server listenning on unix <*>	591
4206	<*> <*> <*> <*> <*> <*> <*> GwClient gRPC handle listening at unix <*>	591
4207	<*> <*> <*> <*> <*> enginemanagerimpl.cpp <*> Started Async Completion Queue thread.	591
4208	<*> <*> <*> <*> <*> grpcchannel.cpp <*> Timeout for authentication request will range between <*> and <*> seconds	1775
4209	<*> <*> <*> <*> <*> grpcchannel.cpp <*> Interval between authentication requests will range between <*> and <*> seconds	1775
4210	<*> <*> <*> <*> <*> grpcchannel.cpp <*> Initiating a secure connection to a GW on address <*> <*> timeout <*> seconds	1775
4211	<*> <*> <*> <*> <*> criquery.cpp <*> Failed to inspect container <*> error an error occurred when try to find container <*> does not exist	144
4212	<*> <*> <*> <*> <*> filenotify.cpp <*> slkhostsecd is running in container db path <*>	12
4213	<*> <*> <*> <*> <*> sedockercmd.cpp <*> Failed to get container <*> for <*>	79
4214	<*> <*> <*> <*> <*> sedockernet.cpp <*> Start sync host policies for netfilter module	12
4215	<*> <*> <*> <*> <*> cricontainer.cpp <*> Failed to inspect the image with id can not resolve locally ambiguous digest string	79
4216	slkscan <*> <*> <*> <*> Starting Server....	12
4217	slkscan <*> <*> <*> <*> Starting Scan Manager ....	12
4218	slkscan <*> <*> <*> <*> Starting Host Assurance Manager ....	12
4219	slkscan <*> <*> <*> <*> Intializing scanners ....	12
4220	slkscan <*> <*> <*> <*> Intializing scanner ....	60
4221	<*> <*> <*> <*> <*> cachedb_container.cpp <*> Failed to update table container	190
4222	<*> <*> <*> <*> <*> grpcchannel.cpp <*> Failed to establish a secure channel to GW <*> <*> with gRPC error <*>	1775
4223	<*> <*> <*> <*> <*> grpcchannel.cpp <*> Failed to establish gRPC Connection. Switching to SSH communication mode.	1773
4224	<*> <*> <*> <*> <*> sshchannel.cpp <*> Using SSH server s <*> <*>	1773
4225	<*> <*> <*> <*> <*> sshchannel.cpp <*> Creating private key file <*>	11
4226	<*> <*> <*> <*> <*> sshchannel.cpp <*> Cannot resolve address <*>	68
4227	<*> <*> <*> <*> <*> sshchannel.cpp <*> Failed to establish a SSH Connection last error <*> . Switching to gRPC communication mode.	1184
4228	<*> <*> <*> <*> <*> server_unix.cpp <*> Aborted at <*> unix time try date <*> <*> if you are using GNU date	48
4229	<*> <*> <*> <*> <*> server_unix.cpp <*> PC @ <*> unknown	48
4230	<*> <*> <*> <*> <*> server_unix.cpp <*> SIGSEGV <*> received by PID <*> TID <*> from PID <*> stack trace	48
4231	<*> <*> <*> <*> <*> server_unix.cpp <*> @ <*> unknown	624
4232	<*> <*> <*> <*> <*> servicemodule.cpp <*> ContainerdEvtClient process was terminated	48
4233	<*> <*> <*> <*> <*> sshchannel.cpp <*> <*> <*> <*>	8176
4234	<*> <*> <*> <*> <*> sshchannel.cpp <*> Starting connection to SSH server <*> <*> IPv4	8165
4235	<*> <*> <*> <*> <*> sshchannel.cpp <*> Failed connecting to GW <*> <*> with error Operation timed out	7578
4236	<*> <*> <*> <*> <*> watchdogmodule.cpp <*> GW client pid <*> last heartbeat 0 restarting ...	579
4237	<*> <*> <*> <*> <*> <*> <*> GW client process was terminated	579
4238	END logs for container aqua-agent of pod <*>	12
4239	Initializing Aqua Container Security Platform KubeEnforcer version <*> 0 <*> commit <*> compiled on Jul <*> <*> <*> <*> <*> <nil>	1
4240	<*> <*> <*> <*> Using the default value provided <*> for AQUA_AUDIT_BULKSIZE	1
4241	<*> <*> <*> <*> Using the default value provided <*> for AQUA_AUDIT_FLASHTIME_INTERVAL	1
4242	<*> <*> <*> <*> Using the default value provided <*> for AQUA_AUDIT_CACHECLEANTIME_INTERVAL	1
4243	<*> <*> <*> <*> Using the default value provided <*> for AQUA_RPC_TIMEOUT	1
4244	<*> <*> <*> <*> Using the default value provided 0 for <*>	1
4245	<*> <*> <*> <*>  <*> 0m Logger started with level INFO	1
4246	<*> <*> <*> <*>  <*> 0m KubeEnforcer Permission status of Pods Allowed true	1
4247	<*> <*> <*> <*>  <*> 0m KubeEnforcer Permission status of Secrets Allowed true	1
4248	<*> <*> <*> <*>  <*> 0m KubeEnforcer Permission status of ClusterRoles Allowed true	1
4249	<*> <*> <*> <*>  <*> 0m KubeEnforcer Permission status of ClusterRoleBindings Allowed true	1
4250	<*> <*> <*> <*>  <*> 0m KubeEnforcer Permission status of ComponentStatuses Allowed true	1
4251	<*> <*> <*> <*>  <*> 0m KubeEnforcer Permission status of Daemonsets Allowed true	1
4252	<*> <*> <*> <*>  <*> 0m KubeEnforcer Permission status for <*> scans Allowed true	1
4253	<*> <*> <*> <*>  <*> 0m Connecting to Aqua Gateway	1
4254	<*> <*> <*> <*>  <*> 0m Registering as Admission controller	1
4255	<*> <*> <*> <*>  <*> 0m Attempting to connect to management server via gRPC	145
4256	<*> <*> <*> <*>  <*> 0m Successfully connected to the server via gRPC	145
4257	<*> <*> <*> <*>  <*> 0m Registering Kube Enforcer with Gateway	145
4258	<*> <*> <*> <*>  <*> 0m Listening to requests from <*> using https...	1
4259	<*> <*> <*> <*>  <*> 0m Listening to requests from <*> using http...	1
4260	⇨ https server started on <*>	1
4261	⇨ http server started on <*>	1
4262	<*> <*> <*> <*>  <*> 0m Failed receiving response from gateway on registration call error rpc error code DeadlineExceeded desc context deadline exceeded	142
4263	<*> <*> <*> <*>  <*> 0m KubeEnforcer Permission status of Nodes Allowed true	1
4264	<*> <*> <*> <*>  <*> 0m Failed connecting to gRPC server. Attempt <*> sleep duration seconds <*> error Failed to register Kube Enforcer rpc error code DeadlineExceeded desc context deadline exceeded	106
4265	<*> <*> <*> <*>  <*> 0m Failed connecting to gRPC server. Attempt 4 sleep duration seconds 0 error Failed to register Kube Enforcer rpc error code DeadlineExceeded desc context deadline exceeded	1
4266	<*> <*> <*> <*>  <*> 0m Failed connecting to gRPC server. Attempt 6 sleep duration seconds <*> error Failed to register Kube Enforcer rpc error code DeadlineExceeded desc context deadline exceeded	1
4267	<*> <*> <*> <*>  <*> 0m Mutation <*> Received request for mutation webhook	519
4268	<*> <*> <*> <*>  <*> 0m Mutation <*> Pod enforcer injection is disabled skipping pod enforcer injection	519
4269	<*> <*> <*> <*>  <*> 0m Admission <*> Admission control is disabled skipping the evaluation for admission control kubernetes assurance	329
4270	<*> <*> <*> <*>  <*> 0m Failed connecting to gRPC server. Attempt <*> sleep duration seconds 0 error Failed to register Kube Enforcer rpc error code DeadlineExceeded desc context deadline exceeded	34
4271	<*> <*> <*> <*>  <*> 0m Failed to register Kube enforcer error rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	2
4272	<*> <*> <*> <*>  <*> 0m Failed connecting to gRPC server. Attempt <*> sleep duration seconds 0 error Failed to register Kube Enforcer rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	1
4273	<*> <*> <*> <*>  <*> 0m Failed connecting to gRPC server. Attempt <*> sleep duration seconds <*> error Failed to register Kube Enforcer rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> <*> i/o timeout	1
4274	<*> <*> <*> <*>  <*> 0m Failed to fetch secret in namespace aqua Error resource name may not be empty	8
4275	<*> <*> <*> <*>  <*> 0m invalid image provided disabling <*> scans	8
4276	<*> <*> <*> <*> <*> setns.cpp <*> Failed to join namespace <*> Invalid argument	3
4277	<*> <*> <*> <*> <*> seagent.cpp <*> Failed to join to host mnt namespace Invalid argument	3
4278	<*> <*> <*> <*> <*> seagent.cpp <*> Core file pattern <*>	1
4279	slkscan <*> <*> <*> <*> Host scan is postponed for <*> seconds	12
4280	slkscan <*> <*> <*> <*> Starting host scan	12
4281	slkscan <*> <*> <*> <*> Scan command args <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	12
4282	slkscan <*> <*> <*> <*> Host scan finished run time 0 days 0 hrs <*> mins <*> secs	7
4283	slkscan <*> <*> <*> <*> Host scan finished run time 0 days 0 hrs <*> mins 4 secs	5
4284	slkscan <*> <*> <*> <*> CloseAndRecv failed after sending <*> to proxyserver rpc error code InvalidArgument desc	92
4285	<*> <*> <*> <*> <*> proxyserver.cpp <*> grpc channel is null	101
4286	slkscan <*> <*> <*> <*> failed to send host.scan.status to proxyserver rpc error code InvalidArgument desc	9
4287	<*> <*> <*> <*> <*> <*> <*> Retry bringing up ContainerdEvtClient in <*> seconds	5
4288	error retrieving resource lock <*> Get https <*> <*> <*> context deadline exceeded	2
4289	Unable to authenticate the request due to an error invalid bearer token context canceled	1
4290	Failed to make webhook authenticator request <*> is forbidden User system <*> cannot create resource tokenreviews in API group <*> at the cluster scope	3
4291	Starting deployment controller	1
4292	Skipping <*>	1
4293	Starting CronJob Manager	1
4294	Skipping ephemeral-volume	1
4295	Initializing eviction metric for zone <*>   <*>	3
4296	Controller detected that zone <*>   <*> is now in state Normal.	3
4297	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetResourceMetric message failed to get cpu utilization unable to get metrics for resource cpu unable to fetch metrics from resource metrics API the server is currently unable to handle the request get <*>	121
4298	failed to compute desired number of replicas based on listed metrics for <*> invalid metrics <*> invalid out of <*> first error is failed to get cpu utilization unable to get metrics for resource cpu unable to fetch metrics from resource metrics API the server is currently unable to handle the request get <*>	80
4299	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedComputeMetricsReplicas message invalid metrics <*> invalid out of <*> first error is failed to get cpu utilization unable to get metrics for resource cpu unable to fetch metrics from resource metrics API the server is currently unable to handle the request get <*>	80
4300	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetResourceMetric message failed to get memory utilization unable to get metrics for resource memory unable to fetch metrics from resource metrics API the server is currently unable to handle the request get <*>	41
4301	failed to compute desired number of replicas based on listed metrics for <*> invalid metrics <*> invalid out of <*> first error is failed to get memory utilization unable to get metrics for resource memory unable to fetch metrics from resource metrics API the server is currently unable to handle the request get <*>	41
4302	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedComputeMetricsReplicas message invalid metrics <*> invalid out of <*> first error is failed to get memory utilization unable to get metrics for resource memory unable to fetch metrics from resource metrics API the server is currently unable to handle the request get <*>	41
4303	couldn t get resource list for <*> the server is currently unable to handle the request	20
4304	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetResourceMetric message failed to get cpu utilization unable to get metrics for resource cpu no metrics returned from resource metrics API	30
4305	failed to compute desired number of replicas based on listed metrics for <*> invalid metrics <*> invalid out of <*> first error is failed to get cpu utilization unable to get metrics for resource cpu no metrics returned from resource metrics API	20
4306	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedComputeMetricsReplicas message invalid metrics <*> invalid out of <*> first error is failed to get cpu utilization unable to get metrics for resource cpu no metrics returned from resource metrics API	20
4307	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetResourceMetric message failed to get memory utilization unable to get metrics for resource memory no metrics returned from resource metrics API	10
4308	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedComputeMetricsReplicas message invalid metrics <*> invalid out of <*> first error is failed to get memory utilization unable to get metrics for resource memory no metrics returned from resource metrics API	10
4309	Event occurred object <*> kind Node apiVersion <*> type Normal reason RemovingNode message Node <*> event Removing Node <*> from Controller	14
4310	PodGC is force deleting Pod <*>	93
4311	Forced deletion of orphaned Pod <*> succeeded	93
4312	Set node <*> PodCIDR to <*>	13
4313	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name collectorforkubernetes GenerateName Namespace collectorforkubernetes SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app collectorforkubernetes Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations labels app collectorforkubernetes name collectorforkubernetes namespace collectorforkubernetes spec selector matchLabels daemon collectorforkubernetes template metadata labels daemon collectorforkubernetes name collectorforkubernetes spec affinity nodeAffinity requiredDuringSchedulingIgnoredDuringExecution nodeSelectorTerms matchExpressions key <*> operator DoesNotExist containers env name KUBERNETES_NODENAME valueFrom fieldRef fieldPath spec.nodeName name POD_NAME valueFrom fieldRef fieldPath metadata.name image <*> <*> imagePullPolicy Always name collectorforkubernetes resources limits cpu <*> memory <*> requests cpu <*> memory <*> securityContext privileged true runAsUser 0 volumeMounts mountPath <*> name <*> mountPath <*> name <*> readOnly true mountPath <*> name cgroup readOnly true mountPath <*> name proc readOnly true mountPath <*> mountPropagation HostToContainer name <*> readOnly true mountPath <*> name <*> readOnly true mountPath <*> name <*> readOnly true mountPath <*> name <*> readOnly true mountPath <*> name logs readOnly true mountPath <*> name run-logs readOnly true mountPath <*> mountPropagation HostToContainer name <*> readOnly true mountPath <*> name localtime readOnly true mountPath <*> name <*> readOnly true dnsPolicy ClusterFirstWithHostNet hostNetwork true priorityClassName <*> serviceAccountName collectorforkubernetes tolerations effect NoSchedule operator Exists effect NoExecute operator Exists volumes hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name cgroup hostPath path <*> name proc hostPath path <*> name logs hostPath path <*> name run-logs hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name localtime configMap items key <*> path <*> key <*> path <*> name collectorforkubernetes name <*> name <*> secret secretName <*> updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name collectorforkubernetes GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string daemon collectorforkubernetes Annotations map string string <*> <*> <*> <*> OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name cgroup VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name proc VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name logs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name run-logs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name localtime VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> nil EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> <*> VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> nil EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> <*> NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> nil Containers <*> <*> Name collectorforkubernetes Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> <*> Name KUBERNETES_NODENAME Value ValueFrom <*> <*> <*> Name POD_NAME Value ValueFrom <*> <*> Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s Format BinarySI VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name cgroup ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name proc ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name logs ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name run-logs ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name localtime ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy Always SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirstWithHostNet NodeSelector map string string nil ServiceAccountName collectorforkubernetes DeprecatedServiceAccount collectorforkubernetes AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> <*> SchedulerName <*> Tolerations <*> <*> Key Operator Exists Value Effect NoSchedule TolerationSeconds <*> nil <*> Key Operator Exists Value Effect NoExecute TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName <*> Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable <*> CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> collectorforkubernetes the object has been modified please apply your changes to the latest version and try again	1
4314	Event occurred object <*> kind DaemonSet apiVersion <*> type Normal reason SuccessfulDelete message Deleted pod <*>	8
4315	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations <*> <*> labels k8s-app <*> name <*> namespace monitoring spec revisionHistoryLimit <*> selector matchLabels k8s-app <*> template metadata creationTimestamp null labels k8s-app <*> name <*> spec affinity nodeAffinity requiredDuringSchedulingIgnoredDuringExecution nodeSelectorTerms matchExpressions key <*> operator Exists containers args <*> <*> <*> <*> <*> <*> <*> image <*> <*> imagePullPolicy IfNotPresent name node-exporter resources limits cpu <*> memory <*> requests cpu <*> memory 30Mi terminationMessagePath <*> terminationMessagePolicy File volumeMounts mountPath <*> name proc readOnly true mountPath <*> name sys readOnly true args <*> <*> <*> http <*> <*> image <*> <*> imagePullPolicy IfNotPresent name <*> ports containerPort <*> hostPort <*> name https protocol TCP resources limits cpu <*> memory <*> requests cpu <*> memory 20Mi terminationMessagePath <*> terminationMessagePolicy File dnsPolicy ClusterFirst hostNetwork true hostPID true restartPolicy Always schedulerName <*> securityContext serviceAccountName node-exporter terminationGracePeriodSeconds <*> tolerations effect NoSchedule key <*> operator Exists volumes hostPath path <*> type name proc hostPath path <*> type name sys updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name <*> GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name proc VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name sys VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> nil Containers <*> <*> Name node-exporter Image <*> <*> Command string nil Args string <*> <*> <*> <*> <*> <*> <*> WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s 30Mi Format BinarySI VolumeMounts <*> <*> Name proc ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name sys ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> nil Stdin false StdinOnce false TTY false <*> Name <*> Image <*> <*> Command string nil Args string <*> <*> <*> http <*> <*> WorkingDir Ports <*> <*> Name https HostPort <*> ContainerPort <*> Protocol TCP HostIP EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s 20Mi Format BinarySI VolumeMounts <*> nil VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> nil Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string nil ServiceAccountName node-exporter DeprecatedServiceAccount node-exporter AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID true HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> <*> SchedulerName <*> Tolerations <*> <*> Key <*> Operator Exists Value Effect NoSchedule TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	1
4316	error syncing item garbagecollector.node identity garbagecollector.objectReference OwnerReference <*> APIVersion <*> Kind IPAddress Name <*> UID <*> Controller bool nil BlockOwnerDeletion bool nil Namespace <*> dependentsLock sync.RWMutex w sync.Mutex state 0 sema 0x0 writerSem 0x0 readerSem 0x0 readerCount <*> readerWait 0 dependents map garbagecollector.node struct deletingDependents false deletingDependentsLock sync.RWMutex w sync.Mutex state 0 sema 0x0 writerSem 0x0 readerSem 0x0 readerCount 0 readerWait 0 beingDeleted false beingDeletedLock sync.RWMutex w sync.Mutex state 0 sema 0x0 writerSem 0x0 readerSem 0x0 readerCount 0 readerWait 0 virtual false virtualLock sync.RWMutex w sync.Mutex state 0 sema 0x0 writerSem 0x0 readerSem 0x0 readerCount 0 readerWait 0 owners <*> <*> APIVersion <*> Kind VSphereMachine Name <*> UID <*> Controller bool nil BlockOwnerDeletion bool nil <*> APIVersion <*> Kind IPPool Name <*> UID <*> Controller bool nil BlockOwnerDeletion bool nil <*> APIVersion <*> Kind IPClaim Name <*> UID <*> Controller bool nil BlockOwnerDeletion bool nil <*> <*> not found	1
4317	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace collectorforkubernetes SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app collectorforkubernetes Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations labels app collectorforkubernetes name <*> namespace collectorforkubernetes spec selector matchLabels daemon collectorforkubernetes template metadata labels daemon collectorforkubernetes name <*> spec affinity nodeAffinity requiredDuringSchedulingIgnoredDuringExecution nodeSelectorTerms matchExpressions key <*> operator Exists containers env name KUBERNETES_NODENAME valueFrom fieldRef fieldPath spec.nodeName name POD_NAME valueFrom fieldRef fieldPath metadata.name image <*> <*> imagePullPolicy Always name collectorforkubernetes resources limits cpu <*> memory <*> requests cpu <*> memory <*> securityContext privileged true runAsUser 0 volumeMounts mountPath <*> name <*> mountPath <*> name <*> readOnly true mountPath <*> name cgroup readOnly true mountPath <*> name proc readOnly true mountPath <*> mountPropagation HostToContainer name docker-logs readOnly true mountPath <*> name <*> readOnly true mountPath <*> name <*> readOnly true mountPath <*> name <*> readOnly true mountPath <*> name logs readOnly true mountPath <*> name run-logs readOnly true mountPath <*> name <*> readOnly true mountPath <*> mountPropagation HostToContainer name kubelet-root readOnly true mountPath <*> name localtime readOnly true mountPath <*> name <*> readOnly true dnsPolicy ClusterFirstWithHostNet hostNetwork true priorityClassName <*> serviceAccountName collectorforkubernetes tolerations effect NoSchedule operator Exists effect NoExecute operator Exists volumes hostPath path <*> name <*> hostPath path <*> name docker-logs hostPath path <*> name cgroup hostPath path <*> name proc hostPath path <*> name logs hostPath path <*> name run-logs hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name kubelet-root hostPath path <*> name localtime configMap items key <*> path <*> key <*> path <*> key <*> path <*> name collectorforkubernetes name <*> name <*> secret secretName <*> updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name <*> GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string daemon collectorforkubernetes Annotations map string string <*> <*> <*> <*> OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name docker-logs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name cgroup VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name proc VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name logs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name run-logs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name kubelet-root VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name localtime VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> nil EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> <*> VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> nil EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> <*> NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> nil Containers <*> <*> Name collectorforkubernetes Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> <*> Name KUBERNETES_NODENAME Value ValueFrom <*> <*> <*> Name POD_NAME Value ValueFrom <*> <*> Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s Format BinarySI VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name cgroup ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name proc ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name docker-logs ReadOnly true MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name logs ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name run-logs ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name kubelet-root ReadOnly true MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name localtime ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy Always SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirstWithHostNet NodeSelector map string string nil ServiceAccountName collectorforkubernetes DeprecatedServiceAccount collectorforkubernetes AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> <*> SchedulerName <*> Tolerations <*> <*> Key Operator Exists Value Effect NoSchedule TolerationSeconds <*> nil <*> Key Operator Exists Value Effect NoExecute TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName <*> Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	1
4318	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations labels k8s-app <*> name <*> namespace <*> spec selector matchLabels k8s-app <*> template metadata labels k8s-app <*> spec containers env name DATASTORE_TYPE value kubernetes name WAIT_FOR_DATASTORE value true name NODENAME valueFrom fieldRef fieldPath spec.nodeName name CALICO_NETWORKING_BACKEND valueFrom configMapKeyRef key calico_backend name <*> name CLUSTER_TYPE value k8s bgp name IP value autodetect name <*> value Always name FELIX_IPINIPMTU valueFrom configMapKeyRef key veth_mtu name <*> name CALICO_DISABLE_FILE_LOGGING value true name FELIX_DEFAULTENDPOINTTOHOSTACTION value ACCEPT name <*> value false name FELIX_HEALTHENABLED value true envFrom configMapRef name <*> optional true image <*> <*> livenessProbe exec command <*> <*> <*> failureThreshold 6 initialDelaySeconds <*> periodSeconds <*> name <*> readinessProbe exec command <*> <*> <*> periodSeconds <*> resources requests cpu <*> securityContext privileged true volumeMounts mountPath <*> name lib-modules readOnly true mountPath <*> name <*> readOnly false mountPath <*> name <*> readOnly false mountPath <*> name <*> readOnly false mountPath <*> name policysync mountPath <*> mountPropagation Bidirectional name sysfs mountPath <*> name <*> readOnly true hostNetwork true initContainers command <*> <*> env name KUBERNETES_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name CALICO_NETWORKING_BACKEND valueFrom configMapKeyRef key calico_backend name <*> envFrom configMapRef name <*> optional true image <*> <*> name upgrade-ipam securityContext privileged true volumeMounts mountPath <*> name <*> mountPath <*> name <*> command <*> env name CNI_CONF_NAME value <*> name CNI_NETWORK_CONFIG valueFrom configMapKeyRef key cni_network_config name <*> name KUBERNETES_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name CNI_MTU valueFrom configMapKeyRef key veth_mtu name <*> name SLEEP value false envFrom configMapRef name <*> optional true image <*> <*> name install-cni securityContext privileged true volumeMounts mountPath <*> name <*> mountPath <*> name <*> image <*> <*> name <*> securityContext privileged true volumeMounts mountPath <*> name <*> nodeSelector <*> linux priorityClassName <*> serviceAccountName <*> terminationGracePeriodSeconds 0 tolerations effect NoSchedule operator Exists key CriticalAddonsOnly operator Exists effect NoExecute operator Exists volumes hostPath path <*> name lib-modules hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> type FileOrCreate name <*> hostPath path <*> type DirectoryOrCreate name sysfs hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> type DirectoryOrCreate name policysync hostPath path <*> type DirectoryOrCreate name <*> updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager kubectl Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name lib-modules VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name sysfs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name policysync VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> <*> Name upgrade-ipam Image <*> <*> Command string <*> <*> Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name KUBERNETES_NODE_NAME Value ValueFrom <*> <*> <*> Name CALICO_NETWORKING_BACKEND Value ValueFrom <*> <*> Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false <*> Name install-cni Image <*> <*> Command string <*> Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name CNI_CONF_NAME Value <*> ValueFrom <*> nil <*> Name CNI_NETWORK_CONFIG Value ValueFrom <*> <*> <*> Name KUBERNETES_NODE_NAME Value ValueFrom <*> <*> <*> Name CNI_MTU Value ValueFrom <*> <*> <*> Name SLEEP Value false ValueFrom <*> nil Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false <*> Name <*> Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false Containers <*> <*> Name <*> Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name DATASTORE_TYPE Value kubernetes ValueFrom <*> nil <*> Name WAIT_FOR_DATASTORE Value true ValueFrom <*> nil <*> Name NODENAME Value ValueFrom <*> <*> <*> Name CALICO_NETWORKING_BACKEND Value ValueFrom <*> <*> <*> Name CLUSTER_TYPE Value k8s bgp ValueFrom <*> nil <*> Name IP Value autodetect ValueFrom <*> nil <*> Name <*> Value Always ValueFrom <*> nil <*> Name FELIX_IPINIPMTU Value ValueFrom <*> <*> <*> Name CALICO_DISABLE_FILE_LOGGING Value true ValueFrom <*> nil <*> Name FELIX_DEFAULTENDPOINTTOHOSTACTION Value ACCEPT ValueFrom <*> nil <*> Name <*> Value false ValueFrom <*> nil <*> Name FELIX_HEALTHENABLED Value true ValueFrom <*> nil Resources <*> Limits <*> nil Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI VolumeMounts <*> <*> Name lib-modules ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name policysync ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name sysfs ReadOnly false MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> <*> ReadinessProbe <*> <*> StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string <*> linux ServiceAccountName <*> DeprecatedServiceAccount <*> AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> nil SchedulerName <*> Tolerations <*> <*> Key Operator Exists Value Effect NoSchedule TolerationSeconds <*> nil <*> Key CriticalAddonsOnly Operator Exists Value Effect TolerationSeconds <*> nil <*> Key Operator Exists Value Effect NoExecute TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName <*> Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	1
4319	unable to retrieve the complete list of server APIs <*> the server is currently unable to handle the request	10
4320	failed to discover some groups map <*> the server is currently unable to handle the request	8
4321	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations <*> <*> labels k8s-app <*> name <*> namespace monitoring spec revisionHistoryLimit <*> selector matchLabels k8s-app <*> template metadata creationTimestamp null labels k8s-app <*> name <*> spec affinity nodeAffinity requiredDuringSchedulingIgnoredDuringExecution nodeSelectorTerms matchExpressions key <*> operator Exists containers args <*> <*> <*> <*> <*> <*> <*> image <*> <*> imagePullPolicy IfNotPresent name node-exporter resources limits cpu <*> memory <*> requests cpu <*> memory 30Mi terminationMessagePath <*> terminationMessagePolicy File volumeMounts mountPath <*> name proc readOnly true mountPath <*> name sys readOnly true args <*> <*> <*> http <*> <*> image <*> <*> imagePullPolicy IfNotPresent name <*> ports containerPort <*> hostPort <*> name https protocol TCP resources limits cpu <*> memory <*> requests cpu <*> memory 20Mi terminationMessagePath <*> terminationMessagePolicy File dnsPolicy ClusterFirst hostNetwork true hostPID true restartPolicy Always schedulerName <*> securityContext serviceAccountName node-exporter terminationGracePeriodSeconds <*> tolerations effect NoSchedule key <*> operator Exists volumes hostPath path <*> type name proc hostPath path <*> type name sys updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name <*> GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name proc VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name sys VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> nil Containers <*> <*> Name node-exporter Image <*> <*> Command string nil Args string <*> <*> <*> <*> <*> <*> <*> WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s 30Mi Format BinarySI VolumeMounts <*> <*> Name proc ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name sys ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> nil Stdin false StdinOnce false TTY false <*> Name <*> Image <*> <*> Command string nil Args string <*> <*> <*> http <*> <*> WorkingDir Ports <*> <*> Name https HostPort <*> ContainerPort <*> Protocol TCP HostIP EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s 20Mi Format BinarySI VolumeMounts <*> nil VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> nil Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string nil ServiceAccountName node-exporter DeprecatedServiceAccount node-exporter AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID true HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> <*> SchedulerName <*> Tolerations <*> <*> Key <*> Operator Exists Value Effect NoSchedule TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled 4 NumberMisscheduled 0 DesiredNumberScheduled 4 NumberReady 4 ObservedGeneration <*> UpdatedNumberScheduled 4 NumberAvailable 4 NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	1
4322	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string <*> <*> OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager kubeadm Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name <*> VolumeSource <*> HostPath <*> nil EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> <*> VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name lib-modules VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> nil Containers <*> <*> Name <*> Image <*> <*> Command string <*> <*> <*> <*> NODE_NAME Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> <*> Name NODE_NAME Value ValueFrom <*> <*> Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name lib-modules ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string <*> linux ServiceAccountName <*> DeprecatedServiceAccount <*> AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> nil SchedulerName <*> Tolerations <*> <*> Key CriticalAddonsOnly Operator Exists Value Effect TolerationSeconds <*> nil <*> Key Operator Exists Value Effect TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName <*> Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	5
4323	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name node-exporter GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app node-exporter Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations <*> <*> labels k8s-app node-exporter name node-exporter namespace monitoring spec revisionHistoryLimit <*> selector matchLabels k8s-app node-exporter template metadata creationTimestamp null labels k8s-app node-exporter name node-exporter spec containers args <*> <*> <*> <*> <*> <*> <*> image <*> <*> imagePullPolicy IfNotPresent name node-exporter resources limits cpu <*> memory <*> requests cpu <*> memory 30Mi terminationMessagePath <*> terminationMessagePolicy File volumeMounts mountPath <*> name proc readOnly true mountPath <*> name sys readOnly true args <*> <*> <*> http <*> <*> image <*> <*> imagePullPolicy IfNotPresent name <*> ports containerPort <*> hostPort <*> name https protocol TCP resources limits cpu <*> memory <*> requests cpu <*> memory 20Mi terminationMessagePath <*> terminationMessagePolicy File dnsPolicy ClusterFirst hostNetwork true hostPID true restartPolicy Always schedulerName <*> securityContext serviceAccountName node-exporter terminationGracePeriodSeconds <*> volumes hostPath path <*> type name proc hostPath path <*> type name sys updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name node-exporter GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app node-exporter Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name proc VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name sys VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> nil Containers <*> <*> Name node-exporter Image <*> <*> Command string nil Args string <*> <*> <*> <*> <*> <*> <*> WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s 30Mi Format BinarySI VolumeMounts <*> <*> Name proc ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name sys ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> nil Stdin false StdinOnce false TTY false <*> Name <*> Image <*> <*> Command string nil Args string <*> <*> <*> http <*> <*> WorkingDir Ports <*> <*> Name https HostPort <*> ContainerPort <*> Protocol TCP HostIP EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s 20Mi Format BinarySI VolumeMounts <*> nil VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> nil Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string nil ServiceAccountName node-exporter DeprecatedServiceAccount node-exporter AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID true HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> nil SchedulerName <*> Tolerations <*> nil HostAliases <*> nil PriorityClassName Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> node-exporter the object has been modified please apply your changes to the latest version and try again	3
4324	Error syncing PodDisruptionBudget <*> requeuing Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	3
4325	Event occurred object <*> kind Pod apiVersion type Normal reason TaintManagerEviction message Cancelling deletion of Pod <*>	46
4326	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name aqua-agent GenerateName Namespace aqua SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app aqua-agent Annotations map string string <*> tcsp <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations creationTimestamp null labels app aqua-agent name aqua-agent namespace aqua spec selector matchLabels app aqua-agent template metadata annotations <*> unconfined creationTimestamp null labels app aqua-agent name aqua-agent namespace aqua spec containers env name AQUA_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name AQUA_TOKEN valueFrom secretKeyRef key token name <*> optional true envFrom configMapRef name <*> image <*> <*> imagePullPolicy IfNotPresent livenessProbe httpGet path <*> port <*> initialDelaySeconds <*> periodSeconds <*> name aqua-agent ports containerPort <*> protocol TCP readinessProbe httpGet path <*> port <*> initialDelaySeconds <*> periodSeconds <*> resources securityContext capabilities add SYS_ADMIN NET_ADMIN NET_RAW SYS_PTRACE KILL MKNOD SETGID SETUID SYS_MODULE AUDIT_CONTROL SYSLOG SYS_CHROOT privileged false terminationMessagePath <*> terminationMessagePolicy File volumeMounts mountPath <*> name <*> mountPath <*> name dev mountPath <*> name sys readOnly true mountPath <*> name proc readOnly true mountPath <*> name etc readOnly true mountPath <*> name aquasec readOnly true mountPath <*> name <*> mountPath <*> name <*> mountPath <*> name <*> dnsPolicy ClusterFirst hostPID true imagePullSecrets name <*> restartPolicy Always schedulerName <*> serviceAccount <*> serviceAccountName <*> terminationGracePeriodSeconds <*> volumes hostPath path <*> type name <*> hostPath path <*> type name dev hostPath path <*> type name sys hostPath path <*> type name proc hostPath path <*> type name etc hostPath path <*> type name aquasec hostPath path <*> type name <*> hostPath path <*> type name <*> hostPath path <*> type name <*> updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate status currentNumberScheduled 0 desiredNumberScheduled 0 numberMisscheduled 0 numberReady 0 n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager kubectl Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name aqua-agent GenerateName Namespace aqua SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app aqua-agent Annotations map string string <*> unconfined <*> <*> <*> <*> OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name dev VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name sys VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name proc VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name etc VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name aquasec VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> nil Containers <*> <*> Name aqua-agent Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> <*> Name HostPort 0 ContainerPort <*> Protocol TCP HostIP EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name AQUA_NODE_NAME Value ValueFrom <*> <*> <*> Name AQUA_TOKEN Value ValueFrom <*> <*> Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name dev ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name sys ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name proc ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name etc ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name aquasec ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> <*> ReadinessProbe <*> <*> StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string nil ServiceAccountName <*> DeprecatedServiceAccount <*> AutomountServiceAccountToken bool nil NodeName HostNetwork false HostPID true HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> <*> Name <*> Hostname Subdomain Affinity <*> nil SchedulerName <*> Tolerations <*> nil HostAliases <*> nil PriorityClassName Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady 0 ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable 0 NumberUnavailable <*> CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> aqua-agent the object has been modified please apply your changes to the latest version and try again	5
4327	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name collectorforkubernetes GenerateName Namespace collectorforkubernetes SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app collectorforkubernetes Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations labels app collectorforkubernetes name collectorforkubernetes namespace collectorforkubernetes spec selector matchLabels daemon collectorforkubernetes template metadata labels daemon collectorforkubernetes name collectorforkubernetes spec affinity nodeAffinity requiredDuringSchedulingIgnoredDuringExecution nodeSelectorTerms matchExpressions key <*> operator DoesNotExist containers env name KUBERNETES_NODENAME valueFrom fieldRef fieldPath spec.nodeName name POD_NAME valueFrom fieldRef fieldPath metadata.name image <*> <*> imagePullPolicy Always name collectorforkubernetes resources limits cpu <*> memory <*> requests cpu <*> memory <*> securityContext privileged true runAsUser 0 volumeMounts mountPath <*> name <*> mountPath <*> name <*> readOnly true mountPath <*> name cgroup readOnly true mountPath <*> name proc readOnly true mountPath <*> mountPropagation HostToContainer name <*> readOnly true mountPath <*> name <*> readOnly true mountPath <*> name <*> readOnly true mountPath <*> name <*> readOnly true mountPath <*> name logs readOnly true mountPath <*> name run-logs readOnly true mountPath <*> mountPropagation HostToContainer name <*> readOnly true mountPath <*> name localtime readOnly true mountPath <*> name <*> readOnly true dnsPolicy ClusterFirstWithHostNet hostNetwork true priorityClassName <*> serviceAccountName collectorforkubernetes tolerations effect NoSchedule operator Exists effect NoExecute operator Exists volumes hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name cgroup hostPath path <*> name proc hostPath path <*> name logs hostPath path <*> name run-logs hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name localtime configMap items key <*> path <*> key <*> path <*> name collectorforkubernetes name <*> name <*> secret secretName <*> updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name collectorforkubernetes GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string daemon collectorforkubernetes Annotations map string string <*> <*> <*> <*> OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name cgroup VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name proc VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name logs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name run-logs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name localtime VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> nil EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> <*> VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> nil EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> <*> NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> nil Containers <*> <*> Name collectorforkubernetes Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> <*> Name KUBERNETES_NODENAME Value ValueFrom <*> <*> <*> Name POD_NAME Value ValueFrom <*> <*> Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format BinarySI Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s Format BinarySI VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name cgroup ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name proc ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name logs ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name run-logs ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name localtime ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy Always SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirstWithHostNet NodeSelector map string string nil ServiceAccountName collectorforkubernetes DeprecatedServiceAccount collectorforkubernetes AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> <*> SchedulerName <*> Tolerations <*> <*> Key Operator Exists Value Effect NoSchedule TolerationSeconds <*> nil <*> Key Operator Exists Value Effect NoExecute TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName <*> Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> collectorforkubernetes the object has been modified please apply your changes to the latest version and try again	4
4328	Error syncing endpoint slices for service <*> retrying. Error failed to update <*> EndpointSlice for Service <*> Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	3
4329	Event occurred object <*> kind Service apiVersion <*> type Warning reason FailedToUpdateEndpointSlices message Error updating Endpoint Slices for Service <*> failed to update <*> EndpointSlice for Service <*> Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	3
4330	Timeout request did not complete within requested timeout <*>	2
4331	<*> failed with Timeout request did not complete within requested timeout <*>	2
4332	Event occurred object <*> kind DaemonSet apiVersion <*> type Warning reason FailedCreate message Error creating Timeout request did not complete within requested timeout <*>	2
4333	Event occurred object <*> kind StatefulSet apiVersion <*> type Normal reason SuccessfulCreate message create Pod <*> in StatefulSet alertmanager-monitoring successful	1
4334	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string nil Annotations map string string <*> <*> OwnerReferences <*> <*> APIVersion <*> Kind StorageCluster Name portworx UID <*> Controller bool <*> BlockOwnerDeletion bool <*> Finalizers string nil ClusterName ManagedFields <*> <*> Manager operator Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string name <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> nil InitContainers <*> nil Containers <*> <*> Name <*> Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> nil VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> <*> StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy Always SecurityContext <*> nil Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string nil ServiceAccountName portworx DeprecatedServiceAccount portworx AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> <*> SchedulerName <*> Tolerations <*> nil HostAliases <*> nil PriorityClassName Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	2
4335	Error syncing endpoint slices for service <*> retrying. Error node <*> not found	21
4336	Event occurred object <*> kind Service apiVersion <*> type Warning reason FailedToUpdateEndpointSlices message Error updating Endpoint Slices for Service <*> node <*> not found	21
4337	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations labels k8s-app <*> name <*> namespace <*> spec selector matchLabels k8s-app <*> template metadata labels k8s-app <*> spec containers env name DATASTORE_TYPE value kubernetes name WAIT_FOR_DATASTORE value true name NODENAME valueFrom fieldRef fieldPath spec.nodeName name CALICO_NETWORKING_BACKEND valueFrom configMapKeyRef key calico_backend name <*> name CLUSTER_TYPE value k8s bgp name IP value autodetect name <*> value Always name FELIX_IPINIPMTU valueFrom configMapKeyRef key veth_mtu name <*> name CALICO_DISABLE_FILE_LOGGING value true name FELIX_DEFAULTENDPOINTTOHOSTACTION value ACCEPT name <*> value false name FELIX_HEALTHENABLED value true envFrom configMapRef name <*> optional true image <*> <*> livenessProbe exec command <*> <*> <*> failureThreshold 6 initialDelaySeconds <*> periodSeconds <*> name <*> readinessProbe exec command <*> <*> <*> periodSeconds <*> resources requests cpu <*> securityContext privileged true volumeMounts mountPath <*> name lib-modules readOnly true mountPath <*> name <*> readOnly false mountPath <*> name <*> readOnly false mountPath <*> name <*> readOnly false mountPath <*> name policysync mountPath <*> mountPropagation Bidirectional name sysfs mountPath <*> name <*> readOnly true hostNetwork true initContainers command <*> <*> env name KUBERNETES_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name CALICO_NETWORKING_BACKEND valueFrom configMapKeyRef key calico_backend name <*> envFrom configMapRef name <*> optional true image <*> <*> name upgrade-ipam securityContext privileged true volumeMounts mountPath <*> name <*> mountPath <*> name <*> command <*> env name CNI_CONF_NAME value <*> name CNI_NETWORK_CONFIG valueFrom configMapKeyRef key cni_network_config name <*> name KUBERNETES_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name CNI_MTU valueFrom configMapKeyRef key veth_mtu name <*> name SLEEP value false envFrom configMapRef name <*> optional true image <*> <*> name install-cni securityContext privileged true volumeMounts mountPath <*> name <*> mountPath <*> name <*> image <*> <*> name <*> securityContext privileged true volumeMounts mountPath <*> name <*> nodeSelector <*> linux priorityClassName <*> serviceAccountName <*> terminationGracePeriodSeconds 0 tolerations effect NoSchedule operator Exists key CriticalAddonsOnly operator Exists effect NoExecute operator Exists volumes hostPath path <*> name lib-modules hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> type FileOrCreate name <*> hostPath path <*> type DirectoryOrCreate name sysfs hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> type DirectoryOrCreate name policysync hostPath path <*> type DirectoryOrCreate name <*> updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager kubectl Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name lib-modules VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name sysfs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name policysync VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> <*> Name upgrade-ipam Image <*> <*> Command string <*> <*> Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name KUBERNETES_NODE_NAME Value ValueFrom <*> <*> <*> Name CALICO_NETWORKING_BACKEND Value ValueFrom <*> <*> Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false <*> Name install-cni Image <*> <*> Command string <*> Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name CNI_CONF_NAME Value <*> ValueFrom <*> nil <*> Name CNI_NETWORK_CONFIG Value ValueFrom <*> <*> <*> Name KUBERNETES_NODE_NAME Value ValueFrom <*> <*> <*> Name CNI_MTU Value ValueFrom <*> <*> <*> Name SLEEP Value false ValueFrom <*> nil Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false <*> Name <*> Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false Containers <*> <*> Name <*> Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name DATASTORE_TYPE Value kubernetes ValueFrom <*> nil <*> Name WAIT_FOR_DATASTORE Value true ValueFrom <*> nil <*> Name NODENAME Value ValueFrom <*> <*> <*> Name CALICO_NETWORKING_BACKEND Value ValueFrom <*> <*> <*> Name CLUSTER_TYPE Value k8s bgp ValueFrom <*> nil <*> Name IP Value autodetect ValueFrom <*> nil <*> Name <*> Value Always ValueFrom <*> nil <*> Name FELIX_IPINIPMTU Value ValueFrom <*> <*> <*> Name CALICO_DISABLE_FILE_LOGGING Value true ValueFrom <*> nil <*> Name FELIX_DEFAULTENDPOINTTOHOSTACTION Value ACCEPT ValueFrom <*> nil <*> Name <*> Value false ValueFrom <*> nil <*> Name FELIX_HEALTHENABLED Value true ValueFrom <*> nil Resources <*> Limits <*> nil Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI VolumeMounts <*> <*> Name lib-modules ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name policysync ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name sysfs ReadOnly false MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> <*> ReadinessProbe <*> <*> StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string <*> linux ServiceAccountName <*> DeprecatedServiceAccount <*> AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> nil SchedulerName <*> Tolerations <*> <*> Key Operator Exists Value Effect NoSchedule TolerationSeconds <*> nil <*> Key CriticalAddonsOnly Operator Exists Value Effect TolerationSeconds <*> nil <*> Key Operator Exists Value Effect NoExecute TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName <*> Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled 4 NumberAvailable <*> NumberUnavailable 0 CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	1
4338	Event occurred object <*> kind StatefulSet apiVersion <*> type Normal reason SuccessfulCreate message create Pod <*> in StatefulSet prometheus-mesh successful	2
4339	Event occurred object <*> kind StatefulSet apiVersion <*> type Normal reason SuccessfulCreate message create Pod <*> in StatefulSet telegraf-blackbox successful	1
4340	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations labels k8s-app <*> name <*> namespace <*> spec selector matchLabels k8s-app <*> template metadata labels k8s-app <*> spec containers env name DATASTORE_TYPE value kubernetes name WAIT_FOR_DATASTORE value true name NODENAME valueFrom fieldRef fieldPath spec.nodeName name CALICO_NETWORKING_BACKEND valueFrom configMapKeyRef key calico_backend name <*> name CLUSTER_TYPE value k8s bgp name IP value autodetect name <*> value Always name FELIX_IPINIPMTU valueFrom configMapKeyRef key veth_mtu name <*> name CALICO_DISABLE_FILE_LOGGING value true name FELIX_DEFAULTENDPOINTTOHOSTACTION value ACCEPT name <*> value false name FELIX_HEALTHENABLED value true envFrom configMapRef name <*> optional true image <*> <*> livenessProbe exec command <*> <*> <*> failureThreshold 6 initialDelaySeconds <*> periodSeconds <*> name <*> readinessProbe exec command <*> <*> <*> periodSeconds <*> resources requests cpu <*> securityContext privileged true volumeMounts mountPath <*> name lib-modules readOnly true mountPath <*> name <*> readOnly false mountPath <*> name <*> readOnly false mountPath <*> name <*> readOnly false mountPath <*> name policysync mountPath <*> mountPropagation Bidirectional name sysfs mountPath <*> name <*> readOnly true hostNetwork true initContainers command <*> <*> env name KUBERNETES_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name CALICO_NETWORKING_BACKEND valueFrom configMapKeyRef key calico_backend name <*> envFrom configMapRef name <*> optional true image <*> <*> name upgrade-ipam securityContext privileged true volumeMounts mountPath <*> name <*> mountPath <*> name <*> command <*> env name CNI_CONF_NAME value <*> name CNI_NETWORK_CONFIG valueFrom configMapKeyRef key cni_network_config name <*> name KUBERNETES_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name CNI_MTU valueFrom configMapKeyRef key veth_mtu name <*> name SLEEP value false envFrom configMapRef name <*> optional true image <*> <*> name install-cni securityContext privileged true volumeMounts mountPath <*> name <*> mountPath <*> name <*> image <*> <*> name <*> securityContext privileged true volumeMounts mountPath <*> name <*> nodeSelector <*> linux priorityClassName <*> serviceAccountName <*> terminationGracePeriodSeconds 0 tolerations effect NoSchedule operator Exists key CriticalAddonsOnly operator Exists effect NoExecute operator Exists volumes hostPath path <*> name lib-modules hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> type FileOrCreate name <*> hostPath path <*> type DirectoryOrCreate name sysfs hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> name <*> hostPath path <*> type DirectoryOrCreate name policysync hostPath path <*> type DirectoryOrCreate name <*> updateStrategy rollingUpdate maxUnavailable <*> type RollingUpdate n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager kubectl Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string k8s-app <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> <*> Name lib-modules VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name sysfs VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name policysync VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil <*> Name <*> VolumeSource <*> HostPath <*> <*> EmptyDir <*> nil GCEPersistentDisk <*> nil AWSElasticBlockStore <*> nil GitRepo <*> nil Secret <*> nil NFS <*> nil ISCSI <*> nil Glusterfs <*> nil PersistentVolumeClaim <*> nil RBD <*> nil FlexVolume <*> nil Cinder <*> nil CephFS <*> nil Flocker <*> nil DownwardAPI <*> nil FC <*> nil AzureFile <*> nil ConfigMap <*> nil VsphereVolume <*> nil Quobyte <*> nil AzureDisk <*> nil PhotonPersistentDisk <*> nil Projected <*> nil PortworxVolume <*> nil ScaleIO <*> nil StorageOS <*> nil CSI <*> nil Ephemeral <*> nil InitContainers <*> <*> Name upgrade-ipam Image <*> <*> Command string <*> <*> Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name KUBERNETES_NODE_NAME Value ValueFrom <*> <*> <*> Name CALICO_NETWORKING_BACKEND Value ValueFrom <*> <*> Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false <*> Name install-cni Image <*> <*> Command string <*> Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name CNI_CONF_NAME Value <*> ValueFrom <*> nil <*> Name CNI_NETWORK_CONFIG Value ValueFrom <*> <*> <*> Name KUBERNETES_NODE_NAME Value ValueFrom <*> <*> <*> Name CNI_MTU Value ValueFrom <*> <*> <*> Name SLEEP Value false ValueFrom <*> nil Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false <*> Name <*> Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false Containers <*> <*> Name <*> Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> <*> Prefix ConfigMapRef <*> <*> SecretRef <*> nil Env <*> <*> Name DATASTORE_TYPE Value kubernetes ValueFrom <*> nil <*> Name WAIT_FOR_DATASTORE Value true ValueFrom <*> nil <*> Name NODENAME Value ValueFrom <*> <*> <*> Name CALICO_NETWORKING_BACKEND Value ValueFrom <*> <*> <*> Name CLUSTER_TYPE Value k8s bgp ValueFrom <*> nil <*> Name IP Value autodetect ValueFrom <*> nil <*> Name <*> Value Always ValueFrom <*> nil <*> Name FELIX_IPINIPMTU Value ValueFrom <*> <*> <*> Name CALICO_DISABLE_FILE_LOGGING Value true ValueFrom <*> nil <*> Name FELIX_DEFAULTENDPOINTTOHOSTACTION Value ACCEPT ValueFrom <*> nil <*> Name <*> Value false ValueFrom <*> nil <*> Name FELIX_HEALTHENABLED Value true ValueFrom <*> nil Resources <*> Limits <*> nil Requests <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI VolumeMounts <*> <*> Name lib-modules ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name <*> ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name policysync ReadOnly false MountPath <*> SubPath MountPropagation <*> nil SubPathExpr <*> Name sysfs ReadOnly false MountPath <*> SubPath MountPropagation <*> <*> SubPathExpr <*> Name <*> ReadOnly true MountPath <*> SubPath MountPropagation <*> nil SubPathExpr VolumeDevices <*> nil LivenessProbe <*> <*> ReadinessProbe <*> <*> StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy IfNotPresent SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string <*> linux ServiceAccountName <*> DeprecatedServiceAccount <*> AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> nil SchedulerName <*> Tolerations <*> <*> Key Operator Exists Value Effect NoSchedule TolerationSeconds <*> nil <*> Key CriticalAddonsOnly Operator Exists Value Effect TolerationSeconds <*> nil <*> Key Operator Exists Value Effect NoExecute TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName <*> Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable <*> CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	3
4341	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string nil Annotations map string string <*> <*> OwnerReferences <*> <*> APIVersion <*> Kind StorageCluster Name portworx UID <*> Controller bool <*> BlockOwnerDeletion bool <*> Finalizers string nil ClusterName ManagedFields <*> <*> Manager operator Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string name <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> nil InitContainers <*> nil Containers <*> <*> Name <*> Image <*> <*> Command string nil Args string nil WorkingDir Ports <*> nil EnvFrom <*> nil Env <*> nil Resources <*> Limits <*> nil Requests <*> nil VolumeMounts <*> nil VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> <*> StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy Always SecurityContext <*> nil Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string nil ServiceAccountName portworx DeprecatedServiceAccount portworx AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> <*> SchedulerName <*> Tolerations <*> nil HostAliases <*> nil PriorityClassName Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable <*> CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	1
4342	Error syncing PodDisruptionBudget <*> requeuing Operation cannot be fulfilled on <*> istio-egressgateway the object has been modified please apply your changes to the latest version and try again	1
4343	Cleaning CSR <*> as it is more than <*> old and approved.	1
4344	Event occurred object <*> kind Node apiVersion <*> type Normal reason NodeNotReady message Node <*> status is now NodeNotReady	1
4345	Event occurred object <*> kind Pod apiVersion <*> type Warning reason NodeNotReady message Node is not ready	5
4346	Failed to get VM managed objects from VM objects. <*> VirtualMachine <*> properties summary.runtime.powerState err ServerFaultCode The object vim.VirtualMachine <*> has already been deleted or has not been completely created	1
4347	Failed to get VM Managed object with property summary. err +ServerFaultCode The object vim.VirtualMachine <*> has already been deleted or has not been completely created	1
4348	Failed to check whether node <*> still exists. err ServerFaultCode The object vim.VirtualMachine <*> has already been deleted or has not been completely created.	1
4349	Unable to find VM by UUID. VM UUID <*>	1
4350	Event occurred object <*> kind Node apiVersion type Normal reason Deleting node <*> because it does not exist in the cloud provider message Node <*> event DeletingNode	1
4351	<*> node IP is an IPv4 address <*> assume IPv4 operation	15
4352	OIDC No <*> certificates provided will use host s root CA set	3
4353	Loaded <*> mutating admission controller s successfully in the following order NamespaceLifecycle LimitRanger ServiceAccount NodeRestriction TaintNodesByCondition PodSecurityPolicy Priority DefaultTolerationSeconds DefaultStorageClass StorageObjectInUseProtection RuntimeClass DefaultIngressClass MutatingAdmissionWebhook.	9
4354	Loaded <*> validating admission controller s successfully in the following order LimitRanger ServiceAccount PodSecurityPolicy Priority PersistentVolumeClaimResize RuntimeClass CertificateApproval CertificateSigning CertificateSubjectRestriction ValidatingAdmissionWebhook ResourceQuota.	9
4355	Resetting endpoints for master service kubernetes to <*> <*> <*> <*>	3
4356	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	10
4357	apiserver received an error that is not an <*> <*> s context canceled	1
4358	SHOULD NOT HAPPEN failed to update managedFields for <*> Kind failed to convert new object <*> Kind Node to smd typed errors	1
4359	.status.addresses duplicate entries for key type ExternalIP	1
4360	.status.addresses duplicate entries for key type InternalIP	1
4361	apiserver received an error that is not an <*> <*> s error dialing backend dial tcp <*> <*> i/o timeout	1
4362	ERROR <*> has invalid property anyOf	217
4363	loading OpenAPI spec for <*> failed with failed to retrieve openAPI spec http error ResponseCode <*> Body error trying to reach service unexpected EOF	3
4364	Failed calling webhook failing open imageassurance.aquasec.com failed calling webhook imageassurance.aquasec.com webhook response was absent	416
4365	failed calling webhook imageassurance.aquasec.com webhook response was absent	416
4366	Unable to authenticate the request due to an error invalid bearer token oidc verify token failed to verify signature fetching keys oidc get keys failed Get https <*> <*> TLS handshake timeout	3
4367	Trace <*> Call validating webhook configuration <*> webhook imageassurance.aquasec.com resource <*> Resource pods subresource operation CREATE UID <*> <*> <*> <*> <*> total time <*>	8
4368	Failed calling webhook failing open imageassurance.aquasec.com failed calling webhook imageassurance.aquasec.com Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	11
4369	failed calling webhook imageassurance.aquasec.com Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	11
4370	unable to encode watch object <*> client disconnected <*> writer http2.responseWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	9
4371	unable to encode watch object <*> http2 stream closed <*> writer framer.lengthDelimitedFrameWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	9
4372	no RequestInfo found in the context	108
4373	loading OpenAPI spec for <*> failed with failed to retrieve openAPI spec http error ResponseCode <*> Body service unavailable	108
4374	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Certificate conversion webhook for <*> Kind Certificate failed Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers reinitializing...	17
4375	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> dial tcp <*> <*> i/o timeout Client.Timeout exceeded while awaiting headers	2
4376	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Certificate conversion webhook for <*> Kind Certificate failed Post https <*> <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers reinitializing...	1
4377	Trace <*> <*> Objects listed <*> <*> <*> <*>	10
4378	unable to encode watch object <*> client disconnected <*> writer framer.lengthDelimitedFrameWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	6
4379	apiserver received an error that is not an <*> <*> msg error trying to reach service context canceled err <*> <*>	14
4380	Trace <*> Call mutating webhook configuration <*> webhook <*> resource <*> Resource pods subresource operation UPDATE UID <*> <*> <*> <*> <*> total time <*>	49
4381	Failed calling webhook failing open <*> failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> i/o timeout	6
4382	failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> i/o timeout	6
4383	Failed calling webhook failing open <*> failed calling webhook <*> Post https <*> <*> <*> context deadline exceeded	86
4384	failed calling webhook <*> Post https <*> <*> <*> context deadline exceeded	86
4385	Trace <*> <*> Transaction prepared <*> <*> <*> <*>	26
4386	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> Format client <*> <*> <*> <*> <*> total time <*>	34
4387	quota admission added evaluator for ingresses.extensions	3
4388	unable to encode watch object <*> write tcp <*> <*> <*> write connection reset by peer <*> writer framer.lengthDelimitedFrameWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	1
4389	failed to prepare current and previous objects conversion webhook for <*> Kind Machine failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	7
4390	<*> <*> watch of <*> Kind Machine ended with Internal error occurred conversion webhook for <*> Kind Machine failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	4
4391	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Machine conversion webhook for <*> Kind Machine failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused reinitializing...	109
4392	failed to prepare current and previous objects conversion webhook for <*> Kind MachineDeployment failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	3
4393	<*> <*> watch of <*> Kind MachineDeployment ended with Internal error occurred conversion webhook for <*> Kind MachineDeployment failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	3
4394	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind MachineDeployment conversion webhook for <*> Kind MachineDeployment failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused reinitializing...	84
4395	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Machine conversion webhook for <*> Kind Machine failed Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers reinitializing...	13
4396	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind MachineDeployment conversion webhook for <*> Kind MachineDeployment failed Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers reinitializing...	12
4397	failed to prepare current and previous objects conversion webhook for <*> Kind VSphereMachine failed Post https <*> <*> <*> dial tcp <*> <*> i/o timeout	1
4398	<*> <*> watch of <*> Kind VSphereMachine ended with Internal error occurred conversion webhook for <*> Kind VSphereMachine failed Post https <*> <*> <*> dial tcp <*> <*> i/o timeout	1
4399	Trace <*> Call validating webhook configuration <*> webhook <*> resource <*> Resource vspherevms subresource operation UPDATE UID <*> <*> <*> <*> <*> total time <*>	68
4400	Failed calling webhook failing closed <*> failed calling webhook <*> Post https <*> <*> <*> context deadline exceeded	229
4401	Trace <*> GuaranteedUpdate etcd3 type unstructured.Unstructured <*> <*> <*> <*> total time <*>	129
4402	Trace <*> Patch url <*> user-agent manager/v0.0.0 linux/amd64 <*> <*> client <*> <*> <*> <*> <*> total time <*>	129
4403	failed to prepare current and previous objects conversion webhook for <*> Kind VSphereMachine failed Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers	5
4404	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind VSphereMachine conversion webhook for <*> Kind VSphereMachine failed Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers reinitializing...	232
4405	Failed calling webhook failing closed <*> failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> i/o timeout	3
4406	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind VSphereMachine conversion webhook for <*> Kind VSphereMachine failed Post https <*> <*> <*> context deadline exceeded reinitializing...	2
4407	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind VSphereMachine conversion webhook for <*> Kind VSphereMachine failed Post https <*> <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers reinitializing...	9
4408	Using <*> <*> as endpoint for portworx REST endpoint	3
4409	Using <*> <*> as endpoint for portworx gRPC endpoint	3
4410	Using http <*> <*> as the endpoint	3
4411	Input arguments <*> <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*>	12
4412	Updated arguments <*> <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*>	12
4413	Setting up container handler	12
4414	Requested <*> from <*> <*> via env. variable	12
4415	Removed env variables PATH PORTWORX_API_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_SERVICE_HOST PORTWORX_API_SERVICE_PORT <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_SERVICE_HOST PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> STORK_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> STORK_SERVICE_SERVICE_HOST STORK_SERVICE_SERVICE_PORT <*> <*> VSPHERE_VCENTER_PORT	12
4416	> run-host <*> install <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*> <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> <*> PX_NAMESPACE <*> <*> PX_SECRETS_NAMESPACE <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*>	1
4417	> Service rpcbind.service not running	30
4418	> Service rpcbind.service not installed	30
4419	> Installing <*> ...	12
4420	> run-host <*> <*> apt-get update	12
4421	Err <*> https <*> <*> InRelease	12
4422	Cannot initiate the connection to <*> <*> <*> <*> 0 <*> . <*> connect <*> Network is unreachable Could not connect to <*> <*> <*> connection timed out	12
4423	Err <*> http <*> bionic-security InRelease	12
4424	Cannot initiate the connection to security.ubuntu.com <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Cannot initiate the connection to security.ubuntu.com <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Could not connect to security.ubuntu.com <*> <*> connection timed out Could not connect to security.ubuntu.com <*> <*> connection timed out	12
4425	Err <*> http <*> bionic InRelease	12
4426	Cannot initiate the connection to <*> <*> <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Cannot initiate the connection to <*> <*> <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Could not connect to <*> <*> <*> connection timed out Could not connect to <*> <*> <*> connection timed out	12
4427	Err 4 http <*> bionic-updates InRelease	10
4428	Cannot initiate the connection to <*> <*> <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Cannot initiate the connection to <*> <*> <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable	24
4429	Err <*> http <*> bionic-backports InRelease	10
4430	Reading package lists...	24
4431	W Failed to fetch http <*> Cannot initiate the connection to <*> <*> <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Cannot initiate the connection to <*> <*> <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Could not connect to <*> <*> <*> connection timed out Could not connect to <*> <*> <*> connection timed out	12
4432	W Failed to fetch http <*> Cannot initiate the connection to <*> <*> <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Cannot initiate the connection to <*> <*> <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable	24
4433	W Failed to fetch http <*> Cannot initiate the connection to security.ubuntu.com <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Cannot initiate the connection to security.ubuntu.com <*> <*> <*> <*> <*> . <*> connect <*> Network is unreachable Could not connect to security.ubuntu.com <*> <*> connection timed out Could not connect to security.ubuntu.com <*> <*> connection timed out	12
4434	W Failed to fetch https <*> Cannot initiate the connection to <*> <*> <*> <*> 0 <*> . <*> connect <*> Network is unreachable Could not connect to <*> <*> <*> connection timed out	12
4435	W Some index files failed to download. They have been ignored or old ones used instead.	12
4436	> run-host <*> <*> DEBIAN_FRONTEND noninteractive apt-get install <*> dbus <*> rpcbind <*>	12
4437	Building dependency tree...	12
4438	Reading state information...	12
4439	Package <*> is not available but is referred to by another package.	12
4440	This may mean that the package is missing has been obsoleted or	12
4441	is only available from another source	12
4442	E Package <*> has no installation <*>	12
4443	E Unable to locate package rpcbind	12
4444	E Unable to locate package <*>	12
4445	Timeout running <*> <*> DEBIAN_FRONTEND noninteractive apt-get install <*> dbus <*> rpcbind <*> command	12
4446	Could not enable NFS service error Could not install NFS service Command DEBIAN_FRONTEND noninteractive apt-get install <*> dbus <*> rpcbind <*> failed Timeout	12
4447	SPEC UPDATED <*> <*>	3
4448	> Updated arguments rm <*>	1
4449	> Updated env add <*> Could not install NFS service Command DEBIAN_FRONTEND noninteractive apt-get install <*> dbus <*> rpcbind <*> failed Timeout rm <*> NFS install skipped in cooldown due to previous failures	1
4450	<*> arguments <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	26
4451	<*> mounts <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> proc <*> nosuid noexec nodev <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> sysfs <*> nosuid noexec nodev cgroup <*> nosuid noexec nodev <*> <*> <*> <*> <*> <*> <*> <*> bind <*> <*> <*> <*> shared <*> <*> shared <*> <*> <*> <*> ro <*> <*> <*> <*>	28
4452	<*> env CONTAINER_RUNTIME containerd CSI_ENDPOINT unix <*> GOMAXPROCS <*> GOTRACEBACK crash HOSTNAME <*> KUBELET_DIR <*> KUBERNETES_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBERNETES_SERVICE_HOST <*> KUBERNETES_SERVICE_PORT <*> KUBERNETES_SERVICE_PORT_HTTPS <*> KUBE_DNS_PORT udp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> udp <*> <*> <*> <*> <*> <*> <*> udp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBE_DNS_SERVICE_HOST <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> LVM_USE_HOST <*> NFS_SERVICE <*> NODE_NAME <*> PATH <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_API_SERVICE_HOST <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_SERVICE_SERVICE_HOST <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> PX_IMAGE_DIGEST sha256 <*> PX_LOGLEVEL info PX_NAMESPACE <*> PX_RUNC true PX_SECRETS_NAMESPACE <*> PX_SHARED <*> shared <*> <*> shared <*> PX_TEMPLATE_VERSION <*> PX_VERSION <*> <*> Could not install NFS service Command DEBIAN_FRONTEND noninteractive apt-get install <*> dbus <*> rpcbind <*> failed Timeout STORK_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp STORK_SERVICE_SERVICE_HOST <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> TERM xterm VSPHERE_DATASTORE_PREFIX <*> VSPHERE_INSECURE true VSPHERE_INSTALL_MODE shared VSPHERE_VCENTER <*> VSPHERE_VCENTER_PORT <*> container oci	12
4453	runC spec got updated <*> restart pending	1
4454	Portworx service restart required due to configuration update.	12
4455	Previous portworx.service started <*> ago	1
4456	> <*> <*> <*> <*> @ <*> <*> portworx.service <*> portworx-output.service <*> init.scope <*> <*> <*> 0	1
4457	<*> systemd <*> Started Monitoring of LVM2 mirrors snapshots etc. using dmeventd or progress polling.	1
4458	<*> systemd <*> Started Apply Kernel Variables.	1
4459	<*> systemd <*> Starting Flush Journal to Persistent Storage...	1
4460	<*> systemd <*> Started <*> Random Seed.	1
4461	<*> systemd <*> Started udev Kernel Device Manager.	1
4462	<*> systemd <*> Started Flush Journal to Persistent Storage.	1
4463	<*> systemd <*> Started Set the console keyboard layout.	1
4464	<*> systemd <*> Reached target Local File <*> Pre .	1
4465	<*> systemd <*> Starting Show Plymouth Boot Screen...	2
4466	<*> systemd <*> Started Show Plymouth Boot Screen.	2
4467	<*> systemd <*> Started Forward Password Requests to Plymouth Directory Watch.	1
4468	<*> systemd <*> Reached target Local Encrypted Volumes.	1
4469	<*> systemd <*> Listening on <*> RF Kill Switch Status <*> Watch.	1
4470	<*> systemd <*> Found device Virtual_disk UEFI.	1
4471	<*> systemd <*> Mounting <*>	1
4472	<*> systemd <*> Mounted <*>	1
4473	<*> systemd <*> Reached target Local File <*>	1
4474	<*> systemd <*> Starting ebtables ruleset management...	1
4475	<*> systemd <*> Starting Create Volatile Files and Directories...	1
4476	<*> systemd <*> Starting AppArmor initialization...	1
4477	<*> systemd <*> Starting Commit a transient <*> on disk...	1
4478	<*> systemd <*> Starting Tell Plymouth To Write Out Runtime Data...	2
4479	<*> systemd <*> Starting Set console font and keymap...	1
4480	<*> systemd <*> Started Tell Plymouth To Write Out Runtime Data.	2
4481	<*> systemd <*> Started Create Volatile Files and Directories.	1
4482	<*> systemd <*> Started Set console font and keymap.	1
4483	<*> systemd <*> Starting Update UTMP about System Boot/Shutdown...	1
4484	<*> systemd <*> Starting Network Time Synchronization...	2
4485	<*> systemd <*> Started Update UTMP about System <*>	1
4486	<*> systemd <*> Started ebtables ruleset management.	1
4487	<*> systemd <*> Started AppArmor initialization.	1
4488	<*> systemd <*> Starting Load AppArmor profiles managed internally by snapd...	1
4489	<*> systemd <*> Started Authentication service for virtual machines hosted on VMware.	1
4490	<*> systemd <*> Started Service for virtual machines hosted on VMware.	1
4491	<*> systemd <*> Starting Initial <*> job pre-networking ...	1
4492	<*> systemd <*> Started Load AppArmor profiles managed internally by snapd.	1
4493	<*> systemd <*> Started Commit a transient <*> on disk.	1
4494	<*> systemd <*> Started Network Time Synchronization.	2
4495	<*> systemd <*> Started Initial <*> job pre-networking .	1
4496	<*> systemd <*> Reached target Network Pre .	1
4497	<*> systemd <*> Starting Network Service...	1
4498	<*> systemd <*> Started Network Service.	1
4499	<*> systemd <*> Starting Network Name Resolution...	1
4500	<*> systemd <*> Starting Wait for Network to be Configured...	1
4501	<*> systemd <*> Started Network Name Resolution.	1
4502	<*> systemd <*> Reached target Network.	1
4503	<*> systemd <*> Reached target Host and Network Name Lookups.	1
4504	<*> systemd <*> Started Wait for Network to be Configured.	1
4505	<*> systemd <*> Starting Initial <*> job metadata service crawler ...	1
4506	<*> systemd <*> Started Initial <*> job metadata service crawler .	1
4507	<*> systemd <*> Reached target System Initialization.	1
4508	<*> systemd <*> Starting LXD <*> unix socket.	1
4509	<*> systemd <*> Listening on <*> System Message Bus Socket.	1
4510	<*> systemd <*> Listening on UUID daemon activation socket.	1
4511	<*> systemd <*> Started ACPI Events Check.	1
4512	<*> systemd <*> Started Daily Cleanup of Temporary Directories.	1
4513	<*> systemd <*> Started Discard unused blocks once a week.	1
4514	<*> systemd <*> Listening on <*> <*> Socket.	1
4515	<*> systemd <*> Listening on ACPID Listen Socket.	1
4516	<*> systemd <*> Starting Socket activation for snappy daemon.	1
4517	<*> systemd <*> Reached target Paths.	1
4518	<*> systemd <*> Started Message of the Day.	111
4519	<*> systemd <*> Reached target Timers.	1
4520	<*> systemd <*> Reached target Network is Online.	1
4521	<*> systemd <*> Starting Availability of block devices...	1
4522	<*> systemd <*> Reached target Remote File <*> Pre .	1
4523	<*> systemd <*> Reached target Remote File <*>	1
4524	<*> systemd <*> Reached target <*> availability.	1
4525	<*> systemd <*> Listening on LXD <*> unix socket.	1
4526	<*> systemd <*> Listening on Socket activation for snappy daemon.	1
4527	<*> systemd <*> Reached target Sockets.	1
4528	<*> systemd <*> Reached target Basic System.	1
4529	<*> systemd <*> Starting Message of the Day...	109
4530	<*> systemd <*> Starting OpenBSD Secure Shell server...	1
4531	<*> systemd <*> Starting Dispatcher daemon for systemd-networkd...	1
4532	<*> systemd <*> Started <*> System Message Bus.	1
4533	<*> systemd <*> Started FUSE filesystem for LXC.	1
4534	<*> systemd <*> Starting System Logging Service...	1
4535	<*> systemd <*> Starting LSB Record successful boot for GRUB...	1
4536	<*> systemd <*> Starting Discard unused blocks...	9
4537	<*> systemd <*> Starting Permit User Sessions...	1
4538	<*> systemd <*> Started irqbalance daemon.	1
4539	<*> systemd <*> Starting Accounts Service...	1
4540	<*> systemd <*> Starting LSB automatic crash report generation...	1
4541	<*> systemd <*> Starting Login Service...	1
4542	<*> systemd <*> Starting Snap Daemon...	1
4543	<*> systemd <*> Starting containerd container runtime...	2
4544	<*> systemd <*> Started Regular background program processing daemon.	1
4545	<*> systemd <*> Started Deferred execution scheduler.	1
4546	<*> systemd <*> Starting Conntrack Daemon...	9
4547	<*> systemd <*> Started <*>	1
4548	<*> systemd <*> Started kubelet The Kubernetes Node Agent.	4
4549	<*> systemd <*> Starting LXD <*> container startup/shutdown...	1
4550	<*> systemd <*> Started System Logging Service.	1
4551	<*> systemd <*> Started Availability of block devices.	1
4552	<*> systemd <*> Started containerd container runtime.	2
4553	<*> systemd <*> Started OpenBSD Secure Shell server.	1
4554	<*> systemd <*> Started Discard unused blocks.	9
4555	<*> systemd <*> Started Permit User Sessions.	1
4556	<*> systemd <*> Starting Hold until boot process finishes up...	1
4557	<*> systemd <*> Starting Terminate Plymouth Boot Screen...	1
4558	<*> systemd <*> Received <*> from PID <*> plymouthd .	1
4559	<*> systemd <*> Started Terminate Plymouth Boot Screen.	1
4560	<*> systemd <*> Started Hold until boot process finishes up.	1
4561	<*> systemd <*> Starting Set console scheme...	1
4562	<*> systemd <*> Started LSB automatic crash report generation.	1
4563	<*> systemd <*> Started Login Service.	1
4564	<*> systemd <*> Started Set console scheme.	1
4565	<*> systemd <*> Created slice <*>	1
4566	<*> systemd <*> Started Getty on tty1.	1
4567	<*> systemd <*> Reached target Login Prompts.	1
4568	<*> systemd <*> Started LSB Record successful boot for GRUB.	1
4569	<*> systemd <*> Starting Authorization Manager...	1
4570	<*> systemd <*> Started Conntrack Daemon.	9
4571	<*> systemd <*> Started Dispatcher daemon for systemd-networkd.	1
4572	<*> systemd <*> Started Authorization Manager.	1
4573	<*> systemd <*> Started Accounts Service.	1
4574	<*> systemd <*> Started LXD <*> container startup/shutdown.	1
4575	<*> systemd <*> kubelet.service Main process exited code exited status <*>	3
4576	<*> systemd <*> kubelet.service Failed with result exit-code .	3
4577	<*> systemd <*> Started Snap Daemon.	1
4578	<*> systemd <*> Starting Wait until snapd is fully seeded...	1
4579	<*> systemd <*> Started Wait until snapd is fully seeded.	1
4580	<*> systemd <*> Starting Apply the settings specified in <*>	1
4581	<*> systemd <*> Reached target <*> System.	1
4582	<*> systemd <*> Reached target Graphical Interface.	1
4583	<*> systemd <*> Starting Update UTMP about System Runlevel Changes...	1
4584	<*> systemd <*> Started Update UTMP about System Runlevel Changes.	1
4585	<*> systemd <*> Stopping Network Time Synchronization...	1
4586	<*> systemd <*> Stopped Network Time Synchronization.	1
4587	<*> systemd <*> Started Apply the settings specified in <*>	1
4588	<*> systemd <*> Starting Execute cloud user/final scripts...	1
4589	<*> systemd <*> kubelet.service Service hold-off time over scheduling restart.	2
4590	<*> systemd <*> kubelet.service Scheduled restart job restart counter is at <*>	2
4591	<*> systemd <*> Stopped kubelet The Kubernetes Node Agent.	3
4592	<*> systemd <*> Stopping containerd container runtime...	1
4593	<*> systemd <*> Stopped containerd container runtime.	1
4594	<*> systemd <*> Configuration file <*> is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.	18
4595	<*> systemd <*> <*>	7
4596	<*> systemd <*> Started Kubernetes systemd probe.	1
4597	<*> systemd <*> Started Execute cloud user/final scripts.	1
4598	<*> systemd <*> Reached target <*> target.	1
4599	<*> systemd <*> Startup finished in <*> kernel + <*> <*> userspace <*> <*>	4
4600	<*> systemd <*> Starting Cleanup of Temporary Directories...	65
4601	<*> systemd <*> Started Cleanup of Temporary Directories.	65
4602	<*> systemd <*> Stopping Conntrack Daemon...	8
4603	<*> systemd <*> Stopped Conntrack Daemon.	8
4604	<*> systemd <*> Listening on Portworx logging FIFO.	5
4605	<*> systemd <*> Started Portworx FIFO logging reader.	5
4606	<*> systemd <*> Starting Portworx OCI Container...	5
4607	<*> systemd <*> Started Portworx OCI Container.	5
4608	Cannot listen on UNIX socket listen unix <*> bind no such file or directory	14
4609	Failed to start <*> failed to listen on pxd.sock ingnoring and continuing...	13
4610	Multipath conf update disabled. PX devices will not be blacklisted.	7
4611	SPEC READ <*> <*>	5
4612	NFS Install still in cooldown for another <*>	18
4613	Could not enable NFS service error NFS install skipped in cooldown due to previous failures	18
4614	<*> env CONTAINER_RUNTIME containerd CSI_ENDPOINT unix <*> GOMAXPROCS <*> GOTRACEBACK crash HOSTNAME <*> KUBELET_DIR <*> KUBERNETES_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBERNETES_SERVICE_HOST <*> KUBERNETES_SERVICE_PORT <*> KUBERNETES_SERVICE_PORT_HTTPS <*> KUBE_DNS_PORT udp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> udp <*> <*> <*> <*> <*> <*> <*> udp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBE_DNS_SERVICE_HOST <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> LVM_USE_HOST <*> NFS_SERVICE <*> NODE_NAME <*> PATH <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_API_SERVICE_HOST <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_SERVICE_SERVICE_HOST <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> PX_IMAGE_DIGEST sha256 <*> PX_LOGLEVEL info PX_NAMESPACE <*> PX_RUNC true PX_SECRETS_NAMESPACE <*> PX_SHARED <*> shared <*> <*> shared <*> PX_TEMPLATE_VERSION <*> PX_VERSION <*> <*> NFS install skipped in cooldown due to previous failures STORK_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp STORK_SERVICE_SERVICE_HOST <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> TERM xterm VSPHERE_DATASTORE_PREFIX <*> VSPHERE_INSECURE true VSPHERE_INSTALL_MODE shared VSPHERE_VCENTER <*> VSPHERE_VCENTER_PORT <*> container oci	16
4615	Switched <*> to PRIVATE mount propagation	1
4616	Found <*> usable runc binaries <*> and <*>	3
4617	Detected kernel release <*>	3
4618	Exec <*> run <*> <*> <*> portworx	3
4619	<*> portworx <*> Executing with arguments <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	2
4620	<*> portworx <*> Wed Sep <*> <*> <*> <*> UTC <*> Running version <*> on Linux <*> <*> <*> SMP Mon Jan <*> <*> <*> <*> UTC <*> <*> <*> <*> GNU/Linux	1
4621	<*> portworx <*> Version Linux version <*> <*> gcc version <*> Ubuntu <*> <*> SMP Mon Jan <*> <*> <*> <*> UTC <*>	3
4622	<*> portworx <*> Installed pxctl...	4
4623	<*> portworx <*> Error failed to listen on pxd.sock	9
4624	<*> portworx <*> Warning Unable to download kernel <*> file.	12
4625	<*> portworx <*> checking <*>	72
4626	<*> portworx <*> Using cluster portworx	14
4627	<*> portworx <*> Using storage device type zeroedthick size <*>	14
4628	<*> portworx <*> Using scheduler kubernetes	14
4629	<*> portworx <*>	45
4630	<*> portworx <*> Checking mdraid0 layout path for null	14
4631	<*> portworx <*> Wed Sep <*> <*> <*> <*> UTC <*> device scan start	1
4632	<*> portworx <*> Scanning for Btrfs filesystems	12
4633	<*> portworx <*> Wed Sep <*> <*> <*> <*> UTC <*> device scan finish	1
4634	<*> portworx <*> Warning Dependency for filesystem does not exist.	14
4635	<*> portworx <*> Checking sysfs mount...	14
4636	<*> portworx <*> sysfs on <*> type sysfs ro relatime	14
4637	<*> portworx <*> sysfs mounted read-only. remounting...	14
4638	<*> portworx <*> mapping	16
4639	<*> portworx <*> Setting <*> <*>	16
4640	<*> portworx <*> px starting in IO Flusher mode	14
4641	<*> portworx <*> bootstrap true	17
4642	<*> portworx <*> <*> <*> <*> <*> <*> CRIT Supervisor running as root no user in config file	14
4643	<*> portworx <*> <*> <*> <*> <*> <*> INFO supervisord started with pid <*>	14
4644	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned reboot-diags with pid <*>	14
4645	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned relayd with pid <*>	14
4646	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned cron with pid <*>	14
4647	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned px-etcd with pid <*>	14
4648	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned lttng with pid <*>	14
4649	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned exec with pid <*>	14
4650	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned cache_mon with pid <*>	14
4651	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned <*> with pid <*>	28
4652	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned px-healthmon with pid <*>	14
4653	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned pxdaemon with pid <*>	17
4654	<*> portworx <*> <*> <*> <*> <*> <*> INFO spawned px_event_listener with pid <*>	14
4655	<*> portworx <*> <*> <*> <*> <*> <*> INFO exited reboot-diags exit status 0 expected	14
4656	<*> portworx <*> Tracefile cleanup Tracing disabled remove all previous traces...	14
4657	<*> portworx <*> Clean out lttng tmpfs location ...	16
4658	<*> portworx <*> PX_STORAGE_IO_FLUSHER yes	18
4659	<*> portworx <*> Starting as an IOFlusher process <*>	17
4660	<*> portworx <*> Process with PID <*> is a IO Flusher	17
4661	<*> Starting..	14
4662	InitPxClient No authentication enabled	31
4663	<*> portworx <*> Installed NS trace handler for SIGHUP	14
4664	<*> portworx <*> Installed NS sig-handler for <*>	14
4665	<*> portworx <*> Installed NS sig-handler for SIGUSR2	14
4666	<*> portworx <*> Starting NS server	14
4667	<*> portworx <*> <*> <*> <*> <*> <*> INFO success relayd entered RUNNING state process has stayed up for > than <*> seconds startsecs	14
4668	<*> portworx <*> <*> <*> <*> <*> <*> INFO success cron entered RUNNING state process has stayed up for > than <*> seconds startsecs	14
4669	<*> portworx <*> <*> <*> <*> <*> <*> INFO success px-etcd entered RUNNING state process has stayed up for > than <*> seconds startsecs	14
4670	<*> portworx <*> <*> <*> <*> <*> <*> INFO success lttng entered RUNNING state process has stayed up for > than <*> seconds startsecs	14
4671	<*> portworx <*> <*> <*> <*> <*> <*> INFO success exec entered RUNNING state process has stayed up for > than <*> seconds startsecs	14
4672	<*> portworx <*> <*> <*> <*> <*> <*> INFO success cache_mon entered RUNNING state process has stayed up for > than <*> seconds startsecs	14
4673	<*> portworx <*> <*> <*> <*> <*> <*> INFO success <*> entered RUNNING state process has stayed up for > than <*> seconds startsecs	28
4674	<*> portworx <*> <*> <*> <*> <*> <*> INFO success px-healthmon entered RUNNING state process has stayed up for > than <*> seconds startsecs	14
4675	<*> portworx <*> <*> <*> <*> <*> <*> INFO success px_event_listener entered RUNNING state process has stayed up for > than <*> seconds startsecs	14
4676	<*> portworx <*> <*> <*> <*> <*> <*> INFO success pxdaemon entered RUNNING state process has stayed up for > than <*> seconds startsecs	17
4677	<*> portworx <*> Tracing is disabled not starting trace processes.	14
4678	<*> portworx <*> PXPROCS INFO Started <*> with pid <*>	17
4679	<*> portworx <*> bash connect Connection refused	17
4680	<*> portworx <*> bash <*> Connection refused	17
4681	<*> portworx <*> PXPROCS INFO <*> not started yet...sleeping	17
4682	<*> portworx <*> PXPROCS INFO Started px with pid <*>	17
4683	<*> portworx <*> PXPROCS INFO Started watchdog with pid <*>	17
4684	<*> portworx <*> <*> <*> <*> <*> Starting watcher	17
4685	<*> portworx <*> <*> <*> <*> <*> Waiting for px process to start	18
4686	<*> portworx <*> <*> <*> <*> <*> pid <*> Begin monitoring	18
4687	Registering kernel as a volume driver	17
4688	Registered the Usage based Metering Agent....	17
4689	Setting log level to info 4	17
4690	read config from env var func init package boot	17
4691	read config from config.json func init package boot	17
4692	Alerts initialized successfully for this cluster	17
4693	Could not find locally attached drive set for cluster portworx Drive is not attached	15
4694	checking datastores for storage pod <*>	19
4695	no drive sets available checking drive sets from store	4
4696	Failed to find locally attached drive set Drive set not found	3
4697	Node is not yet initialized func setNodeInfo package boot	3
4698	Generated a new NodeID <*>	3
4699	creating vmdk <*> <*> of size <*>	1
4700	Given <*> cluster <*> for new disk	1
4701	Using storage pod <*>	1
4702	Using datastore <*> for new disk	1
4703	<*> portworx <*> <*> <*> <*> <*> pid <*> PX REST server died or did not started. return code <*> Timeout <*>	1
4704	Created vSphere disk VMDK with ID <*>	1
4705	created vmdk <*> <*> <*> <*> <*> <nil> Datastore <*>	1
4706	Successfully created a Drive Set for node <*>	1
4707	drive is now attached Drive ID <*> <*> Drive PX Type data Drive Path <*> Drive State Pending Add fn attachDriveSetWithCleanupOnError	1
4708	Successfully attached the Drive Set for node <*>	1
4709	Using GW interface device eth0 ...	34
4710	Detected Machine Hardware Type as vmware Virtual Machine	17
4711	Bootstraping internal kvdb service. fn <*> id <*>	17
4712	Registered auditor for <*>	34
4713	created kv instance func initKv package boot	17
4714	Setting lock timeout to <*>	17
4715	creating kvdb metrics wrapper	17
4716	initialized internal kvdb func init package boot	17
4717	initialized osdconfig manager func init package boot	17
4718	pushed config data to kvdb func InitAndBoot package boot	17
4719	Starting PX Version <*> <*> Build Version <*>	17
4720	Found the following shared mountpoints <*> <*>	17
4721	Node <*> with Index 0 is Up	4
4722	Initializing scheduler hook kubernetes	17
4723	Configured PX Scheduler filter for kubernetes	17
4724	Configured PX Scheduler integration with Kubernetes	17
4725	node previously initialized false func main package main	3
4726	Joining cluster portworx at this discovery service .	3
4727	PX Configuration Loaded...	17
4728	PX Cluster ID portworx UUID <*>	17
4729	PX Node ID <*>	17
4730	PX Node Index 0	4
4731	PX Management Iface	17
4732	PX Discovery Server s	17
4733	PX Storage Type Devices type zeroedthick size <*> Raid Level data md	17
4734	PX Node Cache Function Attributes CacheDevices DedicatedCache false	17
4735	Detected hardware type as VirtualMachine	17
4736	PX Fastpath Parameters Enabled false Secure false Protocol Port AllowMultiReplicas false	17
4737	Initializing licensing	17
4738	Local license missing but global found <*> will download	12
4739	Licensing engine initialized successfully using ID <*>	18
4740	Found 0 features in <*> license collection	3
4741	Found <*> features in trial license collection	3
4742	Parsed license AUTCapacityManagement <*> Autopilot Capacity Management count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4743	Parsed license AggregatedVolume <*> Storage aggregation count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4744	Parsed license CloudMigration <*> <*> migration <*> Migration count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4745	Parsed license EnablePlatformBare <*> Enable virtual machine platforms count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4746	Parsed license EnablePlatformVM <*> Enable bare-metal platforms count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4747	Parsed license EncryptedVolume <*> Encrypted volumes count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4748	Parsed license HaLevel <*> Volume replica count count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4749	Parsed license LocalVolumeAttaches <*> Number of attached volumes per node maximum count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4750	Parsed license NodeCapacity <*> Node disk capacity TB maximum count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4751	Parsed license NodeCapacityExtension <*> Node disk capacity extension count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4752	Parsed license Nodes <*> Number of nodes maximum count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4753	Parsed license OIDCSecurity <*> OIDC Security count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4754	Parsed license ResizeVolume <*> Resize volumes on demand count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4755	Parsed license ScaledVolume <*> Volume sets count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4756	Parsed license SharedVolume <*> Shared volumes count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4757	Parsed license SnapshotToObjectStore <*> Snapshot to object store CloudSnap count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4758	Parsed license SnapshotToObjectStoreDaily <*> Number of CloudSnaps daily per volume maximum count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4759	Parsed license Snapshots <*> Number of volume snapshots count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4760	Parsed license VolumeSize <*> Volume capacity TB maximum count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4761	Parsed license Volumes <*> Number of volumes maximum count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	3
4762	License NodeCapacity already included.	3
4763	License NodeCapacityExtension already included.	3
4764	License LocalVolumeAttaches already included.	3
4765	License SnapshotToObjectStoreDaily already included.	3
4766	License OIDCSecurity already included.	3
4767	Global license watcher re installed. startIdx <*>	25
4768	Trial license configured successfully	3
4769	Attempting Secrets Login to Kubernetes Secrets endpoint...	17
4770	PX starting cluster manager...	17
4771	PX cluster manager running.	17
4772	Adding cluster event listener Scheduler	17
4773	Converting VolumeSpecs to SdkStoragePolicyObjects...	17
4774	PX starting storage...	17
4775	Adding cluster event listener PX Storage Service	17
4776	SDK TLS disabled name <*>	17
4777	<*> gRPC Server ready on <*>	17
4778	SDK TLS disabled name SDK-unix	17
4779	SDK-unix gRPC Server ready on <*>	17
4780	SDK gRPC REST Gateway started on port <*>	17
4781	Setting concurrent API limit <*>	17
4782	Starting server on port <*>	17
4783	PX API server running on port <*>	17
4784	Starting API Server with TLS Disabled.	17
4785	Starting Watchdog server.	17
4786	Authentication with Kubernetes Secrets succeeded!	17
4787	Adding cluster event listener Kvdb_Cluster_Listener	17
4788	Cluster manager starting...	17
4789	initializing osdconfig manager	17
4790	Cluster state is OK... Joining the cluster.	17
4791	Node <*> joining cluster...	17
4792	Cluster ID portworx	17
4793	Node Mgmt IP <*>	17
4794	Node Data IP <*>	17
4795	Node HWType VirtualMachine	17
4796	Node SecurityStatus UNSECURED	17
4797	<*> Node status not OK STATUS_INIT Driver Cluster API ID nodeHealth Request Cluster API	66
4798	Updated the current set of kvdb endpoints to http <*> <*>	1
4799	rtOption using <*> <*> set from init arguments	20
4800	merged option stats_num_detach_volumes <*>	20
4801	merged option dump_node_markdown_state 0	20
4802	merged option <*> <*>	20
4803	merged option rpc_timeout_sec <*>	20
4804	merged option execution_timeout_sec <*>	20
4805	Detected provider vsphere Geo vsphere <*> <*> Titan_CaaS_Prod2 default default default HostSystem <*> <*> <nil>	37
4806	Made <*> pools	1
4807	Benchmarking drive <*>	1
4808	fio test g 0 rw randread bs <*> ioengine libaio iodepth <*> <*> nStarting <*> process n ntest groupid 0 jobs <*> err 0 pid <*> Wed Sep <*> <*> <*> <*> <*> n read io <*> bw <*> iops <*> runt <*> n slat usec min <*> max <*> avg <*> stdev <*> n clat usec min <*> max <*> avg <*> stdev <*> n lat usec min <*> max <*> avg <*> stdev <*> n clat percentiles usec n | <*> <*> <*> <*> <*> <*> <*> <*> n | <*> <*> <*> <*> <*> <*> <*> <*> n | <*> <*> <*> <*> <*> <*> <*> <*> n | <*> <*> <*> <*> <*> <*> <*> <*> n | <*> <*> n bw KB <*> min <*> max <*> per <*> avg <*> stdev <*> n lat usec <*> <*> <*> <*> <*> <*> <*> <*> n lat msec <*> <*> 4 <*> n cpu usr <*> sys <*> ctx <*> majf 0 minf <*> n IO depths <*> <*> <*> <*> 4 <*> <*> <*> <*> <*> <*> <*> > <*> <*> n submit 0 <*> 4 <*> <*> <*> <*> <*> <*> <*> <*> <*> > <*> <*> n complete 0 <*> 4 <*> <*> <*> <*> <*> <*> <*> <*> <*> > <*> <*> n issued total r <*> <*> 0 short r <*> <*> 0 drop r <*> <*> 0 n latency target 0 window 0 percentile <*> depth <*> n nRun status group 0 all jobs n READ io <*> aggrb <*> minb <*> maxb <*> mint <*> maxt <*> n nDisk stats <*> n sdb ios <*> merge <*> ticks <*> in_queue <*> util <*> n	1
4809	Storage pool WriteThroughput <*> <*>	1
4810	Mounting metadata pool Cos HIGH RaidLevel raid0 uuid <*>	2
4811	HAL Created volume <*>	2
4812	Initializing journal <*>	1
4813	Applying labels to Pool 0	15
4814	Sync pxpool 0 mdpoolid 0 initinprogress mdvol labels to Pool 0	1
4815	Created Metadata Volume <*>	1
4816	Node <*> <*> joining the cluster	3
4817	This node participates in quorum decisions	14
4818	Generated a new NodeIndex 6	1
4819	Successfully added storage spec for this node.	3
4820	Successfully persisted Drive Set for node <*> with labels map	3
4821	Successfully saved node identity.	3
4822	Updating proto driver with cluster domain info	17
4823	Cluster manager starting watch at version <*>	17
4824	Waiting for the cluster to reach quorum...	17
4825	Starting Gossip... Gossiping to these nodes <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	1
4826	gossip Successfully joined with 6 node s	1
4827	gossip Adding Node to gossip map <*>	204
4828	Starting collector watch on at 0	17
4829	Watch cb for key <*> returned err done	17
4830	Watch on key <*> closed without a Cancel response.	34
4831	Watch for <*> stopped	42
4832	Cluster db snapshot at <*>	17
4833	Not starting Docker Scheduler	17
4834	Starting storage provider with PXD	17
4835	<*> portworx <*> time <*> <*> <*> level info Error <nil> Function nodeMap.Add MID <*> NID <*> Status Down Version <*>	31
4836	<*> portworx <*> time <*> <*> <*> level info Error <nil> Function nodeMap.Add MID <*> NID 4 Status Down Version <*>	1
4837	<*> portworx <*> time <*> <*> <*> level info Error <nil> Function nodeMap.Add MID <*> NID <*> Status Up Version <*>	139
4838	<*> portworx <*> time <*> <*> <*> level info Error <nil> Function nodeMap.Add MID <*> NID 6 Status Down Version <*>	1
4839	PX storage fastpath initialization with RuntimeParams Enabled false Protocol FASTPATH_PROTO_LOCAL ACL false ClusterParams ClusterID portworx NodeParams NodeUUID <*> NodeID 6 DataIP <*> Port cmdGroup <*>	6
4840	fastpath local target initialized successfully	34
4841	fastpath local initiator initialized	34
4842	Clearing any stale fastpath configs...	34
4843	<*> portworx <*> time <*> <*> <*> level info Error <nil> Function nodeMap.Add MID <*> NID 0 Status Up Version <*>	16
4844	rt-opts for <*> set to ON	17
4845	Found <*> DataPools	14
4846	Loading datapool Cos HIGH RaidLevel raid0 uuid <*>	1
4847	Waiting for storage to become available node down version <*> Driver pxd Function NodeStart	17
4848	Initialized namespace mgr Driver pxd Function loadVolumeMounts	17
4849	Loading block driver Kernel Mode Driver	17
4850	int SystemMonitor load_smon_file SystemMonitor smon_err const string Failed to open sysmon file <*> No such file or directory	20
4851	Setting up NS driver...	17
4852	NS driver setup done...	17
4853	Waiting for <*> grpc server to start...	17
4854	Starting <*> grpc server on <*>	17
4855	<*> grpc server started	17
4856	Version <*> Identity 6 Control Device Id 0 Function <*> Tag 4	3
4857	Setting rpc_timeout_sec option to <*>	17
4858	Using checksum <*>	17
4859	Initializing thread pool with <*> total <*> cpu <*> io <*> high_cos <*> low_cos threads	17
4860	rtconf update updating writeback list config	17
4861	Initializing SM engine with max sm <*>	17
4862	Number of locally attached volumes 0	17
4863	Processing shared memory bufpool.shm	17
4864	Finished processing shared memory	17
4865	Using driver version min <*> max <*>	17
4866	Using checksummed log file <*>	17
4867	Using checksum CRHW for the log file	17
4868	init Using Log <*> size <*>	14
4869	merge_level Recs 0 0 0	3
4870	Replaying the logs ...	14
4871	Log replay empty log	3
4872	GC deleted devices...	14
4873	DeviceStore GC delete unreferenced subvolumes dir <*>	14
4874	DeviceStore GC done	14
4875	Starting messenger ...	17
4876	zctx_new Cannot set thread scheduler to SCHED_RR <*> Operation not permitted	17
4877	Datastore ready.	17
4878	Datastore fastpath params enabled 0 secure 0 protocol <*> supported 0 allow_multi_replicas 0	17
4879	Done Function <*> Tag 4	17
4880	nativeDriver Start done...	17
4881	<*> portworx <*> time <*> <*> <*> level info Function <*> Tag <*>	17
4882	Done Function <*> Tag <*>	19
4883	Storage is ready Driver pxd Error node is not initialized with cluster domains Function NodeStart	17
4884	Not starting NFS services Error NFS install skipped in cooldown due to previous failures Function NewNFSFilter filter NFSFilter	17
4885	<*> not enabled not starting internal snapshots	17
4886	Setting up scheduled snapshots	17
4887	Schedule snapshots setup done	17
4888	Replaying watch updates from index <*> node up version <*>	17
4889	collect replaying <*> update s for <*> callback s	17
4890	Callback watchdog started	17
4891	Storage spec update Error <nil> Function watchNodes MID <*> NID <*> Status Up Version <*>	260
4892	Node <*> Driver kernel Function NodeStateChange Status Up	306
4893	<*> option change enabled true <*> true	17
4894	New Storage Spec Error <nil> Function watchNodes MID <*> NID <*> Status Down Version <*>	18
4895	NodeId <*> Function <*> Tag <*>	239
4896	Storage spec update Error <nil> Function watchNodes MID <*> NID <*> Status Down Version <*>	205
4897	Node <*> Driver kernel Function NodeStateChange Status Down	228
4898	Node unavailable for provisioning spec kernel <*> 0 <*> <*> <*> <*> tcp <*> <*> http <*> <*> <*> <*> map 0 <*> <*> <*> STORAGE_MEDIUM_MAGNETIC true 0 <*> 0 0 <*> <*> seconds <*> nanos <*> false false 0 Resources Scan OK <*> STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 Up <*> <*> 0 0 false 0 0 0 0 0 0 0 0 0 0 0 map 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 vsphere <*> <*> Titan_CaaS_Prod2 default default default HostSystem <*> <*> <nil> map Down 0 0 false Cos HIGH RaidLevel raid0 labels <key iopriority value HIGH > labels <key medium value STORAGE_MEDIUM_MAGNETIC > uuid <*> POOLTYPE_BTRFS 0 false 0 false false false <*> 0 false 0 <*> <*> 0 false current provision info <*> <*> false map domain default racks default regions <*> zones <*> map 0 <*> <*> <*>	7
4899	Ignoring older node down update version <*> node up version <*> Error <nil> Function watchNodes MID <*> NID 6 Status Down Version <*>	3
4900	Storage spec update Error <nil> Function watchNodes MID <*> NID 6 Status Up Version <*>	7
4901	Creating coordinator devices...	17
4902	Shm Replaying async writes ...	17
4903	Cleaning unwanted devices...	17
4904	remove_unmounted Done removing unwanted attached devices	17
4905	Starting watch from index <*>	17
4906	NFS is not installed on this node. Skipping initializtion of sharedv4 services. Installation error NFS install skipped in cooldown due to previous failures	17
4907	Waiting for Namespace server...	17
4908	Namespace server PID is <*>	17
4909	Failed to read catalog mount point open <*> no such file or directory	17
4910	Number of V3 cloudsnap threads <*>	17
4911	Cloudsnap threads set to <*>	17
4912	Checking existing <*> operations...	17
4913	Setting up cloud backup schedule...	17
4914	Cloud backup schedules setup done	17
4915	Caller NodeStart cache flush cluster rtopts.CacheFlush false rtopts.CacheFlushSeconds <*> args for px_cache_mon <*>	17
4916	Starting volume ha-reconcile background task	17
4917	Starting volume IO profile derive background task	17
4918	started <*> gossip routine	17
4919	Starting metering agent...	17
4920	Updated the current set of kvdb endpoints to http <*> <*> http <*> <*>	20
4921	Storage spec update Error <nil> Function watchNodes MID <*> NID 4 Status Down Version <*>	12
4922	NodeId 4 Function <*> Tag <*>	12
4923	Node unavailable for provisioning spec kernel <*> 0 <*> <*> 4 <*> tcp <*> <*> http <*> <*> <*> <*> map 0 <*> <*> <*> STORAGE_MEDIUM_MAGNETIC true 0 <*> 0 0 <*> <*> seconds <*> nanos <*> false false 0 Resources Scan OK <*> STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 Up <*> <*> 0 0 false 0 0 0 0 0 0 0 0 0 0 0 map 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 vsphere <*> <*> Titan_CaaS_Prod2 default default default HostSystem <*> <*> <nil> map Down 0 0 false Cos HIGH RaidLevel raid0 labels <key iopriority value HIGH > labels <key medium value STORAGE_MEDIUM_MAGNETIC > uuid <*> POOLTYPE_BTRFS 0 false 0 false false false <*> 0 false 0 <*> <*> 0 false current provision info <*> 4 false map domain default racks default regions <*> zones <*> map 0 <*> <*> <*>	1
4924	Storage spec update Error <nil> Function watchNodes MID <*> NID 4 Status Up Version <*>	25
4925	metering agent not present for platform vsphere	17
4926	Metering standalone Detected license type as Trial	3
4927	UsageAgent agent is not configured saas account key is not found	17
4928	metering no valid agent found	17
4929	Valid agent not found/configured	17
4930	migration is either ongoing or happened in recent past	15
4931	alerts are not being migrated on this node alerts migration ongoing or attempted in recent past	15
4932	Stopping updates collector	17
4933	Watch cb for key <*> returned err Stopped watch	17
4934	k8s node labels map <*> amd64 <*> linux <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> <*> <*> <*> <*> differ from labels in cache map . Updating storage pools.	17
4935	starting pool expansion watcher...	17
4936	Starting REST service on socket <*>	34
4937	CSI <*> gRPC Server ready on <*>	17
4938	Updated the current set of kvdb endpoints to http <*> <*> http <*> <*> http <*> <*>	36
4939	Kvdb operating at maximum capacity. Not starting kvdb on this node. fn <*> id <*>	17
4940	PX is ready on Node <*> CLI accessible at <*>	17
4941	Detected node <*> to be in the cluster.	271
4942	Kvdb node <*> with IP <*> is online. Marking it as Operational. fn <*> id <*>	64
4943	Kvdb node <*> detected fn <*> id <*>	64
4944	Unable to list containers. Some containers using shared volumes may need to be restarted manually Docker not yet initialized	18
4945	Task to add k8s node watch is canceled	17
4946	failed updating pod <*> Err Operation cannot be fulfilled on pods <*> the object has been modified please apply your changes to the latest version and try again	125
4947	<*> systemd <*> Stopping Portworx OCI Container...	2
4948	<*> portworx <*> <*> <*> <*> <*> <*> WARN received SIGTERM indicating exit request	2
4949	<*> portworx <*> <*> <*> <*> <*> <*> INFO waiting for px-healthmon <*> exec px_event_listener relayd cache_mon cron pxdaemon lttng <*> px-etcd to die	8
4950	<*> portworx <*> <*> <*> <*> <*> <*> WARN killing px_event_listener <*> with SIGKILL	2
4951	<*> portworx <*> <*> <*> <*> <*> <*> INFO stopped px_event_listener terminated by SIGKILL	2
4952	<*> portworx <*> <*> <*> <*> <*> <*> INFO stopped <*> terminated by SIGTERM	4
4953	<*> portworx <*> PXPROCS INFO Received SIGTERM. Exiting PX gracefully....	2
4954	<*> portworx <*> PXPROCS INFO No Managed fstrim instances running on the node. Proceeding with shutdown ...	2
4955	<*> portworx <*> <*> <*> <*> <*> <*> INFO exited exec terminated by SIGTERM not expected	2
4956	<*> portworx <*> PXPROCS INFO wait processes done continuing exit...	2
4957	<*> portworx <*> <*> <*> <*> <*> <*> INFO exited px-etcd terminated by SIGTERM not expected	2
4958	Received signal terminated starting shutdown...	2
4959	Shutting down Scheduler	2
4960	Shutting down PX Storage Service	2
4961	Shutting down Driver pxd Function Shutdown	2
4962	Shutdown false Function <*> Tag <*>	2
4963	Shutdown invoked will exit without core	2
4964	Shutting down Kvdb_Cluster_Listener	2
4965	<*> portworx <*> <*> <*> <*> <*> <*> INFO stopped pxdaemon exit status 0	2
4966	<*> portworx <*> <*> <*> <*> <*> <*> INFO stopped px-healthmon terminated by SIGTERM	2
4967	<*> portworx <*> <*> <*> <*> <*> <*> INFO stopped cache_mon terminated by SIGTERM	2
4968	<*> portworx <*> Exiting lttng	2
4969	<*> portworx <*> <*> <*> <*> <*> <*> INFO stopped lttng exit status 0	2
4970	<*> portworx <*> <*> <*> <*> <*> <*> INFO waiting for relayd cron to die	1
4971	<*> portworx <*> <*> <*> <*> <*> <*> INFO stopped cron terminated by SIGTERM	2
4972	<*> portworx <*> <*> <*> <*> <*> <*> INFO stopped relayd exit status 0	2
4973	<*> systemd <*> Stopped Portworx OCI Container.	4
4974	<*> systemd <*> Stopping Portworx logging FIFO.	2
4975	Found original <*> arguments <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*> <*> <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_NAMESPACE <*> <*> PX_SECRETS_NAMESPACE <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> PX_IMAGE <*> <*> <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*>	1
4976	Param b true oci false false	1
4977	Param c portworx oci false false	1
4978	Param debug true oci true true	1
4979	Using internal <*> switch	1
4980	Param e CSI_ENDPOINT unix <*> HOSTNAME <*> KUBERNETES_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBERNETES_SERVICE_HOST <*> KUBERNETES_SERVICE_PORT <*> KUBERNETES_SERVICE_PORT_HTTPS <*> KUBE_DNS_PORT udp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> udp <*> <*> <*> <*> <*> <*> <*> udp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBE_DNS_SERVICE_HOST <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> PATH <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_API_SERVICE_HOST <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_SERVICE_SERVICE_HOST <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_NAMESPACE <*> PX_SECRETS_NAMESPACE <*> PX_TEMPLATE_VERSION <*> STORK_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp STORK_SERVICE_SERVICE_HOST <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> VSPHERE_INSECURE true VSPHERE_INSTALL_MODE shared VSPHERE_VCENTER <*> VSPHERE_VCENTER_PORT <*> container oci PX_IMAGE <*> <*> CONTAINER_RUNTIME containerd PX_IMAGE_DIGEST sha256 <*> KUBELET_DIR <*> oci true false	1
4981	Param max_storage_nodes_per_zone 4 oci false false	1
4982	Param rt_opts <*> <*> oci false false	1
4983	Param s type zeroedthick size <*> oci false false	1
4984	Param secret_type k8s oci false false	1
4985	Param v <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> oci true false	1
4986	Param x kubernetes oci false false	1
4987	> opport. copy <*> to <*>	2
4988	Nothing to clean up.	1
4989	Spec unmarshaled HASH <*> Version <*> Process <*> Root <*> Hostname Mounts Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type proc Source proc Options nosuid noexec nodev Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type sysfs Source sysfs Options nosuid noexec nodev Destination <*> Type cgroup Source cgroup Options nosuid noexec nodev Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options bind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind shared Destination <*> Type bind Source <*> Options rbind shared Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind ro rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Hooks <nil> Annotations map PxArgs <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*> <*> <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_NAMESPACE <*> <*> PX_SECRETS_NAMESPACE <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> PX_IMAGE <*> <*> <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*> PxVersion <*> Linux <*> Solaris <nil> Windows <nil>	1
4990	Scanning for opportunistic dirs..	1
4991	> Dir <*> missing mount skipped	4
4992	<*> not provided scanning for scheduler dirs..	1
4993	Checking OSType Fedora..	1
4994	Could not open file <*> cont open <*> no such file or directory	2
4995	Checking OSType RedHat..	1
4996	Checking OSType Amazon_Linux 2..	1
4997	Checking OSType SLES..	1
4998	Checking OSType <*>	1
4999	Checking OSType Ubuntu..	1
5000	dbus SystemState returns OUT dbus.Property Name SystemState Value dbus.Variant sig dbus.Signature str s value running ERR %!s <nil>	1
5001	DBus GetUnitProperty rpcbind.service ActiveState <*> prop inactive err <nil>	1
5002	DBus GetUnitProperty rpcbind.service LoadState <*> prop not-found err <nil>	1
5003	Assigning mounts <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	1
5004	Overwriting mount Destination <*> Type bind Source <*> Options rbind shared with Destination <*> Type bind Source <*> Options rbind shared	1
5005	Overwriting mount Destination <*> Type bind Source <*> Options rbind rprivate rw with Destination <*> Type bind Source <*> Options rbind rprivate	1
5006	Overwriting mount Destination <*> Type bind Source <*> Options rbind ro rprivate with Destination <*> Type bind Source <*> Options rbind rprivate	1
5007	Overwriting mount Destination <*> Type bind Source <*> Options rbind rprivate with Destination <*> Type bind Source <*> Options rbind rprivate	1
5008	ValidateNoMountOverlaps scanning <*> mounts ...	1
5009	Assigning arguments <*> <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	1
5010	Assigning env. vars CSI_ENDPOINT unix <*> HOSTNAME <*> KUBERNETES_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBERNETES_SERVICE_HOST <*> KUBERNETES_SERVICE_PORT <*> KUBERNETES_SERVICE_PORT_HTTPS <*> KUBE_DNS_PORT udp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> udp <*> <*> <*> <*> <*> <*> <*> udp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBE_DNS_SERVICE_HOST <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> PATH <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_API_SERVICE_HOST <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_SERVICE_SERVICE_HOST <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_NAMESPACE <*> PX_SECRETS_NAMESPACE <*> PX_TEMPLATE_VERSION <*> STORK_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp STORK_SERVICE_SERVICE_HOST <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> VSPHERE_INSECURE true VSPHERE_INSTALL_MODE shared VSPHERE_VCENTER <*> VSPHERE_VCENTER_PORT <*> container oci PX_IMAGE <*> <*> CONTAINER_RUNTIME containerd PX_IMAGE_DIGEST sha256 <*> KUBELET_DIR <*> <*> NFS install skipped in cooldown due to previous failures NFS_SERVICE <*> <*> NFS install skipped in cooldown due to previous failures PX_VERSION <*>	1
5011	Overwriting env PATH PATH <*> <*> <*> <*> <*> <*> <*> to PATH <*> <*> <*> <*> <*> <*>	1
5012	Overwriting env <*> <*> NFS install skipped in cooldown due to previous failures to <*> NFS install skipped in cooldown due to previous failures	1
5013	Assigning env. vars PX_SHARED <*> shared <*> <*> shared <*>	1
5014	> Updated env add <*> NFS install skipped in cooldown due to previous failures rm <*> Could not install NFS service Command DEBIAN_FRONTEND noninteractive apt-get install <*> dbus <*> rpcbind <*> failed Timeout	2
5015	Spec marshaled HASH <*> ociVersion <*> process user uid 0 gid 0 args <*> <*> <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes env CONTAINER_RUNTIME containerd CSI_ENDPOINT unix <*> GOMAXPROCS <*> GOTRACEBACK crash HOSTNAME <*> KUBELET_DIR <*> KUBERNETES_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBERNETES_SERVICE_HOST <*> KUBERNETES_SERVICE_PORT <*> KUBERNETES_SERVICE_PORT_HTTPS <*> KUBE_DNS_PORT udp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> udp <*> <*> <*> <*> <*> <*> <*> udp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBE_DNS_SERVICE_HOST <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> LVM_USE_HOST <*> NFS_SERVICE <*> NODE_NAME <*> PATH <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_API_SERVICE_HOST <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_SERVICE_SERVICE_HOST <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> PX_IMAGE_DIGEST sha256 <*> PX_LOGLEVEL info PX_NAMESPACE <*> PX_RUNC true PX_SECRETS_NAMESPACE <*> PX_SHARED <*> shared <*> <*> shared <*> PX_TEMPLATE_VERSION <*> PX_VERSION <*> <*> NFS install skipped in cooldown due to previous failures STORK_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp STORK_SERVICE_SERVICE_HOST <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> TERM xterm VSPHERE_DATASTORE_PREFIX <*> VSPHERE_INSECURE true VSPHERE_INSTALL_MODE shared VSPHERE_VCENTER <*> VSPHERE_VCENTER_PORT <*> container oci cwd <*> capabilities bounding CAP_CHOWN CAP_DAC_OVERRIDE CAP_DAC_READ_SEARCH CAP_FSETID CAP_FOWNER CAP_MKNOD CAP_NET_RAW CAP_SETGID CAP_SETUID CAP_SETFCAP CAP_SETPCAP CAP_NET_BIND_SERVICE CAP_NET_ADMIN CAP_SYS_CHROOT CAP_KILL CAP_AUDIT_WRITE CAP_IPC_LOCK CAP_SYS_ADMIN CAP_SYS_MODULE CAP_SYS_PTRACE CAP_LINUX_IMMUTABLE CAP_SYS_RESOURCE CAP_SYS_RAWIO effective CAP_CHOWN CAP_DAC_OVERRIDE CAP_DAC_READ_SEARCH CAP_FSETID CAP_FOWNER CAP_MKNOD CAP_NET_RAW CAP_SETGID CAP_SETUID CAP_SETFCAP CAP_SETPCAP CAP_NET_BIND_SERVICE CAP_NET_ADMIN CAP_SYS_CHROOT CAP_KILL CAP_AUDIT_WRITE CAP_IPC_LOCK CAP_SYS_ADMIN CAP_SYS_MODULE CAP_SYS_PTRACE CAP_LINUX_IMMUTABLE CAP_SYS_RESOURCE CAP_SYS_RAWIO inheritable CAP_CHOWN CAP_DAC_OVERRIDE CAP_DAC_READ_SEARCH CAP_FSETID CAP_FOWNER CAP_MKNOD CAP_NET_RAW CAP_SETGID CAP_SETUID CAP_SETFCAP CAP_SETPCAP CAP_NET_BIND_SERVICE CAP_NET_ADMIN CAP_SYS_CHROOT CAP_KILL CAP_AUDIT_WRITE CAP_IPC_LOCK CAP_SYS_ADMIN CAP_SYS_MODULE CAP_SYS_PTRACE CAP_LINUX_IMMUTABLE CAP_SYS_RESOURCE CAP_SYS_RAWIO permitted CAP_CHOWN CAP_DAC_OVERRIDE CAP_DAC_READ_SEARCH CAP_FSETID CAP_FOWNER CAP_MKNOD CAP_NET_RAW CAP_SETGID CAP_SETUID CAP_SETFCAP CAP_SETPCAP CAP_NET_BIND_SERVICE CAP_NET_ADMIN CAP_SYS_CHROOT CAP_KILL CAP_AUDIT_WRITE CAP_IPC_LOCK CAP_SYS_ADMIN CAP_SYS_MODULE CAP_SYS_PTRACE CAP_LINUX_IMMUTABLE CAP_SYS_RESOURCE CAP_SYS_RAWIO ambient CAP_CHOWN CAP_DAC_OVERRIDE CAP_DAC_READ_SEARCH CAP_FSETID CAP_FOWNER CAP_MKNOD CAP_NET_RAW CAP_SETGID CAP_SETUID CAP_SETFCAP CAP_SETPCAP CAP_NET_BIND_SERVICE CAP_NET_ADMIN CAP_SYS_CHROOT CAP_KILL CAP_AUDIT_WRITE CAP_IPC_LOCK CAP_SYS_ADMIN CAP_SYS_MODULE CAP_SYS_PTRACE CAP_LINUX_IMMUTABLE CAP_SYS_RESOURCE CAP_SYS_RAWIO rlimits type RLIMIT_NOFILE hard <*> soft <*> root path rootfs mounts destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type proc source proc options nosuid noexec nodev destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type sysfs source sysfs options nosuid noexec nodev destination <*> type cgroup source cgroup options nosuid noexec nodev destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options bind rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind shared destination <*> type bind source <*> options rbind shared destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind ro rprivate destination <*> type bind source <*> options rbind rprivate destination <*> type bind source <*> options rbind rprivate annotations PxArgs <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*> <*> <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_NAMESPACE <*> <*> PX_SECRETS_NAMESPACE <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> PX_IMAGE <*> <*> <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*> PxVersion <*> linux resources devices allow true access rwm cpu shares 0 pids limit 0 blockIO namespaces type pid type mount type uts rootfsPropagation shared maskedPaths <*> <*> <*> <*> <*> readonlyPaths <*> <*> <*> <*> <*>	1
5016	removing old soft-link <*>	2
5017	soft-linked <*> to <*>	2
5018	<*> arguments <*> <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	2
5019	RunC Spec Version <*> Process <*> Root <*> Hostname Mounts Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type proc Source proc Options nosuid noexec nodev Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type sysfs Source sysfs Options nosuid noexec nodev Destination <*> Type cgroup Source cgroup Options nosuid noexec nodev Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options bind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind shared Destination <*> Type bind Source <*> Options rbind shared Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind ro rprivate Destination <*> Type bind Source <*> Options rbind rprivate Destination <*> Type bind Source <*> Options rbind rprivate Hooks <nil> Annotations map PxArgs <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*> <*> <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_NAMESPACE <*> <*> PX_SECRETS_NAMESPACE <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> PX_IMAGE <*> <*> <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*> PxVersion <*> Linux <*> Solaris <nil> Windows <nil>	1
5020	Service reinitialization requested. Restarting the service...	2
5021	<*> systemd <*> portworx.service Service hold-off time over scheduling restart.	2
5022	<*> systemd <*> portworx.service Scheduled restart job restart counter is at <*>	2
5023	Parent OCI mount <*> already on PRIVATE propagation private	2
5024	<*> portworx <*> <*> <*> by uid 0 root gid 0 root groups 0 root as <*> <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes on Fri Sep <*> <*> <*> <*> UTC <*>	1
5025	<*> portworx <*> + export PS4 + BASH_SOURCE LINENO FUNCNAME 0 + FUNCNAME 0	1
5026	<*> portworx <*> + PS4 + BASH_SOURCE LINENO FUNCNAME 0 + FUNCNAME 0	1
5027	<*> portworx <*> + <*> <*> main <*> ! EXEC_BIN <*> ! <*> <*>	1
5028	<*> portworx <*> + <*> <*> main set <*>	3
5029	<*> portworx <*> + <*> <*> main printInputParams <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	1
5030	<*> portworx <*> + <*> <*> printInputParams args @	1
5031	<*> portworx <*> + <*> <*> printInputParams local args	1
5032	<*> portworx <*> + <*> <*> printInputParams local hideParams acltoken userpwd cluster_secret_key jwt_shared_secret auth_system_key jwt_issuer oidc_issuer	1
5033	<*> portworx <*> + <*> <*> printInputParams echo <*> Executing with arguments	1
5034	<*> portworx <*> Executing with arguments + <*> <*> printInputParams i 0	1
5035	<*> portworx <*> + <*> <*> printInputParams <*>	14
5036	<*> portworx <*> + <*> <*> printInputParams <*> ~ <*>	6
5037	<*> portworx <*> + <*> <*> printInputParams echo <*> <*>	6
5038	<*> portworx <*> <*> <*> <*> printInputParams echo <*>	6
5039	<*> portworx <*> + <*> <*> printInputParams i++	13
5040	<*> portworx <*> + <*> <*> printInputParams portworx ~ <*>	1
5041	<*> portworx <*> + <*> <*> printInputParams echo <*> portworx	1
5042	<*> portworx <*> portworx+ <*> <*> printInputParams echo <*>	1
5043	<*> portworx <*> + <*> <*> printInputParams 4 ~ <*>	1
5044	<*> portworx <*> + <*> <*> printInputParams echo <*> 4	1
5045	<*> portworx <*> 4+ <*> <*> printInputParams echo <*>	1
5046	<*> portworx <*> + <*> <*> printInputParams <*> <*> ~ <*>	1
5047	<*> portworx <*> + <*> <*> printInputParams echo <*> <*> <*>	1
5048	<*> portworx <*> <*> <*> <*> <*> printInputParams echo <*>	1
5049	<*> portworx <*> + <*> <*> printInputParams type zeroedthick size <*> ~ <*>	1
5050	<*> portworx <*> + <*> <*> printInputParams echo <*> type zeroedthick size <*>	1
5051	<*> portworx <*> type zeroedthick size <*> <*> <*> printInputParams echo <*>	1
5052	<*> portworx <*> + <*> <*> printInputParams -secret_type ~ <*>	1
5053	<*> portworx <*> + <*> <*> printInputParams echo <*> -secret_type	1
5054	<*> portworx <*> -secret_type+ <*> <*> printInputParams echo <*>	1
5055	<*> portworx <*> + <*> <*> printInputParams k8s ~ <*>	1
5056	<*> portworx <*> + <*> <*> printInputParams echo <*> k8s	1
5057	<*> portworx <*> k8s+ <*> <*> printInputParams echo <*>	1
5058	<*> portworx <*> + <*> <*> printInputParams kubernetes ~ <*>	1
5059	<*> portworx <*> + <*> <*> printInputParams echo <*> kubernetes	1
5060	<*> portworx <*> kubernetes+ <*> <*> printInputParams echo <*>	1
5061	<*> portworx <*> + <*> <*> printInputParams echo	1
5062	<*> portworx <*> + <*> <*> main set +f	3
5063	<*> portworx <*> + <*> <*> main CONFIG_FILE <*>	1
5064	<*> portworx <*> + <*> <*> main <*> <*>	12
5065	<*> portworx <*> + <*> <*> main install <*> <*> <*> <*>	1
5066	<*> portworx <*> + <*> <*> main chattr <*> <*>	1
5067	<*> portworx <*> + <*> <*> main source <*>	2
5068	<*> portworx <*> ++ <*> <*> source TERM_LOG <*>	1
5069	<*> portworx <*> +++ <*> <*> source dirname <*>	1
5070	<*> portworx <*> ++ <*> <*> source mkdir <*> <*>	1
5071	<*> portworx <*> ++ <*> <*> source declare <*> PARAM_DISKS	1
5072	<*> portworx <*> ++ <*> 6 source declare <*> PARAM_CACHE_DISKS	1
5073	<*> portworx <*> ++ <*> <*> source declare <*> PARAM_PORTS	1
5074	<*> portworx <*> ++ <*> <*> source PARAM_FORCE_FORMAT 0	1
5075	<*> portworx <*> ++ <*> <*> source PARAM_GENERATE_DISKS 0	1
5076	<*> portworx <*> ++ <*> <*> source PARAM_USE_PARTITIONS 0	1
5077	<*> portworx <*> ++ <*> <*> source PARAM_HEAD_NODE 0	1
5078	<*> portworx <*> ++ <*> <*> source PARAM_DISKS_INDEX 0	1
5079	<*> portworx <*> ++ <*> <*> source PARAM_CACHE_DISKS_INDEX 0	1
5080	<*> portworx <*> ++ <*> <*> source PARAM_BACKEND_AUTOCACHE <*>	1
5081	<*> portworx <*> ++ <*> <*> source PARAM_CACHE_BLOCKSIZE	1
5082	<*> portworx <*> ++ <*> <*> source PARAM_JDISK	1
5083	<*> portworx <*> ++ <*> <*> source PARAM_MDISK	1
5084	<*> portworx <*> ++ <*> <*> source PARAM_KDISK	1
5085	<*> portworx <*> ++ <*> <*> source PARAM_NETWORK_DATA	1
5086	<*> portworx <*> ++ <*> <*> source PARAM_NETWORK_MANAGEMENT	1
5087	<*> portworx <*> ++ <*> <*> source PARAM_KVDB	1
5088	<*> portworx <*> ++ <*> <*> source PARAM_SCHEDULER none	1
5089	<*> portworx <*> ++ <*> <*> source PARAM_API_ROOTCA	1
5090	<*> portworx <*> ++ <*> <*> source PARAM_API_CERT	1
5091	<*> portworx <*> ++ <*> <*> source PARAM_API_KEY	1
5092	<*> portworx <*> ++ <*> <*> source <*>	5
5093	<*> portworx <*> ++ <*> <*> source PARAM_PXV	1
5094	<*> portworx <*> ++ <*> <*> source PARAM_EXT4	1
5095	<*> portworx <*> ++ <*> <*> source PARAM_PORT_RANGE_START <*>	1
5096	<*> portworx <*> ++ <*> <*> source PARAM_RAID 0	1
5097	<*> portworx <*> ++ <*> <*> source PROFILE_NAME	1
5098	<*> portworx <*> ++ <*> <*> source PWX_DEBUG TRUE	1
5099	<*> portworx <*> ++ <*> <*> source PWX_CLUSTERNAME	1
5100	<*> portworx <*> ++ <*> <*> source PWX_CLUSTER_SECRET_KEY	1
5101	<*> portworx <*> ++ <*> <*> source PWX_SECRET_TYPE	1
5102	<*> portworx <*> ++ <*> <*> source PWX_ASG_KEY	1
5103	<*> portworx <*> ++ <*> <*> source PWX_BOOTSTRAP_KEY	1
5104	<*> portworx <*> ++ <*> <*> source <*> 0	1
5105	<*> portworx <*> ++ <*> <*> source PWX_NODE_POOL_LABEL	1
5106	<*> portworx <*> ++ <*> <*> source PWX_CSI_ENDPOINT	1
5107	<*> portworx <*> ++ <*> <*> source PWX_RT_OPTS_CONF	1
5108	<*> portworx <*> ++ <*> <*> source PWX_KVDB_CLUSTER_SIZE	1
5109	<*> portworx <*> ++ <*> <*> source PWX_KVDB_RECOVERY	1
5110	<*> portworx <*> ++ <*> <*> source PWX_CLUSTER_DOMAIN	1
5111	<*> portworx <*> ++ <*> <*> source PWX_MARKETPLACENAME	1
5112	<*> portworx <*> ++ <*> <*> source PARAM_FASTPATH_PROTOCOL local	1
5113	<*> portworx <*> ++ <*> <*> source PARAM_FASTPATH_SECURE <*>	1
5114	<*> portworx <*> ++ <*> <*> source PWX_OIDC_ISSUER	1
5115	<*> portworx <*> ++ <*> <*> source PWX_OIDC_CLIENT_ID	1
5116	<*> portworx <*> ++ <*> <*> source PWX_OIDC_CUSTOM_NAMESPACE	1
5117	<*> portworx <*> ++ <*> <*> source PWX_JWT_ISSUER	1
5118	<*> portworx <*> ++ <*> <*> source PWX_JWT_SHARED_SECRET	1
5119	<*> portworx <*> ++ <*> <*> source PWX_USERNAME_CLAIM sub	1
5120	<*> portworx <*> ++ <*> <*> source PWX_AUTH_SYSTEM_KEY	1
5121	<*> portworx <*> ++ <*> <*> source PWX_CSIVERSION <*>	1
5122	<*> portworx <*> ++ <*> <*> source PWX_ALLOW_SECURITY_REMOVAL	1
5123	<*> portworx <*> ++ <*> <*> source IGNORE_DEVICE_EXISTS_CHECK 0	1
5124	<*> portworx <*> ++ <*> <*> source SAVED_IFS	1
5125	<*> portworx <*> ++ <*> <*> source MIN_DSK_GB <*>	1
5126	<*> portworx <*> ++ <*> <*> source MIN_DSK_SZ <*>	1
5127	<*> portworx <*> ++ <*> <*> source MIN_JDSK_GB <*>	1
5128	<*> portworx <*> ++ <*> <*> source MIN_JDSK_SZ <*>	1
5129	<*> portworx <*> ++ <*> <*> source MIN_MDSK_GB <*>	1
5130	<*> portworx <*> ++ <*> <*> source MIN_MDSK_SZ <*>	1
5131	<*> portworx <*> ++ <*> <*> source MIN_KDSK_GB <*>	1
5132	<*> portworx <*> ++ <*> <*> source MIN_KDSK_SZ <*>	1
5133	<*> portworx <*> ++ <*> <*> source FRESH_INSTALL <*>	1
5134	<*> portworx <*> ++ <*> <*> source <*> <*>	1
5135	<*> portworx <*> ++ <*> <*> source unset FRESH_INSTALL	1
5136	<*> portworx <*> ++ <*> <*> source SKIP_STORAGE_DEVICE	1
5137	<*> portworx <*> ++ <*> <*> source DISK_PROCESSING_OUTPUT	1
5138	<*> portworx <*> + <*> <*> main <*> <*> <*>	6
5139	<*> portworx <*> + <*> <*> main <*> E X E C _ B I N	1
5140	<*> portworx <*> + <*> <*> main trap_signal HUP INT QUIT TERM	1
5141	<*> portworx <*> + <*> <*> trap_signal local sig	1
5142	<*> portworx <*> + <*> <*> trap_signal for sig in @	4
5143	<*> portworx <*> + <*> <*> trap_signal trap signal_exit HUP HUP	1
5144	<*> portworx <*> + <*> <*> trap_signal trap signal_exit INT INT	1
5145	<*> portworx <*> + <*> <*> trap_signal trap signal_exit QUIT QUIT	1
5146	<*> portworx <*> + <*> <*> trap_signal trap signal_exit TERM TERM	1
5147	<*> portworx <*> ++ <*> <*> main uname <*>	3
5148	<*> portworx <*> + <*> <*> main UKERNELRELEASE <*>	1
5149	<*> portworx <*> + <*> <*> main UKERNELVERSION <*> SMP Mon Jan <*> <*> <*> <*> UTC <*>	1
5150	<*> portworx <*> + <*> <*> main HOSTPROC <*>	1
5151	<*> portworx <*> + <*> <*> main HOSTYUM <*>	1
5152	<*> portworx <*> + <*> <*> main HOSTAPT <*>	1
5153	<*> portworx <*> + <*> <*> main APTGET_CMD apt-get	1
5154	<*> portworx <*> + <*> <*> main YUMDNLD_CMD yumdownloader	1
5155	<*> portworx <*> + <*> <*> main MIRRORS_SERVER https <*>	1
5156	<*> portworx <*> + <*> <*> main PX_FOR_INSTALLER https <*>	1
5157	<*> portworx <*> + <*> <*> main YUM_PORTWORX_COM https <*>	1
5158	<*> portworx <*> + <*> <*> main PX_FSLIB_DIR <*>	1
5159	<*> portworx <*> + <*> <*> main DISABLE_HOST_REPO_CHECK yes	1
5160	<*> portworx <*> + <*> <*> main REDHAT Red Hat	1
5161	<*> portworx <*> + <*> <*> main UBUNTU Ubuntu	1
5162	<*> portworx <*> + <*> <*> main DEBIAN Debian	1
5163	<*> portworx <*> + <*> <*> main SUSE SUSE Linux	1
5164	<*> portworx <*> + <*> <*> main BOOT_ID_FILE <*>	1
5165	<*> portworx <*> + <*> <*> main REBOOT_MARKER <*>	1
5166	<*> portworx <*> + <*> <*> main VAR_LIB_OSD <*>	1
5167	<*> portworx <*> + <*> <*> main TMP_KERN_WS <*>	1
5168	<*> portworx <*> + <*> <*> main KERNELROOTPATH <*>	1
5169	<*> portworx <*> + <*> <*> main PXFS_LATEST <*>	1
5170	<*> portworx <*> + <*> <*> main PXFS_HEADERS_DNLD <*>	1
5171	<*> portworx <*> + <*> <*> main CURL_TIMEOUT <*> <*> <*> <*>	1
5172	<*> portworx <*> + <*> <*> main WGET_TIMEOUT <*> <*>	1
5173	<*> portworx <*> + <*> <*> main PXD_NUM_CONTEXT_EXPORTED pxd_num_contexts_exported <*>	1
5174	<*> portworx <*> + <*> <*> main PROXY_ENV env http_proxy https_proxy	1
5175	<*> portworx <*> + <*> <*> main WGET_CMD env http_proxy https_proxy wget	1
5176	<*> portworx <*> + <*> <*> main CURL_CMD env http_proxy https_proxy curl	1
5177	<*> portworx <*> + <*> <*> main PX_BUILD_OUTPUT	1
5178	<*> portworx <*> ++ <*> <*> main linux_type	1
5179	<*> portworx <*> +++ <*> <*> linux_type cat <*>	1
5180	<*> portworx <*> +++ <*> <*> linux_type sed <*> <*> GCC <*> <*> <*> . . <*> <*> <*> <*> <*> . <*> <*> <*> <*>	1
5181	<*> portworx <*> ++ <*> <*> linux_type echo Ubuntu	1
5182	<*> portworx <*> + <*> <*> main LTYPE Ubuntu	1
5183	<*> portworx <*> + <*> <*> main read KRELEASE KBLDNUM KERVER DROP	1
5184	<*> portworx <*> ++ <*> <*> main linux_ver_info Ubuntu	1
5185	<*> portworx <*> ++ <*> <*> linux_ver_info <*> Ubuntu	1
5186	<*> portworx <*> ++ <*> <*> linux_ver_info local ltype Ubuntu	1
5187	<*> portworx <*> +++ <*> <*> linux_ver_info cat <*>	1
5188	<*> portworx <*> +++ <*> <*> linux_ver_info sed <*> s/^Linux version <*> <*> <*> . <*>	1
5189	<*> portworx <*> +++ <*> <*> linux_ver_info sed <*> <*>	1
5190	<*> portworx <*> +++ <*> <*> linux_ver_info sed <*> <*> SMP|# <*>	1
5191	<*> portworx <*> ++ <*> <*> linux_ver_info echo <*> <*> gcc version <*> <*> <*> Mon Jan <*> <*> <*> <*> UTC <*>	1
5192	<*> portworx <*> + <*> <*> main <*>	15
5193	<*> portworx <*> ++ <*> <*> main awk <*> <*> + <*> print <*> <*>	1
5194	<*> portworx <*> + <*> <*> main PX_ENV_VARS <*> <*>	1
5195	<*> portworx <*> <*> <*>	55
5196	<*> portworx <*> PXMOD_SOURCE <*>	3
5197	<*> portworx <*> BTRFS_SOURCE <*>	3
5198	<*> portworx <*> PXMOD_VERSION <*>	3
5199	<*> portworx <*> PXFHASH <*>	3
5200	<*> portworx <*> BTRHASH <*>	3
5201	<*> portworx <*> ASAN_OPTIONS	3
5202	<*> portworx <*> + <*> <*> main for evar in PX_ENV_VARS	9
5203	<*> portworx <*> ++ <*> <*> main echo <*> <*>	3
5204	<*> portworx <*> ++ <*> <*> main cut <*> <*>	9
5205	<*> portworx <*> + <*> <*> main e_var <*>	3
5206	<*> portworx <*> + <*> <*> main eval export <*> <*>	3
5207	<*> portworx <*> ++ <*> <*> main export <*> <*>	3
5208	<*> portworx <*> ++ <*> <*> main <*> <*>	3
5209	<*> portworx <*> + <*> <*> main <*> PXMOD_SOURCE <*>	1
5210	<*> portworx <*> ++ <*> <*> main echo PXMOD_SOURCE <*>	1
5211	<*> portworx <*> + <*> <*> main e_var PXMOD_SOURCE	1
5212	<*> portworx <*> + <*> <*> main eval export PXMOD_SOURCE <*>	1
5213	<*> portworx <*> ++ <*> <*> main export PXMOD_SOURCE <*>	1
5214	<*> portworx <*> ++ <*> <*> main PXMOD_SOURCE <*>	1
5215	<*> portworx <*> + <*> <*> main <*> BTRFS_SOURCE <*>	1
5216	<*> portworx <*> ++ <*> <*> main echo BTRFS_SOURCE <*>	1
5217	<*> portworx <*> + <*> <*> main e_var BTRFS_SOURCE	1
5218	<*> portworx <*> + <*> <*> main eval export BTRFS_SOURCE <*>	1
5219	<*> portworx <*> ++ <*> <*> main export BTRFS_SOURCE <*>	1
5220	<*> portworx <*> ++ <*> <*> main BTRFS_SOURCE <*>	1
5221	<*> portworx <*> + <*> <*> main <*> PXMOD_VERSION <*>	1
5222	<*> portworx <*> ++ <*> <*> main echo PXMOD_VERSION <*>	1
5223	<*> portworx <*> + <*> <*> main e_var PXMOD_VERSION	1
5224	<*> portworx <*> + <*> <*> main eval export PXMOD_VERSION <*>	1
5225	<*> portworx <*> ++ <*> <*> main export PXMOD_VERSION <*>	1
5226	<*> portworx <*> ++ <*> <*> main PXMOD_VERSION <*>	1
5227	<*> portworx <*> + <*> <*> main <*> PXFHASH <*>	1
5228	<*> portworx <*> ++ <*> <*> main echo PXFHASH <*>	1
5229	<*> portworx <*> + <*> <*> main e_var PXFHASH	1
5230	<*> portworx <*> + <*> <*> main eval export PXFHASH <*>	1
5231	<*> portworx <*> ++ <*> <*> main export PXFHASH <*>	1
5232	<*> portworx <*> ++ <*> <*> main PXFHASH <*>	1
5233	<*> portworx <*> + <*> <*> main <*> BTRHASH <*>	1
5234	<*> portworx <*> ++ <*> <*> main echo BTRHASH <*>	1
5235	<*> portworx <*> + <*> <*> main e_var BTRHASH	1
5236	<*> portworx <*> + <*> <*> main eval export BTRHASH <*>	1
5237	<*> portworx <*> ++ <*> <*> main export BTRHASH <*>	1
5238	<*> portworx <*> ++ <*> <*> main BTRHASH <*>	1
5239	<*> portworx <*> + <*> <*> main <*> ASAN_OPTIONS	1
5240	<*> portworx <*> ++ <*> <*> main echo ASAN_OPTIONS	1
5241	<*> portworx <*> + <*> <*> main e_var ASAN_OPTIONS	1
5242	<*> portworx <*> + <*> <*> main eval export ASAN_OPTIONS	1
5243	<*> portworx <*> ++ <*> <*> main export ASAN_OPTIONS	1
5244	<*> portworx <*> ++ <*> <*> main ASAN_OPTIONS	1
5245	<*> portworx <*> + <*> <*> main HOST_OS_RELEASE <*>	1
5246	<*> portworx <*> ++ <*> <*> main cat <*>	4
5247	<*> portworx <*> ++ <*> <*> main egrep ^PRETTY_NAME	1
5248	<*> portworx <*> ++ <*> <*> main sed <*> <*>	2
5249	<*> portworx <*> + <*> <*> main HOST_OS_STR Ubuntu <*> LTS	1
5250	<*> portworx <*> + <*> <*> main <*> Ubuntu <*> LTS	1
5251	<*> portworx <*> + <*> <*> main eval export HOST_OS_NAME Ubuntu <*> LTS	1
5252	<*> portworx <*> ++ <*> <*> main export HOST_OS_NAME Ubuntu <*> LTS	1
5253	<*> portworx <*> ++ <*> <*> main HOST_OS_NAME Ubuntu <*> LTS	1
5254	<*> portworx <*> ++ <*> <*> main egrep ^VERSION_CODENAME	1
5255	<*> portworx <*> + <*> <*> main HOST_OS_VER_NM bionic	1
5256	<*> portworx <*> + <*> <*> main <*> bionic	1
5257	<*> portworx <*> + <*> <*> main eval export HOST_OS_VER_NAME bionic	1
5258	<*> portworx <*> ++ <*> <*> main export HOST_OS_VER_NAME bionic	1
5259	<*> portworx <*> ++ <*> <*> main HOST_OS_VER_NAME bionic	1
5260	<*> portworx <*> + <*> <*> main export HOST_FLAVOR Ubuntu Variety	1
5261	<*> portworx <*> + <*> <*> main HOST_FLAVOR Ubuntu Variety	1
5262	<*> portworx <*> + <*> <*> main export HOST_KERNEL <*>	1
5263	<*> portworx <*> + <*> <*> main HOST_KERNEL <*>	1
5264	<*> portworx <*> + <*> <*> main PX_VERSION	1
5265	<*> portworx <*> ++ <*> <*> main sed <*> <*> <*>	1
5266	<*> portworx <*> + <*> <*> main PX_VERSION version <*>	1
5267	<*> portworx <*> ++ <*> <*> main date	1
5268	<*> portworx <*> + <*> <*> main echo Fri Sep <*> <*> <*> <*> UTC <*> Running version <*> on Linux <*> <*> <*> SMP Mon Jan <*> <*> <*> <*> UTC <*> <*> <*> <*> GNU/Linux	1
5269	<*> portworx <*> Fri Sep <*> <*> <*> <*> UTC <*> Running version <*> on Linux <*> <*> <*> SMP Mon Jan <*> <*> <*> <*> UTC <*> <*> <*> <*> GNU/Linux	2
5270	<*> portworx <*> + <*> <*> main echo Version Linux version <*> <*> gcc version <*> Ubuntu <*> <*> SMP Mon Jan <*> <*> <*> <*> UTC <*>	1
5271	<*> portworx <*> + <*> <*> main check_special_settings <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	1
5272	<*> portworx <*> + <*> <*> check_special_settings args @	1
5273	<*> portworx <*> + <*> <*> check_special_settings local args	1
5274	<*> portworx <*> + <*> <*> check_special_settings i 0	1
5275	<*> portworx <*> + <*> <*> check_special_settings <*>	14
5276	<*> portworx <*> + <*> <*> check_special_settings <*> ! b	1
5277	<*> portworx <*> + <*> <*> check_special_settings case args i ## <*> in	7
5278	<*> portworx <*> + <*> <*> check_special_settings i++	13
5279	<*> portworx <*> + <*> <*> check_special_settings <*> ! c	1
5280	<*> portworx <*> + <*> <*> check_special_settings portworx ! portworx	1
5281	<*> portworx <*> + <*> <*> check_special_settings <*> ! max_storage_nodes_per_zone	1
5282	<*> portworx <*> + <*> <*> check_special_settings 4 ! 4	1
5283	<*> portworx <*> + <*> <*> check_special_settings <*> ! rt_opts	1
5284	<*> portworx <*> + <*> <*> check_special_settings PWX_RT_OPTS_CONF <*> <*>	1
5285	<*> portworx <*> + <*> <*> check_special_settings <*> <*> ! <*> <*>	1
5286	<*> portworx <*> + <*> <*> check_special_settings <*> ! s	1
5287	<*> portworx <*> + <*> <*> check_special_settings type zeroedthick size <*> ! type zeroedthick size <*>	1
5288	<*> portworx <*> + <*> <*> main chmod <*> <*>	1
5289	<*> portworx <*> + <*> <*> check_special_settings -secret_type ! secret_type	1
5290	<*> portworx <*> + <*> <*> check_special_settings k8s ! k8s	1
5291	<*> portworx <*> + <*> <*> check_special_settings <*> ! x	1
5292	<*> portworx <*> + <*> <*> check_special_settings PARAM_SCHEDULER kubernetes	1
5293	<*> portworx <*> + <*> <*> check_special_settings kubernetes ! kubernetes	1
5294	<*> portworx <*> + <*> <*> main build_only	1
5295	<*> portworx <*> + <*> <*> build_only <*>	1
5296	<*> portworx <*> + <*> <*> build_only yes	1
5297	<*> portworx <*> + <*> <*> main source_px_env	2
5298	<*> portworx <*> + <*> <*> source_px_env local pxEnv <*>	2
5299	<*> portworx <*> + <*> <*> source_px_env ! <*> <*>	2
5300	<*> portworx <*> + <*> <*> source_px_env echo mapping	2
5301	<*> portworx <*> + <*> <*> source_px_env	2
5302	<*> portworx <*> + <*> <*> source_px_env egrep <*> ^PWX_MGMT_PORT . <*>	2
5303	<*> portworx <*> + <*> <*> main echo Installed pxctl...	1
5304	<*> portworx <*> + <*> <*> source_px_env sed <*> <*> . <*> <*> <*>	2
5305	<*> portworx <*> + <*> <*> source_px_env echo Setting <*> <*>	2
5306	<*> portworx <*> + <*> <*> source_px_env set <*>	2
5307	<*> portworx <*> + <*> <*> source_px_env source <*>	2
5308	<*> portworx <*> ++ <*> <*> source PWX_MGMT_PORT <*>	2
5309	<*> portworx <*> + <*> <*> source_px_env set +a	2
5310	<*> portworx <*> + <*> <*> source_px_env chmod <*> <*>	2
5311	<*> portworx <*> + <*> <*> main disown <*>	1
5312	<*> portworx <*> + <*> <*> main validate_shm	1
5313	<*> portworx <*> + <*> <*> validate_shm <*> <*>	1
5314	<*> portworx <*> + <*> <*> validate_shm return	1
5315	<*> portworx <*> + <*> <*> main set_apt_proxy	1
5316	<*> portworx <*> + <*> <*> set_apt_proxy echo Acquire http Timeout <*>	1
5317	<*> portworx <*> + <*> <*> set_apt_proxy echo Acquire ftp Timeout <*>	1
5318	<*> portworx <*> + <*> <*> set_apt_proxy echo Acquire http Proxy http <*>	1
5319	<*> portworx <*> + <*> <*> set_apt_proxy echo Acquire https Proxy https <*>	1
5320	<*> portworx <*> + <*> <*> main host_repos_xtra_pkgs	1
5321	<*> portworx <*> + <*> <*> host_repos_xtra_pkgs local apt_xtra_pkg_fl <*>	1
5322	<*> portworx <*> + <*> <*> host_repos_xtra_pkgs local host_repos_func	1
5323	<*> portworx <*> + <*> <*> host_repos_xtra_pkgs ! <*> <*>	1
5324	<*> portworx <*> + <*> <*> host_repos_xtra_pkgs return 0	1
5325	<*> portworx <*> + <*> <*> main 0 <*> 0	9
5326	<*> portworx <*> + <*> <*> main refresh_devices	1
5327	<*> portworx <*> + <*> <*> refresh_devices ! <*> <*>	1
5328	<*> portworx <*> + <*> <*> refresh_devices udevadm trigger	1
5329	<*> portworx <*> ++ <*> <*> refresh_devices module_loaded	1
5330	<*> portworx <*> +++ <*> <*> module_loaded <*>	8
5331	<*> portworx <*> +++ <*> <*> module_loaded grep <*> px	8
5332	<*> portworx <*> ++ <*> <*> module_loaded _out px <*> 0	8
5333	<*> portworx <*> ++ <*> <*> module_loaded 0 <*> 0	8
5334	<*> portworx <*> ++ <*> <*> module_loaded echo 0	8
5335	<*> portworx <*> ++ <*> <*> module_loaded return 0	8
5336	<*> portworx <*> + <*> <*> refresh_devices 0 <*> 0	1
5337	<*> portworx <*> + <*> <*> main enable_lvm	1
5338	<*> portworx <*> + <*> <*> enable_lvm local KMODS dm_thin_pool dm_cache <*> <*>	1
5339	<*> portworx <*> + <*> <*> enable_lvm for kmod in KMODS	4
5340	<*> portworx <*> + <*> <*> enable_lvm modprobe dm_thin_pool	1
5341	<*> portworx <*> + <*> <*> enable_lvm 0 ! 0	4
5342	<*> portworx <*> + <*> <*> enable_lvm modprobe dm_cache	1
5343	<*> portworx <*> + <*> <*> enable_lvm modprobe <*>	2
5344	<*> portworx <*> + <*> <*> enable_lvm return 0	1
5345	<*> portworx <*> + <*> <*> main refresh_md_devices	1
5346	<*> portworx <*> + <*> <*> refresh_md_devices sed <*> <*> <*>	1
5347	<*> portworx <*> + <*> <*> refresh_md_devices <*> <*>	1
5348	<*> portworx <*> ++ <*> <*> refresh_md_devices jq <*> .storage.target_ds_type <*>	1
5349	<*> portworx <*> + <*> <*> refresh_md_devices local datastoretype null	1
5350	<*> portworx <*> ++ <*> <*> refresh_md_devices jq <*> .storage.type <*>	1
5351	<*> portworx <*> + <*> <*> refresh_md_devices local pooltype null	1
5352	<*> portworx <*> ++ <*> <*> refresh_md_devices ls <*> <*>	1
5353	<*> portworx <*> + <*> <*> refresh_md_devices configs	1
5354	<*> portworx <*> + <*> <*> refresh_md_devices <*> ! 0	1
5355	<*> portworx <*> + <*> <*> refresh_md_devices echo Skipping reassembly as no px array config found	1
5356	<*> portworx <*> Skipping reassembly as no px array config found	2
5357	<*> portworx <*> + <*> <*> refresh_md_devices return	1
5358	<*> portworx <*> + <*> <*> main ! <*> <*>	1
5359	<*> portworx <*> + <*> <*> main install_px_mod	1
5360	<*> portworx <*> + <*> <*> install_px_mod mkdir <*> <*> <*>	1
5361	<*> portworx <*> + <*> <*> install_px_mod export_px_manifest	1
5362	<*> portworx <*> + <*> <*> export_px_manifest local pxmod_manifest <*>	1
5363	<*> portworx <*> + <*> <*> export_px_manifest local pxexport_manifest <*>	1
5364	<*> portworx <*> + <*> <*> export_px_manifest <*> <*>	1
5365	<*> portworx <*> + <*> <*> export_px_manifest diff <*> <*> <*>	1
5366	<*> portworx <*> + <*> <*> export_px_manifest 0 <*> 0	1
5367	<*> portworx <*> + <*> <*> export_px_manifest return 0	1
5368	<*> portworx <*> ++ <*> <*> install_px_mod module_loaded	7
5369	<*> portworx <*> + <*> <*> install_px_mod 0 <*> 0	7
5370	<*> portworx <*> + <*> <*> install_px_mod check_for_kmod_upgrade	1
5371	<*> portworx <*> ++ <*> <*> check_for_kmod_upgrade <*> <*>	1
5372	<*> portworx <*> + <*> <*> check_for_kmod_upgrade res Version <*>	1
5373	<*> portworx <*> + <*> <*> check_for_kmod_upgrade version <*> <*> <*> <*>	1
5374	<*> portworx <*> + <*> <*> check_for_kmod_upgrade Version <*> Failed	1
5375	<*> portworx <*> + <*> <*> check_for_kmod_upgrade echo PXD version <*> <*> <*> <*>	1
5376	<*> portworx <*> + <*> <*> install_px_mod check_kmod_version	1
5377	<*> portworx <*> ++ <*> <*> check_kmod_version <*> <*>	1
5378	<*> portworx <*> + <*> <*> check_kmod_version local check_str Module version check Success	1
5379	<*> portworx <*> + <*> <*> check_kmod_version echo Checking fs version...	1
5380	<*> portworx <*> Checking fs version...	2
5381	<*> portworx <*> + <*> <*> check_kmod_version Module version check Success F a i l e d	1
5382	<*> portworx <*> + <*> <*> check_kmod_version Module version check Success U p g r a d e	1
5383	<*> portworx <*> + <*> <*> check_kmod_version echo Module version check Success	1
5384	<*> portworx <*> Module version check Success	2
5385	<*> portworx <*> + <*> <*> check_kmod_version echo Done checking fs version...	1
5386	<*> portworx <*> Done checking fs version...	2
5387	<*> portworx <*> + <*> <*> install_px_mod yes	1
5388	<*> portworx <*> + <*> <*> main args	1
5389	<*> portworx <*> + <*> <*> main tracefile_diskusage_gigs 0	1
5390	<*> portworx <*> + <*> <*> main lttng_shm_dir <*>	1
5391	<*> portworx <*> + <*> <*> main sub_buf_num <*>	1
5392	<*> portworx <*> + <*> <*> main sub_buf_sz <*>	1
5393	<*> portworx <*> + <*> <*> main debug 0	1
5394	<*> portworx <*> + <*> <*> main restart <*>	1
5395	<*> portworx <*> + <*> <*> main parse_cmdline_params <*> <*> portworx <*> 4 <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	1
5396	<*> portworx <*> + <*> <*> parse_cmdline_params <*> -ge <*>	5
5397	<*> portworx <*> + <*> <*> parse_cmdline_params key <*>	6
5398	<*> portworx <*> + <*> <*> parse_cmdline_params case key in	7
5399	<*> portworx <*> + <*> <*> parse_cmdline_params parse_params <*> <*>	1
5400	<*> portworx <*> + <*> <*> parse_params local dev	7
5401	<*> portworx <*> + <*> <*> parse_params key <*>	6
5402	<*> portworx <*> + <*> <*> parse_params consumed 0	7
5403	<*> portworx <*> + <*> <*> parse_params case key in	7
5404	<*> portworx <*> + <*> <*> parse_params PWX_BOOTSTRAP_KEY true	1
5405	<*> portworx <*> + <*> <*> parse_params consumed <*>	7
5406	<*> portworx <*> + <*> <*> parse_params shift	13
5407	<*> portworx <*> + <*> <*> parse_params return <*>	7
5408	<*> portworx <*> + <*> <*> parse_cmdline_params consumed <*>	7
5409	<*> portworx <*> + <*> <*> parse_cmdline_params <*> <*> 0	7
5410	<*> portworx <*> + <*> <*> parse_cmdline_params <*> <*> <*>	7
5411	<*> portworx <*> + <*> <*> parse_cmdline_params shift	13
5412	<*> portworx <*> + <*> <*> parse_cmdline_params parse_params <*> portworx	1
5413	<*> portworx <*> + <*> <*> parse_params echo Using cluster portworx	1
5414	<*> portworx <*> + <*> <*> parse_params PWX_CLUSTERNAME portworx	1
5415	<*> portworx <*> + <*> <*> parse_cmdline_params parse_params <*> 4	1
5416	<*> portworx <*> + <*> <*> parse_params <*> 4	1
5417	<*> portworx <*> + <*> <*> parse_cmdline_params parse_params <*> <*> <*>	1
5418	<*> portworx <*> + <*> <*> parse_params PWX_RT_OPTS_CONF <*> <*>	1
5419	<*> portworx <*> + <*> <*> parse_cmdline_params 6 -ge <*>	1
5420	<*> portworx <*> + <*> <*> parse_cmdline_params parse_params <*> type zeroedthick size <*>	1
5421	<*> portworx <*> + <*> <*> parse_params echo Using storage device type zeroedthick size <*>	1
5422	<*> portworx <*> ++ <*> <*> parse_params echo type zeroedthick size <*>	1
5423	<*> portworx <*> ++ <*> <*> parse_params sed <*> ||	1
5424	<*> portworx <*> + <*> <*> parse_params dev type zeroedthick size <*>	1
5425	<*> portworx <*> + <*> <*> parse_params processStorageDevice type zeroedthick size <*>	1
5426	<*> portworx <*> + <*> <*> processStorageDevice <*> type zeroedthick size <*>	1
5427	<*> portworx <*> + <*> <*> processStorageDevice local storage_devs type zeroedthick size <*>	1
5428	<*> portworx <*> + <*> <*> processStorageDevice local skip_duplicate_check 0	1
5429	<*> portworx <*> + <*> <*> processStorageDevice type zeroedthick size <*> <*> d e v <*>	1
5430	<*> portworx <*> + <*> <*> processStorageDevice skip_duplicate_check <*>	1
5431	<*> portworx <*> + <*> <*> processStorageDevice for dev in storage_devs	1
5432	<*> portworx <*> + <*> <*> processStorageDevice echo	1
5433	<*> portworx <*> + <*> <*> processStorageDevice egrep <*> <*> type zeroedthick size <*>	1
5434	<*> portworx <*> + <*> <*> processStorageDevice <*> <*> 0	1
5435	<*> portworx <*> + <*> <*> processStorageDevice <*> type zeroedthick size <*> <*>	1
5436	<*> portworx <*> + <*> <*> <*> local dev type zeroedthick size <*>	1
5437	<*> portworx <*> + <*> <*> <*> local min_sz <*>	1
5438	<*> portworx <*> + <*> <*> <*> local dsz 0 ret 0	1
5439	<*> portworx <*> + <*> <*> <*> <*> type zeroedthick size <*> <*> <*> <*>	1
5440	<*> portworx <*> + <*> <*> <*> <*> type zeroedthick size <*>	1
5441	<*> portworx <*> + <*> <*> <*> type zeroedthick size <*> <*> d e v <*>	1
5442	<*> portworx <*> + <*> <*> <*> return 0	1
5443	<*> portworx <*> + <*> <*> processStorageDevice 0 <*> 0	1
5444	<*> portworx <*> + <*> <*> processStorageDevice PARAM_DISKS PARAM_DISKS_INDEX type zeroedthick size <*>	1
5445	<*> portworx <*> + <*> <*> processStorageDevice PARAM_DISKS_INDEX <*>	1
5446	<*> portworx <*> + <*> <*> parse_cmdline_params 4 -ge <*>	1
5447	<*> portworx <*> + <*> <*> parse_cmdline_params key -secret_type	1
5448	<*> portworx <*> + <*> <*> parse_cmdline_params parse_params -secret_type k8s	1
5449	<*> portworx <*> + <*> <*> parse_params key -secret_type	1
5450	<*> portworx <*> + <*> <*> parse_params PWX_SECRET_TYPE k8s	1
5451	<*> portworx <*> + <*> <*> parse_cmdline_params parse_params <*> kubernetes	1
5452	<*> portworx <*> + <*> <*> parse_params echo Using scheduler kubernetes	1
5453	<*> portworx <*> + <*> <*> parse_params PARAM_SCHEDULER kubernetes	1
5454	<*> portworx <*> + <*> <*> parse_cmdline_params 0 -ge <*>	1
5455	<*> portworx <*> + <*> <*> main validate_lttng	1
5456	<*> portworx <*> + <*> <*> validate_lttng local <*> <*>	1
5457	<*> portworx <*> ++ <*> <*> validate_lttng nproc	1
5458	<*> portworx <*> + <*> <*> validate_lttng local req_size <*>	1
5459	<*> portworx <*> + <*> <*> validate_lttng local lttng_dir <*>	1
5460	<*> portworx <*> + <*> <*> validate_lttng <*> <*> <*>	2
5461	<*> portworx <*> + <*> <*> validate_lttng mount	2
5462	<*> portworx <*> + <*> <*> validate_lttng grep tmpfs	2
5463	<*> portworx <*> + <*> <*> validate_lttng egrep <*> <*>	1
5464	<*> portworx <*> + <*> <*> validate_lttng 0 <*> 0	3
5465	<*> portworx <*> ++ <*> <*> validate_lttng df <*> <*> size <*>	1
5466	<*> portworx <*> ++ <*> <*> validate_lttng egrep <*> <*>	1
5467	<*> portworx <*> ++ <*> <*> validate_lttng tr <*> space	1
5468	<*> portworx <*> + <*> <*> validate_lttng local cur_sz <*>	1
5469	<*> portworx <*> + <*> <*> validate_lttng grep <*> <*>	1
5470	<*> portworx <*> + <*> <*> validate_lttng <*> <*>	1
5471	<*> portworx <*> + <*> <*> validate_lttng echo Clearing lttng tmpfs location <*>	1
5472	<*> portworx <*> Clearing lttng tmpfs location <*>	2
5473	<*> portworx <*> ++ <*> <*> validate_lttng ls <*> <*>	1
5474	<*> portworx <*> + <*> <*> validate_lttng lttng_tmpfs_dirs	1
5475	<*> portworx <*> + <*> <*> validate_lttng <*> <*> 0	1
5476	<*> portworx <*> + <*> <*> validate_lttng check_size <*> <*>	1
5477	<*> portworx <*> + <*> <*> check_size req_size <*>	1
5478	<*> portworx <*> + <*> <*> check_size dir <*>	1
5479	<*> portworx <*> ++ <*> <*> check_size stat <*> <*> %a %S <*>	1
5480	<*> portworx <*> + <*> <*> check_size size <*>	1
5481	<*> portworx <*> + <*> <*> check_size <*> -ge <*>	1
5482	<*> portworx <*> + <*> <*> check_size return 0	1
5483	<*> portworx <*> + <*> <*> validate_lttng return 0	1
5484	<*> portworx <*> + <*> <*> main generate_config	1
5485	<*> portworx <*> + <*> <*> generate_config validate_params	1
5486	<*> portworx <*> + <*> <*> validate_params <*>	3
5487	<*> portworx <*> + <*> <*> validate_params <*> portworx	1
5488	<*> portworx <*> + <*> <*> validate_params <*> true	1
5489	<*> portworx <*> + <*> <*> validate_params <*> <*> 0 <*> 0 <*> 0	1
5490	<*> portworx <*> + <*> <*> validate_params local storageDevices	1
5491	<*> portworx <*> + <*> <*> validate_params <*> <*>	1
5492	<*> portworx <*> ++ <*> <*> validate_params jq <*> <*> <*>	1
5493	<*> portworx <*> + <*> <*> validate_params storageDevices type zeroedthick size <*>	1
5494	<*> portworx <*> + <*> <*> validate_params 0 <*> 0 <*> <*> type zeroedthick size <*>	1
5495	<*> portworx <*> + <*> <*> validate_params PARAM_DISKS storageDevices	1
5496	<*> portworx <*> + <*> <*> validate_params PARAM_DISKS_INDEX <*>	1
5497	<*> portworx <*> + <*> <*> validate_params <*> <*> 0	3
5498	<*> portworx <*> + <*> <*> validate_params 0 <*> 0	1
5499	<*> portworx <*> ++ <*> <*> validate_params date	1
5500	<*> portworx <*> + <*> <*> validate_params echo <*> # <*> Fri Sep <*> <*> <*> <*> UTC <*> n	1
5501	<*> portworx <*> + <*> <*> validate_params return 0	1
5502	<*> portworx <*> + <*> <*> generate_config generate_config_from_params	1
5503	<*> portworx <*> + <*> <*> generate_config_from_params TMP_CONFIG_FILE <*>	1
5504	<*> portworx <*> + <*> <*> generate_config_from_params echo	6
5505	<*> portworx <*> + <*> <*> generate_config_from_params echo alertingurl	1
5506	<*> portworx <*> + <*> <*> generate_config_from_params local current_cid	1
5507	<*> portworx <*> + <*> <*> generate_config_from_params <*> <*>	2
5508	<*> portworx <*> ++ <*> <*> generate_config_from_params jq <*> .clusterid <*>	1
5509	<*> portworx <*> + <*> <*> generate_config_from_params current_cid portworx	1
5510	<*> portworx <*> + <*> <*> generate_config_from_params 0 <*> 0 <*> <*> portworx	1
5511	<*> portworx <*> + <*> <*> generate_config_from_params PWX_CLUSTERNAME portworx	1
5512	<*> portworx <*> + <*> <*> generate_config_from_params echo clusterid portworx	1
5513	<*> portworx <*> + <*> <*> generate_config_from_params echo dataiface	1
5514	<*> portworx <*> + <*> <*> generate_config_from_params	1
5515	<*> portworx <*> + <*> <*> generate_config_from_params true	1
5516	<*> portworx <*> + <*> <*> generate_config_from_params !	16
5517	<*> portworx <*> + <*> <*> generate_config_from_params true !	1
5518	<*> portworx <*> + <*> <*> generate_config_from_params echo bootstrap true	1
5519	<*> portworx <*> + <*> <*> generate_config_from_params echo mgtiface	1
5520	<*> portworx <*> + <*> <*> generate_config_from_params echo scheduler kubernetes	1
5521	<*> portworx <*> + <*> <*> generate_config_from_params k8s !	1
5522	<*> portworx <*> + <*> <*> generate_config_from_params echo secret	1
5523	<*> portworx <*> + <*> <*> generate_config_from_params echo secret_type k8s	1
5524	<*> portworx <*> + <*> <*> generate_config_from_params echo cluster_secret_key	1
5525	<*> portworx <*> + <*> <*> generate_config_from_params echo storage	1
5526	<*> portworx <*> + <*> <*> generate_config_from_params <*>	3
5527	<*> portworx <*> + <*> <*> generate_config_from_params deviceListVar PARAM_DISKS @	1
5528	<*> portworx <*> + <*> <*> generate_config_from_params local <*> deviceListVar	1
5529	<*> portworx <*> + <*> <*> generate_config_from_params echo devices	1
5530	<*> portworx <*> + <*> <*> generate_config_from_params dev_idx 0	1
5531	<*> portworx <*> + <*> <*> generate_config_from_params last_dev 0	1
5532	<*> portworx <*> + <*> <*> generate_config_from_params 0 <*> <*>	1
5533	<*> portworx <*> + <*> <*> generate_config_from_params 0 <*> 0	2
5534	<*> portworx <*> + <*> <*> generate_config_from_params append_comma	1
5535	<*> portworx <*> + <*> <*> generate_config_from_params echo type zeroedthick size <*>	1
5536	<*> portworx <*> + <*> <*> generate_config_from_params dev_idx <*>	1
5537	<*> portworx <*> + <*> <*> generate_config_from_params <*> <*> <*>	1
5538	<*> portworx <*> + <*> <*> generate_config_from_params cdev_idx 0	1
5539	<*> portworx <*> + <*> <*> generate_config_from_params last_cdev <*>	1
5540	<*> portworx <*> + <*> <*> generate_config_from_params echo cache	1
5541	<*> portworx <*> + <*> <*> generate_config_from_params generate_rt_opts <*>	1
5542	<*> portworx <*> + <*> <*> generate_rt_opts TMP_CONFIG_FILE <*>	1
5543	<*> portworx <*> + <*> <*> generate_rt_opts local IFS	1
5544	<*> portworx <*> + <*> <*> generate_rt_opts local sep	1
5545	<*> portworx <*> + <*> <*> generate_rt_opts echo rt_opts	1
5546	<*> portworx <*> + <*> <*> generate_rt_opts for x in PWX_RT_OPTS_CONF	1
5547	<*> portworx <*> + <*> <*> generate_rt_opts ky <*>	1
5548	<*> portworx <*> + <*> <*> generate_rt_opts va <*>	1
5549	<*> portworx <*> + <*> <*> generate_rt_opts echo <*> <*> <*>	1
5550	<*> portworx <*> + <*> <*> generate_rt_opts sep	1
5551	<*> portworx <*> + <*> <*> generate_rt_opts echo	2
5552	<*> portworx <*> + <*> <*> generate_config_from_params 4 !	1
5553	<*> portworx <*> + <*> <*> generate_config_from_params echo max_storage_nodes_per_zone 4	1
5554	<*> portworx <*> + <*> <*> generate_config_from_params x0 ! x	1
5555	<*> portworx <*> + <*> <*> generate_config_from_params x0 ! x0	1
5556	<*> portworx <*> + <*> <*> generate_config_from_params echo journal_dev	1
5557	<*> portworx <*> + <*> <*> generate_config_from_params echo system_metadata_dev	1
5558	<*> portworx <*> + <*> <*> generate_config_from_params echo kvdb_dev	1
5559	<*> portworx <*> + <*> <*> generate_config_from_params x ! x	1
5560	<*> portworx <*> + <*> <*> generate_config_from_params CONFIG_VERSION <*>	1
5561	<*> portworx <*> + <*> <*> generate_config_from_params echo version <*>	1
5562	<*> portworx <*> + <*> <*> generate_config_from_params mv <*> <*>	1
5563	<*> portworx <*> + <*> <*> generate_config_from_params format_config_file	1
5564	<*> portworx <*> + <*> <*> format_config_file jq . <*>	1
5565	<*> portworx <*> + <*> <*> format_config_file 0 <*> 0	1
5566	<*> portworx <*> + <*> <*> format_config_file mv <*> <*>	1
5567	<*> portworx <*> + <*> <*> generate_config 0 <*> 0	1
5568	<*> portworx <*> + <*> <*> generate_config chmod <*> <*>	1
5569	<*> portworx <*> + <*> <*> generate_config exportServerEnvs	1
5570	<*> portworx <*> + <*> <*> exportServerEnvs export PORTWORX_AUTH_OIDC_ISSUER	1
5571	<*> portworx <*> + <*> <*> exportServerEnvs PORTWORX_AUTH_OIDC_ISSUER	1
5572	<*> portworx <*> + <*> <*> exportServerEnvs export PORTWORX_AUTH_OIDC_CLIENTID	1
5573	<*> portworx <*> + <*> <*> exportServerEnvs PORTWORX_AUTH_OIDC_CLIENTID	1
5574	<*> portworx <*> + <*> <*> exportServerEnvs export <*>	5
5575	<*> portworx <*> + <*> <*> exportServerEnvs <*>	5
5576	<*> portworx <*> + <*> <*> exportServerEnvs export PORTWORX_AUTH_JWT_ISSUER	1
5577	<*> portworx <*> + <*> <*> exportServerEnvs PORTWORX_AUTH_JWT_ISSUER	1
5578	<*> portworx <*> + <*> <*> exportServerEnvs export PORTWORX_AUTH_JWT_SHAREDSECRET	1
5579	<*> portworx <*> + <*> <*> exportServerEnvs PORTWORX_AUTH_JWT_SHAREDSECRET	1
5580	<*> portworx <*> + <*> <*> exportServerEnvs export PORTWORX_AUTH_USERNAME_CLAIM sub	1
5581	<*> portworx <*> + <*> <*> exportServerEnvs PORTWORX_AUTH_USERNAME_CLAIM sub	1
5582	<*> portworx <*> + <*> <*> exportServerEnvs export PORTWORX_AUTH_SYSTEM_KEY	1
5583	<*> portworx <*> + <*> <*> exportServerEnvs PORTWORX_AUTH_SYSTEM_KEY	1
5584	<*> portworx <*> + <*> <*> exportServerEnvs export PORTWORX_CSIVERSION <*>	1
5585	<*> portworx <*> + <*> <*> exportServerEnvs PORTWORX_CSIVERSION <*>	1
5586	<*> portworx <*> + <*> <*> exportServerEnvs export PORTWORX_ALLOW_SECURITY_REMOVAL	1
5587	<*> portworx <*> + <*> <*> exportServerEnvs PORTWORX_ALLOW_SECURITY_REMOVAL	1
5588	<*> portworx <*> + <*> <*> generate_config export_config_params	1
5589	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DESCRIPTION	1
5590	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_MODE	1
5591	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_VERSION	1
5592	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CLUSTER_ID	1
5593	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DOMAIN	1
5594	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_SECRET_TYPE	1
5595	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CLUSTER_SECRET_KEY	1
5596	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_TOKEN	1
5597	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_ADDRESS	1
5598	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CA_CERT	1
5599	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CA_PATH	1
5600	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CLIENT_CERT	1
5601	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CLIENT_KEY	1
5602	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_SKIP_VERIFY	1
5603	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_TLS_SERVER_NAME	1
5604	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_BASE_PATH	1
5605	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_BACKEND_PATH	1
5606	<*> portworx <*> + <*> <*> export_config_params local <*>	3
5607	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_AWS_CMK	1
5608	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_AWS_REGION	1
5609	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_NAME	1
5610	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_USERNAME	1
5611	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_PASSWORD	1
5612	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CA_FILE	1
5613	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CERT_FILE	1
5614	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CERT_KEY_FILE	1
5615	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_TRUSTED_CA_FILE	1
5616	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CLIENT_CERT_AUTH	1
5617	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_ACL_TOKEN	1
5618	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CA_AUTH_ADDRESS	1
5619	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_INSECURE_SKIP_VERIFY false	1
5620	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_TRANSPORT_SCHEME	1
5621	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_DISCOVERY	1
5622	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DISCOVERY	1
5623	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_NODE_ID	1
5624	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CSI_ENDPOINT	1
5625	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_MGT_INTERFACE	1
5626	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DATA_INTERFACE	1
5627	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_DEVICES_MD	1
5628	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DEVICES_MD	1
5629	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_DEVICES	1
5630	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DEVICES	1
5631	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_MAX_COUNT 0	1
5632	<*> portworx <*> + <*> <*> export_config_params local <*> 0	2
5633	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_RAID_LEVEL	1
5634	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_RAID_LEVEL_MD	1
5635	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_RACK	1
5636	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_ZONE	1
5637	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_REGION	1
5638	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CLUSTER_DOMAIN	1
5639	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CLUSTERUUID	1
5640	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_NODE_POOL_LABEL	1
5641	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_KVDB_CLUSTER_SIZE 0	1
5642	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_KVDB_RECOVERY false	1
5643	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_APIROOTCA	1
5644	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_APICERT	1
5645	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_APIKEY	1
5646	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_APIDISCLIENTAUTH false	1
5647	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_BOOTSTRAP false	1
5648	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_BOOTSTRAPTYPE	1
5649	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_LICSERVERURL	1
5650	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_SCHEDULER	1
5651	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_MULTICONTAINER false	1
5652	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_MARKETPLACE_NAME	1
5653	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_JOURNAL_DEV	1
5654	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DRIVER	1
5655	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DEBUG_LEVEL	1
5656	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_ASYNC_IO false	1
5657	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_NUM_THREADS 0	1
5658	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_SYSTEM_METADATA_DEV	1
5659	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_KVDB_DEV	1
5660	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_TARGET_DS_TYPE	1
5661	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_TYPE	1
5662	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_CACHE	1
5663	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CACHE	1
5664	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DEDICATED_CACHE false	1
5665	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_CACHE_BLOCKSIZE	1
5666	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_FASTPATH_ENABLE false	1
5667	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_FASTPATH_SECURE false	1
5668	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_FASTPATH_PROTOCOL	1
5669	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_FASTPATH_PORT	1
5670	<*> portworx <*> + <*> <*> export_config_params local <*> false	1
5671	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_MGMTIP	1
5672	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_DATAIP	1
5673	<*> portworx <*> + <*> <*> export_config_params local OSDCONFIG_NODEINDEX 0	1
5674	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_VERSION <*>	1
5675	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_CLUSTER_ID portworx	1
5676	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_SECRET_TYPE k8s	1
5677	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_CLUSTER_SECRET_KEY	1
5678	<*> portworx <*> + <*> <*> export_config_params !	1
5679	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_CA_FILE	1
5680	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_CERT_FILE	1
5681	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_CERT_KEY_FILE	1
5682	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_ACL_TOKEN	1
5683	<*> portworx <*> + <*> <*> export_config_params	1
5684	<*> portworx <*> + <*> <*> export_config_params true	1
5685	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_DISCOVERY `echo PARAM_KVDB | tr `	1
5686	<*> portworx <*> ++ <*> <*> export_config_params echo	1
5687	<*> portworx <*> ++ <*> <*> export_config_params tr	1
5688	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_CSI_ENDPOINT	1
5689	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_MGT_INTERFACE	1
5690	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_DATA_INTERFACE	1
5691	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_DEVICES PARAM_DISKS @	1
5692	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_APIROOTCA	1
5693	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_APICERT	1
5694	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_APIKEY	1
5695	<*> portworx <*> + <*> <*> export_config_params OSDCONFIG_SCHEDULER kubernetes	1
5696	<*> portworx <*> ++ <*> <*> export_config_params strArray_to_str	3
5697	<*> portworx <*> ++ <*> 4 strArray_to_str out	4
5698	<*> portworx <*> ++ <*> <*> strArray_to_str arr @	4
5699	<*> portworx <*> +++ <*> <*> strArray_to_str echo	3
5700	<*> portworx <*> +++ <*> <*> strArray_to_str sed <*> <*> <*>	4
5701	<*> portworx <*> ++ <*> <*> strArray_to_str out	3
5702	<*> portworx <*> ++ <*> <*> strArray_to_str echo	3
5703	<*> portworx <*> + <*> <*> export_config_params export PWX_CLUSTER_CONFIG description mode version <*> cluster_id portworx domain secrets secret_type k8s cluster_secret_key vault token address ca_cert ca_path client_cert client_key skip_verify tls_server_name base_path backend_path aws aws_access_key_id aws_secret_access_key aws_secret_token_key aws_cmk aws_region kvdb name username password ca_file cert_file cert_key_file trusted_ca_file <*> acl_token ca_auth_address insecure_skip_verify false transport_scheme discovery	1
5704	<*> portworx <*> + <*> <*> export_config_params PWX_CLUSTER_CONFIG description mode version <*> cluster_id portworx domain secrets secret_type k8s cluster_secret_key vault token address ca_cert ca_path client_cert client_key skip_verify tls_server_name base_path backend_path aws aws_access_key_id aws_secret_access_key aws_secret_token_key aws_cmk aws_region kvdb name username password ca_file cert_file cert_key_file trusted_ca_file <*> acl_token ca_auth_address insecure_skip_verify false transport_scheme discovery	1
5705	<*> portworx <*> ++ <*> <*> export_config_params strArray_to_str type zeroedthick size <*>	1
5706	<*> portworx <*> ++ <*> 6 strArray_to_str for i in arr @	1
5707	<*> portworx <*> ++ <*> <*> strArray_to_str out type zeroedthick size <*>	2
5708	<*> portworx <*> +++ <*> <*> strArray_to_str echo type zeroedthick size <*>	1
5709	<*> portworx <*> ++ <*> <*> strArray_to_str echo type zeroedthick size <*>	1
5710	<*> portworx <*> + <*> <*> export_config_params export PWX_NODE_CONFIG node_id <*> network mgt_interface data_interface storage devices_md devices type zeroedthick size <*> max_count 0 max_drive_set_count 0 raid_level raid_level_md geo rack zone region cluster_domain	1
5711	<*> portworx <*> + <*> <*> export_config_params PWX_NODE_CONFIG node_id <*> network mgt_interface data_interface storage devices_md devices type zeroedthick size <*> max_count 0 max_drive_set_count 0 raid_level raid_level_md geo rack zone region cluster_domain	1
5712	<*> portworx <*> + <*> <*> export_config_params export PRIVATE_CLUSTER_CONFIG clusteruuid max_storage_nodes_per_zone 0 node_pool_label kvdb_cluster_size 0 kvdb_recovery false	1
5713	<*> portworx <*> + <*> <*> export_config_params PRIVATE_CLUSTER_CONFIG clusteruuid max_storage_nodes_per_zone 0 node_pool_label kvdb_cluster_size 0 kvdb_recovery false	1
5714	<*> portworx <*> + <*> <*> export_config_params export PRIVATE_NODE_CONFIG https apirootca apicert apikey apidisclientauth false bootstrap false bootstraptype licserverurl scheduler kubernetes multicontainer false marketplace_name storage journal_dev driver debug_level async_io false num_threads 0 system_metadata_dev kvdb_dev target_ds_type type cache dedicated_cache false cache_blocksize fastpath_enable false fastpath_secure false fastpath_protocol fastpath_port fastpath_allow_multi_replicas false network mgmtip dataip nodeindex 0	1
5715	<*> portworx <*> + <*> <*> export_config_params PRIVATE_NODE_CONFIG https apirootca apicert apikey apidisclientauth false bootstrap false bootstraptype licserverurl scheduler kubernetes multicontainer false marketplace_name storage journal_dev driver debug_level async_io false num_threads 0 system_metadata_dev kvdb_dev target_ds_type type cache dedicated_cache false cache_blocksize fastpath_enable false fastpath_secure false fastpath_protocol fastpath_port fastpath_allow_multi_replicas false network mgmtip dataip nodeindex 0	1
5716	<*> portworx <*> + <*> <*> generate_config <*> <*>	1
5717	<*> portworx <*> ++ <*> <*> generate_config cat <*>	1
5718	<*> portworx <*> + <*> <*> generate_config export OLD_CONFIG_JSON	1
5719	<*> portworx <*> alertingurl	3
5720	<*> portworx <*> clusterid portworx	3
5721	<*> portworx <*> dataiface	3
5722	<*> portworx <*> mgtiface	3
5723	<*> portworx <*> scheduler kubernetes	3
5724	<*> portworx <*> secret	3
5725	<*> portworx <*> secret_type k8s	3
5726	<*> portworx <*> cluster_secret_key	3
5727	<*> portworx <*> storage	3
5728	<*> portworx <*> devices	3
5729	<*> portworx <*> type zeroedthick size <*>	3
5730	<*> portworx <*> cache	3
5731	<*> portworx <*> rt_opts	3
5732	<*> portworx <*> max_storage_nodes_per_zone 4	3
5733	<*> portworx <*> journal_dev	3
5734	<*> portworx <*> system_metadata_dev	3
5735	<*> portworx <*> kvdb_dev	3
5736	<*> portworx <*> version <*>	3
5737	<*> portworx <*> + <*> <*> generate_config OLD_CONFIG_JSON	1
5738	<*> portworx <*> + <*> <*> generate_config grep multi-container	1
5739	<*> portworx <*> + <*> <*> generate_config grep true	1
5740	<*> portworx <*> + <*> <*> generate_config cat <*>	1
5741	<*> portworx <*> + <*> <*> generate_config <*> <*> 0	1
5742	<*> portworx <*> + <*> <*> main kernel_mdraid0_layout_patch	1
5743	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch ! <*> <*>	2
5744	<*> portworx <*> ++ <*> <*> kernel_mdraid0_layout_patch jq <*> .storage.type <*>	1
5745	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch local poolType null	1
5746	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch modprobe raid0	1
5747	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch echo	2
5748	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch echo Checking mdraid0 layout path for null	1
5749	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch case poolType in	1
5750	<*> portworx <*> ++ <*> <*> kernel_mdraid0_layout_patch cat <*>	1
5751	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch current 0	1
5752	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch 0 0	1
5753	<*> portworx <*> + <*> <*> kernel_mdraid0_layout_patch return 0	1
5754	<*> portworx <*> + <*> <*> main make_all_dirs	1
5755	<*> portworx <*> + <*> <*> make_all_dirs mkdir <*> <*>	2
5756	<*> portworx <*> + <*> <*> main patch_fs	1
5757	<*> portworx <*> ++ <*> <*> patch_fs echo <*>	2
5758	<*> portworx <*> ++ <*> <*> patch_fs awk <*> print <*>	4
5759	<*> portworx <*> + <*> <*> patch_fs major 4	1
5760	<*> portworx <*> + <*> <*> patch_fs minor <*>	1
5761	<*> portworx <*> + <*> <*> patch_fs <*> 4	1
5762	<*> portworx <*> + <*> <*> patch_fs <*> <*>	2
5763	<*> portworx <*> + <*> <*> patch_fs chmod <*> <*>	1
5764	<*> portworx <*> + <*> <*> patch_fs check_reboot <*>	1
5765	<*> portworx <*> + <*> <*> check_reboot last_insmoded <*>	1
5766	<*> portworx <*> + <*> <*> check_reboot ! <*> <*>	2
5767	<*> portworx <*> ++ <*> <*> check_reboot cat <*>	2
5768	<*> portworx <*> + <*> <*> check_reboot last_bootid <*>	1
5769	<*> portworx <*> + <*> <*> check_reboot current_bootid <*>	1
5770	<*> portworx <*> + <*> <*> check_reboot <*> ! <*>	1
5771	<*> portworx <*> + <*> <*> check_reboot return 0	1
5772	<*> portworx <*> + <*> <*> patch_fs need_insmod 0	1
5773	<*> portworx <*> + <*> <*> patch_fs lsmod	1
5774	<*> portworx <*> + <*> <*> patch_fs egrep <*> <*> btrfs	1
5775	<*> portworx <*> + <*> <*> patch_fs 0 <*> 0 <*> 0 <*> 0 <*> ! yes	1
5776	<*> portworx <*> + <*> <*> patch_fs echo patch_fs already done	1
5777	<*> portworx <*> patch_fs already done	2
5778	<*> portworx <*> + <*> <*> patch_fs return	1
5779	<*> portworx <*> + <*> <*> main check_req_fs xfs	1
5780	<*> portworx <*> + <*> <*> check_req_fs local mod xfs	1
5781	<*> portworx <*> + <*> <*> check_req_fs <*> xfs	1
5782	<*> portworx <*> + <*> <*> check_req_fs lsmod	4
5783	<*> portworx <*> + <*> <*> check_req_fs egrep <*> xfs	1
5784	<*> portworx <*> + <*> <*> check_req_fs 0 <*> 0	1
5785	<*> portworx <*> + <*> <*> check_req_fs return 0	1
5786	<*> portworx <*> + <*> <*> main check_req_fs ext4	1
5787	<*> portworx <*> + <*> <*> check_req_fs local mod ext4	1
5788	<*> portworx <*> + <*> <*> check_req_fs <*> ext4	1
5789	<*> portworx <*> + <*> <*> check_req_fs egrep <*> ext4	3
5790	<*> portworx <*> + <*> <*> check_req_fs <*> <*> 0	2
5791	<*> portworx <*> + <*> <*> check_req_fs mount <*> ext4 <*> <*>	1
5792	<*> portworx <*> + <*> <*> check_req_fs modprobe ext4	1
5793	<*> portworx <*> + <*> <*> main <*> <*> 0	2
5794	<*> portworx <*> + <*> <*> main echo Warning Dependency for filesystem does not exist.	1
5795	<*> portworx <*> + <*> <*> main enable_rt	1
5796	<*> portworx <*> + <*> <*> enable_rt echo <*>	1
5797	<*> portworx <*> + <*> <*> enable_rt <*> <*> 0	1
5798	<*> portworx <*> + <*> <*> main remount_sysfs_rw	1
5799	<*> portworx <*> + <*> <*> remount_sysfs_rw echo Checking sysfs mount...	1
5800	<*> portworx <*> + <*> <*> remount_sysfs_rw mount	1
5801	<*> portworx <*> + <*> <*> remount_sysfs_rw grep sysfs	1
5802	<*> portworx <*> + <*> <*> remount_sysfs_rw grep ro	1
5803	<*> portworx <*> + <*> <*> remount_sysfs_rw 0 <*> 0	1
5804	<*> portworx <*> + <*> <*> remount_sysfs_rw echo sysfs mounted read-only. remounting...	1
5805	<*> portworx <*> + <*> <*> remount_sysfs_rw mount <*> remount rw <*> sysfs sysfs <*>	1
5806	<*> portworx <*> + <*> <*> main set_px_port_range	1
5807	<*> portworx <*> + <*> <*> set_px_port_range <*> <*> <*>	1
5808	<*> portworx <*> + <*> <*> set_px_port_range export PWX_MGMT_PORT <*>	1
5809	<*> portworx <*> + <*> <*> set_px_port_range PWX_MGMT_PORT <*>	1
5810	<*> portworx <*> + <*> <*> set_px_port_range export PWX_GOSSIP_PORT <*>	1
5811	<*> portworx <*> + <*> <*> set_px_port_range PWX_GOSSIP_PORT <*>	1
5812	<*> portworx <*> + <*> <*> set_px_port_range export PWX_STORAGE_PORT <*>	1
5813	<*> portworx <*> + <*> <*> set_px_port_range PWX_STORAGE_PORT <*>	1
5814	<*> portworx <*> + <*> <*> set_px_port_range export PWX_NS_RPC_PORT <*>	1
5815	<*> portworx <*> + <*> <*> set_px_port_range PWX_NS_RPC_PORT <*>	1
5816	<*> portworx <*> + <*> <*> set_px_port_range export PWX_GO_GRPC_PORT <*>	1
5817	<*> portworx <*> + <*> <*> set_px_port_range PWX_GO_GRPC_PORT <*>	1
5818	<*> portworx <*> + <*> <*> set_px_port_range export PWX_C_GRPC_PORT <*>	1
5819	<*> portworx <*> + <*> <*> set_px_port_range PWX_C_GRPC_PORT <*>	1
5820	<*> portworx <*> + <*> <*> set_px_port_range export PWX_OBJECT_STORE_PORT <*>	1
5821	<*> portworx <*> + <*> <*> set_px_port_range PWX_OBJECT_STORE_PORT <*>	1
5822	<*> portworx <*> + <*> <*> set_px_port_range export PWX_KVDB_MON_PORT <*>	1
5823	<*> portworx <*> + <*> <*> set_px_port_range PWX_KVDB_MON_PORT <*>	1
5824	<*> portworx <*> + <*> <*> set_px_port_range export PWX_NTON_GRPC_PORT <*>	1
5825	<*> portworx <*> + <*> <*> set_px_port_range PWX_NTON_GRPC_PORT <*>	1
5826	<*> portworx <*> + <*> <*> set_px_port_range export PWX_NS_GRPC_PORT <*>	1
5827	<*> portworx <*> + <*> <*> set_px_port_range PWX_NS_GRPC_PORT <*>	1
5828	<*> portworx <*> + <*> <*> set_px_port_range export PWX_DIAGS_PORT <*>	1
5829	<*> portworx <*> + <*> <*> set_px_port_range PWX_DIAGS_PORT <*>	1
5830	<*> portworx <*> + <*> <*> set_px_port_range export PWX_OCI_MON_PORT <*>	1
5831	<*> portworx <*> + <*> <*> set_px_port_range PWX_OCI_MON_PORT <*>	1
5832	<*> portworx <*> + <*> <*> set_px_port_range export PWX_FLEXERA_PORT <*>	1
5833	<*> portworx <*> + <*> <*> set_px_port_range PWX_FLEXERA_PORT <*>	1
5834	<*> portworx <*> + <*> <*> set_px_port_range export PWX_WATCH_DOG_PORT <*>	1
5835	<*> portworx <*> + <*> <*> set_px_port_range PWX_WATCH_DOG_PORT <*>	1
5836	<*> portworx <*> + <*> <*> set_px_port_range export PWX_ETCD_PEER_PORT <*>	1
5837	<*> portworx <*> + <*> <*> set_px_port_range PWX_ETCD_PEER_PORT <*>	1
5838	<*> portworx <*> + <*> <*> set_px_port_range export PWX_ETCD_CLIENT_PORT <*>	1
5839	<*> portworx <*> + <*> <*> set_px_port_range PWX_ETCD_CLIENT_PORT <*>	1
5840	<*> portworx <*> + <*> <*> set_px_port_range export <*> <*>	2
5841	<*> portworx <*> + <*> <*> set_px_port_range <*> <*>	2
5842	<*> portworx <*> + <*> <*> set_px_port_range export PWX_HEALTH_MONITOR_PORT <*>	1
5843	<*> portworx <*> + <*> <*> set_px_port_range PWX_HEALTH_MONITOR_PORT <*>	1
5844	<*> portworx <*> + <*> <*> main set_sysctls	1
5845	<*> portworx <*> + <*> <*> set_sysctls enable_cores	1
5846	<*> portworx <*> + <*> <*> enable_cores echo <*>	1
5847	<*> portworx <*> ++ <*> <*> enable_cores cat <*>	1
5848	<*> portworx <*> ++ <*> <*> enable_cores tr <*> space	1
5849	<*> portworx <*> + <*> <*> enable_cores core_pid_enabled <*>	1
5850	<*> portworx <*> + <*> <*> enable_cores <*> <*> <*> <*> 0	1
5851	<*> portworx <*> + <*> <*> enable_cores ulimit <*> unlimited	1
5852	<*> portworx <*> + <*> <*> set_sysctls enable_yptrace	1
5853	<*> portworx <*> + <*> <*> enable_yptrace local yprocsys_loc <*>	1
5854	<*> portworx <*> + <*> <*> enable_yptrace ! <*> <*>	1
5855	<*> portworx <*> ++ <*> <*> enable_yptrace cat <*>	1
5856	<*> portworx <*> + <*> <*> enable_yptrace local ypsysval 0	1
5857	<*> portworx <*> + <*> <*> enable_yptrace 0 <*> 0	2
5858	<*> portworx <*> + <*> <*> enable_yptrace 0 <*> <*>	1
5859	<*> portworx <*> + <*> <*> enable_yptrace return 0	1
5860	<*> portworx <*> + <*> <*> set_sysctls set_vm_dirty_bytes	1
5861	<*> portworx <*> + <*> <*> set_vm_dirty_bytes local saved_dirty_bytes <*> new_dirty_bytes	1
5862	<*> portworx <*> + <*> <*> set_vm_dirty_bytes local vm_dirty_bytes_loc <*>	1
5863	<*> portworx <*> + <*> <*> set_vm_dirty_bytes local <*> <*>	2
5864	<*> portworx <*> + <*> <*> set_vm_dirty_bytes ! <*> <*>	1
5865	<*> portworx <*> + <*> <*> set_vm_dirty_bytes <*>	1
5866	<*> portworx <*> + <*> <*> set_vm_dirty_bytes return 0	1
5867	<*> portworx <*> ++ <*> <*> set_sysctls echo <*>	2
5868	<*> portworx <*> ++ <*> <*> set_sysctls awk <*> print <*>	4
5869	<*> portworx <*> + <*> <*> set_sysctls major 4	1
5870	<*> portworx <*> + <*> <*> set_sysctls minor <*>	1
5871	<*> portworx <*> + <*> <*> set_sysctls <*> 4	1
5872	<*> portworx <*> + <*> <*> set_sysctls <*> <*>	2
5873	<*> portworx <*> + <*> <*> set_sysctls 4 4	1
5874	<*> portworx <*> + <*> <*> main start_kernel_traces	1
5875	<*> portworx <*> + <*> <*> main PX_STORAGE_IO_FLUSHER yes	1
5876	<*> portworx <*> + <*> <*> main echo px starting in IO Flusher mode	1
5877	<*> portworx <*> + <*> <*> main export PX_STORAGE_IO_FLUSHER	1
5878	<*> portworx <*> + <*> <*> main export PX_DISABLE_TRACE yes	1
5879	<*> portworx <*> + <*> <*> main PX_DISABLE_TRACE yes	1
5880	<*> portworx <*> + <*> <*> main LTTNG_PARAMS <*> <*>	1
5881	<*> portworx <*> + <*> <*> main LTTNG_PARAMS <*> <*> <*> <*>	1
5882	<*> portworx <*> + <*> <*> main LTTNG_PARAMS <*> <*> <*> <*> <*> <*>	1
5883	<*> portworx <*> + <*> <*> main <*> 0	2
5884	<*> portworx <*> + <*> <*> main LTTNG_PARAMS <*> 0 <*> <*> <*> <*> <*> <*>	1
5885	<*> portworx <*> + <*> <*> main export LTTNG_PARAMS	1
5886	<*> portworx <*> + <*> <*> main SUPERVISOR_CONF <*>	1
5887	<*> portworx <*> + <*> <*> main cp <*> <*> <*>	1
5888	<*> portworx <*> + <*> <*> main USE_NEW_SUPERVISOR_CONF <*>	1
5889	<*> portworx <*> + <*> <*> main grep <*> program <*> <*>	1
5890	<*> portworx <*> + <*> <*> main export PXDAEMON_START_RETRIES <*>	1
5891	<*> portworx <*> + <*> <*> main PXDAEMON_START_RETRIES <*>	1
5892	<*> portworx <*> + <*> <*> main grep <*> program pxdaemon <*>	1
5893	<*> portworx <*> + <*> <*> main grep bootstrap true <*>	1
5894	<*> portworx <*> + <*> <*> main 0 <*> <*>	1
5895	<*> portworx <*> + <*> <*> main grep <*> program px-etcd <*>	1
5896	<*> portworx <*> + <*> <*> main found_pxetcd 0	1
5897	<*> portworx <*> + <*> <*> main grep <*> MON_PORT <*>	1
5898	<*> portworx <*> + <*> <*> main grep <*> type lvm <*>	1
5899	<*> portworx <*> + <*> <*> main LVMDS <*>	1
5900	<*> portworx <*> + <*> <*> main grep <*> program lvm2 <*>	1
5901	<*> portworx <*> + <*> <*> main <*> <*> 0 <*> <*> <*>	1
5902	<*> portworx <*> + <*> <*> main rm <*> <*>	1
5903	<*> portworx <*> ++ <*> <*> main printenv	1
5904	<*> portworx <*> + <*> <*> main echo <*> # Current Runtime Envs <*> <*>	1
5905	<*> portworx <*> <*> tcp	13
5906	<*> portworx <*> PORTWORX_API_SERVICE_PORT <*>	1
5907	<*> portworx <*> PORTWORX_AUTH_OIDC_CLIENTID	1
5908	<*> portworx <*> PX_RUNC true	1
5909	<*> portworx <*> PORTWORX_API_PORT tcp <*> <*>	1
5910	<*> portworx <*> PX_TEMPLATE_VERSION <*>	1
5911	<*> portworx <*> PWX_C_GRPC_PORT <*>	1
5912	<*> portworx <*> PX_NAMESPACE <*>	1
5913	<*> portworx <*> PX_VERSION version <*>	1
5914	<*> portworx <*> VSPHERE_DATASTORE_PREFIX <*>	1
5915	<*> portworx <*> <*>	5
5916	<*> portworx <*> HOSTNAME <*>	1
5917	<*> portworx <*> OLD_CONFIG_JSON	1
5918	<*> portworx <*> PORTWORX_SERVICE_PORT tcp <*> <*>	1
5919	<*> portworx <*> PX_LOGLEVEL info	1
5920	<*> portworx <*> PX_IMAGE_DIGEST sha256 <*>	1
5921	<*> portworx <*> <*> udp <*> <*>	1
5922	<*> portworx <*> <*> tcp <*> <*>	13
5923	<*> portworx <*> VSPHERE_VCENTER_PORT <*>	1
5924	<*> portworx <*> PORTWORX_ALLOW_SECURITY_REMOVAL	1
5925	<*> portworx <*> GOTRACEBACK crash	1
5926	<*> portworx <*> PWX_WATCH_DOG_PORT <*>	1
5927	<*> portworx <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*>	1
5928	<*> portworx <*> <*> udp	1
5929	<*> portworx <*> PWX_KVDB_MON_PORT <*>	1
5930	<*> portworx <*> PWX_FLEXERA_PORT <*>	1
5931	<*> portworx <*> PORTWORX_CSIVERSION <*>	1
5932	<*> portworx <*> container oci	1
5933	<*> portworx <*> VSPHERE_INSECURE true	1
5934	<*> portworx <*> PWX_OCI_MON_PORT <*>	1
5935	<*> portworx <*> PWX_DIAGS_PORT <*>	1
5936	<*> portworx <*> HOST_OS_NAME Ubuntu <*> LTS	1
5937	<*> portworx <*> PRIVATE_CLUSTER_CONFIG clusteruuid max_storage_nodes_per_zone 0 node_pool_label kvdb_cluster_size 0 kvdb_recovery false	1
5938	<*> portworx <*> VSPHERE_VCENTER <*>	1
5939	<*> portworx <*> PWX_CLUSTER_CONFIG description mode version <*> cluster_id portworx domain secrets secret_type k8s cluster_secret_key vault token address ca_cert ca_path client_cert client_key skip_verify tls_server_name base_path backend_path aws aws_access_key_id aws_secret_access_key aws_secret_token_key aws_cmk aws_region kvdb name username password ca_file cert_file cert_key_file trusted_ca_file <*> acl_token ca_auth_address insecure_skip_verify false transport_scheme discovery	1
5940	<*> portworx <*> KUBERNETES_PORT tcp <*> <*>	1
5941	<*> portworx <*> PWX_NS_GRPC_PORT <*>	1
5942	<*> portworx <*> PX_IMAGE <*> <*>	1
5943	<*> portworx <*> PWD <*>	1
5944	<*> portworx <*> PWX_MGMT_PORT <*>	1
5945	<*> portworx <*> HOME <*>	1
5946	<*> portworx <*> NODE_NAME <*>	1
5947	<*> portworx <*> PRIVATE_NODE_CONFIG https apirootca apicert apikey apidisclientauth false bootstrap false bootstraptype licserverurl scheduler kubernetes multicontainer false marketplace_name storage journal_dev driver debug_level async_io false num_threads 0 system_metadata_dev kvdb_dev target_ds_type type cache dedicated_cache false cache_blocksize fastpath_enable false fastpath_secure false fastpath_protocol fastpath_port fastpath_allow_multi_replicas false network mgmtip dataip nodeindex 0	1
5948	<*> portworx <*> KUBE_DNS_PORT udp <*> <*>	1
5949	<*> portworx <*> KUBERNETES_SERVICE_PORT_HTTPS <*>	1
5950	<*> portworx <*> PWX_NTON_GRPC_PORT <*>	1
5951	<*> portworx <*> LVM_USE_HOST <*>	1
5952	<*> portworx <*> NFS_SERVICE <*>	1
5953	<*> portworx <*> GOMAXPROCS <*>	1
5954	<*> portworx <*> PWX_GO_GRPC_PORT <*>	1
5955	<*> portworx <*> PWX_HEALTH_MONITOR_PORT <*>	1
5956	<*> portworx <*> LTTNG_PARAMS <*> 0 <*> <*> <*> <*> <*> <*>	1
5957	<*> portworx <*> STORK_SERVICE_SERVICE_PORT <*>	1
5958	<*> portworx <*> PORTWORX_AUTH_USERNAME_CLAIM sub	1
5959	<*> portworx <*> HOST_KERNEL <*>	1
5960	<*> portworx <*> KUBELET_DIR <*>	1
5961	<*> portworx <*> STORK_SERVICE_SERVICE_HOST <*>	1
5962	<*> portworx <*> STORK_SERVICE_PORT tcp <*> <*>	1
5963	<*> portworx <*> HOST_OS_VER_NAME bionic	1
5964	<*> portworx <*> TERM xterm	1
5965	<*> portworx <*> PWX_NS_RPC_PORT <*>	1
5966	<*> portworx <*> PORTWORX_SERVICE_SERVICE_PORT <*>	1
5967	<*> portworx <*> PORTWORX_SERVICE_SERVICE_HOST <*>	1
5968	<*> portworx <*> SHLVL <*>	1
5969	<*> portworx <*> PWX_GOSSIP_PORT <*>	1
5970	<*> portworx <*> PORTWORX_AUTH_SYSTEM_KEY	1
5971	<*> portworx <*> PX_SHARED <*> shared <*> <*> shared <*>	1
5972	<*> portworx <*> PWX_ETCD_PEER_PORT <*>	1
5973	<*> portworx <*> KUBERNETES_SERVICE_PORT <*>	1
5974	<*> portworx <*> CONTAINER_RUNTIME containerd	1
5975	<*> portworx <*> PWX_ETCD_CLIENT_PORT <*>	1
5976	<*> portworx <*> PORTWORX_AUTH_OIDC_ISSUER	1
5977	<*> portworx <*> PATH <*> <*> <*> <*> <*> <*>	1
5978	<*> portworx <*> PWX_STORAGE_PORT <*>	1
5979	<*> portworx <*> PWX_NODE_CONFIG node_id <*> network mgt_interface data_interface storage devices_md devices type zeroedthick size <*> max_count 0 max_drive_set_count 0 raid_level raid_level_md geo rack zone region cluster_domain	1
5980	<*> portworx <*> PX_DISABLE_TRACE yes	1
5981	<*> portworx <*> PS4 + BASH_SOURCE LINENO FUNCNAME 0 + FUNCNAME 0	1
5982	<*> portworx <*> PORTWORX_AUTH_JWT_ISSUER	1
5983	<*> portworx <*> PX_SECRETS_NAMESPACE <*>	1
5984	<*> portworx <*> PWX_OBJECT_STORE_PORT <*>	1
5985	<*> portworx <*> VSPHERE_INSTALL_MODE shared	1
5986	<*> portworx <*> <*> NFS install skipped in cooldown due to previous failures	1
5987	<*> portworx <*> PORTWORX_API_SERVICE_HOST <*>	1
5988	<*> portworx <*> KUBERNETES_SERVICE_HOST <*>	1
5989	<*> portworx <*> CSI_ENDPOINT unix <*>	1
5990	<*> portworx <*> HOST_FLAVOR Ubuntu Variety	1
5991	<*> portworx <*> PXDAEMON_START_RETRIES <*>	1
5992	<*> portworx <*> PORTWORX_AUTH_JWT_SHAREDSECRET	1
5993	<*> portworx <*> KUBE_DNS_SERVICE_HOST <*>	1
5994	<*> portworx <*> _ <*>	1
5995	<*> portworx <*> + <*> <*> main cntr 0	1
5996	<*> portworx <*> + <*> <*> main pidof <*> <*>	2
5997	<*> portworx <*> + <*> <*> main pkill <*> <*>	1
5998	<*> portworx <*> + <*> <*> main sleep <*>	1
5999	<*> portworx <*> + <*> <*> main cntr++	1
6000	<*> portworx <*> + <*> <*> main exec <*> <*> <*>	1
6001	Following Drive Set is attached on this node <*>	2
6002	Drive ID <*> <*> Drive Path <*> Drive Size <*>	2
6003	Node is initialized func setNodeInfo package boot	14
6004	Node <*> with Index 6 is Up	2
6005	node previously initialized true func main package main	14
6006	PX Node Index 6	2
6007	Local Trial license in sync with global	2
6008	<*> stopped listening...	5
6009	Starting Gossip... Gossiping to these nodes <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	1
6010	<*> portworx <*> <*> <*> <*> <*> WARN memberlist <*> Refuting a suspect message from <*>	8
6011	gossip Successfully joined with <*> node s	16
6012	<*> portworx <*> time <*> <*> <*> level info Error <nil> Function nodeMap.Add MID <*> NID 6 Status Up Version <*>	16
6013	<*> portworx <*> time <*> <*> <*> level info Error <nil> Function nodeMap.Add MID <*> NID 4 Status Up Version <*>	16
6014	Loading datapool Cos HIGH RaidLevel raid0 labels <key <*> value amd64 > labels <key <*> value linux > labels <key <*> value <*> > labels <key <*> value <*> > labels <key iopriority value HIGH > labels <key <*> value amd64 > labels <key <*> value <*> > labels <key <*> value linux > labels <key medium value STORAGE_MEDIUM_MAGNETIC > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value <*> > uuid <*>	13
6015	deleted older alerts tree successfully from source kv	2
6016	error migrating alerts No alert raised yet	2
6017	<*> portworx <*> <*> <*> <*> <*> WARN memberlist <*> Suspect message from <*>	120
6018	gossip Update Notification from <*> <*>	35
6019	Node unavailable for provisioning spec kernel <*> 0 <*> <*> <*> <*> tcp <*> <*> http <*> <*> <*> <*> map 0 <*> <*> <*> STORAGE_MEDIUM_MAGNETIC true 0 <*> 0 0 <*> <*> seconds <*> nanos <*> false false 0 Resources Scan OK <*> STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 Up <*> <*> 0 0 false 0 0 0 0 0 0 0 0 0 0 0 map 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 vsphere <*> <*> Titan_CaaS_Prod2 default <*> default HostSystem <*> <*> <nil> map <*> amd64 <*> linux <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> <*> <*> <*> <*> Down 0 0 false Cos HIGH RaidLevel raid0 labels <key <*> value amd64 > labels <key <*> value linux > labels <key <*> value <*> > labels <key <*> value <*> > labels <key iopriority value HIGH > labels <key <*> value amd64 > labels <key <*> value <*> > labels <key <*> value linux > labels <key medium value STORAGE_MEDIUM_MAGNETIC > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value <*> > uuid <*> POOLTYPE_BTRFS 0 false 0 false false false <*> 0 false 0 <*> <*> 0 false current provision info <*> <*> false map <*> amd64 <*> linux domain default <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> racks <*> regions <*> <*> <*> <*> <*> zones <*> map 0 <*> <*> <*>	142
6020	<*> portworx <*> <*> <*> <*> <*> ERR memberlist Push/Pull with <*> failed dial tcp <*> <*> connect connection refused	24
6021	Found original <*> arguments <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*> <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> <*> PX_NAMESPACE <*> <*> PX_SECRETS_NAMESPACE <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*>	1
6022	Starting Gossip... Gossiping to these nodes <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	9
6023	Could not retrieve PX node status error Node status not OK STATUS_INIT n	31
6024	PX node status reports portworx service is healthy	15
6025	<*> portworx <*> <*> <*> <*> <*> INFO memberlist Suspect <*> has failed no acks received	105
6026	Node unavailable for provisioning spec kernel <*> 0 <*> <*> 4 <*> tcp <*> <*> http <*> <*> <*> <*> map 0 <*> <*> <*> STORAGE_MEDIUM_MAGNETIC true 0 <*> 0 0 <*> <*> seconds <*> nanos <*> false false 0 Resources Scan OK <*> STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 Up <*> <*> 0 0 false 0 0 0 0 0 0 0 0 0 0 0 map 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 vsphere <*> <*> Titan_CaaS_Prod2 default <*> default HostSystem <*> <*> <nil> map <*> amd64 <*> linux <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> <*> <*> <*> <*> Down 0 0 false Cos HIGH RaidLevel raid0 labels <key <*> value amd64 > labels <key <*> value linux > labels <key <*> value <*> > labels <key <*> value <*> > labels <key iopriority value HIGH > labels <key <*> value amd64 > labels <key <*> value <*> > labels <key <*> value linux > labels <key medium value STORAGE_MEDIUM_MAGNETIC > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value <*> > uuid <*> POOLTYPE_BTRFS 0 false 0 false false false <*> 0 false 0 <*> <*> 0 false current provision info <*> 4 false map <*> amd64 <*> linux domain default <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> racks <*> regions <*> <*> <*> <*> <*> zones <*> map 0 <*> <*> <*>	11
6027	Storage spec update Error <nil> Function watchNodes MID <*> NID 0 Status Down Version <*>	11
6028	NodeId 0 Function <*> Tag <*>	11
6029	Node unavailable for provisioning spec kernel <*> 0 <*> <*> 0 <*> tcp <*> <*> http <*> <*> <*> <*> map 0 <*> <*> <*> STORAGE_MEDIUM_MAGNETIC true 0 <*> 0 0 <*> <*> seconds <*> nanos <*> false false 0 Resources Scan OK <*> STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 Up <*> <*> 0 0 false 0 0 0 0 0 0 0 0 0 0 0 map 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 vsphere <*> <*> Titan_CaaS_Prod2 default <*> default HostSystem <*> <*> <nil> map <*> amd64 <*> linux <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> <*> <*> <*> <*> Down 0 0 false Cos HIGH RaidLevel raid0 labels <key <*> value amd64 > labels <key <*> value linux > labels <key <*> value <*> > labels <key <*> value <*> > labels <key iopriority value HIGH > labels <key <*> value amd64 > labels <key <*> value <*> > labels <key <*> value linux > labels <key medium value STORAGE_MEDIUM_MAGNETIC > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value <*> > uuid <*> POOLTYPE_BTRFS 0 false 0 false false false <*> 0 false 0 <*> <*> 0 false current provision info <*> 0 false map <*> amd64 <*> linux domain default <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> racks <*> regions <*> <*> <*> <*> <*> zones <*> map 0 <*> <*> <*>	11
6030	Storage spec update Error <nil> Function watchNodes MID <*> NID 0 Status Up Version <*>	14
6031	Removing backing storage for device <*> pool 0 on 6	1656
6032	<*> portworx <*> <*> <*> <*> <*> ERR memberlist UDP msg type <*> not supported from <*> <*>	7
6033	Upgrading Local license with global	1
6034	Found <*> features in <*> license collection	15
6035	Parsed license AUTCapacityManagement type VM limited count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6036	Parsed license AggregatedVolume type VM limited count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6037	Parsed license CloudMigration type VM limited count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6038	Parsed license EnablePlatformVM type VM limited count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6039	Parsed license EncryptedVolume type VM limited count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6040	Parsed license HaLevel type VM limited count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6041	Parsed license Nodes type VM limited count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6042	Parsed license OIDCSecurity type VM limited count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6043	Parsed license ResizeVolume type VM limited count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6044	Parsed license ScaledVolume type VM limited count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6045	Parsed license SharedVolume type VM limited count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6046	Parsed license SnapshotToObjectStore type VM limited count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6047	Parsed license Snapshots type VM limited count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6048	Parsed license VolumeSize type VM limited count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6049	Parsed license Volumes type VM limited count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6050	License Volumes already included.	15
6051	License VolumeSize already included.	15
6052	License AggregatedVolume already included.	15
6053	License SharedVolume already included.	15
6054	License ScaledVolume already included.	15
6055	License EncryptedVolume already included.	15
6056	License ResizeVolume already included.	15
6057	License SnapshotToObjectStore already included.	15
6058	License CloudMigration already included.	15
6059	License EnablePlatformVM already included.	15
6060	License Snapshots already included.	15
6061	License HaLevel already included.	15
6062	Adding default license NodeCapacity type default count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6063	Adding default license NodeCapacityExtension type default count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6064	Adding default license LocalVolumeAttaches type default count <*> ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6065	Adding default license SnapshotToObjectStoreDaily type default count unlimited ver <*> starts <*> <*> <*> <*> expires <*> <*> <*> <*>	15
6066	<*> portworx <*> <*> <*> <*> <*> INFO memberlist Marking <*> as failed suspect timeout reached	62
6067	<*> portworx <*> <*> <*> <*> <*> INFO memberlist deadNode <*> dead <*>	86
6068	Detected node <*> to be offline due to inactivity.	86
6069	gossip Request for a Node Leave operation on Node <*>	88
6070	gossip Node <*> should go down.	88
6071	Gossip indicated node <*> to go down. Original status update for <*> Driver pxd Function NodeUpdate	88
6072	<*> portworx <*> <*> <*> <*> <*> ERR <*> memberlist Conflicting address for <*> Mine <*> <*> Theirs <*> <*>	240
6073	<*> portworx <*> <*> <*> <*> <*> ERR memberlist Push/Pull with <*> failed dial tcp <*> <*> i/o timeout	20
6074	Watch on key <*> cancelled. Error etcdserver mvcc required revision has been compacted %!v MISSING	8
6075	License watch stopped re-subscribing... error Kvdb watch revision compacted	8
6076	Watch cb for key <*> returned err Kvdb watch revision compacted	8
6077	Starting the offline node timer of <*> minutes for kvdb node <*> with IP <*> fn <*> id <*>	16
6078	Handled update for kvdb node <*> fn <*> id <*>	19
6079	ProbationCB Removing client tracker for <*>	42
6080	Node unavailable for provisioning spec kernel <*> 0 <*> <*> <*> <*> tcp <*> <*> http <*> <*> <*> <*> map Resources Scan OK 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 Up 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 map 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 vsphere <*> <*> Titan_CaaS_Prod2 default default default HostSystem <*> <*> <nil> map Down 0 0 false POOLTYPE_BTRFS 0 false 0 false false false <*> 0 false 0 <*> <*> 0 false current provision info <*> <*> false map domain default racks default regions <*> zones <*> map <*> <*>	13
6081	Node unavailable for provisioning spec kernel <*> 0 <*> <*> <*> <*> tcp <*> <*> http <*> <*> <*> <*> map Resources Scan OK 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 Up 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 map 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 vsphere <*> <*> Titan_CaaS_Prod2 default <*> default HostSystem <*> <*> <nil> map <*> amd64 <*> linux <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> <*> <*> <*> <*> Down 0 0 false POOLTYPE_BTRFS 0 false 0 false false false <*> 0 false 0 <*> <*> 0 false current provision info <*> <*> false map <*> amd64 <*> linux domain default <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> racks <*> regions <*> <*> <*> <*> <*> zones <*> map <*> <*>	27
6082	ClusterManager watchDB node ID <*> state is Decommission.	16
6083	ClusterManager watchDB decommsission node ID <*> on this node	16
6084	gossip Removing node from gossip map <*>	16
6085	Node unavailable for provisioning spec kernel <*> 0 <*> <*> <*> <*> tcp <*> <*> http <*> <*> <*> <*> map Resources Scan OK 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 Up 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 map 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0 <nil> false false 0 0 0 0 0 0 0 0 false 0 0 0 0 0 0 0 0 0 0 0 vsphere <*> <*> Titan_CaaS_Prod2 default <*> default HostSystem <*> <*> <nil> map <*> amd64 <*> linux <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> <*> <*> <*> <*> Down 0 0 true POOLTYPE_BTRFS 0 false 0 false false false <*> 0 false 0 <*> <*> 0 false current provision info <*> <*> false map <*> amd64 <*> linux domain default <*> <*> <*> <*> <*> amd64 <*> <*> <*> linux <*> <*> racks <*> regions <*> <*> <*> <*> <*> zones <*> map <*> <*>	16
6086	Node <*> Removed Action <*> Error <nil> Function watchNodes Index <*> Key <*> Value uint8	16
6087	Delete Storage Spec Error <nil> Function watchNodes MID <*> NID <*> Status Down Version <*>	16
6088	nativeDriver NodeRemove Handle notification Node Remove	16
6089	block node_remove version <*> node ID <*>	16
6090	Node removed Error <nil> Function nodeMap.Remove MID <*> NID <*> Status Down Version <*>	16
6091	<*> portworx <*> Connecting to <*>	10
6092	update_nodes dev <*> rset 0 curr 6 next 6 next clean empty resync to 6	2
6093	process_cdb_update dev <*> rset 0 node 6 curr 6 next 6 new_rset empty remove empty pool_ids 0 new_pool_ids empty	2
6094	process_cdb_update new state dev <*> rset 0 nodes 6 curr 6 new empty rem empty	2
6095	<*> portworx <*> <*> <*> <*> <*> ERR memberlist Failed TCP fallback ping EOF	9
6096	GRPC response manifest driver pxd name pxd.portworx.com vendor_version <*>	12
6097	CSI driver name pxd.portworx.com	15
6098	Lost connection to unix <*>	4
6099	Broadcasting ARP update for <*> <*> <*> <*> <*> <*> <*> via eth0	1821
6100	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> <*> AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	3
6101	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> <*> VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	4
6102	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> <*> VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	4
6103	<*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c <*> set.empty	10
6104	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c <*> set.empty	10
6105	id <namespace <*> name portworx > labels <key <*> value portworx >	14
6106	id <namespace monitoring name prometheus > labels <key <*> value prometheus >	14
6107	id <namespace <*> name <*> > labels <key app value istiod > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key <*> value Base > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	14
6108	id <namespace monitoring name node-exporter > labels <key <*> value node-exporter >	14
6109	id <namespace std-ingress name default > labels <key <*> value default >	14
6110	id <namespace <*> name <*> > labels <key app value tke-metadata > labels <key <*> value <*> >	14
6111	id <namespace collectorforkubernetes name collectorforkubernetes > labels <key app value collectorforkubernetes > labels <key <*> value collectorforkubernetes >	14
6112	id <namespace smoketest name default > labels <key <*> value default >	14
6113	id <namespace std-ingress name <*> > labels <key <*> value admission-webhook > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	14
6114	id <namespace std-ingress name <*> > labels <key <*> value default-backend > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	14
6115	id <namespace collectorforkubernetes name default > labels <key <*> value default >	14
6116	id <namespace vault name vault > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value vault > labels <key helm.sh/chart value <*> > labels <key <*> value vault >	14
6117	id <namespace vault name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> >	14
6118	id <namespace willitconnect name default > labels <key <*> value default >	14
6119	id <namespace <*> name <*> > labels <key app value <*> > labels <key chart value <*> > labels <key heritage value Helm > labels <key <*> value <*> > labels <key release value <*> >	14
6120	id <namespace <*> name <*> > labels <key app value istio-reader > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key <*> value Base > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	14
6121	id <namespace vault name default > labels <key <*> value default >	14
6122	id <namespace dex name default > labels <key <*> value default >	14
6123	id <namespace dex name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value dex > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	14
6124	id <namespace <*> name stork > labels <key <*> value stork >	14
6125	id <namespace monitoring name <*> > labels <key <*> value <*> >	28
6126	id <namespace <*> name magtape-sa > labels <key app value magtape > labels <key <*> value magtape-sa >	14
6127	id <namespace smoketest name <*> > labels <key <*> value <*> >	14
6128	id <namespace std-ingress name <*> > labels <key <*> value controller > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	14
6129	id <name monitoring > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value RMcguir4 > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value monitoring >	14
6130	id <name smoketest > labels <key <*> value smoketest >	14
6131	id <name <*> > labels <key <*> value <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	14
6132	id <name <*> > labels <key <*> value cluster-api > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	14
6133	id <name <*> > labels <key <*> value bootstrap-kubeadm > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	14
6134	id <name <*> > labels <key app value <*> > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	14
6135	id <name cert-manager > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value cert-manager >	14
6136	id <name <*> > labels <key app value magtape > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value enabled > labels <key <*> value <*> >	14
6137	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	13
6138	bird bird <*> Connected to table <*> Initializing	2
6139	bird bird <*> <*> State changed to feed	2
6140	bird bird <*> Startingdirect1 Starting	1
6141	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 deleted HostBGPConfig node <*> name ip_addr_v6 deleted HostBGPConfig node <*> name network_v4 deleted HostBGPConfig node <*> name rr_cluster_id deleted <*> deleted	96
6142	hostname <*>	96
6143	bird Removing protocol <*>	96
6144	bird <*> Shutting down	96
6145	Reconfiguration requested by SIGHUP	4
6146	<*> <*> <*> <*> I | etcdmain setting maximum number of CPUs to 4 total number of available CPUs is 4	3
6147	<*> <*> <*> <*> I | etcdserver <*> initialized peer connection fast-forwarding <*> ticks election ticks <*> with <*> active peer s	3
6148	<*> <*> <*> <*> INFO <*> term 0 received a MsgHeartbeat message with higher term from <*> term <*>	3
6149	<*> <*> <*> <*> INFO <*> switched to configuration voters <*> <*> <*> <*>	6
6150	<*> <*> <*> <*> E | etcdserver publish error etcdserver request timed out possibly due to connection <*>	3
6151	<*> <*> <*> <*> I | embed rejected connection from <*> <*> error EOF ServerName <*>	5
6152	<*> <*> <*> <*> INFO <*> switched to configuration voters <*> <*> <*>	6
6153	<*> <*> <*> <*> W | rafthttp health check for peer <*> could not connect dial tcp <*> <*> connect connection refused	10
6154	<*> <*> <*> <*> W | rafthttp closed an existing TCP streaming connection with peer <*> stream Message writer	3
6155	<*> <*> <*> <*> W | rafthttp closed an existing TCP streaming connection with peer <*> stream MsgApp <*> writer	3
6156	<*> <*> <*> <*> I | etcdserver start to snapshot applied <*> lastsnap <*>	25
6157	<*> <*> <*> <*> I | etcdserver saved snapshot at index <*>	25
6158	<*> <*> <*> <*> I | etcdserver compacted raft log at <*>	25
6159	<*> <*> <*> <*> I | wal segmented wal file <*> is created	3
6160	<*> <*> <*> <*> I | pkg/fileutil purged file <*> successfully	13
6161	Starting openstorage operator version <*> file operator.go <*>	1
6162	Registering components file operator.go <*>	1
6163	Reconciling StorageNode file storagenode.go <*> storagenode <*>	1411
6164	Updating stork Deployment file <*> <*>	1
6165	Updating <*> Deployment file <*> <*>	2
6166	Creating VolumePlacementStrategy CRD file <*> <*>	1
6167	Updating <*> DaemonSet file <*> <*>	1
6168	Nodes needing storage pods for storage cluster portworx <*> creating <*> file storagecluster.go <*>	3
6169	Adding <*> annotation to pod <*> file storagenode.go <*> storagenode <*>	13
6170	StorageCluster <*> maxUnavailable <*> numUnavailable <*> file update.go <*>	83
6171	Marking all unavailable old pods for deletion file update.go <*>	427
6172	Marking old pods for deletion file update.go <*>	427
6173	Operation cannot be fulfilled on pods <*> the object has been modified please apply your changes to the latest version and try again file <*> <*>	3
6174	Kubernetes node is no longer present file storagenode.go <*> storagenode <*>	7
6175	Updating StorageNode <*> status file status.go <*>	92
6176	Updating StorageNode <*> file status.go <*>	9
6177	creating kvdb pod <*> file storagenode.go <*> storagenode <*>	1
6178	Deleting orphan StorageNode <*> file status.go <*>	4
6179	Removing storage label from pod <*> file storagenode.go <*> storagenode <*>	18
6180	StorageCluster <*> maxUnavailable <*> numUnavailable 0 file update.go <*>	344
6181	Unable to find kubernetes node name for nodeID <*> failed to find k8s node for given addresses file status.go <*>	30
6182	Creating StorageNode <*> file status.go <*>	1
6183	Unable to authenticate the request due to an error invalid bearer token <*> is forbidden User system <*> cannot create resource tokenreviews in API group <*> at the cluster scope	2
6184	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> 0xc0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	5
6185	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> 0xc0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	6
6186	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> 0xc0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	6
6187	bird bird <*> State changed to startdevice1 State changed to feed	1
6188	bird <*> Startingbird <*> State changed to start	1
6189	bird bird <*> Connected to table <*> Starting	1
6190	bird bird <*> State changed to <*> State changed to start	1
6191	bird bird Graceful restart <*> Starting	1
6192	bird Graceful restart donebird	2
6193	<*> State changed to start	3
6194	bird bird <*> Starting	1
6195	bird bird <*> State changed to startdevice1 State changed to up	2
6196	bird <*> Startingbird	2
6197	<*> State changed to up	3
6198	id <name <*> > profile <inbound_rules <action allow rule_id <*> > outbound_rules <action allow rule_id kgWTeS3PQYnQNDEu > >	4
6199	<*> Reconfigured	4
6200	Detected CSI driver pxd.portworx.com	3
6201	Start NewCSISnapshotSideCarController with snapshotter pxd.portworx.com kubeconfig csiTimeout <*> csiAddress <*> resyncPeriod <*> snapshotNamePrefix snapshot snapshotNameUUIDLength <*>	3
6202	Neither <*> nor <*> was specified. Using default API client. This might not work.	3
6203	Authorization is disabled	3
6204	Authentication is disabled	3
6205	Serving healthz insecurely on <*>	3
6206	Detected initial install	11
6207	Skipping digest checks	11
6208	Pulling image <*> <*> ...	11
6209	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	11
6210	<*> <*> <*> <*> <*> <*> <*> <*> <*>	35
6211	<*> <*> <*> <*> <*> <*>	10
6212	Image fetch completed. Unpacking...	11
6213	Image unpack completed	11
6214	Image pulled	11
6215	<*> Portworx OCI files restart pending	11
6216	Cleaning up <*> directory if any	11
6217	Removing old container <*> if any	11
6218	Creating container from image <*> <*>	11
6219	Starting container <*> <*> <*>	11
6220	Waiting for container to complete	11
6221	Executing with arguments <*>	11
6222	INFO Copying binaries...	11
6223	INFO Upgrade request ignored no upgrade required	11
6224	INFO Copying rootfs...	11
6225	INFO Creating rootfs dirs...	11
6226	INFO Copying rootfs files...	11
6227	#################################################################################################### ..................................................................................................Total bytes written <*> <*> <*>	11
6228	INFO Done copying OCI content.	11
6229	You can now run the Portworx OCI bundle by executing one of the following	11
6230	# sudo <*> run options	11
6231	# sudo <*> install options	11
6232	For example	11
6233	# sudo <*> run <*> etcd <*> <*> <*> MY_CLUSTER_ID <*> <*> <*> <*>	11
6234	For a complete list of daemon options and more information on running Portworx with OCI RunC please visit http <*>	11
6235	PX module OK no <*> required	11
6236	RSYNC Cleaning up <*> directory ...	11
6237	> run-host <*> install <*> <*> -oci <*> <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*> <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> <*> PX_NAMESPACE <*> <*> PX_SECRETS_NAMESPACE <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*>	11
6238	> Re Creating <*> link because Error inspecting soft-link lstat <*> no such file or directory	11
6239	> Linked <*> <*> <*> dangling	11
6240	SPEC CREATED <*> <*>	22
6241	Destination service file <*> not a regular file	11
6242	Successfully written <*>	55
6243	Portworx service restart required due to OCI upgrade/install	11
6244	runC spec created <*> restart pending	11
6245	CLEANUP aborted remote registry query not working	11
6246	Finalizing OCI install ...	11
6247	Service portworx.service not yet installed	11
6248	Stopping old build ...	11
6249	Preserving old build ...	11
6250	Installing new build ...	11
6251	> mv <*> <*> <*>	22
6252	New build installed <*> reconfiguring ...	11
6253	> run-host <*> install -oci <*> <*> portworx <*> kubernetes <*> <*> type zeroedthick size <*> <*> 4 -secret_type k8s <*> <*> <*> <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NODE_NAME <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_OPERATOR_METRICS_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> <*> PX_NAMESPACE <*> <*> PX_SECRETS_NAMESPACE <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX <*> <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*>	11
6254	Initial install detected <*> enabling the Portworx service	11
6255	<*> portworx <*> Mon Nov <*> <*> <*> <*> UTC <*> device scan start	11
6256	<*> portworx <*> Mon Nov <*> <*> <*> <*> UTC <*> device scan finish	11
6257	vmdk <*> <*> matched datastore <*>	73
6258	disk <*> <*> is not on a datastore usable by this vm	140
6259	Trying to attach available DriveSet <*> map <*> <*> thin <*> <*> <*> <*> 0 kvdb Pending Add map datastore <*> map ext <*> <*> <*> zeroedthick <*> <*> <*> <*> 0 data In Use map datastore <*> map ext <*>	2
6260	Successfully attached the following DriveSet for node <*>	11
6261	Drive ID <*> <*> Drive Path <*>	14
6262	Mounting kvdb device <*> at <*>	3
6263	Setting up internal kvdb with following parameters fn <*> id <*>	3
6264	Initial Cluster Settings map <*> http <*> <*> fn <*> id <*>	3
6265	Kvdb IP <*> Kvdb PeerPort <*> ClientPort <*> fn <*> id <*>	3
6266	Kvdb Name <*> fn <*> id <*>	3
6267	Kvdb Cluster State existing fn <*> id <*>	3
6268	Kvdb Peer Domain Name <*> fn <*> id <*>	3
6269	Node <*> with Index <*> is Up	10
6270	PX Node Index <*>	10
6271	PX-Enterprise license configured successfully	14
6272	PX storage fastpath initialization with RuntimeParams Enabled false Protocol FASTPATH_PROTO_LOCAL ACL false ClusterParams ClusterID portworx NodeParams NodeUUID <*> NodeID <*> DataIP <*> Port cmdGroup <*>	24
6273	Version <*> Identity <*> Control Device Id 0 Function <*> Tag 4	12
6274	merge_level Recs 0 <*> 0	11
6275	log <*> first <*> last <*>	11
6276	Timestamp replay total records <*> done records <*> checksum <*> stable <*> blocks skipped <*> bytes read <*> csum_replayed <*>	7
6277	SwitchLogData finish node <*> dev <*> log_data 0	8
6278	Ignoring older node down update version <*> node up version <*> Error <nil> Function watchNodes MID <*> NID <*> Status Down Version <*>	13
6279	Metering standalone Detected license type as PX-Enterprise VM limited	14
6280	Updated node <*> <*> new state Down Version <*> Driver pxd Function NodeUpdate	7
6281	Scheduled cloudsnap cleanup task on this node	2
6282	Scheduled background task volume.volumeDetachAndSnapCleanupTask at periodic <*>	2
6283	Scheduled background task volume.jobCleanupTask at periodic <*>	2
6284	Scheduled background task <*> at periodic <*>	2
6285	Scheduled background task volume.assignCoordinatorOp at periodic <*>	2
6286	Scheduled background task volume.licenseExpiryCheck at periodic <*>	2
6287	Selected this node <*> as the cluster coordinator <*> background tasks scheduled	1
6288	Started task to monitor cloud migration restores on this node	2
6289	Started task to prune cloud migration statuses on this node	2
6290	Started task to check for stalled cloud migration backup on this node	2
6291	Cancelled cloudsnap cleanup task on this node	1
6292	Selected node 0 as the cluster coordinator <*> background tasks canceled	1
6293	Cancelled task to monitor cloud migration restores on this node	1
6294	Cancelled task to prune migration statuses on this node	1
6295	Cancelled task to check for stalled cloud migration backup on this node	1
6296	Trying to attach available DriveSet <*> map <*> <*> zeroedthick <*> <*> <*> <*> 0 data In Use map datastore <*> map ext <*>	8
6297	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	4
6298	Unable to start as a storage node Limit for maximum storage nodes 4 in the zone <*> reached	2
6299	Cloud driver provider indicated that node cannot contribute storage as cannot create more drives as max count limit for drive sets reached.. Starting node as storage less.	2
6300	Made 0 pools	2
6301	This node does not participates in quorum decisions	3
6302	Generated a new NodeIndex <*>	2
6303	Starting Gossip... Gossiping to these nodes <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	6
6304	No storage specified using <*>	3
6305	Setting up storage-down handlers	3
6306	Node going down as node <*> s down time has crossed cloud drive node recovery threshold.	3
6307	<*> portworx <*> PXPROCS INFO px daemon exited with code <*>	3
6308	<*> portworx <*> <*> <*> <*> <*> <*> INFO exited pxdaemon exit status <*> not expected	3
6309	<*> portworx <*> PXPROCS INFO previous <*> or px instance has not exited..	3
6310	<*> portworx <*> <*> <*> <*> <*> <*> INFO reaped unknown pid <*>	6
6311	Storage less node <*> transitioning into a storage node.	2
6312	Taking over the node with NodeID <*>	2
6313	Local PX-Enterprise license in sync with global	3
6314	Could not retrieve PX node status error Node status not OK STATUS_NOT_IN_QUORUM n	2
6315	<*> Node status not OK STATUS_NOT_IN_QUORUM Driver Cluster API ID nodeHealth Request Cluster API	5
6316	<*> portworx <*> <*> <*> <*> <*> WARN memberlist handle ping Got ping for unexpected node <*> from <*> <*> config Name <*>	40
6317	<*> portworx <*> <*> <*> <*> <*> WARN memberlist handleConn Got ping for unexpected node <*> from <*> <*> and confi Name <*>	10
6318	DeviceStore GC deleting unreferenced subvolume <*>	1
6319	Error looking up in-cluster authentication configuration Get https <*> <*> <*> context deadline exceeded	1
6320	Successfully loaded configuration. GOMAXPROCS 4 builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> 0xc0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	1
6321	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	1
6322	<*> Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> fe9c <*> set.empty	1
6323	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> fe9c <*> set.empty	1
6324	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	1
6325	Successfully loaded configuration. GOMAXPROCS 4 builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> <*> AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	1
6326	Linux interface addrs changed. addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c a3ae set.empty ifaceName eth0	1
6327	<*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c a3ae set.empty	1
6328	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c a3ae set.empty	1
6329	... dropped <*> logs ...	1
6330	bird bird <*> Initializing	2
6331	<*> Initializing	5
6332	<*> Connected to table masterbird	2
6333	<*> Connected to table master	3
6334	bird bird <*> State changed to feed	1
6335	Watch error received from Upstream ListRoot <*> error an error on the server unable to decode an event from the watch stream http2 client connection <*> has prevented the request from succeeding	40
6336	Calico Node referenced in IPAM data does not exist error resource does not exist Node <*> with error nodes <*> not found	12
6337	Checking node calicoNode <*> k8sNode	12
6338	Cleaning up IPAM resources for deleted node calicoNode <*> k8sNode	12
6339	Node doesn t exist no need to release affinity cidr <*> host <*>	23
6340	Detected new node with <*> to be offline due to inactivity.	2
6341	Node <*> is a storage less node.	1
6342	Marking node <*> down as it has same IP tcp <*> <*> as this node <*>	1
6343	Error looking up in-cluster authentication configuration Get https <*> <*> <*> dial tcp <*> <*> connect connection refused	1
6344	Failed to watch <*> failed to list <*> Get https <*> <*> <*> limit <*> resourceVersion 0 context deadline exceeded	1
6345	Failed to watch <*> failed to list <*> Get https <*> <*> <*> resourceVersion 0 <*> TLS handshake timeout	10
6346	Failed to watch <*> failed to list <*> Get https <*> <*> <*> limit <*> resourceVersion 0 <*> TLS handshake timeout	1
6347	Failed to watch <*> failed to list <*> configmaps <*> is forbidden User system <*> cannot list resource configmaps in API group in the namespace <*>	1
6348	Failed to watch <*> failed to list <*> <*> is forbidden User system <*> cannot list resource statefulsets in API group apps at the cluster scope	1
6349	Failed to watch <*> failed to list <*> persistentvolumes is forbidden User system <*> cannot list resource persistentvolumes in API group at the cluster scope	1
6350	Failed to watch <*> failed to list <*> <*> is forbidden User system <*> cannot list resource replicasets in API group apps at the cluster scope	1
6351	Failed to watch <*> failed to list <*> <*> is forbidden User system <*> cannot list resource <*> in API group <*> at the cluster scope	1
6352	Failed to watch <*> failed to list <*> <*> is forbidden User system <*> cannot list resource <*> in API group policy at the cluster scope	1
6353	Failed to watch <*> failed to list <*> replicationcontrollers is forbidden User system <*> cannot list resource replicationcontrollers in API group at the cluster scope	1
6354	Failed to watch <*> failed to list <*> nodes is forbidden User system <*> cannot list resource nodes in API group at the cluster scope	1
6355	Failed to watch <*> failed to list <*> persistentvolumeclaims is forbidden User system <*> cannot list resource persistentvolumeclaims in API group at the cluster scope	1
6356	Failed to watch <*> failed to list <*> pods is forbidden User system <*> cannot list resource pods in API group at the cluster scope	1
6357	Failed to watch <*> failed to list <*> services is forbidden User system <*> cannot list resource services in API group at the cluster scope	1
6358	Failed to watch <*> failed to list <*> <*> is forbidden User system <*> cannot list resource storageclasses in API group <*> at the cluster scope	1
6359	Err <*> http <*> bionic-updates InRelease	2
6360	Err 4 http <*> bionic-backports InRelease	2
6361	Trying to attach available DriveSet <*> map <*> <*> thin <*> <*> <*> <*> 0 kvdb In Use map datastore <*> map ext <*> <*> <*> zeroedthick <*> <*> <*> <*> 0 data In Use map datastore <*> map ext <*>	1
6362	<*> portworx <*> time <*> <*> <*> level info Error <nil> Function nodeMap.Add MID <*> NID 0 Status Down Version <*>	1
6363	PX storage fastpath initialization with RuntimeParams Enabled false Protocol FASTPATH_PROTO_LOCAL ACL false ClusterParams ClusterID portworx NodeParams NodeUUID <*> NodeID 0 DataIP <*> Port cmdGroup <*>	2
6364	Version <*> Identity 0 Control Device Id 0 Function <*> Tag 4	1
6365	SwitchLogData finish node 0 dev <*> log_data 0	1
6366	Selected this node 0 as the cluster coordinator <*> background tasks scheduled	1
6367	Ignoring older node down update version <*> node up version <*> Error <nil> Function watchNodes MID <*> NID 0 Status Down Version <*>	1
6368	update_nodes dev <*> rset 0 curr 4 <*> next 4 <*> next clean empty resync to 4 <*>	1
6369	0 Start IO profiler on <*>	1
6370	ResyncRequest dev <*> rset 0 v <*> from 4 <*> to 4 <*> clean empty	1
6371	update_nodes dev <*> rset 0 curr 4 <*> next 4 <*> next clean 4 <*> resync to 4 <*>	2
6372	Error while calling home node <*> node <*> Post http <*> token <*> dial tcp <*> <*> i/o timeout	1
6373	failed to update autoscalar annotation on pod due to timed out waiting for the condition	2
6374	update_nodes dev <*> rset 0 curr 4 <*> next 4 next clean 4 resync to 4	1
6375	ResyncRequest dev <*> rset 0 v <*> from 4 <*> to 4 clean 4	1
6376	dev <*> rset 0 trivial resync from 4 <*> to 4	1
6377	update_cdb node 0 token <*> vers <*>	2
6378	update_cdb dev <*> rset 0 node 4 <*> curr 4 <*> next 4 new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	1
6379	volumeStateHandler update AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	10
6380	process_cdb_update dev <*> rset 0 node 4 <*> curr 4 <*> next 4 new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	1
6381	process_cdb_update new state dev <*> rset 0 nodes 4 <*> curr 4 new empty rem empty	1
6382	update_nodes dev <*> rset 0 curr 4 next 4 next clean 4 resync to 4	1
6383	update_nodes dev <*> rset 0 curr 4 next 4 <*> next clean 4 resync to 4 <*>	1
6384	ResyncRequest dev <*> rset 0 v <*> from 4 to 4 <*> clean 4	1
6385	update_cdb dev <*> rset 0 node 4 <*> curr 4 next 4 <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	1
6386	process_cdb_update dev <*> rset 0 node 4 <*> curr 4 next 4 <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	1
6387	Background worker trying to decommission node <*>	2
6388	ClusterManager Remove node.	2
6389	Node <*> must be offline or in maintenance mode to be decommissioned. node status STATUS_OK	1
6390	Background worker node decommission failed for <*> Node <*> must be offline or in maintenance mode to be decommissioned.	1
6391	Remove node ask cluster listener can we remove node ID <*> Scheduler	1
6392	Remove node ask cluster listener can we remove node ID <*> PX Storage Service	1
6393	Remove node ask cluster listener can we remove node ID <*> Kvdb_Cluster_Listener	1
6394	Remove node notify cluster listener Scheduler	1
6395	Remove node notify cluster listener PX Storage Service	1
6396	Storage Remove Node <*>	1
6397	Cluster manager node remove done node ID <*>	1
6398	Removing spec <*>	1
6399	Attempt to decommission PX-Enterprise license ignored	1
6400	Remove node notify cluster listener Kvdb_Cluster_Listener	1
6401	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> 0xed 0xc0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	1
6402	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> 0xed 0xc0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	1
6403	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> 0xed 0xc0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	1
6404	id <name <*> > profile <inbound_rules <action allow rule_id <*> > outbound_rules <action allow rule_id oQhBWTLJpU3ldwis > >	5
6405	error retrieving resource lock <*> Get https <*> <*> read tcp <*> <*> <*> read connection timed out	1
6406	Volume driver on node <*> <*> is still offline STATUS_OFFLINE	16
6407	Failed to get cluster domain info Get http <*> <*> <*> request canceled Client.Timeout exceeded while awaiting headers	1
6408	Cleaning up volume attachments for node <*>	2
6409	Pod doesn t have any volumes by driver Namespace aqua Owner <*> PodName <*>	27
6410	Pod doesn t have any volumes by driver Namespace <*> Owner <*> PodName <*>	228
6411	Pod doesn t have any volumes by driver Namespace cert-manager Owner <*> PodName <*>	6
6412	Pod doesn t have any volumes by driver Namespace collectorforkubernetes Owner <*> PodName <*>	33
6413	Pod doesn t have any volumes by driver Namespace dex Owner <*> PodName <*>	6
6414	Pod doesn t have any volumes by driver Namespace <*> Owner StorageCluster/portworx PodName <*>	24
6415	Pod doesn t have any volumes by driver Namespace monitoring Owner <*> PodName <*>	57
6416	Pod doesn t have any volumes by driver Namespace std-ingress Owner <*> PodName <*>	17
6417	Pod doesn t have any volumes by driver Namespace vault Owner <*> PodName <*>	2
6418	Pod doesn t have any volumes by driver Namespace willitconnect Owner <*> PodName <*>	8
6419	bird bird Unable to open configuration file <*> No such file or directoryUnable to open configuration file <*> No such file or directory	1
6420	bird <*> State changed to feedbird	4
6421	<*> Startingbird	3
6422	Graceful restart startedbird	2
6423	bird <*> Connected to table masterGraceful restart done	1
6424	bird bird <*> State changed to feedStarted	2
6425	bird <*> State changed to upbird	2
6426	bird bird <*> State changed to <*> Starting	1
6427	Linux interface addrs changed. addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c ed6 set.empty ifaceName eth0	1
6428	<*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c ed6 set.empty	1
6429	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c ed6 set.empty	1
6430	Linux interface state changed. ifIndex 6 ifaceName tunl0 state up	2
6431	intdataplane.ifaceUpdate Name tunl0 State up Index 6	2
6432	Netlink address update. addr <*> exists true ifIndex 6	2
6433	bird bird <*> <*> Starting	1
6434	bird bird <*> Connected to table masterdevice1 Connected to table master	2
6435	bird bird <*> State changed to feeddevice1 State changed to feed	2
6436	bird bird Started	1
6437	<*> Starting	3
6438	bird bird <*> Connected to table masterdevice1 State changed to up	1
6439	Timestamp replay total records 0 done records <*> checksum 0 stable 0 blocks skipped 0 bytes read 0 csum_replayed 0	1
6440	update_nodes dev <*> rset 0 curr <*> <*> next <*> <*> next clean empty resync to <*> <*>	3
6441	<*> Start IO profiler on <*>	2
6442	ResyncRequest dev <*> rset 0 v <*> from <*> <*> to <*> <*> clean empty	3
6443	update_nodes dev <*> rset 0 curr <*> <*> next <*> <*> next clean <*> <*> resync to <*> <*>	6
6444	set <*> kvdb error rpc error code Unavailable desc transport is closing retry count 0 n	1
6445	update_nodes dev <*> rset 0 curr <*> <*> next <*> next clean <*> resync to <*>	3
6446	ResyncRequest dev <*> rset 0 v <*> from <*> <*> to <*> clean <*>	3
6447	dev <*> rset 0 trivial resync from <*> <*> to <*>	3
6448	update_cdb node <*> token <*> vers <*>	2
6449	update_cdb dev <*> rset 0 node <*> <*> curr <*> <*> next <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	3
6450	process_cdb_update dev <*> rset 0 node <*> <*> curr <*> <*> next <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	3
6451	process_cdb_update new state dev <*> rset 0 nodes <*> <*> curr <*> new empty rem empty	3
6452	update_nodes dev <*> rset 0 curr <*> next <*> next clean <*> resync to <*>	4
6453	update_nodes dev <*> rset 0 curr <*> next <*> <*> next clean <*> resync to <*> <*>	3
6454	ResyncRequest dev <*> rset 0 v <*> from <*> to <*> <*> clean <*>	3
6455	update_cdb dev <*> rset 0 node <*> <*> curr <*> next <*> <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	3
6456	process_cdb_update dev <*> rset 0 node <*> <*> curr <*> next <*> <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	3
6457	bird <*> Initializingbird	4
6458	<*> State changed to feedbird	2
6459	bird bird <*> State changed to <*> Initializing	2
6460	bird bird Graceful restart <*> Initializing	1
6461	bird bird <*> InitializingStarted	1
6462	<*> State changed to upbird	2
6463	id <name <*> > profile <inbound_rules <action allow rule_id BcdTppRuXxLYewCF > outbound_rules <action allow rule_id <*> > >	1
6464	bird Unable to open configuration file <*> No such file or directorybird	1
6465	Unable to open configuration file <*> No such file or directory	1
6466	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> 0x0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	3
6467	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> 0x0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	3
6468	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> 0x0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	2
6469	Timestamp replay total records <*> done records <*> checksum <*> stable <*> blocks skipped 0 bytes read <*> csum_replayed <*>	2
6470	Resetting endpoints for master service kubernetes to <*> <*> <*>	3
6471	failed to prepare current and previous objects conversion webhook for <*> Kind Cluster failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	1
6472	<*> <*> watch of <*> Kind Cluster ended with Internal error occurred conversion webhook for <*> Kind Cluster failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	1
6473	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Cluster conversion webhook for <*> Kind Cluster failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused reinitializing...	2
6474	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> Format client <*> <*> <*> <*> <*> total time <*>	6
6475	Trace <*> Call validating webhook configuration <*> webhook imageassurance.aquasec.com resource <*> Resource pods subresource operation UPDATE UID <*> <*> <*> <*> <*> total time <*>	6
6476	Failed calling webhook failing open imageassurance.aquasec.com failed calling webhook imageassurance.aquasec.com Post https <*> <*> <*> context deadline exceeded	3
6477	failed calling webhook imageassurance.aquasec.com Post https <*> <*> <*> context deadline exceeded	3
6478	apiserver received an error that is not an <*> context.deadlineExceededError	1
6479	unable to encode watch object <*> write tcp <*> <*> <*> write connection timed out <*> writer http.response <*> encoder versioning.codec <*> buf bytes.Buffer <*>	1
6480	Trace <*> Call validating webhook configuration <*> webhook <*> resource <*> Resource ingresses subresource operation UPDATE UID <*> <*> <*> <*> <*> total time <*>	5
6481	Trace <*> GuaranteedUpdate etcd3 type networking.Ingress <*> <*> <*> <*> total time <*>	3
6482	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> client <*> <*> <*> <*> <*> total time <*>	3
6483	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> statefulset-controller client <*> <*> <*> <*> <*> total time <*>	5
6484	failed to prepare current and previous objects conversion webhook for <*> Kind KubeadmConfig failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	2
6485	<*> <*> watch of <*> Kind KubeadmConfig ended with Internal error occurred conversion webhook for <*> Kind KubeadmConfig failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	2
6486	failed to prepare current and previous objects conversion webhook for <*> Kind MachineSet failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	2
6487	<*> <*> watch of <*> Kind MachineSet ended with Internal error occurred conversion webhook for <*> Kind MachineSet failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	2
6488	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind KubeadmConfig conversion webhook for <*> Kind KubeadmConfig failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused reinitializing...	46
6489	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind MachineSet conversion webhook for <*> Kind MachineSet failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused reinitializing...	56
6490	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind KubeadmConfig conversion webhook for <*> Kind KubeadmConfig failed Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers reinitializing...	9
6491	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind MachineSet conversion webhook for <*> Kind MachineSet failed Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers reinitializing...	7
6492	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind KubeadmConfig conversion webhook for <*> Kind KubeadmConfig failed Post https <*> <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers reinitializing...	1
6493	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Machine conversion webhook for <*> Kind Machine failed Post https <*> <*> <*> context deadline exceeded reinitializing...	1
6494	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind MachineSet conversion webhook for <*> Kind MachineSet failed Post https <*> <*> <*> context deadline exceeded reinitializing...	1
6495	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Machine conversion webhook for <*> Kind Machine failed Post https <*> <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers reinitializing...	1
6496	<*> <*> watch of <*> Kind VSphereMachine ended with Internal error occurred conversion webhook for <*> Kind VSphereMachine failed Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers	2
6497	unable to encode watch object <*> write tcp <*> <*> <*> write connection timed out <*> writer http2.responseWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	4
6498	Node <*> with Index 4 is Up	1
6499	PX Node Index 4	1
6500	PX storage fastpath initialization with RuntimeParams Enabled false Protocol FASTPATH_PROTO_LOCAL ACL false ClusterParams ClusterID portworx NodeParams NodeUUID <*> NodeID 4 DataIP <*> Port cmdGroup <*>	2
6501	Version <*> Identity 4 Control Device Id 0 Function <*> Tag 4	1
6502	SwitchLogData finish node 4 dev <*> log_data 0	1
6503	Ignoring older node down update version <*> node up version <*> Error <nil> Function watchNodes MID <*> NID 4 Status Down Version <*>	1
6504	update_nodes dev <*> rset 0 curr 0 <*> next 0 <*> next clean empty resync to 0 <*>	1
6505	4 Start IO profiler on <*>	2
6506	ResyncRequest dev <*> rset 0 v <*> from 0 <*> to 0 <*> clean empty	1
6507	update_nodes dev <*> rset 0 curr 0 <*> next 0 <*> next clean 0 <*> resync to 0 <*>	2
6508	update_nodes dev <*> rset 0 curr 0 <*> next <*> next clean <*> resync to <*>	1
6509	ResyncRequest dev <*> rset 0 v <*> from 0 <*> to <*> clean <*>	1
6510	dev <*> rset 0 trivial resync from 0 <*> to <*>	1
6511	update_cdb node 4 token <*> vers <*>	6
6512	update_cdb dev <*> rset 0 node 0 <*> curr 0 <*> next <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	1
6513	process_cdb_update dev <*> rset 0 node 0 <*> curr 0 <*> next <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	1
6514	process_cdb_update new state dev <*> rset 0 nodes 0 <*> curr <*> new empty rem empty	1
6515	update_nodes dev <*> rset 0 curr <*> next 0 <*> next clean <*> resync to 0 <*>	1
6516	ResyncRequest dev <*> rset 0 v <*> from <*> to 0 <*> clean <*>	1
6517	update_cdb dev <*> rset 0 node 0 <*> curr <*> next 0 <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	1
6518	process_cdb_update dev <*> rset 0 node 0 <*> curr <*> next 0 <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	1
6519	get <*> kvdb error context deadline exceeded retry count 0 n	1
6520	set <*> kvdb error context deadline exceeded retry count 0 n	1
6521	Timestamp replay total records <*> done records <*> checksum <*> stable <*> blocks skipped 6 bytes read <*> csum_replayed <*>	1
6522	Successfully loaded configuration. GOMAXPROCS 4 builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff <*> <*> <*> 0x0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	1
6523	Linux interface addrs changed. addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c c3ea set.empty ifaceName eth0	1
6524	<*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c c3ea set.empty	1
6525	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c c3ea set.empty	1
6526	bird bird <*> <*> Connected to table master	1
6527	<*> Initializingbird	5
6528	Graceful restart donebird	2
6529	Started	2
6530	bird bird <*> <*> State changed to up	1
6531	<*> <*> <*> <*> INFO <*> term <*> received MsgTimeoutNow from <*> and starts an election to get leadership.	1
6532	Starting CSI snapshotter	1
6533	Failed to list <*> the server could not find the requested resource get <*>	6310
6534	Starting external resizer pxd.portworx.com	1
6535	Could not construct reference to <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string nil Annotations map string string nil OwnerReferences <*> nil Initializers <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> Fields <*> nil Spec <*> HolderIdentity string nil LeaseDurationSeconds <*> nil AcquireTime <*> nil RenewTime <*> nil LeaseTransitions <*> nil due to selfLink was empty can t make reference . Will not report event Normal LeaderElection <*> became leader	1
6536	bird bird <*> Startingdevice1 Initializing	1
6537	bird bird Graceful restart starteddirect1 Starting	1
6538	bird	2
6539	bird bird <*> State changed to <*> State changed to feed	1
6540	bird bird <*> Startingdirect1 State changed to up	1
6541	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> dial tcp <*> <*> connect connection refused	1
6542	Trace <*> Call mutating webhook configuration <*> webhook <*> resource <*> Resource machines subresource operation UPDATE UID <*> <*> <*> <*> <*> total time <*>	33
6543	Trace <*> Call mutating webhook configuration <*> webhook <*> resource <*> Resource machinedeployments subresource operation UPDATE UID <*> <*> <*> <*> <*> total time <*>	5
6544	unable to encode watch object <*> write tcp <*> <*> <*> write connection reset by peer <*> writer http.response <*> encoder versioning.codec <*> buf bytes.Buffer <*>	2
6545	Trace <*> Call validating webhook configuration <*> webhook <*> resource <*> Resource vspheremachines subresource operation UPDATE UID <*> <*> <*> <*> <*> total time <*>	150
6546	Failed calling webhook failing closed <*> failed calling webhook <*> Post https <*> <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers	1
6547	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> client <*> <*> <*> <*> <*> total time <*>	1
6548	NGINX Ingress controller	4
6549	Release <*>	4
6550	Build <*>	4
6551	Repository https <*>	4
6552	nginx version <*>	4
6553	Watching for Ingress class <*>	4
6554	Only Ingresses with class <*> will be processed by this Ingress controller	4
6555	Creating API client host https <*> <*>	4
6556	Running in Kubernetes cluster major <*> minor <*> git <*> state clean commit <*> platform linux/amd64	4
6557	Valid default backend service <*>	4
6558	SSL fake certificate created file <*>	4
6559	Enabling new Ingress features available since Kubernetes <*>	4
6560	No IngressClass resource with name <*> found. Only annotation will be used.	4
6561	loading tls certificate path <*> key <*>	4
6562	Starting NGINX Ingress controller	4
6563	Event <*> Kind ConfigMap Namespace std-ingress Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason CREATE ConfigMap <*>	4
6564	Adding secret to local store name <*>	8
6565	Event <*> Kind Ingress Namespace monitoring Name prometheus-federation-ingress UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6566	Event <*> Kind Ingress Namespace monitoring Name prometheus-ingress UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6567	Event <*> Kind Ingress Namespace willitconnect Name willitconnect UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6568	Event <*> Kind Ingress Namespace <*> Name piris-tools UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6569	Event <*> Kind Ingress Namespace willitconnect Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	12
6570	Event <*> Kind Ingress Namespace dex Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6571	Event <*> Kind Ingress Namespace <*> Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	20
6572	Event <*> Kind Ingress Namespace monitoring Name alertmanager-ingress UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6573	Event <*> Kind Ingress Namespace std-ingress Name echoserver-ing UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6574	Event <*> Kind Ingress Namespace <*> Name willittrace-ing UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6575	Event <*> Kind Ingress Namespace monitoring Name grafana-ingress UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6576	Event <*> Kind Ingress Namespace smoketest Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6577	Starting NGINX process	4
6578	Starting validation webhook address <*> certPath <*> keyPath <*>	4
6579	Configuration changes detected backend reload required	6
6580	Backend successfully reloaded	6
6581	Initial sync sleeping for <*> second	4
6582	Event <*> Kind Pod Namespace std-ingress Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason RELOAD NGINX reload triggered due to a change in configuration	6
6583	New leader <*> identity <*>	10
6584	Service <*> does not have any active Endpoint.	741
6585	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> POST <*> <*> <*> 0 <*> <*> <*> <*> <*> <*> <*> 0 <*> <*> <*> <*> <*>	6480
6586	Event <*> Kind Ingress Namespace monitoring Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Sync Scheduled for sync	4
6587	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> POST <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	4996
6588	<*> <*> <*> <*> error <*> <*> upstream timed out <*> Operation timed out while connecting to upstream client <*> server <*> request GET <*> <*> upstream http <*> <*> host <*>	31
6589	<*> <*> <*> <*> admin <*> <*> <*> <*> <*> GET <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> 0 <*> <*> <*> <*> <*> <*> <*> <*>	17
6590	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> GET <*> <*> <*> 0 <*> <*> <*> <*> <*> <*> <*> 0 <*> <*> <*> <*> <*>	9
6591	<*> <*> <*> <*> admin <*> <*> <*> <*> <*> GET <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	19
6592	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> GET <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	17
6593	<*> <*> <*> <*> admin <*> <*> <*> <*> <*> GET <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> 0 <*> <*> <*> <*> <*> <*> <*> <*>	11
6594	<*> <*> <*> <*> admin <*> <*> <*> <*> <*> GET <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	15
6595	START logs for container patch of pod <*>	1
6596	level info msg patching webhook configurations <*> mutating false validating true failurePolicy Fail source <*> <*> time <*> <*> <*>	1
6597	<*> ValidatingWebhookConfiguration is deprecated in <*> unavailable in <*> use <*> ValidatingWebhookConfiguration	2
6598	level info msg Patched hook s source <*> <*> time <*> <*> <*>	1
6599	END logs for container patch of pod <*>	1
6600	START logs for container echoserver of pod <*>	1
6601	Generating self-signed cert	1
6602	Generating a <*> bit RSA private key	1
6603	......+++	1
6604	.....................................+++	1
6605	writing new private key to <*>	1
6606	Starting nginx	1
6607	END logs for container echoserver of pod <*>	1
6608	successfully validated configuration accepting ingress <*>	5
6609	Service willitconnect/willitconnect does not have any active Endpoint.	39
6610	<*> <*> <*> <*> error <*> <*> connect failed <*> Operation timed out while connecting to upstream client <*> server <*> request GET <*> <*> upstream http <*> <*> host <*>	3
6611	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> GET <*> <*> <*> 0 <*> <*> <*> <*> <*> <*> <*> <*> <*> 0 0 <*> <*> <*> <*> <*> <*> <*>	3
6612	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> GET <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> 0 0 0 <*> <*> <*> <*> <*> <*> <*> <*> <*>	1
6613	secret was updated and it is used in ingress annotations. Parsing secret <*>	2
6614	<*> <*> <*> <*> error <*> <*> upstream timed out <*> Operation timed out while connecting to upstream client <*> server <*> request POST <*> <*> upstream http <*> <*> host <*>	1
6615	<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> POST <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> 0 <*> <*> <*> <*> <*> <*> <*> <*>	1
6616	Rolling out Control Plane machines cluster <*> kubeadmControlPlane <*> namespace <*> needRollout <*>	1
6617	Scaling down control plane cluster <*> kubeadmControlPlane <*> namespace <*> Desired <*> Existing 4	1
6618	Waiting for machines to be deleted cluster <*> kubeadmControlPlane <*> namespace <*> Machines <*>	1
6619	Failed Request POST <*> error An Unknown error occurred. context deadline exceeded	2
6620	retrying <*> Request POST <*> Failed Request POST <*> error An Unknown error occurred. context deadline exceeded	4
6621	Failed to acquire auth token for service ally. Code UnknownError Msg An Unknown error occurred. context deadline exceeded Ref Details <nil> cluster <*>	1
6622	Failed to get auth token for service ally. An Unknown error occurred. context deadline exceeded cluster <*>	1
6623	Initializing Nats connection with url tls <*> <*> <*> cluster <*>	1
6624	Found cached vsphere machines resource version <*> in machines data cluster <*>	1
6625	Found cached resource version <*> of cluster in store cluster <*>	1
6626	Found cached resource version <*> in machines data cluster <*>	1
6627	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	10
6628	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchWorkerNode message provision worker nodes type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	2
6629	No capi machine s found in cache for node name <*> cluster <*>	78
6630	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	10
6631	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Reconciliation on ImageCustomization Done Successfully reason ReconciliationDone status True type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes addition done reason LaunchControlPlaneNode status True type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message all control plane nodes are updated reason NodesRunning status True type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message provision worker nodes reason LaunchWorkerNode status False type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message vault ready. dex ready. reason AddOnDeployed status True type AddOnDeploymentDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Worker nodes deleted reason NodeDeleted status True type WorkerNodeDeletionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes deletion done reason DeleteControlPlaneNode status True type ControlPlaneNodeDeletionDone conditions for spectro cluster cluster <*>	6
6632	Updated host <*> name istio-ingressgateway ports port <*> protocol TCP port <*> protocol TCP host <*> name istio-ingressgateway-healthcheck ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name alertmanager-operated ports port <*> protocol TCP host <*> name grafana-monitoring ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name thanos-querier ports port <*> protocol TCP host <*> name thanos-querier ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name piris-tools ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name willittrace-all ports port <*> protocol TCP host <*> name willitconnect ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP services for spectro cluster cluster <*>	2
6633	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a4 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6634	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f1 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6635	Failed to post manifestCode Request Entity Too Large Msg <*> Request Entity Too Large Ref Details <html> r n<head><title>413 Request Entity Too Large</title></head> r n<body> r <*> Request Entity Too <*> r n<hr><center>nginx</center> r n</body> r <*> r n cluster <*>	283
6636	BACKUP Failed to update hubble with manifest Code Request Entity Too Large Details <html> r n<head><title>413 Request Entity Too Large</title></head> r n<body> r <*> Request Entity Too <*> r n<hr><center>nginx</center> r n</body> r <*> r n Message <*> Request Entity Too Large Ref cluster <*>	283
6637	Creating VsphereMachine <*> and instance state Running in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	2
6638	Created VsphereMachine <*> and instance state Running in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	2
6639	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> c3 ea networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6640	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a3 ae networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6641	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0a networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6642	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6e <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6643	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6644	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6645	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6e <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6646	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0a networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6647	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a8 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6648	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a3 ae networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6649	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> c3 ea networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6650	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a8 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6651	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6652	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6653	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f1 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6654	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a4 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6655	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0f networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6656	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0f networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6657	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	36
6658	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status Running cluster <*>	58
6659	the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> the server is currently unable to handle the request get <*> <*> cluster <*>	4
6660	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a8 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	4
6661	SYNC Deleting machine <*> in machine pool <*> with uid <*> cluster <*>	2
6662	Deleted VsphereMachine <*> in machinePool <*> cluster <*>	10
6663	SYNC Deleted machine <*> in machine pool <*> with uid <*> cluster <*>	2
6664	STORE Removing cloud machine with uid <*> and capi machine name <*> with status Running in machine pool <*>	2
6665	Updating VsphereMachine <*> and instance state Deleting in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	76
6666	Updated VsphereMachine <*> with uid <*> and instance state Deleting in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	76
6667	STORE Adding cloud machine with uid <*> and capi machine name <*> with status Deleting in machine pool <*>	76
6668	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchWorkerNode message provision worker nodes type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type WorkerNodeDeletionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteWorkerNode message Deleting worker nodes type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	6
6669	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Reconciliation on ImageCustomization Done Successfully reason ReconciliationDone status True type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes addition done reason LaunchControlPlaneNode status True type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message all control plane nodes are updated reason NodesRunning status True type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message provision worker nodes reason LaunchWorkerNode status False type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message vault ready. dex ready. reason AddOnDeployed status True type AddOnDeploymentDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Deleting worker nodes reason DeleteWorkerNode status False type WorkerNodeDeletionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes deletion done reason DeleteControlPlaneNode status True type ControlPlaneNodeDeletionDone conditions for spectro cluster cluster <*>	6
6670	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a8 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6671	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a8 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6672	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a8 <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	3
6673	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a8 <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6674	EVENT <*> Resource vspheremachines Type DELETED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a8 <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6675	Deleting vsphere machine <*> cluster <*>	8
6676	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Deleting IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true Restores null cluster <*>	3
6677	Failed to get Node <*> . nodes <*> not found cluster <*>	29
6678	Failed to get node from machine <*> . nodes <*> not found cluster <*>	25
6679	Failed to process health for node from machine <*> nodes <*> not found cluster <*>	25
6680	STORE Removing cloud machine with uid <*> and capi machine name <*> with status Deleting in machine pool <*>	8
6681	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f <*> f <*> f <*> f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	8
6682	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f <*> f <*> f <*> f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	7
6683	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f <*> f <*> f <*> f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	9
6684	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	8
6685	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	8
6686	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	8
6687	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	23
6688	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	7
6689	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	23
6690	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	7
6691	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchWorkerNode message provision worker nodes type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	4
6692	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason PoweringOn type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason PoweringOn cluster <*>	8
6693	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason PoweringOn type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason PoweringOn cluster <*>	8
6694	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	8
6695	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready false conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	8
6696	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> fb <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	17
6697	Creating VsphereMachine <*> and instance state Provisioning in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	8
6698	Created VsphereMachine <*> and instance state Provisioning in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	8
6699	STORE Adding cloud machine with uid <*> and capi machine name <*> with status Provisioning in machine pool <*>	26
6700	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> fb <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6701	Updating VsphereMachine <*> and instance state Provisioning in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	18
6702	Updated VsphereMachine <*> with uid <*> and instance state Provisioning in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	18
6703	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0f networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	5
6704	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0f networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6705	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0f networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	3
6706	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0f networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6707	EVENT <*> Resource vspheremachines Type DELETED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0f networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6708	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Deleting IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true Restores null cluster <*>	2
6709	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true Restores null cluster <*>	1
6710	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchWorkerNode message updating worker nodes of existing machine deployment type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	12
6711	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Reconciliation on ImageCustomization Done Successfully reason ReconciliationDone status True type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes addition done reason LaunchControlPlaneNode status True type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message all control plane nodes are updated reason NodesRunning status True type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message updating worker nodes of existing machine deployment reason LaunchWorkerNode status False type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message vault ready. dex ready. reason AddOnDeployed status True type AddOnDeploymentDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Worker nodes deleted reason NodeDeleted status True type WorkerNodeDeletionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes deletion done reason DeleteControlPlaneNode status True type ControlPlaneNodeDeletionDone conditions for spectro cluster cluster <*>	12
6712	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	7
6713	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready false conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6714	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6715	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0a networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	5
6716	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Reconciliation on ImageCustomization Done Successfully reason ReconciliationDone status True type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes addition done reason LaunchControlPlaneNode status True type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message all control plane nodes are updated reason NodesRunning status True type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message updating worker nodes of existing machine deployment reason LaunchWorkerNode status False type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message vault ready. dex ready. reason AddOnDeployed status True type AddOnDeploymentDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Deleting worker nodes reason DeleteWorkerNode status False type WorkerNodeDeletionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes deletion done reason DeleteControlPlaneNode status True type ControlPlaneNodeDeletionDone conditions for spectro cluster cluster <*>	16
6717	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchWorkerNode message updating worker nodes of existing machine deployment type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type WorkerNodeDeletionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteWorkerNode message Deleting worker nodes type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	16
6718	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0a networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6719	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0a networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	3
6720	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0a networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6721	EVENT <*> Resource vspheremachines Type DELETED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> 0a networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6722	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Deleting IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true Restores null cluster <*>	3
6723	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
6724	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6725	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	4
6726	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	4
6727	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	12
6728	EVENT <*> Resource vspheremachines Type DELETED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	3
6729	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Deleting IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true Restores null cluster <*>	3
6730	Failed to get node summary <*> <*> not found cluster <*>	3
6731	<*> <*> not found cluster <*>	3
6732	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6e <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	5
6733	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6e <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	3
6734	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6e <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6735	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6e <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6736	EVENT <*> Resource vspheremachines Type DELETED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6e <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6737	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Deleting IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true Restores null cluster <*>	3
6738	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true Restores null cluster <*>	3
6739	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6740	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f6 networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	3
6741	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f6 networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6742	EVENT <*> Resource vspheremachines Type DELETED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> f6 networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6743	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Deleting IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true Restores null cluster <*>	4
6744	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> a8 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	6
6745	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> a8 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6746	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Deleting IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true Restores null cluster <*>	3
6747	Cached 4 logs as events cluster <*>	1
6748	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> ee <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6749	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> ee <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	6
6750	Pushing 6 cached event s to hubble cluster <*>	9
6751	Pushed >>> 6 event s cluster <*>	9
6752	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Failed to create spectro-ansible playbook failed to update cloudConfigStatus failed to check if ova is deployed unable to find virtual machine failed to get govmomi finder with datacenter Titan_CaaS_Prod2 reason Failure status False type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes addition done reason LaunchControlPlaneNode status True type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message all control plane nodes are updated reason NodesRunning status True type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message updating worker nodes of existing machine deployment reason LaunchWorkerNode status False type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message vault ready. dex ready. reason AddOnDeployed status True type AddOnDeploymentDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Worker nodes deleted reason NodeDeleted status True type WorkerNodeDeletionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes deletion done reason DeleteControlPlaneNode status True type ControlPlaneNodeDeletionDone conditions for spectro cluster cluster <*>	2
6753	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason Failure message Failed to create spectro-ansible playbook failed to update cloudConfigStatus failed to check if ova is deployed unable to find virtual machine failed to get govmomi finder with datacenter Titan_CaaS_Prod2 type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchWorkerNode message updating worker nodes of existing machine deployment type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	2
6754	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	3
6755	Failed to get capi machine. <*> <*> not found cluster <*>	3
6756	Deleting VsphereMachine with uid <*> in Hubble for cloudConfig <*> and machine pool <*> using cached cloud machine uid cluster <*>	1
6757	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Deleting IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint true CollectMetrics true Restores null cluster <*>	3
6758	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Cloning type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Cloning cluster <*>	1
6759	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	1
6760	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Cloning type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Cloning cluster <*>	1
6761	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Cloning type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Cloning cluster <*>	8
6762	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 0e d6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	9
6763	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 0e d6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6764	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> fb <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6765	EVENT <*> Resource machines Event Type ADDED Name <*> InfraType VSphereMachine InfraTypeName <*> status Deleting cluster <*>	1
6766	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6767	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> ee <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6768	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 0e d6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6769	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> a8 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6770	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 0e d6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6771	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> ee <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6772	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> fb <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	2
6773	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> a8 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	1
6774	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation 4 creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Titan_CaaS_Prod2 folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	1
6775	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchWorkerNode message updating worker nodes of existing machine deployment type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type WorkerNodeDeletionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteWorkerNode message Deleting worker nodes type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	2
6776	Draining node cluster <*> machine <*> namespace <*> node <*>	90
6777	evicting pod <*>	51
6778	Too many replicas machineset <*> namespace <*> deleting <*> need <*>	108
6779	Found delete policy machineset <*> namespace <*> <*> Random	108
6780	Deleted machine machineset <*> namespace <*> machine <*>	107
6781	Evicted pod from Node cluster <*> machine <*> namespace <*> node <*> pod <*>	6
6782	Drain successful cluster <*> machine <*> namespace <*> node <*> null	14
6783	Node volumes all detached cluster <*> machine <*> namespace <*> node <*>	82
6784	Deleting node cluster <*> machine <*> namespace <*> node <*>	1
6785	Target has failed health check marking for remediation message reason NodeNotFound target <*>	439
6786	Unable to delete Machine error <*> <*> not found machineset <*> namespace <*> machine <*>	1
6787	Unable to retrieve Node status error error retrieving node <*> for machine <*> Node <*> not found machineset <*> namespace <*>	69
6788	Failed to reconcile MachineSet error failed to sync MachineSet replicas <*> <*> not found machineset <*> namespace <*>	1
6789	Reconciler error error failed to sync MachineSet replicas <*> <*> not found controller machineset name <*> namespace <*>	1
6790	Failed to reconcile MachineHealthCheck error failed to patch unhealthy machine status for machine <*> <*> <*> not found <*> <*> not found cluster <*>	1
6791	Reconciler error error failed to patch unhealthy machine status for machine <*> <*> <*> not found <*> <*> not found controller machinehealthcheck name <*> namespace <*>	1
6792	Too few replicas machineset <*> namespace <*> creating <*> need <*>	1
6793	Creating machine <*> of <*> <*> <*> <*> currentMachineCount <*> machineset <*> namespace <*>	1
6794	Created machine <*> of <*> with name <*> machineset <*> namespace <*>	1
6795	error when evicting pod <*> will retry after <*> Cannot evict pod as it would violate the pod s disruption budget.	35
6796	Drain failed error error when evicting pod <*> global timeout reached <*> error when waiting for pod <*> terminating global timeout reached <*> cluster <*> machine <*> namespace <*> node <*>	1
6797	Reconciler error error requeue in <*> controller machine name <*> namespace <*>	8
6798	Drain failed error error when waiting for pod <*> terminating global timeout reached <*> error when evicting pod <*> global timeout reached <*> cluster <*> machine <*> namespace <*> node <*>	1
6799	Drain failed error error when evicting pod <*> global timeout reached <*> cluster <*> machine <*> namespace <*> node <*>	6
6800	Could not find node from noderef it may have already been deleted error nodes <*> not found cluster <*> machine <*> namespace <*> node <*>	136
6801	atop not ready for reconcile worker nodes addition not complete. Skipping atop Namespace <*> Name <*>	517
6802	atop not ready for reconcile worker nodes addition not complete. Skipping atop Namespace <*> Name vault	87
6803	atop not ready for reconcile worker nodes addition not complete. Skipping atop Namespace <*> Name dex	87
6804	downloading pack spectrocluster Namespace <*> Name <*> pack ubuntu-vsphere	1
6805	downloading pack spectrocluster Namespace <*> Name <*> pack kubernetes	1
6806	spec patch success spectrocluster Namespace <*> Name <*> <*> Pack name <*>	1
6807	downloading pack spectrocluster Namespace <*> Name <*> pack vault	1
6808	spec patch success spectrocluster Namespace <*> Name <*> <*> Pack name vault	1
6809	pack downloaded spectrocluster Namespace <*> Name <*> <*> vault	1
6810	downloading pack spectrocluster Namespace <*> Name <*> pack dex	1
6811	spec patch success spectrocluster Namespace <*> Name <*> <*> Pack name dex	1
6812	pack downloaded spectrocluster Namespace <*> Name <*> <*> dex	1
6813	machineDeployment replicas not reach target <*> 4 status.AvailableReplicas 4 status.Replicas <*> <*> <*>	81
6814	machine deployment replicas yet to reach target count md <*> required replicas 4 updated replicas <*>	91
6815	no <*> present migration not required spectrocluster Namespace <*> Name <*>	1
6816	machineDeployment replicas not reach target <*> 4 status.AvailableReplicas <*> status.Replicas <*> <*> <*>	22
6817	machine deployment replicas yet to reach target count md <*> required replicas 4 updated replicas 4	7
6818	Certification renew timestamp changed current desired <*> <*> <*> <*> <*> UTC	2
6819	machine template create success spectrocluster Namespace <*> Name <*> name <*>	2
6820	kubeadmconfig template create success spectrocluster Namespace <*> Name <*> name <*>	2
6821	machine deployment update success spectrocluster Namespace <*> Name <*> name <*>	2
6822	update machinedeployment done cluster <*> md <*> pool <*>	2
6823	failed to get node error Node <*> not found spectrocluster Namespace <*> Name <*> node name <*>	58
6824	Reconciler error error unable to reconcile update strategy unable to update machinedeployment strategy Timeout request did not complete within requested timeout <*> controller spectrocluster name <*> namespace <*>	2
6825	Reconciler error error failed to convert to cloudcluster get tag urn vmomi InventoryServiceTag <*> GLOBAL Get https <*> urn vmomi InventoryServiceTag <*> GLOBAL dial tcp lookup <*> on <*> <*> read udp <*> <*> <*> <*> i/o timeout controller spectrocluster name <*> namespace <*>	1
6826	Reconciler error error failed to convert to cloudcluster list categories Get https <*> dial tcp i/o timeout controller spectrocluster name <*> namespace <*>	2
6827	Reconciler error error failed to get kubeadmconfig for worker failed to get vsphere cloud config file get tag urn vmomi InventoryServiceTag <*> GLOBAL Get https <*> urn vmomi InventoryServiceTag <*> GLOBAL dial tcp i/o timeout controller spectrocluster name <*> namespace <*>	1
6828	Reconciler error error failed to convert to cloudcluster list categories Get https <*> dial tcp lookup <*> on <*> <*> read udp <*> <*> <*> <*> i/o timeout controller spectrocluster name <*> namespace <*>	1
6829	No customization needed same base image exists in vcenter spectrocluster <*> imageId http <*> <*>	64
6830	Condition spectrocluster <*> Condition type ImageCustomizationDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason Failure message Failed to create spectro-ansible playbook failed to update cloudConfigStatus failed to check if ova is deployed unable to find virtual machine failed to get govmomi finder with datacenter Titan_CaaS_Prod2	2
6831	Reconciler error error Failed to create image on cloud Failed to create spectro-ansible playbook failed to update cloudConfigStatus failed to check if ova is deployed unable to find virtual machine failed to get govmomi finder with datacenter Titan_CaaS_Prod2 controller spectrocluster name <*> namespace <*>	2
6832	<*> <*> <*> <*> http TLS handshake error from <*> <*> remote error tls bad certificate	514
6833	Starting EventSource controller ippool source Type metadata creationTimestamp null spec namePrefix status	1
6834	Starting EventSource controller ippool source Type metadata creationTimestamp null spec pool status	1
6835	Starting Controller controller ippool	1
6836	Starting workers controller ippool worker count <*>	1
6837	Deleting Claim metal3-ippool Namespace <*> Name <*> IPClaim <*>	10
6838	Deleted Claim metal3-ippool Namespace <*> Name <*> IPClaim <*>	10
6839	failed to Patch IPClaim metal3-ippool Namespace <*> Name <*>	10
6840	Getting address metal3-ippool Namespace <*> Name <*> Claim <*>	23
6841	Address allocated metal3-ippool Namespace <*> Name <*> Claim <*> address <*>	10
6842	Reconciler error error Failed to create the missing data Exhausted IP Pools controller ippool name <*> namespace <*>	13
6843	unable to fully collect metrics unable to fully scrape metrics from source kubelet_summary <*> unable to fetch metrics from Kubelet <*> <*> Get https <*> <*> true read tcp <*> <*> <*> read connection reset by peer	2
6844	unable to fetch node metrics for node <*> no metrics known for node	3
6845	unable to fetch node metrics for node <*> no metrics known for node <*>	3
6846	duplicate pod <*> received	1
6847	Watching objects only in namespace for reconciliation namespace <*>	1
6848	Starting EventSource controller vspherevm source Type metadata creationTimestamp null spec template network devices null status	1
6849	Starting EventSource controller haproxyloadbalancer source Type metadata creationTimestamp null spec template network devices null status	1
6850	Starting EventSource controller vspherevm source	1
6851	Starting EventSource controller vspheremachine source Type metadata creationTimestamp null spec template network devices null status	1
6852	Starting EventSource controller vspherevm source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	1
6853	Starting EventSource controller haproxyloadbalancer source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	1
6854	Starting EventSource controller vspheremachine source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	1
6855	Starting EventSource controller vspherecluster source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	1
6856	Starting Controller controller vspherevm	1
6857	Starting EventSource controller vspheremachine source	1
6858	Starting EventSource controller vspherecluster source Type metadata creationTimestamp null spec template network devices null status ready false	1
6859	Starting EventSource controller haproxyloadbalancer source	1
6860	Starting EventSource controller vspheremachine source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	1
6861	Starting EventSource controller vspherecluster source Type metadata creationTimestamp null spec virtualMachineConfiguration template network devices null status	1
6862	Starting EventSource controller vspherecluster source	1
6863	Starting workers controller vspherevm worker count <*>	1
6864	Starting EventSource controller haproxyloadbalancer source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	1
6865	Handling deleted VSphereMachine	343
6866	Waiting for VSphereVM to be deleted	342
6867	resource is patched local-resource-version <*> remote-resource-version <*>	11
6868	Handling deleted VSphereVM	42
6869	wait for VM to be powered off	2
6870	enqueuing reconcile request on task completion <*> <*> task-entity-name <*> task-name <*> task-ref Type Task Value <*>	2
6871	vm state is not reconciled <*> pending <*> notfound	7
6872	task found description-id <*> state running	3
6873	task is still running description-id <*>	3
6874	triggering GenericEvent reason task <*> <*> task-entity-name <*> task-name <*> task-ref Type Task Value <*> task-state success	2
6875	task found description-id <*> state success	3
6876	task is a success description-id <*>	3
6877	destroying vm	2
6878	wait for VM to be destroyed	2
6879	enqueuing reconcile request on task completion <*> VirtualMachine.destroy task-entity-name <*> task-name Destroy_Task task-ref Type Task Value <*>	2
6880	resource is not patched local-resource-version <*> remote-resource-version <*>	3
6881	triggering GenericEvent reason task <*> VirtualMachine.destroy task-entity-name <*> task-name Destroy_Task task-ref Type Task Value <*> task-state success	2
6882	task found description-id VirtualMachine.destroy state success	2
6883	task is a success description-id VirtualMachine.destroy	2
6884	vm not found by bios uuid biosuuid <*>	35
6885	patch failed error <*> <*> not found vm <*> Kind VSphereVM <*>	1
6886	Reconciler error error <*> <*> not found controller vspherevm name <*> namespace <*>	1
6887	VSphereVM not found won t reconcile key Namespace <*> Name <*>	2
6888	VSphereMachine not found won t reconcile key Namespace <*> Name <*>	5
6889	Waiting for Machine Controller to set OwnerRef on VSphereMachine	4
6890	Waiting for bootstrap data to be available	3
6891	status.ready not found vmGVK <*> Kind vmName <*> vmNamespace <*>	1
6892	waiting for ready state	19
6893	status.ready not found vmGVK <*> Kind VSphereVM vmName <*> vmNamespace <*>	18
6894	using inventory path to find vm path <*>	1
6895	starting clone process	1
6896	applied bootstrap data to VM clone spec	1
6897	cloning machine cloneType fullClone name <*> namespace <*>	1
6898	enqueuing reconcile request on task completion <*> VirtualMachine.clone task-entity-name <*> task-name CloneVM_Task task-ref Type Task Value <*>	1
6899	VM state is not reconciled <*> pending <*> ready	5
6900	task found description-id VirtualMachine.clone state running	1
6901	task is still running description-id VirtualMachine.clone	1
6902	triggering GenericEvent reason task <*> VirtualMachine.clone task-entity-name <*> task-name CloneVM_Task task-ref Type Task Value <*> task-state success	1
6903	task found description-id VirtualMachine.clone state success	1
6904	task is a success description-id VirtualMachine.clone	1
6905	vm found by instance uuid vmref Type VirtualMachine Value <*>	3
6906	updating metadata	1
6907	wait for VM metadata to be updated	1
6908	enqueuing reconcile request on task completion <*> VirtualMachine.reconfigure task-entity-name <*> task-name ReconfigVM_Task task-ref Type Task Value <*>	1
6909	triggering GenericEvent reason task <*> VirtualMachine.reconfigure task-entity-name <*> task-name ReconfigVM_Task task-ref Type Task Value <*> task-state success	1
6910	task found description-id VirtualMachine.reconfigure state success	1
6911	task is a success description-id VirtualMachine.reconfigure	1
6912	powering on	1
6913	wait for VM to be powered on	1
6914	enqueuing reconcile request on task completion <*> <*> task-entity-name <*> task-name PowerOnVM_Task task-ref Type Task Value <*>	1
6915	triggering GenericEvent reason task <*> <*> task-entity-name <*> task-name PowerOnVM_Task task-ref Type Task Value <*> task-state success	1
6916	the VM is missing the requested IP address addressType static addressValue <*>	1
6917	discovered IP address addressType static addressValue <*>	1
6918	ignoring IP address reason failed to validate ip addr fe80 <*> <*> fe9c ed6 <*>	1
6919	the VM has all of the requested IP addresses	1
6920	triggering GenericEvent ipAddress <*> reason network	1
6921	updated provider ID <*> vsphere <*>	1
6922	task found description-id VirtualMachine.destroy state running	1
6923	task is still running description-id VirtualMachine.destroy	1
6924	patch failed error Timeout request did not complete within requested timeout <*> vm <*> Kind VSphereVM <*>	34
6925	Reconciler error error Timeout request did not complete within requested timeout <*> controller vspherevm name <*> namespace <*>	34
6926	Creating BootstrapData for the worker node kind Machine kubeadmconfig Namespace <*> Name <*> name <*> version <*>	14
6927	register IPAM metal3io	1
6928	static IP for VSphereMachine is <*> namespace <*> vsphereMachine <*>	4
6929	assigning IP address <*> to VSphereMachine namespace <*> vsphereMachine <*>	4
6930	failed to reconcile VSphereMachine IP error failed to patch VSphereMachine <*> Timeout request did not complete within requested timeout <*> vspheremachine Namespace <*> Name <*>	75
6931	Reconciler error error failed to patch VSphereMachine <*> Timeout request did not complete within requested timeout <*> controller vspheremachine name <*> namespace <*>	75
6932	starting controller <*> <*> version <*>	1
6933	configured acme <*> nameservers nameservers <*> <*>	1
6934	enabled controllers certificaterequests-approver <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> challenges clusterissuers <*> issuers orders	1
6935	starting leader election	1
6936	listening for connections on address IP Port <*> Zone	1
6937	starting controller controller <*>	13
6938	starting controller controller clusterissuers	1
6939	starting controller controller challenges	1
6940	not starting controller as it s disabled controller <*>	1
6941	starting controller controller orders	1
6942	starting controller controller issuers	1
6943	starting controller controller certificaterequests-approver	1
6944	<*> Ingress is deprecated in <*> unavailable in <*> use <*> Ingress	14
6945	starting version <*> revision <*>	1
6946	Normal message <*> became leader object kind Lease namespace <*> name <*> uid <*> apiVersion <*> resourceVersion <*> reason LeaderElection	1
6947	Starting EventSource source	20
6948	Starting Controller	8
6949	Starting workers worker count <*>	8
6950	updated object resource_kind MutatingWebhookConfiguration resource_name <*> resource_namespace resource_version <*>	5
6951	updated object resource_kind ValidatingWebhookConfiguration resource_name <*> resource_namespace resource_version <*>	7
6952	updated object resource_kind CustomResourceDefinition resource_name <*> resource_namespace resource_version <*>	24
