0	Cluster Name <*>	2130
1	<*>	4264
2	Pod Name <*>	710
3	Namespace <*>	1065
4	Node Name <*>	1420
5	Pod Labels component <*> tier control-plane	150
6	Cluster Uid <*>	2485
7	Tenant Uid <*>	2840
8	Project Uid <*>	3195
9	Cloud Type vsphere	3550
10	Cluster Env cleanup	440
11	Time <*> <*> <*> <*> <*> UTC m <*>	3905
12	...........................................	13240
13	Container Name <*>	3112
14	Image Id <*> <*>	4750
15		22635
16	Pod Events	1871
17	Pod Labels k8s-app <*> <*> <*>	60
18	Watch channel closed by remote <*> recreate watcher ListRoot <*>	185745
19	Terminating main client watcher loop	495
20	Main client watcher loop	496
21	Container Name coredns	88
22	Pod Labels <*> <*> k8s-app <*> <*> <*>	400
23	Pod Labels <*> <*> <*> <*> k8s-app <*>	55
24	Pod Labels k8s-app <*> <*> <*> <*> <*>	80
25	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*>	346247
26	Using autodetected IPv4 address on interface eth0 <*>	387398
27	Pod Labels component etcd tier control-plane	55
28	Container Name etcd	121
29	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/api/etcdhttp <*> OK status code <*>	411719
30	<*> <*> <*> <*> <*> <*> <*> I | etcdserver start to snapshot applied <*> lastsnap <*>	5775
31	<*> <*> <*> <*> <*> <*> <*> I | etcdserver saved snapshot at index <*>	5775
32	<*> <*> <*> <*> <*> <*> <*> I | etcdserver compacted raft log at <*>	5775
33	<*> <*> <*> <*> <*> <*> <*> I | pkg/fileutil purged file <*> successfully	6556
34	<*> <*> <*> <*> <*> <*> <*> I | mvcc store.index compact <*>	13948
35	<*> <*> <*> <*> <*> <*> <*> I | mvcc finished scheduled compaction at <*> took <*>	13948
36	Discovered VM using normal UUID format	3723
37	<*> <*> <*> <*> <*> <*> <*> W | rafthttp the clock difference against peer <*> is too high <*> > <*>	46332
38	parsed scheme <*>	76082
39	ccResolverWrapper sending update to cc https <*> <*> <nil> 0 <nil> <nil> <nil>	76079
40	ClientConn switching balancer to pick_first	80906
41	Error proxying data from backend to client tls use of closed connection	7141
42	Pod Labels app <*> <*> <*> <*> <*> role <*>	5
43	Throttling request took <*> request GET https <*> <*> <*>	40503
44	Error while processing Node <*> failed to allocate cidr from cluster cidr at idx 0 CIDR allocation failed there are no remaining CIDRs left to allocate in the accepted range	2574
45	Event occurred object <*> kind Node apiVersion <*> type Normal reason CIDRNotAvailable message Node <*> status is now CIDRNotAvailable	2574
46	Pod Labels role <*> app <*> <*> <*> <*> <*>	5
47	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*>	14960
48	Auditing failed of request encoding failed <*> Kind DeleteOptions is unstructured and is not suitable for converting to <*>	2640
49	Watch error received from Upstream ListRoot <*> error too old resource version <*> <*>	2681
50	Full resync is required ListRoot <*>	3625
51	Pod Labels app <*> <*> <*> role <*>	5
52	forcing resync	1254
53	Watch close <*> <*> total 0 items received	3531
54	Connecting to unix <*>	1074048
55	Pod Labels <*> <*> <*> <*> role <*> app <*>	5
56	Pod Labels control-plane <*> <*> <*>	20
57	Pod Labels <*> <*> control-plane controller-manager	5
58	Pod Labels <*> infrastructure-vsphere control-plane controller-manager <*> <*>	15
59	Pod Labels app spectro component cluster-management-agent log-regex logrus-text module ally <*> <*> <*> proxy	10
60	Pod Labels control-plane controller-manager <*> <*> <*> <*>	5
61	Pod Labels <*> cluster-api control-plane controller-manager <*> <*>	20
62	Pod Labels <*> <*> <*> <*> <*> infrastructure-metal3 control-plane controller-manager	10
63	Pod Labels <*> <*> broadcastjob-name <*> <*> proxy <*> host <*> skip	90
64	Pod Labels <*> <*> <*> bootstrap-kubeadm control-plane controller-manager	15
65	Pod Labels <*> skip <*> <*> broadcastjob-name <*> <*> proxy <*> host	50
66	Container Name cluster-management-agent	44
67	Pod Labels control-plane controller-manager <*> <*> <*> proxy	10
68	Container Name manager	330
69	Container Name node-agent	539
70	Cached <*> logs as events cluster <*>	5412
71	Pushing <*> cached event s to hubble cluster <*>	3993
72	Starting node agent controller	486
73	Pushed >>> <*> event s cluster <*>	3993
74	Found <*> spectro node tasks to reconcile	487
75	upgrade agent No change in version is required as current version and newVersion is <*> same cluster <*>	990
76	Reconciling <*> spectro node task	488
77	<*> <*> <*> register aws provider <*>	22
78	Running cmd exec task <*>	484
79	<*> <*> <*> register azure provider <*>	22
80	Creating <*> file	557
81	Executing command <*> +x print-logs.sh	484
82	<*> <*> <*> register maas provider <*>	22
83	Executing command <*> print-logs.sh	484
84	>>>>>>> Watching SpectroCluster CRD in <*> namespace cluster <*>	242
85	<*> <*> <*> register vsphere provider	22
86	<*> <*> <*> register gcp provider <*>	22
87	<*> <*> <*> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~	1133
88	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus conditions type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed cluster <*>	286
89	Skipping to post <*> conditions to hubble as there is no difference in cached conditions cluster <*>	484
90	<*> <*> <*> register generic provider	22
91	<*> <*> <*> <*>	3168
92	metrics server is starting to listen addr <*> <*>	103
93	register field index	55
94	<*> <*> <*> register openstack provider	22
95	new clientset registry	55
96	watch in a single namespace namespace <*>	66
97	ExecSync for <*> with command <*> <*> <*> and timeout <*> s	286905
98	setup webhook	55
99	Exec process <*> exits with exit code 0 and error <nil>	326742
100	resync period every <*>	66
101	Finish piping stdout of container exec <*>	326645
102	registering webhook path <*>	1028
103	ExecSync for <*> returns with exit code 0	326884
104	Finish piping stderr of container exec <*>	326592
105	metrics server is starting to listen addr <*>	85
106	Registered webhook handler <*>	770
107	Portforward for <*> port	4180
108	starting manager	110
109	Portforward for <*> returns URL http <*> <*>	4180
110	attempting to acquire leader lease <*>	306
111	Executing port forwarding command <*> <*> TCP4 localhost <*> in network namespace host	4180
112	starting palette metrics server at <*>	33
113	starting metrics server path <*>	181
114	successfully acquired lease <*>	244
115	Starting EventSource controller spectrocluster source Type metadata creationTimestamp null spec clusterProfileTemplate clusterConfig machineManagementConfig machineHealthConfig status	55
116	Applying rbac rules cluster <*>	1066
117	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error EOF stderr	2728
118	Starting EventSource controller pack source Type metadata creationTimestamp null spec packConfigSpec layer packRef layer server name tag status	33
119	<*> items n cluster <*>	1065
120	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error exit status <*> stderr <*> <*> <*> <*> socat <*> E write <*> <*> <*> Broken pipe n	418
121	Starting Controller controller pack	33
122	Starting workers controller pack worker count <*>	33
123	Starting EventSource controller spectrocluster source Type metadata creationTimestamp null spec clusterConfig region endpointAccess status	33
124	Starting EventSource controller spectrocluster source Type metadata creationTimestamp null spec cloudAccountRef null clusterConfig network networkName ipPool nameserver controlPlaneEndpoint placement network networkName ipPool nameserver machinePoolConfig null status nodeImage	33
125	Starting EventSource controller spectrocluster source Type metadata creationTimestamp null spec clusterConfig subscriptionId resourceGroup location sshKey controlPlaneSubnet workerSubnet status vhdImage images	33
126	Starting Controller controller spectrocluster	55
127	ExecSync for <*> with command <*> <*> and timeout <*> s	8008
128	Unable to retrieve pull secret <*> for <*> due to secret <*> not found. The image pull may not succeed.	23424
129	Starting workers controller spectrocluster worker count <*>	55
130	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus conditions type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed cluster <*>	220
131	Summarising 6 dataplane reconciliation loops over <*> avg <*> longest <*> <*>	4180
132	detecting env spectrocluster Namespace <*> Name <*>	40027
133	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady conditions for spectro cluster cluster <*>	220
134	Finish port forwarding for <*> port <*>	814
135	detect env done spectrocluster Namespace <*> Name <*> env cleanup	741
136	reconcile delete target spectrocluster Namespace <*> Name <*>	740
137	reconcileCAPI spectrocluster Namespace <*> Name <*>	11299
138	createCAPISecret spectrocluster Namespace <*> Name <*>	16094
139	deployment ready spectrocluster Namespace <*> Name <*> name <*>	80872
140	deployment ready spectrocluster Namespace <*> Name <*> name cert-manager	11308
141	>>>>>>> Watching event s in <*> namespace cluster <*>	231
142	initialize webhook	55
143	Starting <*>	253
144	reconcileCAPI done spectrocluster Namespace <*> Name <*>	11307
145	Waiting for caches to sync for <*>	241
146	pivot resource back to prepare cleanup spectrocluster Namespace <*> Name <*>	737
147	Starting reflector <*> 0s from <*> <*>	242
148	getForcePivotStatus	737
149	Listing and watching <*> from <*> <*>	19044
150	reconcileTargetKubeClient spectrocluster Namespace <*> Name <*>	737
151	fetching kubeconfig with key spectrocluster Namespace <*> Name <*> key Namespace <*> Name <*>	737
152	reconcileTargetKubeClient done spectrocluster Namespace <*> Name <*>	737
153	target namespace already marked for deletion	737
154	reconcilePivotBack spectrocluster Namespace <*> Name <*>	737
155	start to scale down controller deployments spectrocluster Namespace <*> Name <*>	737
156	scale down controller success spectrocluster Namespace <*> Name <*> <*> <*>	4419
157	Secret <*> added	55
158	ValidatingWebhookConfiguration <*> added	55
159	MutatingWebhookConfiguration <*> added	55
160	CustomResourceDefinition <*> added	110
161	scale down controller deployments done spectrocluster Namespace <*> Name <*>	734
162	caches populated	561
163	pivot move resource spectrocluster Namespace <*> Name <*>	733
164	Caches are synced for <*>	242
165	Reconciler error error failed to pivot move resource back failed to pause capi cluster error updating the pause status for <*> Kind <*> Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused controller spectrocluster name <*> namespace <*>	732
166	Started <*>	187
167	Starting to sync webhook certs and configurations	3828
168	cert is invalid or expiring regenerating a new one	33
169	Secret <*> updated	33
170	Cert writer update secret <*> resourceVersion from <*> to <*>	33
171	cert directory doesn t exist <*>	55
172	cloud setup already done skipping spectrocluster Namespace <*> Name <*>	11264
173	performed write of new data to ts data directoryts <*>	55
174	Find path <*> not in handlers map <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	3828
175	ValidatingWebhookConfiguration <*> updated	66
176	Finished to sync webhook certs and configurations	3828
177	MutatingWebhookConfiguration <*> update	66
178	wait webhook ready	55
179	Starting reflector <*> <*> from <*> <*>	481
180	>>>>>>>>> Watching Namespaces cluster <*>	154
181	Error proxying data from backend to client write tcp <*> <*> <*> write broken pipe	220
182	current pathstarget <*> <*> <*> cert.pem key.pem tls.crt tls.key	3773
183	new pathstarget <*> <*> <*> cert.pem key.pem tls.crt tls.key	3773
184	paths to removetarget <*>	3773
185	Error proxying data from backend to client write tcp <*> <*> <*> write connection reset by peer	22
186	>>>>>>> Watching <*> in <*> namespace cluster <*>	451
187	no update required for target <*>	3773
188	Error proxying data from client to backend tls use of closed connection	66
189	Normal message <*> became leader object kind ConfigMap namespace <*> name <*> uid <*> apiVersion <*> resourceVersion <*> reason LeaderElection	55
190	<*> <*> <*> <*> <*> <*> <*> I | wal segmented wal file <*> is created	869
191	starting webhook server	83
192	Updated current TLS certificate	78
193	serving webhook server host <*> port <*>	55
194	Starting certificate watcher	72
195	setup controllers	55
196	Starting AdvancedCronJob Controller	55
197	Starting EventSource controller <*> source Type metadata creationTimestamp null spec schedule template status	55
198	Starting EventSource controller <*> source Type metadata creationTimestamp null spec template metadata creationTimestamp null spec containers null completionPolicy failurePolicy status active 0 succeeded 0 failed 0 desired 0 phase	110
199	Starting EventSource controller <*> source Type metadata creationTimestamp null spec containers null status	55
200	Starting EventSource controller <*> source Type metadata creationTimestamp null spec status daemonEndpoints kubeletEndpoint Port 0 nodeInfo machineID systemUUID bootID kernelVersion osImage containerRuntimeVersion kubeletVersion kubeProxyVersion operatingSystem architecture	55
201	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result range_response_count <*> size <*> took too long <*> to execute	792
202	custom resource gate not found groupVersionKind <*> Kind StatefulSet in discovery the server could not find the requested resource	55
203	Starting EventSource controller <*> source Type metadata creationTimestamp null spec template metadata creationTimestamp null spec containers null status	55
204	Starting Controller controller <*>	110
205	Starting workers controller <*> worker count <*>	110
206	received request webhook <*> UID <*> kind group <*> version <*> kind BroadcastJob resource group <*> version <*> resource broadcastjobs	110
207	wrote response webhook <*> UID <*> allowed true result metadata code <*>	55
208	wrote response webhook <*> UID <*> allowed true result metadata reason allowed to be admitted code <*>	55
209	<*> has <*> nodes remaining to schedule pods	1988
210	Before broadcastjob reconcile <*> desired <*> active 0 failed 0	139
211	creating pod on node <*>	616
212	Controller <*> created pod <*>	616
213	Normal message Created pod <*> object kind BroadcastJob namespace <*> name <*> uid <*> apiVersion <*> resourceVersion <*> reason SuccessfulCreate	616
214	After broadcastjob reconcile <*> desired <*> active <*> failed 0	1749
215	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active <*> Succeeded 0 Failed 0 Desired <*> Phase running	759
216	Successfully Reconciled controller <*> name <*> namespace <*>	2204
217	Before broadcastjob reconcile <*> desired <*> active <*> failed 0	1694
218	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active <*> Succeeded <*> Failed 0 Desired <*> Phase running	880
219	job <*> is Complete Job completed <*> pods succeeded 0 pods failed	55
220	Job <*> is Complete will be deleted after <*> seconds	55
221	After broadcastjob reconcile <*> desired <*> active 0 failed 0	83
222	Updating job <*> status <*> Conditions <*> <*> Type Complete Status True LastProbeTime <*> Time time.Time wall <*> ext <*> loc time.Location <*> LastTransitionTime <*> Time time.Time wall <*> ext <*> loc time.Location <*> Reason Complete Message Job completed <*> pods succeeded 0 pods failed StartTime <*> <*> CompletionTime <*> <*> Active 0 Succeeded <*> Failed 0 Desired <*> Phase completed	55
223	Normal message Job <*> is completed <*> pods succeeded 0 pods failed object kind BroadcastJob namespace <*> name <*> uid <*> apiVersion <*> resourceVersion <*> reason JobComplete	55
224	<*> <*> <*> <*> Successfully assigned <*> to <*>	18
225	<*> <*> <*> <*> Pulling image <*> <*>	318
226	<*> <*> <*> <*> Successfully pulled image <*> <*> in <*>	271
227	<*> <*> <*> <*> Created container manager	18
228	<*> <*> <*> <*> Started container manager	15
229	<*> <*> <*> <*> Readiness probe failed Get http <*> <*> dial tcp <*> <*> connect connection refused	4
230	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result range_response_count 0 size <*> took too long <*> to execute	198
231	<*> <*> <*> <*> <*> <*> <*> W | etcdserver failed to send out heartbeat on time exceeded the <*> timeout for <*> to <*>	22
232	<*> <*> <*> <*> <*> <*> <*> W | etcdserver server is likely overloaded	22
233	Error proxying data from backend to client read tcp <*> <*> <*> read connection reset by peer	11
234	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error write tcp <*> <*> <*> use of closed network connection stderr	110
235	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error write tcp <*> <*> <*> write broken pipe stderr	88
236	Local endpoint updated id WorkloadEndpoint node <*> orchestrator k8s workload <*> name eth0	27709
237	id <orchestrator_id k8s workload_id <*> endpoint_id eth0 > endpoint <state active name <*> profile_ids <*> profile_ids <*> ipv4_nets <*> >	25795
238	Updating per-endpoint chains. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	27564
239	Queueing update of chain. chainName <*> ipVersion <*> table filter	126127
240	Updating endpoint routes. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	27558
241	Chain became referenced marking it for programming chainName <*>	50116
242	Skipping configuration of interface because it is oper down. ifaceName <*>	8657
243	Re-evaluated workload endpoint status adminUp true failed false known true operUp false status down workloadEndpointID proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	8855
244	Storing endpoint status update ipVersion <*> status down workload proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	8855
245	Trying to connect to netlink	8525
246	Endpoint down for at least one IP version id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0 ipVersion <*> status down	8855
247	Reporting combined status. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0 status down	8855
248	Linux interface addrs changed. addrs set.mapSet ifaceName <*>	13915
249	Linux interface state changed. ifIndex <*> ifaceName <*> state up	8536
250	&intdataplane.ifaceAddrsUpdate Name <*> Addrs set.mapSet	13024
251	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name <*> Addrs set.mapSet	13024
252	&intdataplane.ifaceUpdate Name <*> State up Index <*>	7931
253	Workload interface came up marking for reconfiguration. ifaceName <*>	8580
254	Workload interface state changed marking for status update. ifaceName <*>	8492
255	Applying <*> configuration to interface. ifaceName <*>	27391
256	Re-evaluated workload endpoint status adminUp true failed false known true operUp true status up workloadEndpointID proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	27191
257	Storing endpoint status update ipVersion <*> status up workload proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	27189
258	Endpoint up for at least one IP version id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0 ipVersion <*> status up	27187
259	Reporting combined status. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0 status up	27185
260	Netlink address update. addr fe80 ecee eeff feee eeee exists true ifIndex <*>	5665
261	Linux interface addrs changed. addrs set.mapSet fe80 ecee eeff feee eeee set.empty ifaceName <*>	5775
262	&intdataplane.ifaceAddrsUpdate Name <*> Addrs set.mapSet fe80 ecee eeff feee eeee set.empty	5126
263	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name <*> Addrs set.mapSet fe80 ecee eeff feee eeee set.empty	5126
264	Local endpoint deleted id WorkloadEndpoint node <*> orchestrator k8s workload <*> name eth0	10362
265	id <orchestrator_id k8s workload_id <*> endpoint_id eth0 >	10362
266	Workload removed deleting its chains. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10362
267	Queuing deletion of chain. chainName <*> ipVersion <*> table filter	47454
268	Workload removed deleting old state. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10362
269	Chain no longer referenced marking it for removal chainName <*>	47454
270	Re-evaluated workload endpoint status adminUp false failed false known false operUp false status workloadEndpointID proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10362
271	Storing endpoint status update ipVersion <*> status workload proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10362
272	Removing conntrack flows ip <*>	10450
273	Reporting endpoint removed. id proto.WorkloadEndpointID OrchestratorId k8s WorkloadId <*> EndpointId eth0	10317
274	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result range_response_count 0 size <*> took too long <*> to execute	44
275	<*> <*> <*> bird KIF Received address message for unknown interface <*>	1001
276	Linux interface state changed. ifIndex <*> ifaceName <*> state down	8228
277	&intdataplane.ifaceUpdate Name <*> State down Index <*>	7909
278	Netlink address update. addr fe80 ecee eeff feee eeee exists false ifIndex <*>	5412
279	Linux interface addrs changed. addrs <nil> ifaceName <*>	8239
280	&intdataplane.ifaceAddrsUpdate Name <*> Addrs set.Set nil	7909
281	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name <*> Addrs set.Set nil	7909
282	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*>	1947
283	Summarising 6 dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*>	220
284	id <name <*> > profile <inbound_rules <action allow rule_id RlLgQRgidk_vSbTC > outbound_rules <action allow rule_id <*> > >	11
285	Queueing update of chain. chainName <*> ipVersion <*> table mangle	9273
286	id <name <*> > profile <>	4290
287	id <name <*> >	8019
288	Queuing deletion of chain. chainName <*> ipVersion <*> table mangle	7975
289	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*>	1254
290	Upgrading palette as current version is <*> and new version is <*> cluster <*>	11
291	Successfully audited via rest Upgrading palette as current version is <*> and new version is <*> Normal cluster <*>	11
292	Pushing 4 cached event s to hubble cluster <*>	55
293	Pushed >>> 4 event s cluster <*>	55
294	Cached 6 logs as events cluster <*>	11
295	Event occurred object <*> kind Deployment apiVersion <*> type Normal reason <*> message Scaled up replica set <*> to <*>	1670
296	Event occurred object <*> kind ReplicaSet apiVersion <*> type Normal reason SuccessfulCreate message Created pod <*>	1826
297	Event occurred object <*> kind Deployment apiVersion <*> type Normal reason <*> message Scaled down replica set <*> to 0	44
298	Event occurred object <*> kind ReplicaSet apiVersion <*> type Normal reason SuccessfulDelete message Deleted pod <*>	44
299	<*> <*> <*> <*> <*> <*> <*> Handling the message <*>	44
300	NATS Received message with key <*> cluster <*>	44
301	Successfully audited Received message with key <*> nats Normal cluster <*>	44
302	Collecting logs on demand cluster <*>	44
303	Cluster Feature Log Fetcher Request noOfLines <*> duration <*> k8sRequest namespace <*> <*> nodeRequest nodeLog <*> <*> cluster <*>	22
304	Successfully audited Started processing log collection request at <*> <*> <*> <*> <*> UTC m <*> log Normal cluster <*>	44
305	Applying crony task controller by getting it from scar cluster <*>	22
306	Creating crony task controller deployment with version <*> cluster <*>	22
307	Fetching manifest of service crony and version <*> for action apply cluster <*>	22
308	Applying manifest with file name <*> cluster <*>	22
309	Applying on demand log fetch spectro node task cluster <*>	44
310	Fetching manifest from service crony and version <*> for action resources with file name <*> cluster <*>	132
311	Applying spectro node task <*> cluster <*>	55
312	Finding spectro node task <*> cluster <*>	55
313	spectro node task <*> is not found cluster <*>	33
314	Creating spectro node task <*> cluster <*>	33
315	Created spectro node task <*> cluster <*>	33
316	Applied spectro node task <*> cluster <*>	55
317	Applied on demand log fetch spectro node task cluster <*>	44
318	Checking for replica to be in running state for deployment <*> in iteration 0 cluster <*>	44
319	Waiting for pod to be in running state for deployment <*> cluster <*>	66
320	Checking for replica to be in running state for deployment <*> in iteration <*> cluster <*>	44
321	Checking for replica to be in running state for deployment <*> in iteration 4 cluster <*>	11
322	Checking for replica to be in running state for deployment <*> in iteration 6 cluster <*>	11
323	Deployment <*> is in running state with <*> replica cluster <*>	33
324	Applying on demand log fetch broadcast job cluster <*>	66
325	Deleting <*> broadcast job cluster <*>	66
326	Deleted <*> broadcast job cluster <*>	66
327	Checking for deletion of all log grep pods in iteration 0 cluster <*>	66
328	Old Log grep pods on all nodes have been deleted successfully in iteration 0 cluster <*>	55
329	Applying <*> broadcast job cluster <*>	66
330	Finding broadcast job <*> cluster <*>	396
331	broadcast job <*> is not found cluster <*>	66
332	Creating <*> broadcast job cluster <*>	66
333	Created <*> broadcast job cluster <*>	44
334	Applied <*> broadcast job cluster <*>	44
335	Applied on demand log fetch broadcast job cluster <*>	44
336	Checking for completed log grep pods in iteration 0 cluster <*>	44
337	Found broadcast job <*> cluster <*>	330
338	Waiting for pod containing node logs to get completed... cluster <*>	275
339	Checking for completed log grep pods in iteration <*> cluster <*>	231
340	Considering pod <*> with phase Running cluster <*>	3465
341	Pod <*> doesn t have any label. Thus skipping to parse logs. cluster <*>	121
342	Considering pod <*> with phase Succeeded cluster <*>	561
343	error forwarding port <*> to pod <*> uid failed to execute portforward in network namespace host socat command returns error write tcp <*> <*> <*> write connection reset by peer stderr	22
344	topologymanager Topology Admit Handler	1397
345	operationExecutor.VerifyControllerAttachedVolume started for volume <*> UniqueName <*> pod <*> UID <*>	1177
346	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd <*> Started Kubernetes transient mount for <*>	66
347	RunPodsandbox for &PodSandboxMetadata Name <*> Uid <*> Namespace <*> Attempt 0	1027
348	Calico CNI found existing endpoint & WorkloadEndpoint <*> <*> <*> <*> <*> <*> 0 <*> <*> <*> <*> <*> UTC <nil> <nil> map control-plane <*> <*> <*> <*> <*> <*> k8s <*> default map k8s <*> <*> eth0 <*> <*> <*> <*> TCP <*> metrics TCP <*> health TCP <*> ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
349	Extracted identifiers for CmdAddK8s ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
350	Calico CNI IPAM request count IPv4 <*> IPv6 0 ContainerID <*> HandleID <*> Workload <*>	484
351	Auto assigning IP ContainerID <*> HandleID <*> Workload <*> assignArgs ipam.AutoAssignArgs Num4 <*> Num6 0 HandleID string <*> Attrs map string string namespace <*> node <*> pod <*> timestamp <*> <*> <*> <*> <*> UTC Hostname <*> IPv4Pools <*> IPv6Pools <*> MaxBlocksPerHost 0 HostReservedAttrIPv4s ipam.HostReservedAttr nil HostReservedAttrIPv6s ipam.HostReservedAttr nil	66
352	About to acquire host-wide IPAM lock. source ipam_plugin.go <*>	2167
353	Acquired host-wide IPAM lock. source ipam_plugin.go <*>	2167
354	Auto-assign <*> ipv4 0 ipv6 addrs for host <*>	517
355	Looking up existing affinities for host handle <*> host <*>	517
356	Looking up existing affinities for host host <*>	517
357	Trying affinity for <*> host <*>	484
358	Attempting to load block cidr <*> host <*>	517
359	Affinity is confirmed and block has been loaded cidr <*> host <*>	484
360	Attempting to assign <*> addresses from block block <*> handle <*> host <*>	517
361	Creating new handle <*>	517
362	Writing block in order to claim IPs block <*> handle <*> host <*>	517
363	Successfully claimed IPs <*> block <*> handle <*> host <*>	517
364	Auto-assigned <*> out of <*> IPv4s <*> handle <*> host <*>	517
365	Released host-wide IPAM lock. source ipam_plugin.go <*>	2167
366	Calico CNI IPAM assigned addresses IPv4 <*> IPv6 ContainerID <*> HandleID <*> Workload <*>	484
367	Populated endpoint ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string control-plane <*> <*> <*> <*> <*> <*> k8s <*> default Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC Ports <*> <*> Name <*> Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name metrics Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name health Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*>	66
368	Calico CNI using IPs <*> ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
369	Setting the host side veth name to <*> ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
370	Disabling IPv4 forwarding ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
371	<*> <*> <*> Oct <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_UP <*> link is not ready	22
372	<*> <*> <*> Oct <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_UP eth0 link is not ready	22
373	<*> <*> <*> Oct <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_CHANGE eth0 link becomes ready	22
374	<*> <*> <*> Oct <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_CHANGE <*> link becomes ready	22
375	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-udevd <*> link_config autonegotiation is unset or enabled the speed and duplex are not writable.	22
376	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-networkd <*> <*> Link UP	22
377	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-networkd <*> <*> Gained carrier	22
378	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-timesyncd <*> Network configuration changed trying to establish connection.	44
379	<*> <*> <*> Oct <*> <*> <*> <*> <*> <*> <*> WARNING Unknown index <*> <*> <*> interface list	22
380	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string control-plane <*> <*> <*> <*> <*> <*> k8s <*> default Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC a2 <*> <*> f4 <*> 3a Ports <*> <*> Name <*> Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name metrics Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name health Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*>	22
381	Wrote updated endpoint to datastore ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*>	66
382	starting signal loop namespace <*> path <*> pid <*>	3094
383	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-timesyncd <*> Synchronized to time server <*> <*> <*> .	44
384	RunPodSandbox for &PodSandboxMetadata Name <*> Uid <*> Namespace <*> Attempt 0 returns sandbox id <*>	1014
385	PullImage <*> <*>	1090
386	ImageUpdate event &ImageUpdate Name <*> <*> Labels map string string <*> managed XXX_unrecognized	2530
387	ImageUpdate event &ImageUpdate Name sha256 <*> Labels map string string <*> managed XXX_unrecognized	1034
388	PullImage <*> <*> returns image reference sha256 <*>	1067
389	CreateContainer within sandbox <*> for container &ContainerMetadata Name manager Attempt 0	66
390	CreateContainer within sandbox <*> for container &ContainerMetadata Name node-agent Attempt 0	924
391	CreateContainer within sandbox <*> for &ContainerMetadata Name node-agent Attempt 0 returns container id <*>	924
392	StartContainer for <*>	1738
393	StartContainer for <*> returns successfully	1749
394	CreateContainer within sandbox <*> for &ContainerMetadata Name manager Attempt 0 returns container id <*>	66
395	<*> <*> <*> Oct <*> <*> <*> <*> <*> systemd-networkd <*> <*> Gained IPv6LL	22
396	<*> <*> <*> tail can t open <*> No such file or directory	429
397	<*> <*> <*> tail no files	429
398	Failed to run command <*> print-logs.sh with output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~	451
399	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result range_response_count 0 size <*> took too long <*> to execute	539
400	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result range_response_count <*> size <*> took too long <*> to execute	9119
401	<*> <*> <*> <*> <*> <*> <*> W | etcdserver request header <ID <*> username <*> auth_revision <*> > txn <compare <target MOD key <*> mod_revision <*> > success <request_put <key <*> value_size <*> >> failure <>> with result size <*> took too long <*> to execute	11
402	<*> <*> <*> and error exit status <*>	451
403	Failed to run command <*> print-logs.sh . exit status <*>	451
404	Execution failed. Failed to execute command <*> print-logs.sh . exit status <*>	451
405	exit status 1Failed to run ansible task	451
406	Failed to execute task exit status 1Failed to run cmd exec task <*>	451
407	Reconciled successfully	453
408	<*> <*> <*> <*> Created container node-agent	205
409	<*> <*> <*> <*> Started container node-agent	164
410	<*> <*> <*> level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg fullSync is triggered TraceId <*>	209
411	<*> <*> <*> level info time <*> <*> <*> caller <*> <*> msg FullSync start TraceId <*>	209
412	<*> <*> <*> level warn time <*> <*> <*> caller <*> <*> msg could not find any volume which is present in both k8s and in CNS TraceId <*>	209
413	<*> <*> <*> level info time <*> <*> <*> caller <*> <*> msg FullSync fullSyncDeleteVolumes could not find any volume which is not present in k8s and needs to be checked for volume deletion. TraceId <*>	209
414	<*> <*> <*> level info time <*> <*> <*> caller <*> <*> msg FullSync end TraceId <*>	209
415	<*> <*> <*> level warn time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg CSI migration feature state is disabled TraceId <*>	176
416	Pod Labels tier control-plane component <*>	15
417	Cluster Env target	3465
418	Early log level set to info	88
419	Using NODENAME environment for node name <*>	88
420	Determined node name <*>	88
421	Starting node <*> with version <*>	44
422	Checking datastore connection	44
423	Generated self-signed cert in-memory	76
424	Datastore connection verified	44
425	<*> EndpointSlice is deprecated in <*> unavailable in <*> use <*> EndpointSlice	14731
426	Datastore is ready	44
427	Unable to get <*> in <*> Usually fixed by kubectl create rolebinding <*> <*> ROLEBINDING_NAME <*> <*> <*> YOUR_NS YOUR_SA	11
428	<*> <*> <*> Flag <*> has been deprecated see <*> instead.	22
429	Initialize BGP data	33
430	Error looking up in-cluster authentication configuration configmaps <*> is forbidden User system <*> cannot get resource configmaps in API group in the namespace <*>	11
431	Continuing without authentication configuration. This may treat all requests as anonymous.	15
432	Node IPv4 changed will check for conflicts	33
433	To require authentication configuration lookup to succeed set <*> false	16
434	Version <*>	217
435	No AS number configured on node resource using global value	44
436	Starting request-header <*>	55
437	Serving securely on <*> <*>	67
438	Successfully retrieved node IP <*>	17
439	Setting NetworkUnavailable to False	44
440	Detected node IP <*>	20
441	Starting <*> <*>	57
442	Starting <*> <*> <*> <*>	104
443	found <*> <*> in the kubeadm config map	44
444	Unknown proxy mode assuming iptables proxy	23
445	Starting RequestHeaderAuthRequestController	19
446	Waiting for caches to sync for <*> <*> <*> <*>	108
447	Pod Labels <*> <*> broadcastjob-name <*> log-regex klog <*> proxy	5
448	<*> <*> <*> WARNING Deprecated <*> capnslog flag is set use <*> zap flag instead	22
449	<*> running in <*> mode IPv4-primary	26
450	Pod Labels <*> proxy <*> <*> broadcastjob-name <*> log-regex klog	5
451	Pod Labels <*> <*> <*> <*> <*> <*>	5
452	found v6 in the kubeadm config map	44
453	Pod Labels log-regex klog <*> proxy <*> <*> broadcastjob-name <*>	15
454	Waiting for caches to sync for RequestHeaderAuthRequestController	22
455	Pod Labels <*> host <*> skip <*> <*> broadcastjob-name <*> <*> proxy	35
456	<*> <*> <*> <*> <*> <*> <*> I | etcdmain etcd Version <*>	11
457	Using iptables Proxier.	29
458	<*> is false through environment variable	44
459	Using node name <*>	44
460	<*> <*> <*> <*> <*> <*> <*> I | etcdmain Git SHA <*>	11
461	creating dualStackProxier for iptables.	32
462	Caches are synced for <*> <*> <*> <*>	83
463	<*> set to ClusterCIDR but no IPv6 cluster CIDR defined defaulting to <*> detect-local for IPv6	35
464	Releasing all IPs with handle <*>	3575
465	<*> <*> <*> <*> <*> <*> <*> I | etcdmain Go Version <*>	11
466	Pod Labels <*> proxy <*> host <*> skip <*> <*> broadcastjob-name <*>	25
467	<*> <*> <*> <*> <*> <*> <*> I | etcdmain Go <*> linux/amd64	11
468	Assign a new tunnel address type ipipTunnelAddress	33
469	Trace <*> Call conversion webhook custom-resource-definition <*> desired-api-version <*> object-count <*> UID <*> <*> <*> <*> <*> total time <*>	1878
470	<*> <*> <*> Trace <*> <*> <*> END	4114
471	Trace <*> List etcd3 key <*> resourceVersion resourceVersionMatch limit <*> continue <*> <*> <*> <*> total time <*>	1881
472	Release any old tunnel addresses IP type ipipTunnelAddress	33
473	Set sysctl <*> to <*>	85
474	<*> <*> <*> <*> <*> <*> <*> I | etcdmain setting maximum number of CPUs to <*> total number of available CPUs is <*>	11
475	Setting nf_conntrack_max to <*>	44
476	cacher unstructured.Unstructured unexpected ListAndWatch error failed to list <*> Kind Tenant conversion webhook for <*> Kind Tenant failed Post https <*> <*> <*> dial tcp <*> <*> connect connection refused reinitializing...	1609
477	Assign new tunnel address IP type ipipTunnelAddress	33
478	Setting conntrack hashsize to <*>	33
479	<*> <*> <*> <*> <*> <*> <*> I | embed peerTLS cert <*> key <*> <*> <*> <*> true crl-file	11
480	error retrieving resource lock <*> <*> <*> is forbidden User system <*> cannot get resource leases in API group <*> in the namespace <*>	11
481	Starting Orchestration Executor	13
482	Set sysctl net/netfilter/nf_conntrack_tcp_timeout_established to <*>	44
483	Caches are synced for RequestHeaderAuthRequestController	21
484	<*> <*> <*> <*> <*> <*> <*> I | embed name <*>	11
485	Pod Labels <*> <*> control-plane controller-manager <*> <*>	15
486	Starting cluster management agent...	14
487	<*> <*> <*> <*> <*> <*> <*> I | embed data dir <*>	11
488	Pod Labels control-plane controller-manager <*> <*>	15
489	Event occurred object <*> kind Lease apiVersion <*> type Normal reason LeaderElection message <*> became leader	22
490	Starting service config controller	43
491	Waited for <*> due to <*> throttling not priority and fairness request GET https <*> <*> <*>	22
492	Setting hubble ip to <*> and port to	15
493	<*> <*> <*> <*> <*> <*> <*> I | embed member dir <*>	11
494	Starting endpoint slice config controller	41
495	unable to get all supported resources from server unable to retrieve the complete list of server APIs <*> the server is currently unable to handle the request	11
496	Ran out of existing affine blocks for host host <*>	33
497	Looking for <*> config map in namespace <*>	16
498	<*> <*> <*> <*> <*> <*> <*> I | embed heartbeat <*>	11
499	Waiting for caches to sync for service config	42
500	No more affine blocks but need to claim more block <*> allocate another block host <*>	33
501	WARNING vsphere built-in cloud provider is now deprecated. The vSphere provider is deprecated and will be removed in a future release	33
502	Found cluster id as <*> cluster name as <*> tenant id as <*> project uid as <*> and is system false	17
503	<*> <*> <*> <*> <*> <*> <*> I | embed election <*>	11
504	Initializing hubble client with URI <*> cluster <*>	18
505	Looking for an unclaimed block host <*>	33
506	Waiting for caches to sync for endpoint slice config	40
507	create attach manifest files	14971
508	SecretName and/or SecretNamespace is not provided. VCP will use username and password from config file	11
509	One or more endpoints uses a profile that doesn t exist generating <*> profile. This can happen transiently when a Kubernetes namespace is deleted. profileID <*>	660
510	Initializing nats connection cluster <*>	19
511	<*> <*> <*> <*> <*> <*> <*> I | embed snapshot count <*>	11
512	Found free block <*>	33
513	<*> <*> <*> <*> <*> <*> <*> I | embed advertise client URLs https <*> <*>	11
514	Waiting for caches to sync for tokens	22
515	fetch process output object complete	13079
516	id <name <*> > profile <inbound_rules <action <*> rule_id <*> > outbound_rules <action <*> rule_id <*> > >	638
517	Successfully fetched Nats configuration <*> cluster <*>	20
518	Found unclaimed block host <*> subnet <*>	33
519	<*> <*> <*> <*> <*> <*> <*> I | etcdserver starting member <*> in cluster <*>	11
520	Successfully fetched Nats credentials <*> cluster <*>	21
521	Trying to create affinity in pending state host <*> subnet <*>	33
522	Started serviceaccount	22
523	Auditing failed of request encoding failed authentication.TokenRequest is not suitable for converting to <*> in scheme <*> <*>	3521
524	Caches are synced for service config	37
525	id <orchestrator_id k8s workload_id <*> endpoint_id eth0 > endpoint <state active name <*> profile_ids kns.brighteon profile_ids <*> ipv4_nets <*> >	1848
526	<*> <*> <*> <*> <*> <*> <*> INFO <*> switched to configuration voters	11
527	Initializing Nats connection with url tls <*> <*> <*> tls <*> <*> <*> tls <*> <*> <*> cluster <*>	11
528	Successfully created pending affinity for block host <*> subnet <*>	33
529	<*> is set but cloud provider does not support routes. Will not configure cloud provider routes.	11
530	Caches are synced for endpoint slice config	36
531	<*> <*> <*> <*> <*> <*> <*> INFO <*> became <*> at term 0	11
532	<*> <*> <*> <*> <*> <*> <*> http TLS handshake error from <*> <*> remote error tls bad certificate	53944
533	Initialized Nats connection.. cluster <*>	22
534	Skipping route	22
535	<*> <*> <*> <*> <*> <*> <*> INFO newRaft <*> peers term 0 commit 0 applied 0 lastindex 0 lastterm 0	11
536	<*> <*> <*> <*> <*> <*> <*> W | auth simple token is not cryptographically signed	11
537	<*> <*> <*> register IPAM metal3io	11
538	process status output complete	9350
539	The referenced block doesn t exist trying to create it cidr <*> host <*>	33
540	id <namespace default name <*> >	13288
541	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started HTTP pipelining with peer <*>	44
542	Starting service account controller	22
543	<*> <*> <*> <*> <*> <*> <*> no error handler specified with the subscriber. going with default error handler	11
544	reconciled manifest service status for pack pack permission-manager	891
545	<*> <*> <*> <*> <*> <*> <*> I | rafthttp starting peer <*>	33
546	Wrote affinity as pending cidr <*> host <*>	33
547	Waiting for caches to sync for service account	22
548	pack readiness status pack permission-manager status true	891
549	<*> <*> <*> <*> <*> <*> <*> Listening on <*>	11
550	reconcile charts atop Namespace <*> Name <*>	3751
551	Attempting to claim the block cidr <*> host <*>	33
552	ExecSync for <*> with command sh <*> <*> <*> and timeout 6 s	5610
553	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started streaming with peer <*> writer	66
554	Subscribed to msg channel <*> cluster <*>	22
555	Attempting to create a new block host <*> subnet <*>	33
556	ExecSync for <*> with command sh <*> <*> <*> and timeout <*> s	5610
557	Starting PV protection controller	22
558	Successfully created block	33
559	Waiting for caches to sync for PV protection	22
560	Started job	22
561	Confirming affinity host <*> subnet <*>	33
562	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started peer <*>	33
563	ExecSync for <*> with command sh <*> <*> bash <*> n# If the node is starting up wait for the cluster to be ready request params wait_for_status green&timeout <*> n# Once it has started only check that the node itself is responding nSTART_FILE <*> n n# Disable nss cache to avoid filling dentry cache when calling curl n# This is required with Elasticsearch Docker using nss < <*> nexport NSS_SDB_USE_CACHE no n nhttp n local path $ <*> n local args $ <*> n set <*> <*> <*> n n if $args ! then n set <*> $@ $args n fi n n if <*> $ ELASTIC_USERNAME && <*> $ ELASTIC_PASSWORD then n set <*> $@ <*> $ ELASTIC_USERNAME $ ELASTIC_PASSWORD n fi n n curl <*> <*> <*> $@ http <*> <*> path n n nif <*> $ START_FILE then n echo Elasticsearch is already running lets check the node is healthy n HTTP_CODE $ http <*> <*> % http_code n RC $? n if $ RC <*> 0 then n echo curl <*> <*> <*> <*> <*> <*> % http_code $ BASIC_AUTH http <*> <*> failed with RC $ RC n exit $ RC n fi n # ready if HTTP code <*> <*> is tolerable if ES version is <*> n if $ HTTP_CODE <*> then n exit 0 n elif $ HTTP_CODE <*> && <*> 6 then n exit 0 n else n echo curl <*> <*> <*> <*> <*> <*> % http_code $ BASIC_AUTH http <*> <*> failed with HTTP code $ HTTP_CODE n exit <*> n fi n nelse n echo Waiting for elasticsearch cluster to become ready request params wait_for_status green&timeout <*> n if http <*> green&timeout <*> <*> then n touch $ START_FILE n exit 0 n else n echo Cluster is not yet ready request params wait_for_status green&timeout <*> n exit <*> n fi nfi n and timeout <*> s	6028
564	Starting job controller	22
565	Successfully confirmed affinity host <*> subnet <*>	33
566	Block <*> has <*> free ips which is more than <*> ips required. host <*> subnet <*>	33
567	STARTUP Running start up task cluster <*>	19
568	Starting EventSource controller vspherecluster source Type metadata creationTimestamp null spec cloudProviderConfiguration global network disk workspace labels providerConfig controlPlaneEndpoint host port 0 status	11
569	starting manager version	47
570	Waiting for caches to sync for job	22
571	<*> <*> <*> <*> <*> <*> <*> I | rafthttp added peer <*>	33
572	STARTUP Syncing capi machine s with hubble cluster <*>	18
573	Starting EventSource controller haproxyloadbalancer source Type metadata creationTimestamp null spec virtualMachineConfiguration template network devices null status	11
574	Started replicaset	22
575	Starting EventSource controller vspheremachine source Type metadata creationTimestamp null spec template network devices null status ready false	11
576	<*> <*> <*> <*> <*> <*> <*> I | etcdserver starting server... version <*> cluster version to_be_decided	11
577	Initializing shutdown hooks... cluster <*>	17
578	Starting Controller controller vspherecluster	11
579	Starting replicaset controller	22
580	Error updating resource Key KubeControllersConfiguration default Name default Resource KubeControllersConfigurations Value <*> TypeMeta <*> Kind KubeControllersConfiguration APIVersion <*> ObjectMeta <*> Name default GenerateName Namespace SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string nil Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> LogSeverityScreen Info HealthChecks Enabled EtcdV3CompactionPeriod <*> <*> PrometheusMetricsPort int <*> Controllers <*> Node <*> <*> Policy <*> <*> WorkloadEndpoint v3.WorkloadEndpointControllerConfig <*> ServiceAccount v3.ServiceAccountControllerConfig <*> Namespace <*> <*> Status <*> RunningConfig <*> LogSeverityScreen Info HealthChecks Enabled EtcdV3CompactionPeriod <*> <*> PrometheusMetricsPort int nil Controllers <*> Node <*> <*> Policy <*> nil WorkloadEndpoint v3.WorkloadEndpointControllerConfig nil ServiceAccount v3.ServiceAccountControllerConfig nil Namespace <*> nil EnvironmentVars map string string DATASTORE_TYPE kubernetes ENABLED_CONTROLLERS node error etcdserver leader changed	9
581	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started streaming with peer <*> stream Message reader	33
582	reconcileCAPICluster spectrocluster Namespace <*> Name <*>	10564
583	STARTUP task executed cluster <*>	15
584	Waiting for caches to sync for ReplicaSet	22
585	Starting workers controller vspherecluster worker count <*>	11
586	unable to perform status update on KubeControllersConfiguration default error etcdserver leader changed	8
587	<*> <*> <*> <*> <*> <*> <*> I | rafthttp started streaming with peer <*> stream MsgApp <*> reader	33
588	Starting EventSource controller kubeadmcontrolplane source Type metadata creationTimestamp null spec version infrastructureTemplate kubeadmConfigSpec status initialized false ready false	11
589	>>>>>>> Scheduling polling of event s after every <*> seconds cluster <*>	14
590	looking for releases filter <*> namespace default	7502
591	Starting Controller controller vspheremachine	11
592	Assigned tunnel address to node IP <*> type ipipTunnelAddress	33
593	Started disruption	22
594	Error getting cluster information config ClusterInformation default error etcdserver request timed out	7
595	<*> <*> <*> <*> <*> <*> <*> I | embed ClientTLS cert <*> key <*> <*> <*> <*> true crl-file	11
596	Starting EventSource controller kubeadmcontrolplane source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	11
597	>>>>>>> Scheduling log monitor service cluster <*>	13
598	Failed to verify datastore error etcdserver request timed out	6
599	found release releases	9262
600	Starting EventSource controller kubeadmconfig source Type metadata creationTimestamp null spec status	11
601	Starting disruption controller	22
602	Starting Controller controller haproxyloadbalancer	11
603	Successfully audited Acquired all resources to Orchestrate SpectroCluster Acquired all resources Normal cluster <*>	11
604	ExecSync for <*> with command bash <*> # Run the proper check depending on the version n $ mongo <*> | grep MongoDB shell ~ <*> + . <*> + . <*> + && VERSION $ BASH_REMATCH <*> n. <*> nVERSION_MAJOR $ get_sematic_version $VERSION <*> nVERSION_MINOR $ get_sematic_version $VERSION <*> nVERSION_PATCH $ get_sematic_version $VERSION <*> nif $VERSION_MAJOR -ge 4 && $VERSION_MINOR -ge 4 && $VERSION_PATCH -ge <*> then n mongo <*> $TLS_OPTIONS <*> <*> .isWritablePrimary || <*> .secondary | grep <*> true nelse n mongo <*> $TLS_OPTIONS <*> db.isMaster .ismaster || db.isMaster .secondary | grep <*> true nfi n and timeout <*> s	1210
605	Starting EventSource controller kubeadmcontrolplane source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	11
606	Waiting for caches to sync for disruption	22
607	ExecSync for <*> with command mongo <*> <*> db.adminCommand ping and timeout <*> s	1210
608	Starting EventSource controller kubeadmconfig source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	11
609	<*> <*> <*> <*> <*> <*> <*> I | embed listening for metrics on http <*> <*>	11
610	pack has no charts atop Namespace <*> Name <*>	3751
611	Scheduling in target cluster... cluster <*>	11
612	Starting EventSource controller kubeadmconfig source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	11
613	Started csrapproving	22
614	Starting workers controller haproxyloadbalancer worker count <*>	11
615	Starting Controller controller kubeadmcontrolplane	11
616	<*> <*> <*> Calico node started successfully	11
617	Starting EventSource controller machinehealthcheck source Type metadata creationTimestamp null spec clusterName selector unhealthyConditions null status	11
618	<*> <*> <*> <*> <*> <*> <*> I | embed listening for peers on <*> <*>	11
619	reconcile manifests atop Namespace <*> Name <*>	3751
620	reconcile control plane endpoint address for VSphereCluster namespace <*> vsphereCluster <*>	9306
621	Starting workers controller kubeadmcontrolplane worker count <*>	11
622	Starting certificate controller csrapproving	22
623	Starting EventSource controller cluster source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	22
624	<*> <*> <*> <*> <*> <*> <*> I | rafthttp peer <*> became active	33
625	<*> <*> <*> bird Unable to open configuration file <*> No such file or directory	22
626	control plane endpoint is already allocated for the VSphereCluster namespace <*> vsphereCluster <*> vSphereCluster <*>	9306
627	Successfully audited Provisioning in target cluster Normal cluster <*>	11
628	Managed <*> is installed cluster <*>	11
629	<*> chart with name <*> and version <*> is already installed and status is deployed. It was last updated on <*> <*> <*> <*> <*> UTC and revision count is <*> cluster <*>	11
630	Un-managed metrics server test... Getting metrics for node <*> cluster <*>	11
631	Starting pod metrics scrapper cluster <*>	11
632	upgrade agent >>>>>>>>>> Initializing upgrade scheduler cluster <*>	11
633	>>>>>>>>>> Initializing health scheduler cluster <*>	11
634	Syncing spc packs manifests and registries cluster <*>	3883
635	Cluster is deployed and all nodes are running. Applying startup os patch config cluster <*>	11
636	Found spectro node task <*> cluster <*>	22
637	Updating spectro node task <*> cluster <*>	22
638	Updated spectro node task <*> cluster <*>	22
639	Starting EventSource controller machine source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	11
640	ExecSync for <*> with command <*> <*> <*> <*> check_running && <*> <*> check_local_alarms and timeout <*> s	792
641	Starting workers controller vspheremachine worker count <*>	11
642	Starting Controller controller kubeadmconfig	11
643	reconcile IP address for VSphereMachine namespace <*> vsphereMachine <*>	174680
644	Reconcile KubeadmControlPlane cluster <*> kubeadmControlPlane <*> namespace <*>	26323
645	ExecSync for <*> with command <*> <*> <*> <*> ping and timeout <*> s	792
646	VSphereCluster spec or failure domains is not changed spectrocluster Namespace <*> Name <*> name <*>	5786
647	Starting EventSource controller machine source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	11
648	Starting workers controller kubeadmconfig worker count <*>	11
649	Skipping confd config file.	44
650	Scaling up control plane cluster <*> kubeadmControlPlane <*> namespace <*> Desired <*> Existing <*>	165
651	successfully reconciled IP address for VSphereMachine namespace <*> vsphereMachine <*>	163570
652	<*> <*> <*> <*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream Message reader	44
653	Starting EventSource controller machineset source Type metadata creationTimestamp null spec clusterName selector template metadata spec clusterName bootstrap infrastructureRef status	11
654	Starting EventSource controller machinedeployment source Type metadata creationTimestamp null spec clusterName selector template metadata spec clusterName bootstrap infrastructureRef status	33
655	Started ttl	22
656	cloud cluster reconcile done spectrocluster Namespace <*> Name <*>	10573
657	<*> <*> <*> <*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream MsgApp <*> reader	44
658	Refreshing token until the infrastructure has a chance to consume it kind Machine kubeadmconfig Namespace <*> Name <*> name <*> version <*>	6116
659	Starting TTL controller	22
660	Waiting for control plane to pass preflight checks cluster <*> kubeadmControlPlane <*> namespace <*> failures machine <*> does not have APIServerPodHealthy condition machine <*> does not have ControllerManagerPodHealthy condition machine <*> does not have SchedulerPodHealthy condition machine <*> does not have EtcdPodHealthy condition machine <*> does not have EtcdMemberHealthy condition	22
661	Starting EventSource controller machinepool source Type metadata creationTimestamp null spec clusterName template metadata spec clusterName bootstrap infrastructureRef status replicas 0 bootstrapReady false infrastructureReady false	11
662	Starting EventSource controller cluster source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	11
663	Start called	139
664	reconcile cloud level setups spectrocluster Namespace <*> Name <*>	10582
665	<*> <*> <*> <*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream Message writer	44
666	Waiting for caches to sync for TTL	22
667	Checking for lock cluster-name <*> configmap-name <*> namespace <*>	209
668	<*> <*> <*> <*> <*> <*> <*> INFO <*> term 0 received a MsgVote message with higher term from <*> term <*>	11
669	Starting Controller controller cluster	22
670	Sending status update Status <*>	282
671	Caches are synced for TTL	22
672	Starting workers controller cluster worker count <*>	22
673	setting up ipam ip pool for cluster spectrocluster Namespace <*> Name <*>	5786
674	<*> <*> <*> <*> <*> <*> <*> INFO <*> became <*> at term <*>	77
675	Control plane init lock not found it may have been released already cluster-name <*> configmap-name <*> namespace <*>	209
676	Starting main event processing loop	143
677	Starting EventSource controller machinehealthcheck source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	11
678	reconcileCNI start spectrocluster Namespace <*> Name <*>	5786
679	Started tokencleaner	22
680	Failed to delete route error no such process ifaceName <*> ifaceRegex ^cali. ipVersion <*>	22
681	Altering JoinConfiguration.Discovery.BootstrapToken kubeadmconfig <*> APIServerEndpoint <*> <*>	154
682	<*> <*> <*> <*> <*> <*> <*> INFO <*> logterm 0 index 0 vote 0 cast MsgVote for <*> logterm <*> index <*> at term <*>	11
683	pack object digest not changed skip reconcile spectrocluster Namespace <*> Name <*> digest sha256 <*>	11572
684	Starting EventSource controller machinehealthcheck source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	11
685	>>>>>>>>>>>> Starting to watch vsphere machines cluster <*>	11
686	Starting token cleaner controller	22
687	Altering JoinConfiguration.Discovery.BootstrapToken kubeadmconfig <*> Token <*>	154
688	reconcileCSI start spectrocluster Namespace <*> Name <*>	5786
689	Starting Controller controller machinehealthcheck	11
690	Starting to watch statefulsets cluster <*>	11
691	Waiting for caches to sync for token_cleaner	22
692	<*> <*> <*> <*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream MsgApp <*> writer	44
693	Creating BootstrapData for the join control plane kind Machine kubeadmconfig Namespace <*> Name <*> name <*> version <*>	209
694	Sending synced update ListRoot <*>	945
695	Interface was deleted during operation filtering error error netlink update operation failed ifaceName <*> ifaceRegex ^cali. ipVersion <*>	22
696	Starting workers controller machinehealthcheck worker count <*>	11
697	Caches are synced for token_cleaner	22
698	Starting to watch pods cluster <*>	11
699	<*> <*> <*> <*> <*> <*> <*> INFO raft.node <*> <*> leader <*> at term <*>	33
700	creating or update kubeadm control plane init false	5786
701	Interface missing will retry if it appears. ifaceName <*> ifaceRegex ^cali. ipVersion <*>	1903
702	using os image from mold spectrocluster Namespace <*> Name <*> template <*>	12727
703	Failed to start service controller the cloud provider does not support external load balancers	22
704	Sending status update Status resync	143
705	Received InSync event from one of the watcher caches	944
706	Starting to watch deployments cluster <*>	11
707	>>>>>>>>>>>> Starting to watch nodes cluster <*>	11
708	<*> <*> <*> <*> <*> <*> <*> I | rafthttp receiving database snapshot index <*> from <*> raft message size <*> kB	11
709	Skipping service	22
710	Reconciling machinehealthcheck <*> namespace <*>	156141
711	create update operations cptemplate 0 kcp 0	5797
712	Started podgc	22
713	<*> <*> <*> <*> <*> <*> <*> I | snap saved database snapshot to disk total bytes <*>	11
714	>>>>>>>>>>>> Starting to watch spectrocluster cluster <*>	11
715	Starting Controller controller machine	11
716	Starting GC controller	22
717	setting machine health check	5797
718	Starting workers controller machine worker count <*>	11
719	waiting for machine controller to set ownerRef on VSphereMachine vspheremachine Namespace <*> Name <*>	143
720	Starting to watch jobs cluster <*>	11
721	Waiting for caches to sync for GC	22
722	Starting EventSource controller machineset source Type metadata creationTimestamp null spec clusterName bootstrap infrastructureRef status bootstrapReady false infrastructureReady false	22
723	<*> <*> <*> <*> <*> <*> <*> I | rafthttp successfully received and saved database snapshot index <*> from <*> raft message size <*> kB db size <*> MB took <*>	11
724	All watchers have sync d data <*> sending data and final sync	140
725	starting reconcile unhealthy control-plane machines	3476
726	Started daemonset	22
727	<*> <*> <*> <*> <*> <*> <*> INFO log committed 0 applied 0 unstable.offset <*> len unstable.Entries 0 starts to restore snapshot index <*> term <*>	11
728	>>>>>>>>>>>> Starting to watch events cluster <*>	11
729	IPPool <*> is available namespace <*> vsphereMachine <*>	11110
730	<*> <*> <*> <*> <*> <*> <*> INFO <*> switched to configuration voters <*> <*>	22
731	Starting EventSource controller machineset source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	11
732	checking machine machine <*>	10428
733	Starting daemon sets controller	22
734	<*> <*> <*> <*> <*> <*> <*> INFO <*> commit <*> lastindex <*> lastterm <*> restored snapshot index <*> term <*>	11
735	get IPAddress <*> namespace <*> vsphereMachine <*>	11110
736	Starting to watch cronjobs cluster <*>	11
737	Starting Controller controller machineset	11
738	Starting to watch kubeconfig secret cluster <*>	11
739	<*> <*> <*> <*> <*> <*> <*> INFO <*> commit <*> restored snapshot index <*> term <*>	11
740	Waiting for caches to sync for daemon sets	22
741	waiting for IPClaim <*> namespace <*> vsphereMachine <*>	11110
742	<*> <*> <*> <*> <*> <*> <*> I | etcdserver applying snapshot at index 0...	11
743	Starting workers controller machineset worker count <*>	11
744	Starting to watch daemonsets cluster <*>	11
745	<*> <*> <*> <*> <*> <*> <*> I | etcdserver raft applied incoming snapshot at index <*>	11
746	allocate IP <*> namespace <*> vsphereMachine <*>	11110
747	create IPClaim <*> namespace <*> vsphereMachine <*>	143
748	mdelete mdelete	3476
749	Started statefulset	22
750	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering lessor...	11
751	Listing event s in <*> namespace cluster <*>	11
752	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering lessor	11
753	>>>>>>>>>>>> Starting to watch machines cluster <*>	11
754	<*> <*> <*> <*> <*> <*> <*> I | etcdserver restoring mvcc store...	11
755	created IPClaim <*> waiting for IPAddress to be available namespace <*> vsphereMachine <*>	143
756	reconcile unhealthy control-plane machines done	3476
757	Starting stateful set controller	22
758	Starting to watch namespaces cluster <*>	11
759	waiting for IP address to be available for the VSphereMachine namespace <*> vsphereMachine <*>	11110
760	Starting EventSource controller machinedeployment source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	11
761	Starting Controller controller machinedeployment	11
762	controlplane scale up ongoing requeue after <*> minute	3476
763	<*> <*> <*> <*> <*> <*> <*> I | mvcc restore compact to <*>	11
764	id <name <*> > profile <inbound_rules <action allow rule_id <*> > outbound_rules <action allow rule_id <*> > >	3443
765	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config &config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> <*> AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	11
766	Waiting for caches to sync for stateful set	22
767	Current resource version of nodes is <*> cluster <*>	11
768	Starting workers controller machinedeployment worker count <*>	11
769	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished restoring mvcc store	11
770	Resource version for nodes is <*> cluster <*>	11
771	kcp status spec <*> status selector <*> <*> <*> replicas <*> updatedReplicas <*> readyReplicas <*> unavailableReplicas <*> initialized true ready true observedGeneration <*> conditions type Ready status False severity Warning lastTransitionTime <*> <*> <*> reason ScalingUp message Scaling up control plane to <*> replicas actual <*> type Available status True lastTransitionTime <*> <*> <*> type CertificatesAvailable status True lastTransitionTime <*> <*> <*> type ControlPlaneComponentsHealthy status True lastTransitionTime <*> <*> <*> type EtcdClusterHealthyCondition status True lastTransitionTime <*> <*> <*> type MachinesReady status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation @ <*> message <*> of <*> completed type Resized status False severity Warning lastTransitionTime <*> <*> <*> reason ScalingUp message Scaling up control plane to <*> replicas actual <*> version <*>	3476
772	Using internal linux dataplane driver.	44
773	Started persistentvolume-binder	22
774	id <namespace default name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	26543
775	Starting EventSource controller machinepool source Type metadata creationTimestamp null spec controlPlaneEndpoint host port 0 status infrastructureReady false controlPlaneInitialized false	11
776	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering alarms...	11
777	Calculated iptables mark bits acceptMark <*> endpointMark <*> endpointMarkNonCali 0x0 passMark <*> scratch0Mark <*> scratch1Mark <*>	44
778	Starting persistent volume controller	22
779	Putting Kubeconfig to hubble cluster <*>	110
780	Starting Controller controller machinepool	11
781	id <name <*> > profile <inbound_rules <action allow rule_id aBMQCbsUMESPKGRp > outbound_rules <action allow rule_id <*> > >	627
782	detect env done spectrocluster Namespace <*> Name <*> env target	5764
783	<*> <*> <*> <*> <*> <*> <*> I | etcdserver closing old backend...	11
784	Starting workers controller machinepool worker count <*>	11
785	Waiting for caches to sync for persistent volume	22
786	Current resource version of cluster is <*> cluster <*>	11
787	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> <*> VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	22
788	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering alarms	11
789	reconcile on target spectrocluster Namespace <*> Name <*>	5764
790	Adding watcher on external object cluster <*> namespace <*> GroupVersionKind <*> Kind VSphereCluster	11
791	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> <*> VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	22
792	Starting EventSource controller cluster source Type apiVersion <*> kind VSphereCluster	11
793	reconcilePacks spectrocluster Namespace <*> Name <*>	10560
794	Resource version for cluster is <*> cluster <*>	11
795	Starting EventSource controller machinehealthcheck source	11
796	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering auth store...	11
797	Workload to host packets will be accepted.	44
798	reconcilePacks done spectrocluster Namespace <*> Name <*>	5764
799	Starting TTL after finished controller	22
800	IPClaim <*> already exists skipping creation namespace <*> vsphereMachine <*>	10967
801	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished closing old backend	11
802	reconcile OS Image spectrocluster Namespace <*> Name <*>	10560
803	image ready status spectrocluster Namespace <*> Name <*> err null ready true	10560
804	Adding watcher on external object cluster <*> namespace <*> GroupVersionKind <*> Kind KubeadmControlPlane	11
805	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering auth store	11
806	filter table allowed packets will be accepted immediately.	44
807	Current resource version of vsphere machines is <*> cluster <*>	11
808	Waiting for caches to sync for TTL after finished	22
809	os image is ready spectrocluster Namespace <*> Name <*>	10560
810	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering store v2...	11
811	Starting EventSource controller cluster source Type apiVersion <*> kind KubeadmControlPlane	11
812	mangle table allowed packets will be accepted immediately.	44
813	Resource version for vsphere machines is <*> cluster <*>	11
814	Packets to unknown service IPs will be dropped	44
815	Started endpoint	22
816	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering store <*>	11
817	kube apply success atop Namespace <*> Name <*> file <*>	3751
818	Unable to retrieve machine from node error expecting one machine for node <*> got node <*>	33
819	Determined pod MTU mtu <*>	44
820	<*> <*> <*> <*> <*> <*> <*> I | etcdserver recovering cluster configuration...	11
821	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/api enabled capabilities for version <*>	11
822	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/membership added member <*> https <*> <*> to cluster <*> from store	22
823	Starting endpoint controller	22
824	reconcile service status atop Namespace <*> Name <*>	3751
825	configured to periodically rescan interfaces. interval <*>	44
826	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> 2a a9 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
827	Starting EventSource controller machine source	11
828	Unable to retrieve machine from node error no matching Machine node <*>	33
829	Waiting for caches to sync for endpoint	22
830	Looked up iptables command backendMode legacy candidates string <*> <*> command <*> ipVersion <*> <*> <*>	264
831	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes scaling up type ControlPlaneReady status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes scaling up type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message <*> ready. <*> ready. istio ready. permission-manager ready. services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name backend ports protocol TCP port <*> host <*> name frontend ports protocol TCP port <*> host <*> name frontend-streaming ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name minio ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> cluster <*>	11
832	Current resource version of capi machines is <*> cluster <*>	11
833	VM Hardware version <*> from node <*> is deprecated. Please consider upgrading virtual machine hardware version to <*> or higher	77
834	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/membership set the cluster version to <*> from store	11
835	Adding watcher on external object machine <*> namespace <*> GroupVersionKind <*> Kind VSphereMachine	11
836	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished recovering cluster configuration	11
837	Starting garbage collector controller	22
838	Resource version for capi machine is <*> cluster <*>	11
839	reconciled chart service status for pack pack <*>	3751
840	Starting EventSource controller machine source Type apiVersion <*> kind VSphereMachine	11
841	Waiting for caches to sync for garbage collector	55
842	GraphBuilder running	22
843	<*> <*> <*> <*> <*> <*> <*> I | etcdserver removing old peers from network...	11
844	Neither <*> nor <*> was specified. Using the inClusterConfig. This might not work.	74
845	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopping peer <*>	11
846	Set Machine s NodeRef machine <*> namespace <*> noderef <*>	22
847	Started garbagecollector	22
848	EVENT <*> Resource machines Event Type ADDED Name <*> InfraType VSphereMachine InfraTypeName <*> status Running cluster <*>	2453
849	Updating detected iptables features features iptables.Features SNATFullyRandom true MASQFullyRandom true RestoreSupportsLock true iptablesVersion <*> kernelVersion <*>	44
850	<*> <*> <*> <*> <*> <*> <*> I | rafthttp closed the TCP streaming connection with peer <*> stream MsgApp <*> writer	11
851	Started deployment	22
852	EVENT <*> Resource machines Type ADDED Name <*> Uid <*> cluster <*>	2475
853	Calculated old-insert detection regex. pattern ? <*> cali-| ? <*> <*> ? <*> <*> ? <*> <*> ? <*> <*> ? <*> <*> ? <*> calipo-| ? <*> felix-	132
854	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> writer	22
855	<*> <*> <*> <*> <*> <*> <*> I | rafthttp closed the TCP streaming connection with peer <*> stream Message writer	11
856	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 4f ba networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
857	Starting controller controller deployment	22
858	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped HTTP pipelining with peer <*>	11
859	Looked up iptables command backendMode legacy candidates string <*> iptables-restore command <*> ipVersion <*> <*> restore	176
860	<*> <*> <*> <*> <*> <*> <*> W | rafthttp <*> the TCP streaming connection with peer <*> stream MsgApp <*> reader	22
861	Waiting for caches to sync for deployment	22
862	Successfully audited Successfully patched os security updates for node <*> at <*> <*> <*> <*> <*> UTC ospatch Normal cluster <*>	308
863	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> stream MsgApp <*> reader	11
864	Updating VsphereMachine <*> and instance state Running in Hubble for cloudConfig <*> and machine pool master-pool. cluster <*>	539
865	Starting certificate controller <*>	88
866	<*> <*> <*> <*> <*> <*> <*> W | rafthttp <*> the TCP streaming connection with peer <*> stream Message reader	22
867	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Reconciliation on ImageCustomization Done Successfully reason ReconciliationDone status True type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes scaling up reason LaunchControlPlaneNode status False type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes scaling up reason LaunchControlPlaneNode status False type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message worker nodes created successfully reason NodeReady status True type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message <*> ready. <*> ready. istio ready. permission-manager ready. reason AddOnDeployed status True type AddOnDeploymentDone conditions for spectro cluster cluster <*>	33
868	reconciled manifest service status for pack pack <*>	3751
869	<*> <*> <*> <*> <*> <*> <*> E | rafthttp failed to read <*> on stream Message context canceled	11
870	Calculated old-insert detection regex. pattern ? <*> cali-| ? <*> <*> ? <*> <*> ? <*> <*> ? <*> <*> ? <*> <*> ? <*> calipo-| ? <*> felix-|-A POSTROUTING . <*> . <*> POSTROUTING <*> tunl0 <*> addrtype ! <*> LOCAL <*> <*> addrtype <*> LOCAL <*> MASQUERADE	44
871	Updated VsphereMachine <*> with uid <*> and instance state Running in Hubble for cloudConfig <*> and machine pool master-pool. cluster <*>	539
872	Starting <*> <*> <*>	99
873	pack readiness status pack <*> status true	3751
874	<*> <*> <*> <*> <*> <*> <*> I | rafthttp peer <*> became inactive message send to peer failed	11
875	STORE Adding cloud machine with uid <*> and capi machine name <*> with status Running in machine pool master-pool	539
876	etcd cluster before remediation cluster <*> kubeadmControlPlane <*> namespace <*> currentMembers <*> <*> currentTotalMembers <*>	132
877	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	22
878	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> stream Message reader	11
879	<*> <*> <*> <*> <*> <*> <*> I | rafthttp stopped peer <*>	11
880	<*> <*> <*> <*> <*> <*> <*> I | rafthttp removed peer <*>	11
881	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished removing old peers from network	11
882	etcd cluster projected after remediation of <*> cluster <*> kubeadmControlPlane <*> namespace <*> canSafelyRemediate true healthyMembers <*> <*> <*> <*> targetQuorum <*> targetTotalMembers <*> targetUnhealthyMembers 0 unhealthyMembers	132
883	Advertise global service ranges from this node	132
884	Updated host <*> port <*> api endpoints for spectro cluster cluster <*>	11
885	<*> <*> <*> <*> <*> <*> <*> I | etcdserver adding peers from new cluster configuration into network...	11
886	Remediating unhealthy machine cluster <*> kubeadmControlPlane <*> namespace <*> UnhealthyMachine <*>	132
887	Started csrsigning	22
888	Updating VsphereMachine <*> and instance state Running in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	4070
889	Can t enable XDP acceleration. error kernel is too old have <*> but want at least <*>	44
890	Updated VsphereMachine <*> with uid <*> and instance state Running in Hubble for cloudConfig <*> and machine pool <*> cluster <*>	4070
891	Updated with new cluster IP CIDRs	44
892	STORE Adding cloud machine with uid <*> and capi machine name <*> with status Running in machine pool <*>	4070
893	Updated host <*> name istio-ingressgateway ports port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name backend ports port <*> protocol TCP host <*> name frontend ports port <*> protocol TCP host <*> name frontend-streaming ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name minio ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP services for spectro cluster cluster <*>	11
894	Updated with new external IP CIDRs	44
895	Adding watcher on external object machine <*> namespace <*> GroupVersionKind <*> Kind KubeadmConfig	11
896	Caches are synced for tokens	22
897	Starting EventSource controller machine source Type apiVersion <*> kind KubeadmConfig	11
898	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished adding peers from new cluster configuration into network...	11
899	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> dd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
900	Started csrcleaner	22
901	Updated with new Loadbalancer IP CIDRs	44
902	<*> <*> <*> <*> <*> <*> <*> I | etcdserver finished applying incoming snapshot at index <*>	11
903	Bootstrap provider is not ready requeuing machine <*> namespace <*>	11
904	Starting CSR cleaner controller	22
905	Infrastructure provider is not ready requeuing machine <*> namespace <*>	1188
906	Posting manifest to hubble cluster <*>	363
907	Cannot reconcile Machine s Node no valid ProviderID yet machine <*> namespace <*>	1188
908	<*> <*> <*> <*> <*> <*> <*> I | etcdserver published Name <*> ClientURLs https <*> <*> to cluster <*>	11
909	Source SourceRouteGenerator readiness changed ready true	44
910	<*> <*> <*> <*> <*> <*> <*> I | embed ready to serve client requests	22
911	Starting PVC protection controller	22
912	bootstrap data secret for KubeadmConfig already exists updating KubeadmConfig <*> secret <*>	66
913	Waiting for caches to sync for PVC protection	22
914	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> dd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
915	Unable to retrieve pull secret the image pull may not succeed. pod <*> secret err secret <*> not found	396
916	<*> <*> <*> <*> <*> <*> <*> I | embed serving client requests on <*> <*>	22
917	Started bootstrapsigner	22
918	Successfully updated kubeconfig file to hubble cluster <*>	110
919	Fetching pack values for layer k8s and field path clientConfig and pack name cluster <*>	110
920	Waiting for caches to sync for bootstrap_signer	22
921	Sending events to api server	44
922	EVENT <*> Resource machines Event Type ADDED Name <*> InfraType VSphereMachine InfraTypeName <*> status Provisioning cluster <*>	11
923	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	11
924	Starting <*> controller	44
925	lock is held by <*> and has not yet expired	153
926	Started cronjob	22
927	Current address is still valid do nothing currentAddr <*> type ipipTunnelAddress	55
928	failed to acquire lease <*>	154
929	Starting cronjob controller <*>	22
930	Waiting for caches to sync for cronjob	22
931	. . . . . VSphereMachine s <*> providerId is empty. Thus skipping to post to hubble. cluster <*>	308
932	Sending events to api server.	99
933	Failed to get node from machine <*> . Failed to find node reference from machine s <*> status as node ref is empty. cluster <*>	242
934	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	11
935	Failed to process health for node from machine <*> Failed to find node reference from machine s <*> status as node ref is empty. cluster <*>	242
936	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> 2a a9 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
937	No Secondary Service CIDR provided. Skipping filtering out secondary service addresses.	22
938	Started nodeipam	22
939	Updated SpectroClusterStatusCondition condition KubeConfigReady reason KubeConfigReady status True message Kubeconfig file is available. cluster <*>	110
940	Starting ipam controller	22
941	Waiting for caches to sync for node	22
942	Updated kubeconfig ready condition <*> cluster <*>	110
943	Caches are synced for node	22
944	>>>>>>> Watching secret with name <*> cluster <*>	99
945	Starting range CIDR allocator	22
946	Source SourceSyncer readiness changed ready true	44
947	Data is now syncd can start rendering templates	44
948	Started attachdetach	22
949	Target config <*> has been updated	264
950	Failed to update statusUpdateNeeded field in actual state of world Failed to set statusUpdateNeeded to needed true because nodeName <*> does not exist	110
951	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 4f ba networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
952	Successfully updated manifest file to hubble cluster <*>	363
953	Running bpftool to look up programs attached to cgroup args string bpftool <*> <*> cgroup show <*>	44
954	Calculated interface name regexp regex ^cali.	44
955	Queueing IP set for creation family inet setID <*> setType hash net	209
956	Calculated interface name regexp regex <*>	44
957	Registering to report health.	44
958	attempted to modprobe nf_conntrack_proto_sctp error exit status <*> output	44
959	Making sure IPv4 forwarding is enabled.	44
960	Queueing update of chain. chainName <*> ipVersion <*> table <*>	517
961	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> da networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
962	BACKUP Skipping update to hubble as manifest data is same cluster <*>	2354
963	Starting attach detach controller	22
964	Waiting for caches to sync for attach detach	22
965	Started persistentvolume-expander	22
966	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> c7 d6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
967	Starting expand controller	22
968	Waiting for caches to sync for expand	22
969	Starting root CA certificate configmap publisher	22
970	Waiting for caches to sync for crt configmap	22
971	Started ephemeral-volume	22
972	Starting ephemeral volume controller	22
973	Waiting for caches to sync for ephemeral	22
974	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> c7 d6 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
975	Started endpointslice	22
976	Starting endpoint slice controller	22
977	Waiting for caches to sync for endpoint_slice	22
978	Started horizontalpodautoscaling	22
979	Starting HPA controller	22
980	Waiting for caches to sync for HPA	22
981	Started endpointslicemirroring	22
982	Starting EndpointSliceMirroring controller	22
983	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	11
984	Failed predicate on node <*> node s had taints that the pod didn t tolerate	5471
985	Waiting for caches to sync for endpoint_slice_mirroring	22
986	Job <*> does not fit on node <*>	44
987	QuotaMonitor created object count evaluator for <*>	1595
988	Failed to access interface because it doesn t exist. error Link not found ifaceName <*> ifaceRegex ^cali. ipVersion <*>	1881
989	Failed to get interface it s <*> error Link not found ifaceName <*> ifaceRegex ^cali. ipVersion <*>	1881
990	QuotaMonitor created object count evaluator for limitranges	22
991	Pod does not fit on node <*>	5377
992	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> da networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	11
993	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> cluster <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	22
994	QuotaMonitor created object count evaluator for jobs.batch	22
995	QuotaMonitor created object count evaluator for ingresses.extensions	22
996	resyncPeriod <*> is smaller than resyncCheckPeriod <*> and the informer has already started. Changing it to <*>	22
997	QuotaMonitor created object count evaluator for serviceaccounts	22
998	IPIP enabled starting thread to keep tunnel configuration in sync.	44
999	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active 0 Succeeded <*> Failed 0 Desired <*> Phase running	27
1000	Connect to the dataplane driver.	44
1001	using resource updates where applicable	44
1002	Created Syncer syncer <*> status 0x0 watcherCaches <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> results chan interface <*> numSynced 0 callbacks calc.SyncerCallbacksDecoupler <*> wgwc sync.WaitGroup nil wgws sync.WaitGroup nil cancel context.CancelFunc nil	44
1003	Starting the datastore Syncer	44
1004	QuotaMonitor created object count evaluator for endpoints	22
1005	Started internal iptables dataplane driver loop	44
1006	Creating calculation graph filtered to hostname <*>	44
1007	QuotaMonitor created object count evaluator for cronjobs.batch	22
1008	Will refresh IP sets on timer interval <*>	44
1009	Registering listener for type model.WorkloadEndpointKey <*> <*>	264
1010	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status Provisioning cluster <*>	99
1011	EVENT <*> Resource machines Type MODIFIED Name <*> Uid <*> cluster <*>	209
1012	Will refresh routes on timer interval <*>	44
1013	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	88
1014	Registering listener for type model.HostEndpointKey <*> <*>	264
1015	IPIP thread started.	44
1016	Registering listener for type model.PolicyKey <*> <*>	88
1017	Registering listener for type model.ProfileRulesKey <*> <*>	44
1018	Registering listener for type model.ProfileLabelsKey <*> <*>	132
1019	Registering listener for type model.ProfileTagsKey <*> <*>	88
1020	<*> <*> <*> Trace <*> <*> Request completed <*> <*> <*> <*>	132
1021	Registering listener for type model.NetworkSetKey <*> <*>	44
1022	Registering listener for type model.HostIPKey <*> <*>	88
1023	Registering listener for type model.IPPoolKey <*> <*>	44
1024	Registering listener for type model.WireguardKey <*> <*>	44
1025	Registering listener for type model.ResourceKey <*> <*>	44
1026	Registering listener for type model.GlobalConfigKey <*> <*>	44
1027	Registering listener for type model.HostConfigKey <*> <*>	88
1028	Registering listener for type model.ReadyFlagKey <*> <*>	44
1029	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	11
1030	Starting AsyncCalcGraph	44
1031	Started the processing graph	44
1032	Watch close <*> <*> total <*> items received	3531
1033	Started internal status report thread	44
1034	Process status reports disabled	44
1035	reconcile charts atop Namespace <*> Name permission-manager	880
1036	Interface monitoring thread started.	44
1037	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	22
1038	Subscribed to netlink updates.	44
1039	Failed to get IPIP tunnel device assuming it isn t present error Link not found	44
1040	<*> <*> <*> Nov <*> <*> <*> <*> <*> CRON <*> root CMD cd <*> && <*> <*> <*>	22
1041	Linux interface state changed. ifIndex <*> ifaceName lo state up	44
1042	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status Deleting cluster <*>	33
1043	Linux interface addrs changed. addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty ifaceName lo	44
1044	Linux interface state changed. ifIndex <*> ifaceName eth0 state up	44
1045	QuotaMonitor created object count evaluator for podtemplates	22
1046	Linux interface addrs changed. addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c <*> set.empty ifaceName eth0	22
1047	&intdataplane.ifaceUpdate Name lo State up Index <*>	11
1048	looking for releases filter permission-manager namespace default	1760
1049	pack has no charts atop Namespace <*> Name permission-manager	880
1050	Started resourcequota	22
1051	&intdataplane.ifaceUpdate Name eth0 State up Index <*>	11
1052	reconcile manifests atop Namespace <*> Name permission-manager	880
1053	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	11
1054	Starting resource quota controller	22
1055	&intdataplane.ifaceAddrsUpdate Name lo Addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty	11
1056	Waiting for caches to sync for resource quota	55
1057	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name lo Addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty	11
1058	EVENT <*> Resource vspheremachines Type DELETED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> deletionTimestamp <*> <*> <*> deletionGracePeriodSeconds 0 labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason Deleting type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason Deleting cluster <*>	11
1059	QuotaMonitor running	22
1060	Queueing IP set for creation family inet setID <*> setType hash ip	297
1061	Started namespace	22
1062	&intdataplane.ifaceAddrsUpdate Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c <*> set.empty	22
1063	Starting namespace controller	22
1064	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> fe9c <*> set.empty	22
1065	Failed to get VSphereMachine <*> <*> not found cluster <*>	33
1066	Waiting for caches to sync for namespace	22
1067	Failed to get VsphereMachine data from store using capi machine name <*> Failed to get machine data as couldn t find any matching machine with capi machine name <*> cluster <*>	33
1068	Failed to delete vsphere machine using cached capi machine <*> <*> not found cluster <*>	33
1069	Failed to get VSphereMachine <*> . <*> <*> not found cluster <*>	33
1070	Controller will reconcile labels.	22
1071	Cached machines data Namespace <*> CloudConfigUid <*> ClusterLastResourceVersion CapiMachinesLastResourceVersion CloudMachinesLastResourceVersion NodesLastResourceVersion Machines <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true <*> MachinePoolName master-pool MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane true MasterTaint true CollectMetrics true <*> MachinePoolName <*> MachineUid <*> CapiMachineName <*> CloudMachineName <*> NodeName <*> Status Running IsControlPlane false MasterTaint false CollectMetrics true Restores null cluster <*>	33
1072	Started nodelifecycle	22
1073	AsyncCalcGraph running	44
1074	Failed to process machine event for machine <*> <*> <*> not found cluster <*>	33
1075	config <key CalicoVersion value <*> > config <key ClusterGUID value <*> > config <key ClusterType value k8s bgp kubeadm kdd > config <key DatastoreType value kubernetes > config <key DefaultEndpointToHostAction value ACCEPT > config <key FelixHostname value <*> > config <key HealthEnabled value true > config <key IpInIpEnabled value true > config <key IpInIpMtu value 0 > config <key IpInIpTunnelAddr value <*> > config <key Ipv6Support value false > config <key LogFilePath value None > config <key LogSeverityFile value None > config <key LogSeverityScreen value Info > config <key LogSeveritySys value None > config <key MetadataAddr value None > config <key ReportingIntervalSecs value 0 >	44
1076	Reading from dataplane driver pipe...	44
1077	Starting node controller	22
1078	Waiting for caches to sync for taint	22
1079	Started clusterrole-aggregation	22
1080	Starting ClusterRoleAggregator	22
1081	Waiting for caches to sync for ClusterRoleAggregator	22
1082	Caches are synced for service account	22
1083	Caches are synced for cronjob	22
1084	Caches are synced for GC	22
1085	Caches are synced for stateful set	22
1086	Caches are synced for endpoint	22
1087	Caches are synced for endpoint_slice_mirroring	22
1088	Caches are synced for ephemeral	22
1089	Caches are synced for namespace	22
1090	Caches are synced for daemon sets	22
1091	Caches are synced for TTL after finished	22
1092	Caches are synced for deployment	22
1093	Caches are synced for endpoint_slice	22
1094	Watch close <*> <*> total 4 items received	352
1095	Caches are synced for job	22
1096	No driver process to monitor	44
1097	kube apply success atop Namespace <*> Name permission-manager file <*>	880
1098	Caches are synced for PVC protection	22
1099	Failed to add IPIP tunnel device error exit status <*>	44
1100	reconcile service status atop Namespace <*> Name permission-manager	880
1101	Failed configure IPIP tunnel device retrying... error exit status <*>	44
1102	Caches are synced for ReplicaSet	22
1103	Caches are synced for disruption	22
1104	reconciled chart service status for pack pack permission-manager	880
1105	Global config update GlobalFelixConfig name ClusterGUID <*> <*> <nil> 0s <*>	44
1106	Caches are synced for ClusterRoleAggregator	22
1107	Caches are synced for bootstrap_signer	22
1108	Global config update GlobalFelixConfig name ClusterType k8s bgp kubeadm kdd <*> <nil> 0s <*>	44
1109	Caches are synced for PV protection	22
1110	Caches are synced for HPA	22
1111	Global config update GlobalFelixConfig name CalicoVersion <*> <*> <nil> 0s <*>	44
1112	Caches are synced for taint	22
1113	EVENT <*> Resource machines Event Type DELETED Name <*> InfraType VSphereMachine InfraTypeName <*> status Deleting cluster <*>	11
1114	Initializing eviction metric for zone dycolo   brighteon1	11
1115	EVENT <*> Resource machines Type DELETED Name <*> Uid <*> cluster <*>	11
1116	Missing timestamp for Node <*> Assuming now as a timestamp.	110
1117	Watch close <*> <*> total 6 items received	374
1118	reconcile charts atop Namespace <*> Name istio	880
1119	Controller detected that zone dycolo   brighteon1 is now in state Normal.	11
1120	Starting NoExecuteTaintManager	22
1121	Caches are synced for persistent volume	22
1122	Event occurred object <*> kind Node apiVersion <*> type Normal reason RegisteredNode message Node <*> event Registered Node <*> in Controller	110
1123	Global config update GlobalFelixConfig name LogSeverityScreen Info <*> <nil> 0s <*>	44
1124	Global config update GlobalFelixConfig name IpInIpEnabled true <*> <nil> 0s <*>	44
1125	Caches are synced for expand	22
1126	Global config update GlobalFelixConfig name ReportingIntervalSecs 0 <*> <nil> 0s <*>	44
1127	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	11
1128	looking for releases filter istio namespace default	2640
1129	Caches are synced for attach detach	22
1130	id <*> pool <cidr <*> masquerade true >	44
1131	found release releases name istio-istio-controlplane namespace default revision <*> updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version <*> name <*> namespace default revision <*> updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version	2640
1132	Caches are synced for crt configmap	22
1133	begin helm get manifest namespace default release istio-istio-controlplane	1760
1134	EVENT <*> Resource machines Event Type ADDED Name <*> InfraType VSphereMachine InfraTypeName <*> status cluster <*>	11
1135	Event occurred object <*> kind DaemonSet apiVersion <*> type Normal reason SuccessfulCreate message Created pod <*>	22
1136	Waited for <*> due to <*> throttling not priority and fairness request GET https <*> <*> 500&resourceVersion 0	11
1137	Caches are synced for resource quota	55
1138	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	11
1139	Host config update for this host HostConfig node <*> name IpInIpTunnelAddr <*> <*> <nil> 0s <*>	44
1140	Caches are synced for garbage collector	55
1141	hostname <*> ipv4_addr <*>	231
1142	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status cluster <*>	11
1143	Garbage collector all resource monitors have synced. Proceeding to collect garbage	22
1144	helm get manifest complete namespace default release istio-istio-controlplane	1760
1145	Event occurred object brighteon/backend kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetResourceMetric message failed to get memory utilization unable to get metrics for resource memory no metrics returned from resource metrics API	1252
1146	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	22
1147	Event occurred object brighteon/backend kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetResourceMetric message failed to get cpu utilization unable to get metrics for resource cpu no metrics returned from resource metrics API	1250
1148	failed to compute desired number of replicas based on listed metrics for <*> invalid metrics <*> invalid out of <*> first error is failed to get memory utilization unable to get metrics for resource memory no metrics returned from resource metrics API	1251
1149	Event occurred object brighteon/backend kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedComputeMetricsReplicas message invalid metrics <*> invalid out of <*> first error is failed to get memory utilization unable to get metrics for resource memory no metrics returned from resource metrics API	1249
1150	begin helm get manifest namespace default release <*>	1760
1151	EVENT <*> Resource machines Event Type MODIFIED Name <*> InfraType VSphereMachine InfraTypeName <*> status Pending cluster <*>	66
1152	helm get manifest complete namespace default release <*>	1760
1153	datadir <*> atop Namespace <*> Name istio	880
1154	begin helm reconcile for release name istio	880
1155	id <namespace <*> name default > labels <key <*> value default >	3784
1156	id <namespace <*> name <*> > labels <key app value istiod > labels <key <*> value istio-controlplane > labels <key <*> value Base > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1157	id <namespace cert-manager name cert-manager > labels <key app value cert-manager > labels <key <*> value controller > labels <key <*> value cert-manager > labels <key <*> value Helm > labels <key <*> value cert-manager > labels <key helm.sh/chart value <*> > labels <key <*> value cert-manager >	242
1158	get chart name for release name istio-istio-controlplane	880
1159	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false cluster <*>	11
1160	id <namespace <*> name <*> > labels <key <*> value <*> >	4037
1161	get chart name for release name <*>	2849
1162	id <namespace <*> name <*> > labels <key app value kiali > labels <key <*> value istio-controlplane > labels <key <*> value AddonComponents > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1163	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	11
1164	begin helm inspect chartpath <*>	3729
1165	helm inspect complete output name <*> version <*> apiVersion <*> ChartPath <*>	880
1166	id <namespace cert-manager name <*> > labels <key app value cainjector > labels <key <*> value cainjector > labels <key <*> value cert-manager > labels <key <*> value Helm > labels <key <*> value cainjector > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	242
1167	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	11
1168	id <namespace default name default > labels <key <*> value default >	121
1169	id <namespace <*> name <*> > labels <key <*> value Helm > labels <key <*> value <*> >	22
1170	helm inspect complete output name istio-controlplane version <*> apiVersion <*> appVersion <*> ChartPath <*>	880
1171	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForBootstrapData cluster <*>	55
1172	id <namespace <*> name <*> > labels <key app value istio-ingressgateway > labels <key <*> value istio-controlplane > labels <key istio value ingressgateway > labels <key <*> value IngressGateways > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1173	QueryVirtualDiskUuid failed for diskPath <*> <*> . err ServerFaultCode File <*> <*> was not found	11
1174	chart found in release name <*>	2849
1175	id <namespace <*> name <*> > labels <key app value istio-reader > labels <key <*> value istio-controlplane > labels <key <*> value Base > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1176	nothing to upgrade skipping name <*>	2849
1177	id <namespace brighteon name default > labels <key <*> value default >	11
1178	chart found in release name istio-istio-controlplane	880
1179	id <namespace cert-manager name <*> > labels <key app value webhook > labels <key <*> value webhook > labels <key <*> value cert-manager > labels <key <*> value Helm > labels <key <*> value webhook > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	220
1180	nothing to upgrade skipping name istio-istio-controlplane	880
1181	atop helm reconcile complete	2849
1182	helm charts reconciled successfully for pack istio atop Namespace <*> Name istio files <*> <*>	880
1183	reconcile manifests atop Namespace <*> Name istio	880
1184	id <namespace <*> name bootstrap-signer > labels <key <*> value bootstrap-signer >	44
1185	id <namespace <*> name prometheus > labels <key app value prometheus > labels <key <*> value istio-controlplane > labels <key <*> value AddonComponents > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value prometheus > labels <key release value istio >	11
1186	id <namespace <*> name attachdetach-controller > labels <key <*> value attachdetach-controller >	44
1187	id <namespace cert-manager name default > labels <key <*> value default >	176
1188	id <namespace <*> name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	440
1189	id <namespace <*> name <*> > labels <key app value istio-egressgateway > labels <key <*> value istio-controlplane > labels <key istio value egressgateway > labels <key <*> value EgressGateways > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	11
1190	reconcile service status atop Namespace <*> Name istio	880
1191	id <namespace drone name default > labels <key <*> value default >	11
1192	id <namespace elasticsearch name default > labels <key <*> value default >	11
1193	id <name <*> > labels <key <*> value <*> > labels <key <*> value <*> >	264
1194	id <name <*> > labels <key <*> value bootstrap-kubeadm > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value <*> >	44
1195	reconcile status done for pack pack istio release istio-istio-controlplane	880
1196	id <name <*> > labels <key <*> value cluster-api > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value <*> >	44
1197	id <name default > labels <key <*> value default > labels <key <*> value default >	44
1198	id <name <*> > labels <key app value metallb > labels <key <*> value <*> > labels <key <*> value <*> >	44
1199	reconcile status done for pack pack istio release <*>	880
1200	id <name monitoring > labels <key <*> value monitoring > labels <key <*> value monitoring >	11
1201	reconciled chart service status for pack pack istio	880
1202	id <name permission-manager > labels <key <*> value permission-manager > labels <key <*> value permission-manager >	11
1203	id <name <*> > labels <key <*> value <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value <*> >	44
1204	reconciled manifest service status for pack pack istio	880
1205	id <name cert-manager > labels <key <*> value cert-manager > labels <key <*> value cert-manager >	44
1206	id <name <*> > labels <key <*> value Helm > labels <key istio-injection value disabled > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> >	22
1207	pack readiness status pack istio status true	880
1208	id <name mongodb > labels <key <*> value mongodb > labels <key <*> value mongodb >	11
1209	EVENT <*> Resource vspheremachines Type MODIFIED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f resourcePool f template f status . f conditions spec template <*> cloneMode fullClone datacenter Datacenter folder <*> datastore <*> resourcePool Cluster/Resources network devices networkName <*> numCPUs <*> memoryMiB <*> diskGiB <*> status ready false conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation type VMProvisioned status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForStaticIPAllocation cluster <*>	11
1210	id <name drone > labels <key <*> value drone > labels <key <*> value drone >	11
1211	id <name elasticsearch > labels <key <*> value elasticsearch > labels <key <*> value elasticsearch >	11
1212	id <name nginx > labels <key <*> value nginx > labels <key <*> value nginx >	11
1213	id <name redis > labels <key <*> value redis > labels <key <*> value redis >	11
1214	id <name brighteon > labels <key <*> value brighteon > labels <key <*> value brighteon >	11
1215	id <name <*> > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value <*> >	187
1216	id <namespace <*> name endpointslice-controller > labels <key <*> value endpointslice-controller >	44
1217	id <namespace <*> name coredns > labels <key <*> value coredns >	66
1218	id <namespace <*> name endpoint-controller > labels <key <*> value endpoint-controller >	110
1219	id <namespace <*> name deployment-controller > labels <key <*> value deployment-controller >	44
1220	id <namespace <*> name endpointslicemirroring-controller > labels <key <*> value endpointslicemirroring-controller >	44
1221	id <namespace <*> name token-cleaner > labels <key <*> value token-cleaner >	44
1222	id <namespace <*> name speaker > labels <key app value metallb > labels <key <*> value speaker >	341
1223	id <namespace permission-manager name <*> > labels <key <*> value <*> >	11
1224	id <namespace <*> name service-controller > labels <key <*> value service-controller >	11
1225	id <namespace <*> name <*> > labels <key k8s-app value <*> > labels <key <*> value <*> >	11
1226	id <namespace permission-manager name default > labels <key <*> value default >	11
1227	id <namespace <*> name controller > labels <key app value metallb > labels <key <*> value controller >	374
1228	id <namespace mongodb name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value mongodb > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	11
1229	id <namespace <*> name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	11
1230	id <namespace redis name <*> > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value redis > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	11
1231	id <namespace <*> name statefulset-controller > labels <key <*> value statefulset-controller >	44
1232	id <namespace redis name default > labels <key <*> value default >	11
1233	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes scaling up type ControlPlaneReady status False lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes scaling up type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message <*> ready. <*> ready. istio ready. permission-manager ready. services name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name backend ports protocol TCP port <*> host <*> name frontend ports protocol TCP port <*> host <*> name frontend-streaming ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name minio ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> cluster <*>	22
1234	id <namespace monitoring name default > labels <key <*> value default >	11
1235	Skipping to post <*> api endpoints to hubble as there is no difference in cached api endpoints cluster <*>	748
1236	Skipping to post <*> services to hubble as there is no difference in cached services cluster <*>	726
1237	id <namespace <*> name resourcequota-controller > labels <key <*> value resourcequota-controller >	44
1238	<*> <*> <*> ... dropped <*> logs ...	11
1239	id <namespace nginx name default > labels <key <*> value default >	11
1240	id <namespace <*> name service-account-controller > labels <key <*> value service-account-controller >	44
1241	Datamodel in sync flushing config update	44
1242	Sending config update global map CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 host map IpInIpTunnelAddr <*> .	44
1243	First time we ve been in sync	44
1244	Health of component changed lastReport health.HealthReport Live true Ready false name async_calc_graph newReport &health.HealthReport Live true Ready true	11
1245	Possible config update. global map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 host map string string IpInIpTunnelAddr <*>	44
1246	Merging in config from datastore global map CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0	44
1247	Parsing value for DatastoreType kubernetes from environment variable	88
1248	Finish piping stderr of container <*>	1034
1249	Parsed value for DatastoreType kubernetes from environment variable	88
1250	Finish piping stdout of container <*>	1034
1251	Parsing value for Ipv6Support false from environment variable	88
1252	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> <*> Consumed <*> CPU time	11
1253	Parsed value for Ipv6Support false from environment variable	88
1254	Parsing value for HealthEnabled true from environment variable	88
1255	TaskExit event &TaskExit ContainerID <*> ID <*> Pid <*> ExitStatus <*> ExitedAt <*> <*> <*> <*> <*> UTC XXX_unrecognized	1066
1256	Parsed value for HealthEnabled true from environment variable	88
1257	shim disconnected id <*>	1703
1258	Parsing value for FelixHostname <*> from environment variable	88
1259	RemoveContainer containerID <*>	37
1260	Parsed value for FelixHostname <*> from environment variable	88
1261	Parsing value for DefaultEndpointToHostAction ACCEPT from environment variable	88
1262	Parsed value for DefaultEndpointToHostAction ACCEPT from environment variable	88
1263	Error syncing pod skipping err failed to StartContainer for brighteon-be with CrashLoopBackOff back-off <*> restarting failed container brighteon-be pod <*> <*> pod <*> podUID <*>	6
1264	RemoveContainer for <*>	940
1265	Parsing value for IpInIpMtu 0 from environment variable	88
1266	RemoveContainer for <*> returns successfully	939
1267	Parsed value for IpInIpMtu 0 from environment variable	88
1268	Parsing value for MetadataAddr None from config file	88
1269	Value set to none replacing with zero-value .	352
1270	Parsed value for MetadataAddr from config file	88
1271	Parsing value for LogFilePath None from config file	88
1272	Parsed value for LogFilePath from config file	88
1273	Parsing value for LogSeverityFile None from config file	88
1274	Pushing <*> cached pod metrics s to hubble cluster <*>	11
1275	Pushed >>> <*> node metrics s cluster <*>	11
1276	Pushed >>> <*> pod metrics s cluster <*>	13662
1277	Parsed value for LogSeverityFile from config file	88
1278	Parsing value for LogSeveritySys None from config file	88
1279	Parsed value for LogSeveritySys from config file	88
1280	Parsing value for IpInIpTunnelAddr <*> from datastore per-host	88
1281	Parsed value for IpInIpTunnelAddr <*> from datastore per-host	88
1282	Parsing value for ClusterGUID <*> from datastore global	88
1283	Parsed value for ClusterGUID <*> from datastore global	88
1284	Parsing value for ClusterType k8s bgp kubeadm kdd from datastore global	88
1285	Parsed value for ClusterType k8s bgp kubeadm kdd from datastore global	88
1286	Parsing value for CalicoVersion <*> from datastore global	88
1287	Parsed value for CalicoVersion <*> from datastore global	88
1288	Parsing value for LogSeverityScreen Info from datastore global	88
1289	Parsed value for LogSeverityScreen INFO from datastore global	88
1290	Parsing value for IpInIpEnabled true from datastore global	88
1291	Parsed value for IpInIpEnabled true from datastore global	88
1292	Parsing value for ReportingIntervalSecs 0 from datastore global	88
1293	Parsed value for ReportingIntervalSecs 0s from datastore global	88
1294	Merging in config from datastore per-host map IpInIpTunnelAddr <*>	44
1295	Waiting before first check-in delay <*>	44
1296	Linux interface addrs changed. addrs set.mapSet ifaceName tunl0	44
1297	First flush after becoming in sync sending InSync message.	44
1298	Datastore now in sync.	44
1299	Datastore in sync for first time sending message to status reporter.	44
1300	&intdataplane.ifaceAddrsUpdate Name tunl0 Addrs set.mapSet	11
1301	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name tunl0 Addrs set.mapSet	11
1302	Datastore in sync flushing the dataplane for the first time... timeSinceStart <*>	44
1303	Checking for completed log grep pods in iteration 4 cluster <*>	33
1304	IPAM pools updated refreshing iptables rule ipVersion <*>	44
1305	All-hosts IP set out-of sync refreshing it.	121
1306	Trying to connect to linkClient	44
1307	Public key out of sync or updated ourPublicKey AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA	44
1308	Doing full IP set rewrite family inet numMembersInPendingReplace <*> setID <*>	330
1309	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	88
1310	<*> <*> <*> bird Reconfiguration requested by SIGHUP	110
1311	Target config <*> has been updated due to change in key <*>	176
1312	Completed first update to dataplane. secsSinceStart <*>	44
1313	<*> <*> <*> bird Reconfiguring	110
1314	Health of component changed lastReport health.HealthReport Live true Ready false name <*> newReport &health.HealthReport Live true Ready true	11
1315	Tunnel wasn t admin up enabling it flags 0 mtu <*> tunnelAddr <*>	44
1316	<*> <*> <*> bird <*> Reconfigured	770
1317	Set tunnel admin up mtu <*> tunnelAddr <*>	44
1318	Address wasn t present adding it. addr <*> link tunl0	44
1319	Linux interface state changed. ifIndex <*> ifaceName tunl0 state up	44
1320	Linux interface addrs changed. addrs set.mapSet <*> set.empty ifaceName tunl0	44
1321	&intdataplane.ifaceUpdate Name tunl0 State up Index <*>	11
1322	&intdataplane.ifaceAddrsUpdate Name tunl0 Addrs set.mapSet <*> set.empty	11
1323	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name tunl0 Addrs set.mapSet <*> set.empty	11
1324	<*> <*> <*> bird Reconfigured	110
1325	Doing full IP set rewrite family inet numMembersInPendingReplace 4 setID <*>	110
1326	Netlink address update. addr <*> exists true ifIndex <*>	99
1327	<*> <*> <*> bird <*> Initializing	154
1328	<*> <*> <*> bird <*> Starting	165
1329	<*> <*> <*> bird <*> Connected to table master	165
1330	<*> <*> <*> bird <*> State changed to feed	165
1331	<*> <*> <*> bird <*> State changed to start	121
1332	Target has failed health check marking for remediation message Node failed to report startup in <*> reason NodeStartupTimeout target <*>	77
1333	<*> <*> <*> bird Graceful restart started	22
1334	<*> <*> <*> bird Started	22
1335	<*> <*> <*> bird <*> State changed to up	165
1336	<*> <*> <*> <*> Created container cluster-management-agent	6
1337	<*> <*> <*> <*> Started container cluster-management-agent	5
1338	Deleting Kubernetes Node associated with Machine is not allowed cluster <*> machine <*> namespace <*> cause noderef is nil node null	42
1339	<*> <*> <*> bird Graceful restart done	22
1340	<*> <*> <*> bird <*> State changed to wait	66
1341	Reconciler error error <*> <*> not found controller machine name <*> namespace <*>	6
1342	Overall health status changed newStatus &health.HealthReport Live true Ready true	11
1343	Recompute BGP peerings <*> updated	132
1344	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name network_v4 updated	88
1345	<*> <*> <*> bird Adding protocol <*>	55
1346	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>	33
1347	<*> <*> <*>	55
1348	Initial delay complete doing first report	33
1349	Reporting cluster usage/checking for deprecation warnings. alpEnabled false calicoVersion <*> clusterGUID <*> clusterType k8s bgp kubeadm kdd gitRevision <*> kubernetesVersion <*> stats calc.StatsUpdate NumHosts <*> NumWorkloadEndpoints <*> NumHostEndpoints 0 NumPolicies 0 NumProfiles <*> NumALPPolicies 0 version <*>	198
1350	First report done starting ticker	33
1351	Summarising <*> dataplane reconciliation loops over <*> avg 0s longest <*> <*>	44
1352	Netlink address update. addr <*> exists false ifIndex <*>	66
1353	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*>	99
1354	Linux interface addrs changed. addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> fe9c <*> set.empty ifaceName eth0	11
1355	&intdataplane.ifaceAddrsUpdate Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> fe9c <*> set.empty	11
1356	Interface addrs changed. update &intdataplane.ifaceAddrsUpdate Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> fe9c <*> set.empty	11
1357	sync <*> failed with <*> <*> not found	11
1358	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> <*> Consumed <*> <*> CPU time	22
1359	CreateContainer within sandbox <*> for container &ContainerMetadata Name cluster-management-agent Attempt <*>	22
1360	CreateContainer within sandbox <*> for &ContainerMetadata Name cluster-management-agent Attempt <*> returns container id <*>	22
1361	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> Started libcontainer container <*>	198
1362	<*> <*> <*> <*> <*> <*> <*> I | etcdserver/membership added member <*> https <*> <*> to cluster <*>	11
1363	<*> <*> <*> <*> <*> <*> <*> W | etcdserver failed to reach the peerURL https <*> <*> of member <*> Get https <*> <*> dial tcp <*> <*> connect connection refused	11
1364	<*> <*> <*> <*> <*> <*> <*> W | etcdserver cannot get the version of member <*> Get https <*> <*> dial tcp <*> <*> connect connection refused	11
1365	<*> <*> <*> <*> <*> <*> <*> WARN <*> stepped down to <*> since quorum is not active	11
1366	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error context canceled took too long <*> to execute	264
1367	<*> <*> <*> WARNING <*> <*> <*> <*> grpc <*> failed to write status connection error desc transport is closing	341
1368	<*> <*> <*> <*> <*> <*> <*> INFO <*> is starting a new election at term <*>	55
1369	<*> <*> <*> <*> <*> <*> <*> INFO <*> received MsgVoteResp from <*> at term <*>	66
1370	<*> <*> <*> <*> <*> <*> <*> INFO <*> logterm <*> index <*> sent MsgVote request to <*> at term <*>	55
1371	<*> <*> <*> <*> <*> <*> <*> W | etcdserver/api/etcdhttp <*> error no leader status code <*>	11
1372	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error context deadline exceeded took too long <*> to execute	99
1373	<*> <*> <*> <*> <*> <*> <*> INFO <*> became <*> at term 4	11
1374	<*> <*> <*> <*> <*> <*> <*> INFO <*> received MsgVoteResp from <*> at term 4	11
1375	<*> <*> <*> <*> <*> <*> <*> INFO <*> logterm <*> index <*> sent MsgVote request to <*> at term 4	11
1376	<*> <*> <*> <*> <*> <*> <*> W | rafthttp health check for peer <*> could not connect dial tcp <*> <*> connect connection refused	44
1377	<*> <*> <*> <*> <*> <*> <*> INFO <*> is starting a new election at term 4	11
1378	<*> <*> <*> <*> <*> <*> <*> W | etcdserver timed out waiting for read index response local node might have slow network	22
1379	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error etcdserver request timed out took too long <*> to execute	110
1380	<*> <*> <*> <*> <*> <*> <*> INFO <*> became <*> at term 6	11
1381	<*> <*> <*> <*> <*> <*> <*> INFO <*> received MsgVoteResp from <*> at term 6	11
1382	<*> <*> <*> <*> <*> <*> <*> INFO <*> logterm <*> index <*> sent MsgVote request to <*> at term 6	11
1383	<*> <*> <*> <*> <*> <*> <*> INFO <*> is starting a new election at term 6	11
1384	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result error context canceled took too long <*> to execute	22
1385	<*> <*> <*> <*> <*> <*> <*> INFO <*> has received <*> MsgVoteResp votes and 0 vote rejections	11
1386	<*> <*> <*> <*> <*> <*> <*> INFO <*> became leader at term <*>	11
1387	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error etcdserver leader changed took too long <*> to execute	275
1388	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result error etcdserver leader changed took too long <*> to execute	176
1389	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result error etcdserver leader changed took too long <*> to execute	2057
1390	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result error etcdserver leader changed took too long <*> to execute	11
1391	Topology Admit Handler	88
1392	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> Created slice libcontainer container <*>	88
1393	<*> <*> <*> <*> <*> <*> <*> I | rafthttp start to send database snapshot index <*> to <*> size <*> MB ...	11
1394	<*> <*> <*> <*> <*> <*> <*> I | etcdserver wrote database snapshot out total bytes <*>	11
1395	<*> <*> <*> <*> <*> <*> <*> I | rafthttp database snapshot index <*> to <*> sent out successfully	11
1396	<*> <*> <*> <*> <*> <*> <*> W | rafthttp closed an existing TCP streaming connection with peer <*> stream MsgApp <*> writer	11
1397	<*> <*> <*> <*> <*> <*> <*> W | rafthttp closed an existing TCP streaming connection with peer <*> stream Message writer	11
1398	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result error etcdserver request timed out took too long <*> to execute	165
1399	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count <*> size <*> took too long <*> to execute	957
1400	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count 0 size <*> took too long <*> to execute	869
1401	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count 6 size <*> took too long <*> to execute	187
1402	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count 4 size <*> took too long <*> to execute	55
1403	<*> <*> <*> <*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result range_response_count 6 size <*> took too long <*> to execute	11
1404	Before broadcastjob reconcile <*> desired <*> active 4 failed 0	88
1405	After broadcastjob reconcile <*> desired <*> active 4 failed 0	88
1406	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active 4 Succeeded <*> Failed 0 Desired <*> Phase running	88
1407	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active <*> Succeeded 4 Failed 0 Desired <*> Phase running	88
1408	Container Name mold-manager	33
1409	starting mold manager	22
1410	ImageBuilderPath spectrocluster <*> ImageBuilderPath <*>	12254
1411	NewImageBuilderPath spectrocluster <*> NewImageBuilderPath <*>	12254
1412	########### login to vcenter for soap client ###############	22
1413	########### login to vcenter for rest client ###############	22
1414	found vm with inventory path spectrocluster <*> InventoryPath <*>	12254
1415	No customization needed same base image exists in vcenter spectrocluster <*> imageId https <*>	12254
1416	Condition spectrocluster <*> Condition type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully	12254
1417	Pod Labels <*> <*> name <*> <*> <*>	150
1418	Pod Labels kvdb true operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx	25
1419	Pod Labels name stork <*> <*> tier control-plane	30
1420	Container Name stork	66
1421	Kubernetes watch closed attempting to re-establish	5324
1422	watch re-established	5610
1423	Pod Labels component scheduler <*> <*> tier control-plane	25
1424	Pod Labels <*> <*> tier control-plane component scheduler	5
1425	Pod Labels <*> <*> <*> <*> name <*>	15
1426	Pod Labels name <*> <*> <*> <*> <*>	15
1427	Pod Labels <*> <*> name portworx operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx storage true	100
1428	Pod Labels app <*> <*> <*>	25
1429	Pod Labels operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx storage true <*> <*> name portworx	25
1430	Pod Labels name portworx operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx storage true <*> <*>	35
1431	Pod Labels operator.libopenstorage.org/name portworx storage true <*> <*> name portworx operator.libopenstorage.org/driver portworx	5
1432	Container Name portworx	396
1433	Action <*> data <nil> AttachedOn <*> Driver kernel Error <nil> Function VolumeStateChange ID <*> State VOLUME_STATE_ATTACHED Version <*>	140052
1434	Action <*> data <nil> AttachedOn Driver kernel Error <nil> Function VolumeStateChange ID <*> State VOLUME_STATE_DETACHED Version <*>	50618
1435	Pod Labels name <*> <*> <*>	10
1436	Action 4 data <nil> AttachedOn Driver kernel Error <nil> Function VolumeStateChange ID <*> State VOLUME_STATE_DELETED Version <*>	25344
1437	Pod Labels job-name <*> controller-uid <*>	5
1438	Pod Labels <*> bootstrap-kubeadm control-plane controller-manager <*> <*>	5
1439	Pod Labels app <*> <*> <*> release <*>	10
1440	Pod Labels broadcastjob-name <*> <*> proxy <*> host <*> skip <*> <*>	20
1441	remove_device_from_map <*>	25344
1442	unfreeze <*>	1023
1443	Pod Labels <*> <*> <*> infrastructure-metal3 control-plane controller-manager <*> <*>	5
1444	Volume Name <*> Id <*> Path <*> unmounted successfully	1023
1445	Monitoring storage nodes	6611
1446	Removing backing storage for device <*> pool 0 on <*>	2112
1447	Detaching AbortOnError false AttachedState ATTACH_STATE_INTERNAL_SWITCH Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	2618
1448	Container Name main	22
1449	PVC with name <*> and namespace smoketest for volumeID <*> already deleted. Skipping check for volume bound	1419
1450	delete <*> started	1309
1451	Pod Labels <*> <*> <*> proxy control-plane controller-manager	10
1452	unable to determine resource for scale target reference no matches for kind Deployment in group extensions	8229
1453	delete <*> volume deleted	1309
1454	Delete AbortOnError false AttachedState ATTACH_STATE_INTERNAL_SWITCH Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_DELETED Version <*>	1419
1455	Reconciling StorageCluster file storagecluster.go <*> Request.Name portworx Request.Namespace <*>	18
1456	Pod Labels <*> proxy app spectro component cluster-management-agent log-regex logrus-text module ally <*> <*>	5
1457	process_cdb_update dev <*> rset 0 node <*> curr <*> next <*> new_rset empty remove empty pool_ids 0 new_pool_ids empty	2024
1458	unable to fetch pod metrics for pod <*> no metrics known for pod	6842
1459	Event occurred object <*> kind HorizontalPodAutoscaler apiVersion <*> type Warning reason FailedGetScale message no matches for kind Deployment in group extensions	8225
1460	delete <*> persistentvolume deleted	1309
1461	StorageCluster Predicates failed on node <*> for storage cluster portworx for reason node s had taints that the pod didn t tolerate file storagecluster.go <*>	57
1462	process_cdb_update new state dev <*> rset 0 nodes <*> curr <*> new empty rem empty	2024
1463	delete <*> succeeded	1309
1464	StorageCluster Predicates failed on node <*> for storage cluster portworx for reason node s didn t match node selector file storagecluster.go <*>	51
1465	Pod Labels <*> <*> <*> infrastructure-vsphere control-plane controller-manager	5
1466	6 block_finish_io for dev <*> op_id <*>	351
1467	Volume PV access shared flag false	1419
1468	provision <*> class <*> started	2596
1469	detach AbortOnError false AttachedState ATTACH_STATE_INTERNAL_SWITCH Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_DETACHED Version <*>	2440
1470	Selected domains map map map	1419
1471	Event <*> Kind PersistentVolumeClaim Namespace smoketest Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason Provisioning External provisioner is provisioning volume for claim <*>	1309
1472	cos LOW ha <*> aggr <*> pools map zones map racks map domains map exclude map use false force false placement <nil> usage 0	1419
1473	<*> <*> <*> <*> systemd <*> Starting Message of the Day...	363
1474	create volume rep CapacityBytes <*> VolumeId <*> VolumeContext map attached ATTACH_STATE_INTERNAL_SWITCH error parent readonly false secure false shared false sharedv4 false state VOLUME_STATE_DETACHED ContentSource <nil> AccessibleTopology XXX_NoUnkeyedLiteral XXX_unrecognized XXX_sizecache 0	1309
1475	Failed to delete mount path <*> remove <*> operation not permitted	6031
1476	<*> <*> <*> <*> systemd <*> Started Message of the Day.	352
1477	provision region <*> aggr <*> ha <*> selectAll false use false	1419
1478	successfully created PV <*> for PVC <*> and csi volume name <*>	1309
1479	unmount ignoring attached remote error Volume is detached. Using device path <*>	6021
1480	pool <*>	1419
1481	provision <*> class <*> volume <*> provisioned	1309
1482	Volume Name <*> Id <*> Path <*> was not mounted.	6018
1483	attach AbortOnError true AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format FS_TYPE_NONE Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	1419
1484	provision <*> class <*> succeeded	1309
1485	Event <*> Kind PersistentVolumeClaim Namespace smoketest Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason ProvisioningSucceeded Successfully provisioned volume <*>	1309
1486	Fetching manifest with uid <*> for pack dex cluster <*>	3740
1487	update_nodes dev <*> rset 0 curr <*> next <*> next clean empty resync to <*>	1034
1488	Applying additional pack manifests for pack <*> in config map cluster <*>	7480
1489	Device <*> starting repl set start event	2464
1490	Updating <*> with name <*> in namespace <*> cluster <*>	7480
1491	attach_if_mounted dev <*> should be mounted but is not	2464
1492	Formatting... AbortOnError true AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format FS_TYPE_NONE Function fsOps.format ID <*> State VOLUME_STATE_ATTACHED Version <*>	1419
1493	Applied additional pack manifests for pack <*> in config map cluster <*>	7480
1494	format AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	1419
1495	Fetching manifest with uid <*> for pack <*> cluster <*>	7480
1496	Calico CNI releasing IP address ContainerID <*>	1683
1497	CRD watch closed attempting to re-establish	286
1498	Applying additional pack manifests for pack manifests-tkesystem in config map cluster <*>	3740
1499	Updating <*> with name manifests-tkesystem in namespace <*> cluster <*>	3740
1500	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-timesyncd <*> Synchronized to time server <*> <*> <*> .	1265
1501	ExecSync for <*> with command <*> <*> curl http <*> <*> <*> | ngrep <*> .+ n and timeout <*> s	10230
1502	Applied additional pack manifests for pack manifests-tkesystem in config map cluster <*>	3740
1503	Releasing address using handleID ContainerID <*> HandleID <*> Workload <*>	1683
1504	parsed scheme	4833
1505	<*> block_finish_io for dev <*> op_id <*>	2090
1506	Released address using handleID ContainerID <*> HandleID <*> Workload <*>	451
1507	scheme not registered fallback to default scheme	4832
1508	Failed to parse Failed to parse logs for pod <*> in namespace <*> as no suitable regex filter is found cluster <*>	3773
1509	provision <*> class <*> persistentvolume <*> already exists skipping	1287
1510	ccResolverWrapper sending update to cc <*> <nil> 0 <nil> <nil> <nil>	4831
1511	Releasing address using workloadID ContainerID <*> HandleID <*> Workload <*>	1683
1512	Failed to get log lines Failed to parse logs cluster <*>	3773
1513	reconcile charts atop Namespace <*> Name vault	990
1514	Failed to process logs Failed to parse logs cluster <*>	3773
1515	looking for releases filter vault namespace vault	2970
1516	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv4 martian source <*> from <*> on dev <*>	110
1517	Pushed >>> <*> metrics s cluster <*>	3201
1518	blockingPicker the picked transport is not ready loop back to repick	4807
1519	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff d2 <*> a6 f2 0f <*> <*> <*> ........... ..	11
1520	Removing mount path directory <*>	1001
1521	Teardown processing complete. ContainerID <*>	1683
1522	Attach for <*> with tty false and stdin false	154
1523	TearDown network for sandbox <*> successfully	2079
1524	Volume <*> unmounted from path <*>	1001
1525	Attach for <*> returns URL http <*> <*>	154
1526	StopPodSandbox for <*> returns successfully	2079
1527	<*> <*> <*> http2 server error reading preface from client <*> <*> read tcp <*> <*> <*> read connection reset by peer	99
1528	operationExecutor.VerifyControllerAttachedVolume started for volume <*> UniqueName <*> pod temp UID <*>	363
1529	Event occurred object <*> kind StatefulSet apiVersion <*> type Normal reason SuccessfulCreate message create Claim <*> Pod <*> in StatefulSet <*> success	869
1530	StopPodSandbox for <*>	2013
1531	Event occurred object <*> kind PersistentVolumeClaim apiVersion <*> type Normal reason ExternalProvisioning message waiting for a volume to be created either by external provisioner pxd.portworx.com or manually created by system administrator	1404
1532	Attach stream <*> closed	308
1533	Container to stop <*> must be in running or unknown state current state CONTAINER_EXITED	1595
1534	found release releases name <*> namespace vault revision <*> updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version <*>	2970
1535	begin helm get manifest namespace vault release <*>	1980
1536	Starting cloudsnap cleanup for cred <*>	242
1537	Path <*> does not exist	440
1538	Event occurred object <*> kind StatefulSet apiVersion <*> type Normal reason SuccessfulCreate message create Pod <*> in StatefulSet <*> successful	869
1539	TaskExit event &TaskExit ContainerID <*> ID <*> Pid <*> ExitStatus 0 ExitedAt <*> <*> <*> <*> <*> UTC XXX_unrecognized	638
1540	RunPodsandbox for &PodSandboxMetadata Name temp Uid <*> Namespace monitoring Attempt 0	264
1541	Cleaning up netns ContainerID <*>	1661
1542	Attaching pxd volume <*> to host	1045
1543	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Gained IPv6LL	319
1544	helm get manifest complete namespace vault release <*>	1980
1545	Releasing IP address es ContainerID <*>	1661
1546	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-timesyncd <*> Network configuration changed trying to establish connection.	1177
1547	attach AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	1045
1548	datadir <*> atop Namespace <*> Name vault	990
1549	begin helm reconcile for release name vault	990
1550	topologymanager RemoveContainer <*> Container ID <*>	4059
1551	FsResizeRequired false FsckRequiredForResize false scanPolicy Trigger SCAN_TRIGGER_NONE Action SCAN_ACTION_NONE AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function isAutoFsckRequired ID <*> State VOLUME_STATE_ATTACHED Version <*>	1045
1552	Volume Name <*> Id <*> Path <*> mounted successfully.	1045
1553	StopContainer for <*> with timeout <*> s	374
1554	helm inspect complete output name vault version <*> apiVersion <*> appVersion <*> ChartPath <*>	990
1555	Volume <*> mounted on <*>	1045
1556	Asked to release address but it doesn t exist. Ignoring ContainerID <*> HandleID <*> Workload <*>	1232
1557	Stop container <*> with signal terminated	253
1558	operationExecutor.UnmountVolume started for volume <*> UniqueName <*> pod <*> UID <*>	841
1559	UnmountVolume.TearDown succeeded for volume <*> OuterVolumeSpecName <*> pod <*> UID <*> . InnerVolumeSpecName <*> . PluginName <*> VolumeGidValue	693
1560	helm charts reconciled successfully for pack vault atop Namespace <*> Name vault files <*>	990
1561	WorkloadEndpoint does not exist in the datastore moving forward with the clean up ContainerID <*> WorkloadEndpoint <*>	1364
1562	StopContainer for <*> returns successfully	451
1563	reconcile manifests atop Namespace <*> Name vault	990
1564	Error syncing pod <*> <*> <*> skipping failed to StartContainer for <*> with CrashLoopBackOff back-off <*> restarting failed container <*> pod <*> <*>	2640
1565	SYNC Machines in store is in sync with hubble cluster <*>	852
1566	Calico CNI found existing endpoint & WorkloadEndpoint <*> <*> monitoring <*> <*> 0 <*> <*> <*> <*> <*> UTC <nil> <nil> map <*> monitoring <*> k8s <*> default run temp map k8s <*> temp eth0 <*> <*> <*> ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1567	Calico CNI deleting device in netns <*> ContainerID <*>	429
1568	reconcile service status atop Namespace <*> Name vault	990
1569	Extracted identifiers for CmdAddK8s ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1570	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Link DOWN	429
1571	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Lost carrier	429
1572	Auto assigning IP ContainerID <*> HandleID <*> Workload <*> assignArgs ipam.AutoAssignArgs Num4 <*> Num6 0 HandleID string <*> Attrs map string string namespace monitoring node <*> pod temp timestamp <*> <*> <*> <*> <*> UTC Hostname <*> IPv4Pools <*> IPv6Pools <*> MaxBlocksPerHost 0 HostReservedAttrIPv4s ipam.HostReservedAttr nil HostReservedAttrIPv6s ipam.HostReservedAttr nil	264
1573	Volume detached for volume <*> UniqueName <*> on node <*> DevicePath	693
1574	CONTROLLER OnUpdate oldObj <*> PersistentVolumeClaimName <*> SnapshotDataName <*>	17270
1575	CONTROLLER OnUpdate newObj <*> PersistentVolumeClaimName <*> SnapshotDataName <*>	17270
1576	Calico CNI deleted device in netns <*> ContainerID <*>	429
1577	controlplane replica count up to date	2321
1578	kcp status spec <*> status selector <*> <*> <*> replicas <*> updatedReplicas <*> readyReplicas <*> initialized true ready true observedGeneration <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type Available status True lastTransitionTime <*> <*> <*> type CertificatesAvailable status True lastTransitionTime <*> <*> <*> type ControlPlaneComponentsHealthy status True lastTransitionTime <*> <*> <*> type EtcdClusterHealthyCondition status True lastTransitionTime <*> <*> <*> type MachinesReady status True lastTransitionTime <*> <*> <*> type MachinesSpecUpToDate status True lastTransitionTime <*> <*> <*> type Resized status True lastTransitionTime <*> <*> <*> version <*>	825
1579	begin worker reconcile	2321
1580	reconcile status done for pack pack vault release <*>	990
1581	reconciled chart service status for pack pack vault	990
1582	reconciled manifest service status for pack pack vault	990
1583	pack readiness status pack vault status true	990
1584	Populated endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC Ports <*> nil	264
1585	machineDeployment templates are up to date cluster <*> mdNum <*> pool <*>	6930
1586	Calico CNI using IPs <*> ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1587	starting to reconcile update strategy	6930
1588	Setting the host side veth name to <*> ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1589	StatefulSet has been deleted <*>	858
1590	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_UP <*> link is not ready	484
1591	Disabling IPv4 forwarding ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1592	Waiting for pending conntrack deletion to finish ip <*>	1782
1593	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_CHANGE <*> link becomes ready	484
1594	Done waiting for pending conntrack deletion to finish ip <*>	1782
1595	Container <*> not found in pod s containers	748
1596	finish reconcile for machine pool poolName <*>	6930
1597	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Link UP	484
1598	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-networkd <*> <*> Gained carrier	484
1599	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> c2 <*> <*> <*> Ports <*> nil	22
1600	<*> <*> <*> Nov <*> <*> <*> <*> <*> <*> <*> WARNING Unknown index <*> <*> <*> interface list	484
1601	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-udevd <*> link_config autonegotiation is unset or enabled the speed and duplex are not writable.	484
1602	Wrote updated endpoint to datastore ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*>	264
1603	veth does not exist no need to clean up. ContainerID <*> ifName eth0	440
1604	RunPodSandbox for &PodSandboxMetadata Name temp Uid <*> Namespace monitoring Attempt 0 returns sandbox id <*>	264
1605	PullImage <*> latest	605
1606	Trace <*> List etcd3 key <*> resourceVersion resourceVersionMatch limit 0 continue <*> <*> <*> <*> total time <*>	66
1607	finish reconcile for workers	2310
1608	Trace <*> List url <*> user-agent <*> linux/amd64 <*> client <*> <*> <*> <*> <*> total time <*>	44
1609	reconcileAPIEndpoint spectrocluster Namespace <*> Name <*>	2310
1610	<*> <*> <*> Trace <*> <*> Listing from storage done <*> <*> <*> <*>	44
1611	reconcileAPIEndpoint Done spectrocluster Namespace <*> Name <*>	2310
1612	reconcileLoadBalancerService spectrocluster Namespace <*> Name <*>	2310
1613	reconcileLoadBalancerService Done spectrocluster Namespace <*> Name <*>	2310
1614	reconcileInstallPriorityForPacks spectrocluster Namespace <*> Name <*>	2310
1615	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> a9 c7 <*> df Ports <*> nil	11
1616	ImageUpdate event &ImageUpdate Name <*> latest Labels map string string <*> managed XXX_unrecognized	1210
1617	marking addon packs ready for install spectrocluster Namespace <*> Name <*> cluster <*> installPriority 0	2310
1618	reconcileInstallPriorityForPacks done spectrocluster Namespace <*> Name <*>	2310
1619	begin migration on target spectrocluster Namespace <*> Name <*>	2310
1620	PullImage <*> latest returns image reference sha256 <*>	605
1621	podpreset migration already done spectrocluster Namespace <*> Name <*>	2310
1622	CreateContainer within sandbox <*> for container &ContainerMetadata Name temp Attempt 0	385
1623	finished migration on target spectrocluster Namespace <*> Name <*>	2310
1624	CreateContainer within sandbox <*> for &ContainerMetadata Name temp Attempt 0 returns container id <*>	385
1625	reconcile loop done spectrocluster Namespace <*> Name <*>	2310
1626	CreateContainer within sandbox <*> for container &ContainerMetadata Name <*> Attempt <*>	308
1627	healthz check failed checker webhook-ready error Op Get URL https <*> <*> Err Op dial Net tcp Source null Addr IP <*> Port <*> Zone Err Syscall connect Err <*>	33
1628	CreateContainer within sandbox <*> for &ContainerMetadata Name <*> Attempt <*> returns container id <*>	308
1629	healthz check failed statuses	33
1630	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> <*> c2 <*> <*> <*> <*> <*> ..............	22
1631	handleIoPatternChange <*> Resetting DB remote profile	132
1632	DerievedIoProfilerUpdaterOp AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	275
1633	handleIoPatternChange <*> Setting DB remote profile	143
1634	process_cdb_update dev <*> rset 0 node 0 <*> curr 0 <*> next 0 <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	88
1635	process_cdb_update new state dev <*> rset 0 nodes 0 <*> curr 0 <*> new empty rem empty	88
1636	process_cdb_update dev <*> rset 0 node <*> <*> curr <*> <*> next <*> <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	143
1637	process_cdb_update new state dev <*> rset 0 nodes <*> <*> curr <*> <*> new empty rem empty	143
1638	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> <*> a9 c7 <*> df <*> <*> ......VB......	11
1639	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted services name <*> ports protocol TCP port <*> host <*> name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name deviceservice-svc ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-config ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-pagerduty ports protocol TCP port <*> host <*> name tbot-support ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	374
1640	Updated lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message start to provision new cluster reason ProvisionStarts status True type Progressing lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Reconciliation on ImageCustomization Done Successfully reason ReconciliationDone status True type ImageCustomizationDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message cluster-api providers crd installed and controllers deployed reason CRDInstalled status True type ProviderReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Infrastructure is ready on cloud reason InfrastructureReady status True type CloudInfrastructureReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes addition done reason LaunchControlPlaneNode status True type ControlPlaneNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message all control plane nodes are updated reason NodesRunning status True type ControlPlaneReady lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message worker nodes created successfully reason NodeReady status True type WorkerNodeAdditionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message vault ready. dex ready. reason AddOnDeployed status True type AddOnDeploymentDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message control plane nodes deletion done reason DeleteControlPlaneNode status True type ControlPlaneNodeDeletionDone lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> message Worker nodes deleted reason NodeDeleted status True type WorkerNodeDeletionDone conditions for spectro cluster cluster <*>	528
1641	Pushed >>> 4 metrics s cluster <*>	539
1642	RunPodsandbox for &PodSandboxMetadata Name temp Uid <*> Namespace smoketest Attempt 0	99
1643	Calico CNI found existing endpoint & WorkloadEndpoint <*> <*> smoketest <*> <*> 0 <*> <*> <*> <*> <*> UTC <nil> <nil> map <*> smoketest <*> k8s <*> default run temp map k8s <*> temp eth0 <*> <*> <*> ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	99
1644	Extracted identifiers for CmdAddK8s ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	99
1645	Auto assigning IP ContainerID <*> HandleID <*> Workload <*> assignArgs ipam.AutoAssignArgs Num4 <*> Num6 0 HandleID string <*> Attrs map string string namespace smoketest node <*> pod temp timestamp <*> <*> <*> <*> <*> UTC Hostname <*> IPv4Pools <*> IPv6Pools <*> MaxBlocksPerHost 0 HostReservedAttrIPv4s ipam.HostReservedAttr nil HostReservedAttrIPv6s ipam.HostReservedAttr nil	99
1646	process_cdb_update dev <*> rset 0 node 4 <*> curr 4 <*> next 4 <*> new_rset empty remove empty pool_ids 0 0 new_pool_ids empty	44
1647	process_cdb_update new state dev <*> rset 0 nodes 4 <*> curr 4 <*> new empty rem empty	44
1648	Populated endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC Ports <*> nil	99
1649	Calico CNI using IPs <*> ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	99
1650	Setting the host side veth name to <*> ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	99
1651	Disabling IPv4 forwarding ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	121
1652	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC d6 dd 6a <*> <*> <*> Ports <*> nil	22
1653	Wrote updated endpoint to datastore ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*>	121
1654	RunPodSandbox for &PodSandboxMetadata Name temp Uid <*> Namespace smoketest Attempt 0 returns sandbox id <*>	121
1655	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC fe <*> 4f c2 a2 bf Ports <*> nil	11
1656	Failed to detach volume. AbortOnError false AttachedState ATTACH_STATE_INTERNAL_SWITCH Driver pxd Error Failed with status device or resource busy Format <*> Function Detaching ID <*> State VOLUME_STATE_ATTACHED Version <*>	176
1657	removeKernelDevice AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error <nil> Format <*> Function d.volumePut ID <*> State VOLUME_STATE_ATTACHED Version <*>	176
1658	detach failed. retry count 0 AbortOnError false AttachedState ATTACH_STATE_EXTERNAL Driver pxd Error Volume is busy Format <*> Function detachWithExponentialBackoff ID <*> State VOLUME_STATE_ATTACHED Version <*>	176
1659	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> d3 ee networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1660	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	792
1661	Failed to process watch event EventType 0 Name <*> WatchSource 0 task <*> not found not found	286
1662	Partial failure issuing cadvisor.ContainerInfoV2 partial failures <*> RecentStats unable to find data in memory cache	165
1663	Partial failure issuing cadvisor.ContainerInfoV2 partial failures <*> RecentStats unable to find data in memory cache <*> RecentStats unable to find data in memory cache	22
1664	reconcile charts atop Namespace <*> Name dex	979
1665	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> b1 a5 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1666	looking for releases filter dex namespace dex	2937
1667	found release releases name <*> namespace dex revision 4 updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version <*>	1122
1668	begin helm get manifest namespace dex release <*>	1958
1669	helm get manifest complete namespace dex release <*>	1958
1670	datadir <*> atop Namespace <*> Name dex	979
1671	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> e2 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1672	begin helm reconcile for release name dex	979
1673	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> fc <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1674	helm inspect complete output name dex version <*> apiVersion <*> appVersion <*> ChartPath <*>	979
1675	helm charts reconciled successfully for pack dex atop Namespace <*> Name dex files <*>	979
1676	reconcile manifests atop Namespace <*> Name dex	979
1677	Couldn t get containers partial failures <*> containerDataToContainerInfo unable to find data in memory cache	33
1678	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> Device <*> added with mode 0x0 fastpath 0 npath 0	165
1679	kube apply success atop Namespace <*> Name dex file <*>	979
1680	reconcile service status atop Namespace <*> Name dex	979
1681	<*> <*> <*> <*> systemd <*> Starting Cleanup of Temporary Directories...	176
1682	<*> <*> <*> <*> systemd <*> Started Cleanup of Temporary Directories.	176
1683	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a0 cd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1684	reconcile status done for pack pack dex release <*>	979
1685	reconciled chart service status for pack pack dex	979
1686	reconciled manifest service status for pack pack dex	979
1687	pack readiness status pack dex status true	979
1688	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> af networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1689	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> cd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1690	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a2 c2 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1691	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> d3 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1692	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> c8 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1693	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6d cb networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1694	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> f3 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1695	RemovePodSandbox for <*>	605
1696	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 3a a0 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1697	RemovePodSandbox <*> returns successfully	605
1698	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> ab <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1699	Summarising <*> dataplane reconciliation loops over <*> avg <*> longest <*> <*> <*> <*> <*> <*>	22
1700	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> ec networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1701	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a9 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1702	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6d f4 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1703	EVENT <*> Resource vspheremachines Type ADDED JSON Msg metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> c4 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	88
1704	id <name atlascustomerjourney-prd > labels <key <*> value <*> > labels <key <*> value sshirey > labels <key <*> value unknown > labels <key <*> value sanugu > labels <key <*> value <*> > labels <key <*> value > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value atlascustomerjourney-prd >	396
1705	<*> attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...	55
1706	MountVolume.MountDevice succeeded for volume <*> UniqueName <*> pod <*> UID <*> device mount path <*>	55
1707	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active <*> Succeeded 6 Failed 0 Desired <*> Phase running	22
1708	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> <*> <*> mounted filesystem with ordered data mode. Opts discard	55
1709	RunPodsandbox for &PodSandboxMetadata Name <*> Uid <*> Namespace smoketest Attempt 0	55
1710	Calico CNI found existing endpoint & WorkloadEndpoint <*> <*> <*> smoketest <*> <*> 0 <*> <*> <*> <*> <*> UTC <nil> <nil> map app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> map k8s <*> <*> eth0 <*> <*> <*> ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1711	Extracted identifiers for CmdAddK8s ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1712	Auto assigning IP ContainerID <*> HandleID <*> Workload <*> assignArgs ipam.AutoAssignArgs Num4 <*> Num6 0 HandleID string <*> Attrs map string string namespace smoketest node <*> pod <*> timestamp <*> <*> <*> <*> <*> UTC Hostname <*> IPv4Pools <*> IPv6Pools <*> MaxBlocksPerHost 0 HostReservedAttrIPv4s ipam.HostReservedAttr nil HostReservedAttrIPv6s ipam.HostReservedAttr nil	55
1713	Populated endpoint ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC Ports <*> nil	55
1714	Calico CNI using IPs <*> ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1715	Setting the host side veth name to <*> ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1716	Disabling IPv4 forwarding ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1717	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_UP eth0 link is not ready	308
1718	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> IPv6 ADDRCONF NETDEV_CHANGE eth0 link becomes ready	308
1719	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC 3e <*> <*> <*> <*> <*> Ports <*> nil	11
1720	Wrote updated endpoint to datastore ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*>	55
1721	RunPodSandbox for &PodSandboxMetadata Name <*> Uid <*> Namespace smoketest Attempt 0 returns sandbox id <*>	55
1722	CreateContainer within sandbox <*> for container &ContainerMetadata Name <*> Attempt 0	55
1723	CreateContainer within sandbox <*> for &ContainerMetadata Name <*> Attempt 0 returns container id <*>	55
1724	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> type ExternalIP address <*> network connected true ipAddrs <*> <*> macAddr <*> <*> <*> <*> f3 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1725	Failed to watch <*> failed to list <*> the server could not find the requested resource get <*>	18411
1726	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	693
1727	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> c8 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1728	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6d f4 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1729	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> cd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1730	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> d3 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1731	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> c4 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1732	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> ab <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1733	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> ec networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1734	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a2 c2 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1735	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 3a a0 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1736	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> d3 ee networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1737	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a0 cd networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1738	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> fc <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1739	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> b1 a5 networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1740	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> e2 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1741	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind KubeadmControlPlane name <*> uid <*> apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid k uid <*> . f apiVersion f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs 4 memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> a9 <*> networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1742	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> <*> af networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1743	Before broadcastjob reconcile <*> desired <*> active 6 failed 0	66
1744	EVENT <*> Resource vspheremachines Type ADDED JSON Msg kind VSphereMachine apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> annotations <*> <*> <*> <*> ownerReferences apiVersion <*> kind Machine name <*> uid <*> controller true blockOwnerDeletion true finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f finalizers . v <*> f labels . f <*> f <*> f <*> f <*> f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f cloneMode f datacenter f datastore f diskGiB f folder f memoryMiB f network . f devices f numCPUs f providerID f resourcePool f template f status . f addresses f conditions f network f ready spec template <*> cloneMode fullClone datacenter <*> folder <*> datastore <*> resourcePool <*> network devices networkName <*> gateway4 <*> ipAddrs <*> nameservers <*> <*> searchDomains numCPUs <*> memoryMiB <*> diskGiB <*> providerID vsphere <*> status ready true addresses type ExternalIP address <*> network connected true ipAddrs <*> macAddr <*> <*> <*> <*> 6d cb networkName <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type VMProvisioned status True lastTransitionTime <*> <*> <*> cluster <*>	77
1745	After broadcastjob reconcile <*> desired <*> active 6 failed 0	66
1746	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active 6 Succeeded <*> Failed 0 Desired <*> Phase running	22
1747	Kill container <*>	33
1748	id <namespace esim-stage name default > labels <key <*> value default >	209
1749	ContainerStatus for <*> failed error an error occurred when try to find container <*> does not exist	33
1750	id <namespace esim-stage name <*> > labels <key <*> value <*> >	220
1751	ContainerStatus <*> from runtime service failed rpc error code Unknown desc an error occurred when try to find container <*> does not exist	33
1752	pod_container_deletor DeleteContainer returned error for id containerd <*> failed to get container status <*> rpc error code Unknown desc an error occurred when try to find container <*> does not exist	33
1753	Operation for volumeName <*> podName <*> nodeName failed. No retries permitted until <*> <*> <*> <*> <*> UTC m <*> durationBeforeRetry <*> . Error UnmountVolume.TearDown failed for volume <*> UniqueName <*> pod <*> UID <*> <*> mounter.TearDownAt failed rpc error code Internal desc Mount path still exists <*>	138
1754	<*> <*> <*> <*> Readiness probe failed Get http <*> <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	8
1755	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC fa bd <*> f3 c0 <*> Ports <*> nil	22
1756	id <namespace aqua name <*> > labels <key deployedby value <*> > labels <key <*> value <*> >	143
1757	id <namespace aqua name <*> > labels <key <*> value <*> >	132
1758	id <namespace velero name default > labels <key <*> value default >	77
1759	id <namespace velero name velero > labels <key component value velero > labels <key <*> value velero >	77
1760	id <namespace aqua name default > labels <key <*> value default >	77
1761	id <namespace <*> name default >	77
1762	id <namespace <*> name <*> >	88
1763	id <namespace atlascustomerjourney-prd name default > labels <key <*> value default >	154
1764	id <namespace ext-ingress name default > labels <key <*> value default >	165
1765	id <namespace <*> name <*> > labels <key app value strimzi > labels <key <*> value <*> >	143
1766	id <namespace atlascustomerjourney-prd name svc-tke-atlascustomerjourneyprd > labels <key <*> value svc-tke-atlascustomerjourneyprd >	165
1767	id <namespace ext-ingress name <*> > labels <key <*> value admission-webhook > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	165
1768	id <namespace ext-ingress name <*> > labels <key <*> value controller > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	187
1769	id <namespace <*> name <*> > labels <key app value <*> > labels <key <*> value <*> >	165
1770	id <namespace ext-ingress name <*> > labels <key <*> value default-backend > labels <key <*> value <*> > labels <key <*> value Helm > labels <key <*> value <*> > labels <key <*> value <*> > labels <key helm.sh/chart value <*> > labels <key <*> value <*> >	187
1771	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd-timesyncd <*> Timed out waiting for reply from <*> <*> <*> .	154
1772	id <namespace <*> name <*> > labels <key app value istio-ingressgateway > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key istio value ingressgateway > labels <key <*> value IngressGateways > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	22
1773	id <namespace <*> name <*> > labels <key app value istio-egressgateway > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key istio value egressgateway > labels <key <*> value EgressGateways > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	22
1774	id <namespace <*> name <*> > labels <key app value kiali > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key <*> value AddonComponents > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value <*> > labels <key release value istio >	22
1775	id <namespace <*> name prometheus > labels <key app value prometheus > labels <key <*> value installed-state > labels <key <*> value <*> > labels <key <*> value AddonComponents > labels <key <*> value Reconcile > labels <key <*> value <*> > labels <key <*> value prometheus > labels <key release value istio >	22
1776	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> a3 <*> 0a fb 2e Ports <*> nil	22
1777	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> a3 <*> 0a fb 2e <*> <*> ..............	22
1778	id <name dex > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value dex >	33
1779	id <name vault > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value vault >	33
1780	id <name default > labels <key <*> value <*> > labels <key <*> value default >	22
1781	id <name default > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value default >	33
1782	id <name willitconnect > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value willitconnect >	33
1783	id <name <*> > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> > labels <key <*> value <*> >	33
1784	id <name <*> > labels <key app value magtape > labels <key <*> value <*> > labels <key <*> value <*> >	33
1785	id <name smoketest > labels <key <*> value <*> > labels <key <*> value smoketest >	33
1786	id <name collectorforkubernetes > labels <key <*> value <*> > labels <key <*> value collectorforkubernetes >	33
1787	id <name monitoring > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value <*> > labels <key <*> value monitoring >	33
1788	id <name std-ingress > labels <key app value std-ingress > labels <key <*> value <*> > labels <key <*> value std-ingress >	33
1789	id <name <*> > labels <key <*> value <*> >	88
1790	id <name <*> > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value unknown > labels <key <*> value atippar1 > labels <key <*> value <*> > labels <key <*> value > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value <*> >	55
1791	id <name monitoring > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value RMcguir4 > labels <key <*> value <*> > labels <key <*> value monitoring >	187
1792	id <name velero > labels <key component value velero > labels <key <*> value velero >	22
1793	id <name std-ingress > labels <key app value std-ingress > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value TBD > labels <key <*> value std-ingress >	33
1794	id <name velero > labels <key component value velero > labels <key <*> value <*> > labels <key <*> value velero >	11
1795	id <name aqua > labels <key <*> value aqua >	11
1796	id <name velero > labels <key component value velero > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value velero >	11
1797	id <name aqua > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value aqua >	33
1798	id <name <*> > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	176
1799	id <name esim-stage > labels <key istio-injection value enabled > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value abentle1 > labels <key <*> value unknown > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value esim-stage >	88
1800	id <name <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	187
1801	id <name <*> > labels <key app value magtape > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value <*> >	55
1802	id <name smoketest > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value smoketest >	55
1803	id <name collectorforkubernetes > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value collectorforkubernetes >	55
1804	id <name velero > labels <key component value velero > labels <key <*> value <*> > labels <key <*> value RMcguir4 > labels <key <*> value velero >	33
1805	id <name <*> > labels <key app value <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value RMcguir4 > labels <key <*> value proxyman-alerts > labels <key <*> value <*> >	88
1806	id <name <*> > labels <key istio-injection value enabled > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value abentle1 > labels <key <*> value unknown > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value <*> >	88
1807	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> fb <*> <*> <*> <*> Ports <*> nil	22
1808	id <name smoketest > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value smoketest >	22
1809	id <name <*> > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value <*> >	33
1810	id <name <*> > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value unknown > labels <key <*> value cpoojar5 > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value enabled > labels <key <*> value <*> >	88
1811	id <name <*> > labels <key app value magtape > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value <*> >	22
1812	id <name collectorforkubernetes > labels <key <*> value <*> > labels <key <*> value RMcquir4 > labels <key <*> value collectorforkubernetes >	11
1813	id <name <*> > labels <key control-plane value controller-manager > labels <key <*> value mesh > labels <key <*> value <*> >	66
1814	Trace <*> Get url <*> user-agent <*> client <*> <*> <*> <*> <*> total time <*>	22
1815	<*> <*> <*> Trace <*> <*> Transformed response object <*> <*> <*> <*>	22
1816	id <name <*> > labels <key app value <*> > labels <key control-plane value controller-manager > labels <key <*> value mesh > labels <key <*> value proxyman-alerts > labels <key <*> value <*> >	33
1817	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> fb <*> <*> <*> <*> <*> <*> <*>	22
1818	id <name <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value <*> >	22
1819	id <name <*> > labels <key app value <*> > labels <key control-plane value controller-manager > labels <key <*> value <*> > labels <key <*> value mesh > labels <key <*> value proxyman-alerts > labels <key <*> value <*> >	11
1820	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> Starting Message of the Day...	44
1821	<*> <*> <*> Nov <*> <*> <*> <*> <*> <*> <*> Super-optimized for small spaces <*> read how we shrank the memory	22
1822	<*> <*> <*> Nov <*> <*> <*> <*> <*> <*> <*> footprint of MicroK8s to make it the smallest full K8s around.	22
1823	<*> <*> <*> Nov <*> <*> <*> <*> <*> <*> <*> https <*>	22
1824	<*> <*> <*> Nov <*> <*> <*> <*> <*> systemd <*> Started Message of the Day.	22
1825	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> <*> dc <*> <*> Ports <*> nil	22
1826	Unable to authenticate the request due to an error invalid bearer token <*> error in cryptographic primitive	66
1827	id <name dex > labels <key <*> value <*> > labels <key <*> value dex >	22
1828	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted services name <*> ports protocol TCP port <*> host <*> name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name deviceservice-svc ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-config ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-pagerduty ports protocol TCP port <*> host <*> name tbot-support ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	110
1829	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string control-plane <*> <*> <*> <*> <*> <*> k8s <*> default Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> ce <*> <*> b5 f6 Ports <*> <*> Name <*> Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name metrics Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name health Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*>	22
1830	ImageCreate event &ImageCreate Name <*> <*> Labels map string string <*> managed XXX_unrecognized	1287
1831	ImageCreate event &ImageCreate Name sha256 <*> Labels map string string <*> managed XXX_unrecognized	638
1832	object- <*> <*> <*> Failed to watch <*> failed to list <*> secrets <*> is forbidden User system node <*> cannot list resource secrets in API group in the namespace <*> no relationship found between node <*> and this object	440
1833	Error proxying data from client to backend read tcp <*> <*> <*> read connection reset by peer	22
1834	Successfully Reconciled controller vspheremachine name <*> namespace <*>	93665
1835	Fetching IPAddress objects metal3-ippool Namespace <*> Name <*>	28699
1836	Reconciling VSphereCluster	2838
1837	skipping load balancer reconciliation reason VSphereCluster.Spec.LoadBalancerRef is nil	2838
1838	skipping reconcile when API server is online reason controlPlaneInitialized	2838
1839	API server is online controlPlaneEndpoint <*> <*>	2838
1840	cloud provider config was not specified in VSphereCluster skipping reconciliation of the cloud provider integration	2838
1841	storage config was not specified in VSphereCluster skipping reconciliation of the CSI driver	2838
1842	Successfully Reconciled controller vspherecluster name <*> namespace <*>	2838
1843	vm found by bios uuid vmref Type VirtualMachine Value <*>	30316
1844	unable to encode watch object <*> http2 stream closed <*> writer http2.responseWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	99
1845	powered on	30316
1846	vm <*> biosuuid <*>	30316
1847	VSphereVM is ready	30316
1848	resource patch was not required local-resource-version <*> remote-resource-version <*>	30316
1849	Successfully Reconciled controller vspherevm name <*> namespace <*>	30316
1850	Unable to authenticate the request due to an error invalid bearer token oidc verify token oidc token is expired Token Expiry <*> <*> <*> <*> <*> UTC	33
1851	slow openapi aggregation of <*> <*>	198
1852	Trace <*> Call mutating webhook configuration <*> webhook <*> resource <*> Resource pods subresource operation CREATE UID <*> <*> <*> <*> <*> total time <*>	792
1853	Failed calling webhook failing open <*> failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	55
1854	failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	55
1855	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> client <*> <*> <*> <*> <*> total time <*>	77
1856	<*> <*> <*> Trace <*> <*> Object stored in database <*> <*> <*> <*>	55
1857	error building openapi models for <*> ERROR <*> has invalid property anyOf	99
1858	parsed scheme endpoint	2196
1859	ccResolverWrapper sending new addresses to cc https <*> <*> <nil> 0 <nil>	2197
1860	id <name vault > labels <key <*> value <*> > labels <key <*> value vault >	11
1861	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> <*> <*> <*> <*> total time <*>	22
1862	quota admission added evaluator for <*>	154
1863	Trace <*> Call mutating webhook configuration <*> webhook <*> resource <*> Resource broadcastjobs subresource operation CREATE UID <*> <*> <*> <*> <*> total time <*>	44
1864	Failed calling webhook failing closed <*> failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	792
1865	>>>>>>>>>>>>>>>>> Event type MODIFIED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted services name <*> ports protocol TCP port <*> host <*> name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name deviceservice-svc ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-config ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-interaction ports protocol TCP port <*> host <*> name tbot-pagerduty ports protocol TCP port <*> host <*> name tbot-support ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	176
1866	Updated host <*> name <*> ports port <*> protocol TCP host <*> name istio-ingressgateway ports port <*> protocol TCP port <*> protocol TCP host <*> name istio-ingressgateway-healthcheck ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name alertmanager-operated ports port <*> protocol TCP host <*> name grafana-monitoring ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name thanos-querier ports port <*> protocol TCP host <*> name thanos-querier ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name deviceservice-svc ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name tbot-config ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name tbot-interaction ports port <*> protocol TCP host <*> name tbot-pagerduty ports port <*> protocol TCP host <*> name tbot-support ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name piris-tools ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name <*> ports port <*> protocol TCP host <*> name willittrace-all ports port <*> protocol TCP host <*> name willitconnect ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP host <*> <*> . name <*> ports port <*> protocol TCP services for spectro cluster cluster <*>	22
1867	<*> <*> <*> KIF Received address message for unknown interface <*>	11
1868	>>>>>>>>>>>>>>>>> Event type ADDED SpectroClusterStatus apiEndpoints host <*> port <*> conditions type Progressing status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ProvisionStarts message start to provision new cluster type ImageCustomizationDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason ReconciliationDone message Reconciliation on ImageCustomization Done Successfully type ProviderReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason CRDInstalled message cluster-api providers crd installed and controllers deployed type CloudInfrastructureReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason InfrastructureReady message Infrastructure is ready on cloud type ControlPlaneNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason LaunchControlPlaneNode message control plane nodes addition done type ControlPlaneReady status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodesRunning message all control plane nodes are updated type WorkerNodeAdditionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeReady message worker nodes created successfully type AddOnDeploymentDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason AddOnDeployed message vault ready. dex ready. type ControlPlaneNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason DeleteControlPlaneNode message control plane nodes deletion done type WorkerNodeDeletionDone status True lastProbeTime <*> <*> <*> lastTransitionTime <*> <*> <*> reason NodeDeleted message Worker nodes deleted services name <*> ports protocol TCP port <*> host <*> name istio-ingressgateway ports protocol TCP port <*> protocol TCP port <*> host <*> name istio-ingressgateway-healthcheck ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name alertmanager-operated ports protocol TCP port <*> host <*> name grafana-monitoring ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name thanos-querier ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name deviceservice-svc ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-config ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name tbot-interaction ports protocol TCP port <*> host <*> name tbot-pagerduty ports protocol TCP port <*> host <*> name tbot-support ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name piris-tools ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> name willittrace-all ports protocol TCP port <*> host <*> name willitconnect ports protocol TCP port <*> host <*> name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . name <*> ports protocol TCP port <*> host <*> <*> . cluster <*>	66
1869	Cluster Feature Log Fetcher Request noOfLines <*> duration <*> k8sRequest namespace <*> <*> <*> <*> <*> <*> nodeRequest nodeLog <*> <*> cluster <*>	22
1870	Deployment <*> is in running state with 0 replica cluster <*>	11
1871	Failed to create broadcast job <*> Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused cluster <*>	22
1872	Failed to apply log fetch broadcast manifest crd fileInternal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused cluster <*>	22
1873	Failed to apply log fetch broadcast job Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused cluster <*>	22
1874	Checking for completed log grep pods in iteration 6 cluster <*>	11
1875	Pod Labels operator.libopenstorage.org/name portworx kvdb true operator.libopenstorage.org/driver portworx	5
1876	Pod Labels storage true <*> <*> name portworx operator.libopenstorage.org/driver portworx operator.libopenstorage.org/name portworx	15
1877	Pod Labels <*> <*> app <*>	5
1878	Trace <*> List url <*> user-agent <*> <*> <*> client <*> <*> <*> <*> <*> total time <*>	440
1879	<*> <*> <*> Trace <*> <*> Writing http response done count <*> <*> <*> <*> <*>	440
1880	Pod Labels controller-uid <*> job-name <*>	5
1881	Pod Labels module ally <*> <*> <*> proxy app spectro component cluster-management-agent log-regex logrus-text	5
1882	Pod Labels control-plane controller-manager <*> <*> <*> <*> <*> infrastructure-metal3	5
1883	Removing backing storage for device <*> pool 0 on 4	2079
1884	update_nodes dev <*> rset 0 curr 4 next 4 next clean empty resync to 4	1430
1885	process_cdb_update dev <*> rset 0 node 4 curr 4 next 4 new_rset empty remove empty pool_ids 0 new_pool_ids empty	2189
1886	process_cdb_update new state dev <*> rset 0 nodes 4 curr 4 new empty rem empty	2189
1887	Nodes needing storage pods for storage cluster portworx creating 0 file storagecluster.go <*>	11
1888	Pods to delete for storage cluster portworx deleting 0 file storagecluster.go <*>	11
1889	Checking if relevant fields in pod <*> have changed since <*> file update.go <*>	71
1890	kcp status spec <*> status selector <*> <*> <*> replicas <*> updatedReplicas <*> readyReplicas <*> initialized true ready true observedGeneration <*> conditions type Ready status True lastTransitionTime <*> <*> <*> type Available status True lastTransitionTime <*> <*> <*> type CertificatesAvailable status True lastTransitionTime <*> <*> <*> type ControlPlaneComponentsHealthy status True lastTransitionTime <*> <*> <*> type EtcdClusterHealthyCondition status True lastTransitionTime <*> <*> <*> type MachinesReady status True lastTransitionTime <*> <*> <*> type Resized status True lastTransitionTime <*> <*> <*> version <*>	1496
1891	Getting unavailable numbers file update.go <*>	7
1892	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC ea b5 <*> <*> <*> <*> Ports <*> nil	22
1893	Checking for deletion of all log grep pods in iteration <*> cluster <*>	11
1894	Old Log grep pods on all nodes have been deleted successfully in iteration <*> cluster <*>	11
1895	found release releases name <*> namespace dex revision <*> updated <*> <*> <*> <*> <*> UTC status deployed chart <*> app_version <*>	1815
1896	Error while calling home node <*> <*> Bad Gateway	11
1897	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC ee <*> b3 a2 ca ae Ports <*> nil	11
1898	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> <*> fe <*> <*> Ports <*> nil	11
1899	Updating job <*> status <*> Conditions <*> nil StartTime <*> <*> CompletionTime <*> nil Active 6 Succeeded 6 Failed 0 Desired <*> Phase running	44
1900	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC f2 db <*> d4 0f <*> Ports <*> nil	22
1901	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> 0d <*> fc <*> Ports <*> nil	22
1902	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> dd <*> 0a 0f <*> Ports <*> nil	22
1903	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> <*> <*> <*> <*> Ports <*> nil	22
1904	operationExecutor.UnmountDevice started for volume <*> UniqueName <*> on node <*>	22
1905	<*> attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...	22
1906	UnmountDevice succeeded for volume <*> %! EXTRA string UnmountDevice succeeded for volume <*> UniqueName <*> on node <*>	22
1907	<*> <*> <*> 0 Successfully assigned <*> to <*>	9
1908	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> b1 <*> 0b <*> 4d Ports <*> nil	11
1909	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> <*> <*> <*> <*> c4 Ports <*> nil	22
1910	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC de <*> <*> <*> ad <*> Ports <*> nil	22
1911	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> dc <*> <*> <*> fa Ports <*> nil	22
1912	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace <*> Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string control-plane <*> <*> <*> <*> <*> <*> k8s <*> default Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC fe <*> <*> ae <*> <*> Ports <*> <*> Name <*> Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name metrics Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*> <*> Name health Protocol numorstring.Protocol Type <*> NumVal 0x0 StrVal TCP Port <*>	22
1913	<*> <*> <*> Nov <*> <*> <*> <*> <*> kernel <*> ll header <*> ff ff ff ff ff ff <*> dc <*> <*> <*> fa <*> <*> ........lh....	22
1914	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> smoketest <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC 6e b5 <*> f2 <*> c2 Ports <*> nil	22
1915	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace monitoring Pod temp WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName Namespace monitoring SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string <*> monitoring <*> k8s <*> default run temp Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod temp Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC <*> a3 <*> <*> cd <*> Ports <*> nil	22
1916	Couldn t get secret <*> failed to sync secret cache timed out waiting for the condition	29
1917	Operation for volumeName <*> podName <*> nodeName failed. No retries permitted until <*> <*> <*> <*> <*> UTC m <*> durationBeforeRetry <*> . Error MountVolume.SetUp failed for volume <*> UniqueName <*> pod <*> UID <*> failed to sync secret cache timed out waiting for the condition	28
1918	PVC <*> failed with Operation cannot be fulfilled on persistentvolumeclaims <*> StorageError invalid object Code 4 Key <*> ResourceVersion 0 AdditionalErrorMsg Precondition failed UID in precondition <*> UID in object meta	11
1919	Added Mac interface name and active container ID to endpoint ContainerID <*> Namespace smoketest Pod <*> WorkloadEndpoint <*> endpoint <*> TypeMeta <*> Kind WorkloadEndpoint APIVersion <*> ObjectMeta <*> Name <*> GenerateName <*> Namespace smoketest SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app <*> <*> <*> <*> smoketest <*> k8s <*> default <*> <*> Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec v3.WorkloadEndpointSpec Orchestrator k8s Workload Node <*> ContainerID <*> Pod <*> Endpoint eth0 IPNetworks string <*> IPNATs <*> nil IPv4Gateway IPv6Gateway Profiles string <*> <*> InterfaceName <*> MAC fe <*> <*> <*> f9 <*> Ports <*> nil	22
1920	StopContainer for <*> with timeout 0 s	88
1921	failed to keep alive rest client unauthorized error Unauthorized	11
1922	listening for secure connections address <*>	6
1923	START logs for container cert-manager of pod <*>	1
1924	using <*> certificate generating using CA stored in Secret resource secret_name <*> secret_namespace cert-manager	4
1925	listening for insecure healthz connections address <*>	5
1926	registered pprof handlers	7
1927	Failed to generate initial serving certificate retrying... error failed verifying CA keypair tls failed to find any PEM data in certificate input interval <*>	81
1928	caller level.go <*> event createNDPResponder interface <*> level info msg created NDP responder for interface ts <*> <*> <*>	544
1929	START logs for container speaker of pod <*>	3
1930	branch main caller level.go <*> commit <*> goversion gc <*> <*> <*> amd64 level info msg MetalLB speaker starting commit <*> branch main ts <*> <*> <*> version	6
1931	caller level.go <*> event createARPResponder interface eth0 level info msg created ARP responder for interface ts <*> <*> <*>	9
1932	caller level.go <*> event createNDPResponder interface eth0 level info msg created NDP responder for interface ts <*> <*> <*>	12
1933	caller level.go <*> event createARPResponder interface <*> level info msg created ARP responder for interface ts <*> <*> <*>	538
1934	caller level.go <*> level info msg node event <*> forcing sync node addr <*> node event NodeJoin node name <*> ts <*> <*> <*>	36
1935	caller level.go <*> configmap <*> event configLoaded level info msg config re loaded ts <*> <*> <*>	81
1936	caller level.go <*> event nodeLabelsChanged level info msg Node labels changed resyncing BGP peers ts <*> <*> <*>	28
1937	caller level.go <*> level info msg triggering discovery op memberDiscovery ts <*> <*> <*>	12720
1938	caller level.go <*> level info msg memberlist join succesfully number of other nodes <*> op Member detection ts <*> <*> <*>	11
1939	caller level.go <*> error creating NDP responder for <*> listen ip6 <*> fe80 ecee eeff feee <*> bind cannot assign requested address interface <*> level error msg failed to create NDP responder op createNDPResponder ts <*> <*> <*>	61
1940	caller level.go <*> error <*> error occurred n t Failed to join <*> No installed keys could decrypt the message n n expected <*> joined 0 level error msg partial join op memberDiscovery ts <*> <*> <*>	8986
1941	Trace <*> Reflector ListAndWatch name <*> <*> <*> <*> <*> <*> total time <*>	60
1942	START logs for container controller of pod <*>	1
1943	branch main caller level.go <*> commit <*> goversion gc <*> <*> <*> amd64 level info msg MetalLB controller starting commit <*> branch main ts <*> <*> <*> version	2
1944	Trace <*> <*> <*> END	4943
1945	Failed to watch <*> failed to list <*> Get https <*> <*> metadata.name%3Dconfig limit <*> resourceVersion 0 dial tcp <*> <*> i/o timeout	3
1946	Failed to watch <*> failed to list <*> Get https <*> <*> <*> resourceVersion 0 dial tcp <*> <*> i/o timeout	36
1947	caller level.go <*> event stateSynced level info msg controller synced can allocate IPs now ts <*> <*> <*>	3
1948	END logs for container controller of pod <*>	1
1949	caller level.go <*> error <*> errors occurred n t Failed to join <*> No installed keys could decrypt the message n t Failed to join <*> No installed keys could decrypt the message n n expected <*> joined 0 level error msg partial join op memberDiscovery ts <*> <*> <*>	27
1950	caller level.go <*> event deleteARPResponder interface <*> level info msg deleted ARP responder for interface ts <*> <*> <*>	253
1951	caller level.go <*> event deleteNDPResponder interface <*> level info msg deleted NDP responder for interface ts <*> <*> <*>	253
1952	Health check failed as CertificateSource is unhealthy	3
1953	END logs for container <*> of pod <*>	298
1954	START logs for container <*> of pod <*>	318
1955	Valid token audiences	8
1956	Generating self signed cert as no cert is provided	12
1957	Starting TCP socket on <*> <*>	16
1958	Listening securely on <*> <*>	20
1959	START logs for container manager of pod <*>	35
1960	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfig	9
1961	Registering a validating webhook GVK Group <*> Version <*> Kind KubeadmConfig path <*>	10
1962	conversion webhook enabled object metadata creationTimestamp null spec status	11
1963	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfigList	11
1964	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfigList	11
1965	conversion webhook enabled object metadata items null	52
1966	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfigTemplate	11
1967	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind KubeadmConfigTemplate	11
1968	conversion webhook enabled object metadata creationTimestamp null spec template spec	11
1969	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind <*>	10
1970	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind <*>	9
1971	creating controller manager version <*>	8
1972	error opening credentials file error open <*> no such file or directory	9
1973	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereCluster	22
1974	Registering a validating webhook GVK Group <*> Version <*> Kind VSphereCluster path <*>	11
1975	serving webhook server host port <*>	20
1976	END logs for container manager of pod <*>	16
1977	caller net.go <*> component Memberlist level error msg memberlist failed to receive No installed keys could decrypt the message from <*> <*> ts <*> <*> <*>	9074
1978	Registering a mutating webhook GVK Group <*> Version <*> Kind KubeadmControlPlane path <*>	9
1979	Registering a validating webhook GVK Group <*> Version <*> Kind KubeadmControlPlane path <*>	9
1980	END logs for container cert-manager of pod <*>	1
1981	conversion webhook enabled object metadata creationTimestamp null spec cloudProviderConfiguration global network disk workspace labels providerConfig controlPlaneEndpoint host port 0 status	11
1982	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereClusterList	11
1983	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereClusterList	11
1984	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereMachine	22
1985	Registering a validating webhook GVK Group <*> Version <*> Kind VSphereMachine path <*>	11
1986	conversion webhook enabled object metadata creationTimestamp null spec template network devices null status ready false	11
1987	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineList	11
1988	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineList	11
1989	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineTemplate	21
1990	Registering a validating webhook GVK Group <*> Version <*> Kind VSphereMachineTemplate path <*>	11
1991	conversion webhook enabled object metadata creationTimestamp null spec template spec template network devices null	11
1992	END logs for container speaker of pod <*>	3
1993	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineTemplateList	11
1994	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineTemplateList	11
1995	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereVM	11
1996	Registering a validating webhook GVK Group <*> Version <*> Kind VSphereVM path <*>	11
1997	END logs for container upgrade-ipam of pod <*>	18
1998	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind VSphereVMList	11
1999	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereVMList	11
2000	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind HAProxyLoadBalancer	11
2001	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind HAProxyLoadBalancer	11
2002	skip registering a mutating webhook admission.Defaulter interface is not implemented GVK Group <*> Version <*> Kind HAProxyLoadBalancerList	11
2003	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind HAProxyLoadBalancerList	11
2004	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereCluster	11
2005	conversion webhook enabled object metadata creationTimestamp null spec cloudProviderConfiguration global network disk workspace labels providerConfig status ready false	11
2006	START logs for container upgrade-ipam of pod <*>	3
2007	migrating from host-local to calico-ipam...	6
2008	checking host-local IPAM data dir dir existence...	9
2009	host-local IPAM data dir dir not found no migration necessary successfully exiting...	12
2010	migration from host-local to calico-ipam complete node <*>	15
2011	START logs for container install-cni of pod <*>	21
2012	Running as a Kubernetes pod source install.go <*>	24
2013	Installed <*>	288
2014	Wrote Calico CNI binaries to <*> n	33
2015	CNI plugin version <*> n	33
2016	<*> is not writeable skipping	33
2017	Using CNI config template from CNI_NETWORK_CONFIG environment variable. source install.go <*>	33
2018	Created <*>	33
2019	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereMachine	11
2020	conversion webhook enabled object metadata creationTimestamp null spec template datacenter network devices null status ready false	11
2021	skip registering a validating webhook admission.Validator interface is not implemented GVK Group <*> Version <*> Kind VSphereMachineTemplate	9
2022	conversion webhook enabled object metadata creationTimestamp null spec template metadata spec template datacenter network devices null	8
2023	starting controller manager	7
2024	name <*>	33
2025	cniVersion <*>	33
2026	plugins	33
2027	type calico	33
2028	log_level info	33
2029	log_file_path <*>	33
2030	datastore_type kubernetes	33
2031	nodename <*>	33
2032	mtu 0	33
2033	ipam	33
2034	type calico-ipam	33
2035	policy	33
2036	type k8s	33
2037	kubernetes	33
2038	kubeconfig <*>	33
2039	type <*>	33
2040	snat true	33
2041	capabilities portMappings true	33
2042	type bandwidth	33
2043	capabilities bandwidth true	33
2044	Done configuring CNI. Sleep false	33
2045	END logs for container install-cni of pod <*>	33
2046	Error getting resource Key GlobalFelixConfig name CalicoVersion Name calicoversion Resource GlobalFelixConfigs error the server could not find the requested resource get <*> calicoversion	11
2047	<*> is true defaulted through environment variable	11
2048	Ensure default IPv4 pool is created. IPIP mode Always VXLAN mode Never	11
2049	Created default IPv4 pool <*> with NAT outgoing true. IPIP mode Always VXLAN mode Never	11
2050	Calico node started successfully	33
2051	bird Unable to open configuration file <*> No such file or directory	55
2052	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	11
2053	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0x0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	11
2054	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0x0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	11
2055	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0x0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	11
2056	Calling CSI driver to discover driver name	18
2057	Attempting to open a gRPC connection with <*>	20
2058	Still connecting to unix <*>	221580
2059	GRPC call <*>	21
2060	GRPC request	24
2061	GRPC response name <*> vendor_version <*>	27
2062	GRPC error <nil>	30
2063	CSI driver name <*>	83
2064	Starting Registration Server at <*>	33
2065	Registration Server started at <*>	33
2066	Skipping healthz server because port set to 0	33
2067	Received GetInfo call InfoRequest	33
2068	Received NotifyRegistrationStatus call RegistrationStatus PluginRegistered true Error	33
2069	level info time <*> <*> <*> caller logger/logger.go <*> msg Setting default log level to PRODUCTION	99
2070	level info time <*> <*> <*> caller <*> <*> msg Version <*> TraceId <*>	55
2071	level info time <*> <*> <*> caller <*> <*> msg Defaulting feature states configmap name to <*> TraceId <*>	55
2072	Error looking up in-cluster authentication configuration the server was unable to return a response in the time allotted but may still be processing the request get configmaps <*>	3
2073	Failed to watch <*> failed to list <*> Get https <*> <*> <*> limit <*> resourceVersion 0 dial tcp <*> <*> connect connection refused	79
2074	Failed to watch <*> failed to list <*> Get https <*> <*> <*> resourceVersion 0 dial tcp <*> <*> connect connection refused	491
2075	Creating new default config for lighthouse	96
2076	START logs for container config-init of pod <*>	1
2077	<*> <*> <*> <*> Get http <*> <*> dial tcp <*> <*> connect connection refused Next retry in <*>	101
2078	level info time <*> <*> <*> caller <*> <*> msg Defaulting feature states configmap namespace to <*> TraceId <*>	55
2079	level info time <*> <*> <*> caller service/service.go <*> msg configured <*> with clusterFlavor VANILLA and mode node TraceId <*>	33
2080	identity service registered	44
2081	node service registered	33
2082	serving endpoint unix <*>	44
2083	level info time <*> <*> <*> caller <*> <*> msg No Net Permissions given in Config. Using default permissions. TraceId <*>	55
2084	level info time <*> <*> <*> caller service/node.go <*> msg Config file provided to node daemonset with zones and regions. Assuming topology aware cluster. TraceId <*>	33
2085	level info time <*> <*> <*> caller <*> <*> msg Defaulting timeout for vCenter Client to <*> minutes TraceId <*>	44
2086	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Initializing defaultVirtualCenterManager... TraceId <*>	44
2087	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully initialized defaultVirtualCenterManager TraceId <*>	44
2088	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully registered VC <*> TraceId <*>	44
2089	level info time <*> <*> <*> caller vsphere/virtualcenter.go <*> msg New session ID for VSPHERE.LOCAL arvind <*> TraceId <*>	44
2090	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Initiating asynchronous datacenter listing with uuid <*> TraceId <*>	99
2091	level info time <*> <*> <*> caller <*> <*> msg Publishing datacenter Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> TraceId <*>	99
2092	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg AsyncGetAllDatacenters with uuid <*> sent a dc Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> TraceId <*>	99
2093	level error time <*> <*> <*> caller <*> <*> msg Couldn t find VM given uuid <*> TraceId <*> stacktrace <*> Datacenter .GetVirtualMachineByUUID n <*> <*> <*> n <*> <*>	33
2094	level warn time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Couldn t find VM given uuid <*> on DC Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> with err virtual machine wasn t found continuing search TraceId <*>	33
2095	level error time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Returning VM not found err for UUID <*> TraceId <*> stacktrace <*> n <*> <*> <*> service .NodeGetInfo n <*> <*> <*> n <*> <*> <*> interceptor .handle n <*> <*> <*> n <*> <*> <*> StoragePlugin .injectContext n <*> <*> <*> n <*> <*> <*> n <*> <*> <*> n <*> <*> <*> Server .processUnaryRPC n <*> <*> <*> Server .handleStream n <*> <*> <*> Server <*> n <*> <*>	33
2096	level error time <*> <*> <*> caller service/node.go <*> msg failed to get nodeVM for uuid <*> err virtual machine wasn t found TraceId <*> stacktrace <*> service .NodeGetInfo n <*> <*> <*> n <*> <*> <*> interceptor .handle n <*> <*> <*> n <*> <*> <*> StoragePlugin .injectContext n <*> <*> <*> n <*> <*> <*> n <*> <*> <*> n <*> <*> <*> Server .processUnaryRPC n <*> <*> <*> Server .handleStream n <*> <*> <*> Server <*> n <*> <*>	33
2097	Error initializing lighthouse config. timed out performing task	11
2098	END logs for container config-init of pod <*>	10
2099	START logs for container px-lighthouse of pod <*>	9
2100	Request log error the server rejected our request for an unknown reason get pods <*>	15
2101	END logs for container px-lighthouse of pod <*>	7
2102	ERROR <*> <*> <*> HINFO read udp <*> <*> <*> i/o timeout	95
2103	START logs for container coredns of pod <*>	1
2104	. <*>	2
2105	INFO <*> Running configuration <*> <*>	3
2106	linux/amd64 <*> <*>	5
2107	Warning option provisioner pxd.portworx.com is deprecated and has no effect	6
2108	feature gates map	9
2109	Building kube configs for running in cluster...	26
2110	caller level.go <*> level info msg node event <*> forcing sync node addr <*> node event NodeLeave node name <*> ts <*> <*> <*>	11
2111	caller level.go <*> error <*> error occurred n t Failed to join <*> dial tcp <*> <*> connect connection refused n n expected <*> joined 0 level error msg partial join op memberDiscovery ts <*> <*> <*>	44
2112	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Found VM VirtualMachine <*> VirtualCenterHost <*> UUID <*> Datacenter Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> given uuid <*> on DC Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> TraceId <*>	66
2113	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Returning VM VirtualMachine <*> VirtualCenterHost <*> UUID <*> Datacenter Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> for UUID <*> TraceId <*>	66
2114	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Found tag DND for object ClusterComputeResource <*> Folder <*> GPU Cluster <nil> TraceId <*>	33
2115	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Found tag az4 for object ClusterComputeResource <*> Folder <*> GPU Cluster <nil> TraceId <*>	33
2116	level info time <*> <*> <*> caller vsphere/virtualmachine.go <*> msg Found tag <*> for object Datacenter <*> Folder <*> Datacenter <nil> TraceId <*>	33
2117	level info time <*> <*> <*> caller <*> <*> msg PbmClient wasn t connected ignoring TraceId <*>	33
2118	level info time <*> <*> <*> caller <*> <*> msg CnsClient wasn t connected ignoring TraceId <*>	33
2119	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully unregistered VC <*> TraceId <*>	33
2120	calling CSI driver to discover driver name	44
2121	metrics endpoint will not be started because `metrics-address` was not specified.	62
2122	Serving requests to <*> on <*> <*>	44
2123	Service handler initialized via as DBus type dbus svc portworx.service id <*>	6
2124	START logs for container portworx of pod <*>	1
2125	Input arguments <*> <*> <*> <*> type zeroedthick size <*> <*> <*> -secret_type k8s <*> <*> kubernetes	2
2126	Updated arguments <*> <*> <*> <*> type zeroedthick size <*> <*> <*> -secret_type k8s <*> <*> kubernetes	3
2127	<*> computed version <*>	4
2128	Flag <*> has been deprecated see <*> instead.	4
2129	REAPER Starting ...	5
2130	Activating REST server	7
2131	Locating my container handler	8
2132	> Attempt to use Docker as container handler failed error <*> not a socket-file	9
2133	> Using ContainerD as container handler	10
2134	Detected HostNetwork setting <*> will track portworx status via REST	11
2135	Registering CRDs	6
2136	START logs for container stork of pod <*>	1
2137	error retrieving resource lock <*> Get https <*> <*> <*> <*> request canceled Client.Timeout exceeded while awaiting headers	54
2138	Starting stork version <*>	2
2139	Using driver pxd	3
2140	Failed to discover group <*> error the server is currently unable to handle the request	4
2141	Using http <*> <*> as endpoint for portworx REST API	7
2142	Using <*> <*> as endpoint for portworx gRPC API	8
2143	Starting snapshot controller	20
2144	START logs for container stork-connector of pod <*>	3
2145	Removed env variables AUTOPILOT_PORT <*> <*> <*> <*> AUTOPILOT_SERVICE_HOST AUTOPILOT_SERVICE_PORT AUTOPILOT_SERVICE_PORT_AUTOPILOT CLOUD_CONTROLLER_MANAGER_PORT <*> <*> <*> <*> <*> <*> PATH PORTWORX_API_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_SERVICE_HOST PORTWORX_API_SERVICE_PORT <*> <*> <*> PORTWORX_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_SERVICE_HOST PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> PX_LIGHTHOUSE_PORT <*> <*> <*> <*> <*> <*> <*> <*> PX_LIGHTHOUSE_SERVICE_HOST PX_LIGHTHOUSE_SERVICE_PORT <*> <*> STORK_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> STORK_SERVICE_SERVICE_HOST STORK_SERVICE_SERVICE_PORT <*> <*> VSPHERE_VCENTER_PORT	11
2146	Preparing to download Portworx image...	11
2147	REST Changing install-state ST_UNKNOWN <*> ST_INSTALL	11
2148	error retrieving resource lock <*> Get https <*> <*> <*> stream error stream ID <*> INTERNAL_ERROR Client.Timeout exceeded while awaiting headers	11
2149	Unexpected error when reading response body <*> request canceled Client.Timeout or context cancellation while reading body	11
2150	error retrieving resource lock <*> unexpected error when reading response body. Please retry. Original error <*> request canceled Client.Timeout or context cancellation while reading body	11
2151	Error getting nodes Failed to get nodes for the driver Get http <*> <*> dial tcp <*> <*> connect connection refused	15
2152	<*> <*> <*> <*> failed to create cluster domains status object for driver pxd Failed to get clusterID for the driver Get http <*> <*> dial tcp <*> <*> connect connection refused Next retry in <*>	120
2153	Linux interface addrs changed. addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> feb6 <*> set.empty ifaceName eth0	55
2154	QuotaMonitor created object count evaluator for actionapprovals.autopilot.libopenstorage.org	11
2155	QuotaMonitor created object count evaluator for migrationschedules.stork.libopenstorage.org	11
2156	QuotaMonitor created object count evaluator for migrations.stork.libopenstorage.org	11
2157	QuotaMonitor created object count evaluator for autopilotruleobjects.autopilot.libopenstorage.org	11
2158	QuotaMonitor created object count evaluator for rules.stork.libopenstorage.org	11
2159	QuotaMonitor created object count evaluator for clusterpairs.stork.libopenstorage.org	11
2160	END logs for container stork-connector of pod <*>	1
2161	Detected imagePullPolicy Always	11
2162	Attempting to retrieve latest <*> <*> image pullPolicy Always	11
2163	Using anonymous Docker credentials	11
2164	Remote Portworx image digest identical to current image s digest pull skipped	11
2165	Got requested Portworx image <*> <*> with digest sha256 <*>	11
2166	Installed image digest sha256 <*> same as remote/pulled image s no need to reinstall	11
2167	Installing Portworx OCI service to <*>	11
2168	Prepending computed kubelet directory mount <*> <*> shared	11
2169	Adding computed <*> as volatile mount regex	11
2170	RSYNC Found volatile mount <*> <*>	44
2171	> <*> <*> <*> <*> <*> <*> <*>	55
2172	> Changed mount <*> <*> to <*> <*>	44
2173	RSYNC Found volatile mount <*> <*> ro	11
2174	> Changed mount <*> <*> ro to <*> <*>	11
2175	CPU shares limit NOT passed to Portworx service use <*> <*> param instead	11
2176	> run-host <*> install <*> <*> <*> type zeroedthick size <*> <*> <*> -secret_type k8s <*> <*> kubernetes <*> <*> <*> shared <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> AUTOPILOT_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> AUTOPILOT_SERVICE_HOST <*> <*> AUTOPILOT_SERVICE_PORT <*> <*> AUTOPILOT_SERVICE_PORT_AUTOPILOT <*> <*> <*> <*> <*> CLOUD_CONTROLLER_MANAGER_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> CSI_ENDPOINT unix <*> <*> HOSTNAME <*> <*> HTTPS_PROXY http <*> <*> <*> HTTP_PROXY http <*> <*> <*> KUBERNETES_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBERNETES_SERVICE_HOST <*> <*> KUBERNETES_SERVICE_PORT <*> <*> KUBERNETES_SERVICE_PORT_HTTPS <*> <*> KUBE_DNS_PORT udp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> udp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> udp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> KUBE_DNS_SERVICE_HOST <*> <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> NO_PROXY <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> <*> PATH <*> <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_API_SERVICE_HOST <*> <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PORTWORX_SERVICE_SERVICE_HOST <*> <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_LIGHTHOUSE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> PX_LIGHTHOUSE_SERVICE_HOST <*> <*> PX_LIGHTHOUSE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> PX_TEMPLATE_VERSION <*> <*> STORK_SERVICE_PORT tcp <*> <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> tcp <*> STORK_SERVICE_SERVICE_HOST <*> <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> USER_NO_PROXY <*> <*> <*> <*> VSPHERE_DATASTORE_PREFIX datastore <*> VSPHERE_INSECURE true <*> VSPHERE_INSTALL_MODE shared <*> VSPHERE_PASSWORD <*> VSPHERE_USER <*> VSPHERE_VCENTER <*> <*> VSPHERE_VCENTER_PORT <*> <*> container oci <*> http_proxy http <*> <*> <*> https_proxy http <*> <*> <*> no_proxy <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> <*> PX_IMAGE <*> <*> <*> CONTAINER_RUNTIME containerd <*> PX_IMAGE_DIGEST sha256 <*> <*> KUBELET_DIR <*>	11
2177	Rootfs found at <*>	11
2178	PX binaries found at <*>	11
2179	error retrieving resource lock <*> Get https <*> <*> <*> dial tcp <*> <*> connect connection refused	54
2180	Failed to watch <*> failed to list <*> Get https <*> <*> <*> resourceVersion 0 dial tcp <*> <*> connect no route to host	15
2181	Initializing as version <*> OCI	11
2182	Using http_proxy http <*> <*>	11
2183	Enabling Sharedv4 NFS support ...	11
2184	Setting up NFS service	11
2185	> Initialized service controls via DBus type dbus svc <*> id <*>	11
2186	Fixing <*> mount	11
2187	> Removing mount for <*> <*> rbind rprivate	11
2188	> Adding mount for <*> <*> bind rprivate	11
2189	> <*> <*> <*> <*> already exists	11
2190	Checking mountpoints for following shared directories <*> <*>	11
2191	Found following mountpoints for shared dirs map <*> isMP T Opts shared <*> <*> isMP f Opts shared <*> Parent <*> <*> isMP f Opts shared <*> Parent <*>	11
2192	SPEC UNCHANGED <*> <*>	11
2193	<*> arguments <*> <*> <*> <*> <*> <*> type zeroedthick size <*> -secret_type k8s <*> kubernetes	11
2194	<*> mounts <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> proc <*> nosuid noexec nodev <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> sysfs <*> nosuid noexec nodev cgroup <*> nosuid noexec nodev <*> <*> <*> <*> <*> <*> <*> <*> bind <*> <*> <*> <*> shared <*> <*> <*> <*> shared <*> <*> <*> <*> ro <*> <*> <*> <*>	11
2195	<*> env AUTOPILOT_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp AUTOPILOT_SERVICE_HOST <*> AUTOPILOT_SERVICE_PORT <*> AUTOPILOT_SERVICE_PORT_AUTOPILOT <*> <*> <*> CLOUD_CONTROLLER_MANAGER_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> <*> <*> <*> CONTAINER_RUNTIME containerd CSI_ENDPOINT unix <*> GOMAXPROCS <*> GOTRACEBACK crash HOSTNAME <*> HTTPS_PROXY http <*> <*> HTTP_PROXY http <*> <*> KUBELET_DIR <*> KUBERNETES_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBERNETES_SERVICE_HOST <*> KUBERNETES_SERVICE_PORT <*> KUBERNETES_SERVICE_PORT_HTTPS <*> KUBE_DNS_PORT udp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> udp <*> <*> <*> <*> <*> <*> <*> udp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp KUBE_DNS_SERVICE_HOST <*> KUBE_DNS_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> LVM_USE_HOST <*> NFS_SERVICE <*> NO_PROXY <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> PATH <*> <*> <*> <*> <*> <*> PORTWORX_API_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_API_SERVICE_HOST <*> PORTWORX_API_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> PORTWORX_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PORTWORX_SERVICE_SERVICE_HOST <*> PORTWORX_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> <*> <*> <*> <*> PX_IMAGE <*> <*> PX_IMAGE_DIGEST sha256 <*> PX_LIGHTHOUSE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp PX_LIGHTHOUSE_SERVICE_HOST <*> PX_LIGHTHOUSE_SERVICE_PORT <*> <*> <*> <*> <*> PX_LOGLEVEL info PX_RUNC true PX_SHARED <*> shared <*> <*> shared <*> PX_TEMPLATE_VERSION <*> PX_VERSION <*> STORK_SERVICE_PORT tcp <*> <*> <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp <*> tcp <*> <*> <*> <*> <*> <*> <*> tcp STORK_SERVICE_SERVICE_HOST <*> STORK_SERVICE_SERVICE_PORT <*> <*> <*> <*> <*> TERM xterm USER_NO_PROXY <*> <*> <*> VSPHERE_DATASTORE_PREFIX datastore VSPHERE_INSECURE true VSPHERE_INSTALL_MODE shared VSPHERE_PASSWORD VSPHERE_USER VSPHERE_VCENTER <*> VSPHERE_VCENTER_PORT <*> container oci http_proxy http <*> <*> https_proxy http <*> <*> no_proxy <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*>	11
2196	<*> content unchanged <*> <*>	44
2197	intdataplane.ifaceUpdate Name lo State up Index <*>	33
2198	intdataplane.ifaceUpdate Name eth0 State up Index <*>	33
2199	<*> Name lo Addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty	33
2200	Interface addrs changed. update <*> Name lo Addrs set.mapSet <*> set.empty <*> set.empty <*> set.empty	33
2201	<*> Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> feb6 <*> set.empty	55
2202	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty <*> set.empty fe80 <*> <*> feb6 <*> set.empty	55
2203	<*> Name tunl0 Addrs set.mapSet	33
2204	Interface addrs changed. update <*> Name tunl0 Addrs set.mapSet	33
2205	Could not enable portworx-reboot error exit status <*> out Failed to connect to bus No data available nFailed to connect to bus No data available n	11
2206	Could create systemd service error Could not enable portworx-reboot exit status <*>	11
2207	runC spec unchanged	11
2208	Portworx service restart required due to missing/invalid <*>	11
2209	Reloading + Restarting portworx service	11
2210	Initializing eviction metric for zone <*>   az4	11
2211	<*> <*> <*> <*> I | etcdmain Go <*> linux/amd64	12
2212	START logs for container etcd of pod <*>	2
2213	WARNING Deprecated <*> capnslog flag is set use <*> zap flag instead	21
2214	<*> <*> <*> <*> I | etcdmain etcd Version <*>	6
2215	<*> <*> <*> <*> I | etcdmain Git SHA <*>	8
2216	<*> <*> <*> <*> I | etcdmain Go Version <*>	10
2217	<*> <*> <*> <*> I | etcdmain setting maximum number of CPUs to <*> total number of available CPUs is <*>	14
2218	<*> <*> <*> <*> I | embed peerTLS cert <*> key <*> <*> <*> <*> true crl-file	19
2219	<*> <*> <*> <*> I | embed name <*>	21
2220	<*> <*> <*> <*> I | embed data dir <*>	22
2221	<*> <*> <*> <*> I | embed member dir <*>	22
2222	<*> <*> <*> <*> I | embed heartbeat <*>	22
2223	<*> <*> <*> <*> I | embed election <*>	22
2224	<*> <*> <*> <*> I | embed snapshot count <*>	22
2225	<*> <*> <*> <*> I | embed advertise client URLs https <*> <*>	22
2226	<*> <*> <*> <*> I | etcdserver starting member <*> in cluster <*>	11
2227	<*> <*> <*> <*> INFO <*> switched to configuration voters	11
2228	<*> <*> <*> <*> INFO <*> became <*> at term 0	11
2229	<*> <*> <*> <*> INFO newRaft <*> peers term 0 commit 0 applied 0 lastindex 0 lastterm 0	11
2230	<*> <*> <*> <*> W | auth simple token is not cryptographically signed	22
2231	<*> <*> <*> <*> I | rafthttp started HTTP pipelining with peer <*>	44
2232	Probing CSI driver for readiness	16
2233	Controller detected that zone <*>   az4 is now in state Normal.	11
2234	Error creating spec for volume <*> pod wordpress <*> <*> error processing PVC wordpress <*> <*> PVC <*> has non-bound phase Pending or empty pvc.Spec.VolumeName	11
2235	Error creating spec for volume data pod wordpress <*> <*> error processing PVC wordpress <*> <*> PVC <*> has non-bound phase Pending or empty pvc.Spec.VolumeName	11
2236	<*> failed with error storing status for daemon set <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name speaker GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation <*> CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app metallb component speaker Annotations map string string <*> <*> <*> apiVersion <*> kind DaemonSet metadata annotations labels app metallb component speaker name speaker namespace <*> spec selector matchLabels app metallb component speaker template metadata annotations <*> <*> <*> true labels app metallb component speaker spec containers args <*> <*> <*> config env name METALLB_NODE_NAME valueFrom fieldRef fieldPath spec.nodeName name METALLB_HOST valueFrom fieldRef fieldPath status.hostIP name METALLB_ML_BIND_ADDR valueFrom fieldRef fieldPath status.podIP name METALLB_ML_LABELS value app metallb component speaker name METALLB_ML_NAMESPACE valueFrom fieldRef fieldPath metadata.namespace name METALLB_ML_SECRET_KEY valueFrom secretKeyRef key secretkey name memberlist image <*> main imagePullPolicy Always name speaker ports containerPort <*> name monitoring resources limits cpu <*> memory <*> securityContext allowPrivilegeEscalation false capabilities add NET_ADMIN NET_RAW SYS_ADMIN drop ALL readOnlyRootFilesystem true hostNetwork true nodeSelector <*> linux serviceAccountName speaker terminationGracePeriodSeconds <*> tolerations effect NoSchedule key <*> n OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager kubectl Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> Selector <*> <*> Template <*> ObjectMeta <*> Name GenerateName Namespace SelfLink UID ResourceVersion Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext 0 loc time.Location nil DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string app metallb component speaker Annotations map string string <*> <*> <*> true OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> nil Spec <*> Volumes <*> nil InitContainers <*> nil Containers <*> <*> Name speaker Image <*> main Command string nil Args string <*> <*> <*> config WorkingDir Ports <*> <*> Name monitoring HostPort <*> ContainerPort <*> Protocol TCP HostIP EnvFrom <*> nil Env <*> <*> Name METALLB_NODE_NAME Value ValueFrom <*> <*> <*> Name METALLB_HOST Value ValueFrom <*> <*> <*> Name METALLB_ML_BIND_ADDR Value ValueFrom <*> <*> <*> Name METALLB_ML_LABELS Value app metallb component speaker ValueFrom <*> nil <*> Name METALLB_ML_NAMESPACE Value ValueFrom <*> <*> <*> Name METALLB_ML_SECRET_KEY Value ValueFrom <*> <*> Resources <*> Limits <*> cpu resource.Quantity i <*> value <*> scale <*> d resource.infDecAmount Dec inf.Dec nil s <*> Format DecimalSI memory resource.Quantity i <*> value <*> scale 0 d resource.infDecAmount Dec inf.Dec nil s <*> Format BinarySI Requests <*> nil VolumeMounts <*> nil VolumeDevices <*> nil LivenessProbe <*> nil ReadinessProbe <*> nil StartupProbe <*> nil Lifecycle <*> nil TerminationMessagePath <*> TerminationMessagePolicy File ImagePullPolicy Always SecurityContext <*> <*> Stdin false StdinOnce false TTY false EphemeralContainers <*> nil RestartPolicy Always TerminationGracePeriodSeconds <*> <*> ActiveDeadlineSeconds <*> nil DNSPolicy ClusterFirst NodeSelector map string string <*> linux ServiceAccountName speaker DeprecatedServiceAccount speaker AutomountServiceAccountToken bool nil NodeName HostNetwork true HostPID false HostIPC false ShareProcessNamespace bool nil SecurityContext <*> <*> ImagePullSecrets <*> nil Hostname Subdomain Affinity <*> nil SchedulerName <*> Tolerations <*> <*> Key <*> Operator Value Effect NoSchedule TolerationSeconds <*> nil HostAliases <*> nil PriorityClassName Priority <*> nil DNSConfig <*> nil ReadinessGates <*> nil RuntimeClassName string nil EnableServiceLinks bool nil PreemptionPolicy <*> nil Overhead <*> nil TopologySpreadConstraints <*> nil SetHostnameAsFQDN bool nil UpdateStrategy <*> Type RollingUpdate RollingUpdate <*> <*> MinReadySeconds 0 RevisionHistoryLimit <*> <*> Status <*> CurrentNumberScheduled <*> NumberMisscheduled 0 DesiredNumberScheduled <*> NumberReady <*> ObservedGeneration <*> UpdatedNumberScheduled <*> NumberAvailable <*> NumberUnavailable <*> CollisionCount <*> nil Conditions <*> nil Operation cannot be fulfilled on <*> speaker the object has been modified please apply your changes to the latest version and try again	11
2237	CSI driver supports ControllerPublishUnpublish using real CSI handler	8
2238	Service handler initialized via as DBus type dbus svc portworx-reboot.service id <*>	11
2239	Waited for <*> due to <*> throttling not priority and fairness request GET https <*> <*> <*> resourceVersion 0	11
2240	This node is starting with leadership of the cluster	6
2241	START logs for container kube-vip of pod <*>	1
2242	FLAG <*> false	214
2243	<*> <*> <*> <*> I | rafthttp starting peer <*>	33
2244	Beginning cluster membership namespace <*> lock name <*> id <*>	2
2245	<*> version VERSION	4
2246	Node <*> is assuming leadership of the cluster	14
2247	END logs for container coredns of pod <*>	1
2248	FLAG <*> <*>	622
2249	start dhcp client for ddns	7
2250	waiting for ip from dhcp	8
2251	<*> <*> <*> <*> N | etcdmain the server is already initialized as member before starting as etcd member...	8
2252	<*> <*> <*> <*> eth0 sending Discover	9
2253	FLAG <*>	434
2254	<*> <*> <*> <*> eth0 received Offer	11
2255	Service portworx.service not yet active	11
2256	<*> <*> <*> <*> eth0 sending Request	11
2257	Loaded <*> mutating admission controller s successfully in the following order NamespaceLifecycle LimitRanger ServiceAccount NodeRestriction TaintNodesByCondition AlwaysPullImages PodSecurityPolicy Priority DefaultTolerationSeconds DefaultStorageClass StorageObjectInUseProtection RuntimeClass DefaultIngressClass MutatingAdmissionWebhook.	39
2258	<*> <*> <*> <*> I | rafthttp started streaming with peer <*> writer	66
2259	Flag <*> has been deprecated This flag has no effect now and will be removed in <*>	4
2260	external host was not specified using <*>	6
2261	Starting CSI attacher	11
2262	Got initial config snapshot	6
2263	<*> <*> <*> <*> eth0 received Ack	11
2264	Activating <*>	11
2265	Loaded <*> validating admission controller s successfully in the following order LimitRanger ServiceAccount AlwaysPullImages PodSecurityPolicy Priority PersistentVolumeClaimResize RuntimeClass CertificateApproval CertificateSigning CertificateSubjectRestriction ValidatingAdmissionWebhook ResourceQuota.	43
2266	Loaded configuration from environment config config.Config LogLevel info WorkloadEndpointWorkers <*> ProfileWorkers <*> PolicyWorkers <*> NodeWorkers <*> Kubeconfig DatastoreType kubernetes	2
2267	CRD actionapprovals.autopilot.libopenstorage.org updated successfully. file actionapproval.go <*>	6
2268	Ensuring Calico datastore is initialized	4
2269	START logs for container autopilot of pod <*>	1
2270	Starting autopilot version <*> file main.go <*>	2
2271	using params url http <*> <*> for provider prometheus file main.go <*>	3
2272	CRD autopilotrules.autopilot.libopenstorage.org updated successfully. file rule.go <*>	4
2273	CRD autopilotruleobjects.autopilot.libopenstorage.org updated successfully. file rule.go <*>	5
2274	Using rule engine <*> file rule.go <*>	7
2275	Using cool down period of <*> seconds. file engine.go <*>	8
2276	Using minimum poll period of <*> seconds. file engine.go <*>	9
2277	<*> <*> <*> <*> I | rafthttp started peer <*>	33
2278	<*> <*> <*> <*> I | rafthttp added peer <*>	33
2279	<*> <*> <*> <*> I | etcdserver starting server... version <*> cluster version to_be_decided	11
2280	<*> <*> <*> <*> I | rafthttp started streaming with peer <*> stream MsgApp <*> reader	33
2281	<*> <*> <*> <*> I | rafthttp started streaming with peer <*> stream Message reader	33
2282	<*> <*> <*> <*> I | embed ClientTLS cert <*> key <*> <*> <*> <*> true crl-file	22
2283	<*> <*> <*> <*> I | embed listening for peers on <*> <*>	22
2284	<*> <*> <*> <*> I | rafthttp peer <*> became active	22
2285	Getting initial config snapshot from datastore	5
2286	got ip from dhcp <*>	11
2287	Using http <*> <*> as endpoint for portworx REST API file connection.go <*>	626
2288	Starting status report routine	8
2289	Using <*> <*> as endpoint for portworx gRPC API file connection.go <*>	626
2290	Starting Prometheus metrics server on port <*>	9
2291	Starting controller ControllerType Node	10
2292	Starting Node controller	11
2293	START logs for container cluster-management-agent of pod <*>	1
2294	START logs for container node-agent of pod <*>	1
2295	Generated self-signed cert <*> <*>	2
2296	Initializing Nats connection with url tls <*> <*> <*> tls <*> <*> <*> cluster <*>	11
2297	Portworx service is ACTIVE	11
2298	Running ansible task <*>	5
2299	<*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream MsgApp <*> writer	22
2300	starting the DNS updater for the address <*>	11
2301	REST Changing install-state ST_INSTALL <*> ST_FINISH	11
2302	syncing licenses file portworx.go <*> fn syncLicenses	715
2303	Starting serving-cert <*> <*>	17
2304	Serving securely on <*>	38
2305	settin webhook	9
2306	Registering a mutating webhook GVK Group <*> Version <*> Kind PodPreset path <*>	11
2307	Start tailing portworx.service logs	11
2308	<*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream Message writer	22
2309	grpc addrConn.createTransport failed to connect to https <*> <*> <nil> 0 <nil> . Err connection error desc transport Error while dialing dial tcp <*> <*> connect connection refused . Reconnecting...	33
2310	skipping action approval watcher <*> due to config for provider <*> is not provided. Github SCM provider requires additional configuration. Refer to Autopilot documentation. file main.go <*>	11
2311	Broadcasting ARP update for <*> <*> <*> <*> b6 <*> <*> via eth0	657
2312	<*> <*> <*> <*> I | embed listening for metrics on http <*> <*>	22
2313	> Starting local log-tailer	11
2314	<*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream Message reader	22
2315	verified action approval watcher <*> file main.go <*>	11
2316	setting <*> as an IP	662
2317	Node controller syncer status updated <*>	17
2318	<*> <*> <*> <*> no error handler specified with the subscriber. going with default error handler	11
2319	Registering a validating webhook GVK Group <*> Version <*> Kind PodPreset path <*>	11
2320	Starting http server to serve metrics at port <*> endpoint <*> file server.go <*>	11
2321	END logs for container stork of pod <*>	1
2322	> <*> <*> <*> <*> @ <*> <*> portworx.service <*> portworx-output.service <*> init.scope <*> <*> <*> <*>	11
2323	<*> <*> <*> <*> I | rafthttp established a TCP streaming connection with peer <*> stream MsgApp <*> reader	22
2324	<*> <*> <*> <*> Listening on <*>	11
2325	Executing command chmod +x set-env.sh bash set-env.sh ansible-playbook <*> chroot <*> inventory playbook.yaml in dir <*>	11
2326	Install done <*> MAIN exiting	11
2327	Setting up handler for user defined signal <*> signal file main.go <*>	11
2328	<*> <*> <*> <*> I | embed initial advertise peer URLs https <*> <*>	11
2329	<*> <*> <*> <*> INFO <*> term 0 received a MsgVote message with higher term from <*> term <*>	11
2330	Registering a mutating webhook GVK Group <*> Version <*> Kind ClusterPodPreset path <*>	11
2331	Executing command <*> +x set-env.sh	11
2332	<*> Flushing logs for PID <*> <*> lines <*>	11
2333	<*> <*> <*> <*> I | embed initial cluster	11
2334	Failed to scrape node err Get https <*> <*> true read tcp <*> <*> <*> read connection reset by peer node <*>	2
2335	failed to check if actions <*> <*> are licensed due to Head http <*> <*> AUTCapacityManagement dial tcp <*> <*> connect connection refused file portworx.go <*> fn syncLicenses	715
2336	<*> <*> <*> <*> INFO <*> became <*> at term <*>	121
2337	<*> <*> <*> <*> I | etcdserver recovered store from snapshot at index <*>	11
2338	Executing command <*> set-env.sh	11
2339	<*> Start tailing the logs for portworx.service portworx-output.service init.scope <*>	11
2340	<*> <*> <*> <*> I | mvcc restore compact to <*>	33
2341	actions <*> <*> for feature AUTCapacityManagement are not licensed. file portworx.go <*>	715
2342	<*> name Configure chroot	11
2343	<*> <*> <*> <*> INFO <*> logterm 0 index 0 vote 0 cast MsgVote for <*> logterm <*> index <*> at term <*>	11
2344	<*> portworx <*> found <*>	11
2345	Event occurred object <*> kind Endpoints apiVersion <*> type Warning reason FailedToUpdateEndpoint message Failed to update endpoint <*> Operation cannot be fulfilled on endpoints <*> the object has been modified please apply your changes to the latest version and try again	22
2346	Registering a validating webhook GVK Group <*> Version <*> Kind ClusterPodPreset path <*>	11
2347	Scraping all the objects from the system. file engine.go <*> component <*>	616
2348	<*> <*> <*> <*> I | etcdserver restarting member <*> in cluster <*> at commit index <*>	11
2349	FLAG <*> vsphere	22
2350	<*> portworx <*> Using <*>	11
2351	hosts chroots	11
2352	grpc addrConn.createTransport failed to connect to https <*> <*> <nil> 0 <nil> . Err connection error desc transport authentication handshake failed read tcp <*> <*> <*> read connection reset by peer . Reconnecting...	4
2353	<*> <*> <*> <*> INFO raft.node <*> <*> leader <*> at term <*>	77
2354	Node controller syncer status updated resync	11
2355	<*> <*> <*> <*> INFO <*> switched to configuration voters <*>	33
2356	user root	11
2357	<*> portworx <*> Creating px fs...	11
2358	<*> <*> <*> <*> I | rafthttp receiving database snapshot index <*> from <*> raft message size <*> kB	11
2359	FLAG <*> kubernetes	22
2360	<*> portworx <*> Checking alternate paths please wait...	11
2361	connection chroot	11
2362	Using reconciler lease	11
2363	<*> <*> <*> <*> I | snap saved database snapshot to disk total bytes <*>	11
2364	failed to create node client to check pool expansion status. err error connecting to GRPC server <*> <*> Connection timed out file portworx.go <*>	614
2365	<*> <*> <*> <*> INFO newRaft <*> peers <*> term <*> commit <*> applied <*> lastindex <*> lastterm <*>	11
2366	<*> portworx <*> Failed to build PX filesystem dependency...	11
2367	<*> <*> <*> <*> I | rafthttp successfully received and saved database snapshot index <*> from <*> raft message size <*> kB db size <*> MB took <*>	11
2368	<*> <*> <*> <*> I | etcdserver/api enabled capabilities for version <*>	22
2369	FLAG <*> true	88
2370	<*> portworx <*> Downloading from https <*>	22
2371	vars	11
2372	Failed to scrape all the objects from the system error connecting to GRPC server <*> <*> Connection timed out file engine.go <*> component <*>	613
2373	<*> <*> <*> <*> INFO log committed 0 applied 0 unstable.offset <*> len unstable.Entries 0 starts to restore snapshot index <*> term <*>	11
2374	<*> <*> <*> <*> I | etcdserver/membership added member <*> https <*> <*> to cluster <*> from store	33
2375	apt_distro buster	11
2376	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg Initializing k8sOrchestratorInstance TraceId <*>	11
2377	<*> <*> <*> <*> INFO <*> switched to configuration voters <*> <*>	22
2378	<*> <*> <*> <*> INFO <*> commit <*> lastindex <*> lastterm <*> restored snapshot index <*> term <*>	11
2379	<*> <*> <*> <*> I | etcdserver/membership set the cluster version to <*> from store	22
2380	FLAG <*> 0s	44
2381	Event occurred object <*> kind ReplicaSet apiVersion <*> type Warning reason FailedCreate message Error creating Internal error occurred failed calling webhook <*> Post https <*> <*> <*> EOF	22
2382	<*> portworx <*> checking local archive please wait...	11
2383	successfully synced all hostendpoints	5
2384	<*> <*> <*> <*> INFO <*> commit <*> restored snapshot index <*> term <*>	11
2385	level info time <*> <*> <*> caller <*> <*> msg k8s client using in-cluster config TraceId <*>	33
2386	tasks	11
2387	END logs for container cluster-management-agent of pod <*>	1
2388	got pod namespace <*>	22
2389	<*> portworx <*> Failed to load PX filesystem dependencies for kernel <*>	11
2390	<*> <*> <*> <*> I | etcdserver applying snapshot at index 0...	11
2391	Node controller is now running	4
2392	level info time <*> <*> <*> caller <*> <*> msg Setting client QPS to <*> and Burst to <*> TraceId <*>	33
2393	sync <*> failed with Internal error occurred failed calling webhook <*> Post https <*> <*> <*> EOF	22
2394	<*> name Distribution	22
2395	<*> systemd <*> portworx.service Main process exited code exited status <*>	11
2396	got podpresets podpresetlist kind PodPreset apiVersion <*> metadata name proxy namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	22
2397	<*> <*> <*> <*> I | etcdserver raft applied incoming snapshot at index <*>	11
2398	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg New internal feature states values stored successfully map <*> false TraceId <*>	11
2399	Synchronizing IPAM data	3
2400	<*> <*> <*> <*> I | etcdserver starting server... version <*> cluster version <*>	11
2401	<*> <*> <*> <*> I | etcdserver recovering lessor...	11
2402	ansible_os_family	22
2403	got filtered podpresets filteredpodpreset kind PodPreset apiVersion <*> metadata name proxy namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	22
2404	<*> systemd <*> portworx.service Failed with result exit-code .	11
2405	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg k8sOrchestratorInstance initialized TraceId <*>	11
2406	sync <*> failed with Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	747
2407	<*> <*> <*> <*> I | etcdserver finished recovering lessor	11
2408	namespaced env env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	22
2409	<*> <*> <*> <*> I | etcdserver <*> as single-node fast-forwarding <*> ticks election ticks <*>	11
2410	Node and IPAM data is in sync	2
2411	FLAG <*> 0	66
2412	ansible_distribution	22
2413	<*> <*> <*> <*> I | etcdserver restoring mvcc store...	11
2414	Event occurred object <*> kind ReplicaSet apiVersion <*> type Warning reason FailedCreate message Error creating Internal error occurred failed calling webhook <*> Post https <*> <*> <*> dial tcp <*> <*> connect connection refused	746
2415	namespaced volumes volumes null	65
2416	<*> systemd <*> Stopping Portworx FIFO logging reader...	11
2417	level info time <*> <*> <*> caller <*> <*> msg Initializing CNS controller TraceId <*>	11
2418	<*> name Distribution version	11
2419	<*> systemd <*> Stopped Portworx FIFO logging reader.	11
2420	ansible_distribution_version	22
2421	<*> <*> <*> <*> I | etcdserver finished restoring mvcc store	11
2422	<*> systemd <*> Closed Portworx logging FIFO.	11
2423	got clusterpodpresets clusterpodpresetlist kind ClusterPodPreset apiVersion <*> metadata name proxy uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> <*> apiVersion <*> kind ClusterPodPreset metadata annotations name proxy spec env metadata merge_strategy append separator type multi name NO_PROXY value <*> localhost <*> kubernetes <*> <*> <*> <*> <*> <*> <*> metadata merge_strategy append separator type multi name no_proxy value <*> localhost <*> kubernetes <*> <*> <*> <*> <*> <*> <*> metadata merge_strategy append separator type multi name USER_NO_PROXY value <*> <*> <*> metadata merge_strategy replace separator type single name HTTP_PROXY value http <*> <*> metadata merge_strategy replace separator type single name http_proxy value http <*> <*> metadata merge_strategy replace separator type single name HTTPS_PROXY value http <*> <*> metadata merge_strategy replace separator type single name https_proxy value http <*> <*> selector matchLabels <*> proxy n managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace	31
2424	<*> name Distribution major version	11
2425	<*> <*> <*> <*> I | etcdserver recovering alarms...	11
2426	<*> <*> <*> <*> I | etcdserver/membership added member <*> https <*> <*> to cluster <*>	11
2427	got filtered clusterpodpreset filteredclusterpodpreset kind ClusterPodPreset apiVersion <*> metadata name proxy uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> <*> apiVersion <*> kind ClusterPodPreset metadata annotations name proxy spec env metadata merge_strategy append separator type multi name NO_PROXY value <*> localhost <*> kubernetes <*> <*> <*> <*> <*> <*> <*> metadata merge_strategy append separator type multi name no_proxy value <*> localhost <*> kubernetes <*> <*> <*> <*> <*> <*> <*> metadata merge_strategy append separator type multi name USER_NO_PROXY value <*> <*> <*> metadata merge_strategy replace separator type single name HTTP_PROXY value http <*> <*> metadata merge_strategy replace separator type single name http_proxy value http <*> <*> metadata merge_strategy replace separator type single name HTTPS_PROXY value http <*> <*> metadata merge_strategy replace separator type single name https_proxy value http <*> <*> selector matchLabels <*> proxy n managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace	30
2428	id <namespace <*> name autopilot-account > labels <key <*> value autopilot-account >	165
2429	<*> <*> <*> <*> I | etcdserver closing old backend...	11
2430	<*> <*> <*> <*> I | etcdserver finished recovering alarms	11
2431	ansible_distribution_major_version	22
2432	<*> systemd <*> <*> Consumed <*> CPU time	143
2433	cluster env env name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append	11
2434	<*> <*> <*> <*> I | etcdserver recovering auth store...	11
2435	cluster volumes volumes null	55
2436	level info time <*> <*> <*> caller volume/manager.go <*> msg Initializing new volume.defaultManager... TraceId <*>	11
2437	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg New feature states values from <*> stored successfully map <*> false TraceId <*>	22
2438	level info time <*> <*> <*> caller node/manager.go <*> msg Initializing node.defaultManager... TraceId <*>	11
2439	level info time <*> <*> <*> caller node/manager.go <*> msg node.defaultManager initialized TraceId <*>	11
2440	level info time <*> <*> <*> caller <*> <*> msg Adding watch on path <*> TraceId <*>	11
2441	<*> name Include amazon os family changes	11
2442	level info time <*> <*> <*> caller service/service.go <*> msg configured <*> with clusterFlavor VANILLA and mode controller TraceId <*>	11
2443	include_tasks <*>	11
2444	<*> <*> <*> <*> I | etcdserver finished recovering auth store	11
2445	Could not retrieve PX node status error Get http <*> <*> dial tcp <*> <*> connect connection refused	715
2446	when ansible_facts distribution Amazon	11
2447	<*> <*> <*> <*> I | etcdserver recovering store v2...	11
2448	controller service registered	11
2449	merged env merged env name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> metadata type multi separator merge_strategy append	11
2450	merged volumes merged volumes null	25
2451	level info time <*> <*> <*> caller node/manager.go <*> msg Successfully registered node <*> with nodeUUID <*> TraceId <*>	33
2452	<*> <*> <*> <*> I | etcdserver/membership removed member <*> from cluster <*>	22
2453	<*> <*> <*> <*> E | etcdserver the member has been permanently removed from the cluster	11
2454	<*> name Include centos/debian os family changes	11
2455	id <namespace <*> name px-account > labels <key <*> value px-account >	132
2456	<*> <*> <*> <*> I | etcdserver finished closing old backend	11
2457	FLAG <*> endpointsleases	22
2458	merged volume mounts merged volume mounts null	24
2459	include_tasks <*> ansible_os_family <*>	11
2460	<*> <*> <*> <*> I | etcdserver finished recovering store <*>	11
2461	<*> <*> <*> <*> I | etcdserver the <*> used by this member must be removed.	10
2462	<*> <*> <*> <*> I | etcdserver aborting publish because server is stopped	9
2463	got pod namespace cert-manager	11
2464	when ansible_facts distribution ! Amazon	11
2465	<*> <*> <*> <*> I | etcdserver recovering cluster configuration...	11
2466	<*> <*> <*> <*> I | rafthttp stopping peer <*>	30
2467	got podpresets podpresetlist kind PodPreset apiVersion <*> metadata name proxy namespace cert-manager uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	11
2468	#data is added with extra tab identation to match identation with playbook.yaml	11
2469	environment	11
2470	got filtered podpresets filteredpodpreset kind PodPreset apiVersion <*> metadata name proxy namespace cert-manager uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> annotations <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f spec . f env f selector . f matchLabels . f <*> spec selector matchLabels <*> proxy env name NO_PROXY value <*> metadata type multi separator merge_strategy append name no_proxy value <*> metadata type multi separator merge_strategy append	11
2471	<*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> writer	57
2472	http_proxy ansible_env.http_proxy	11
2473	<*> <*> <*> <*> I | rafthttp stopped HTTP pipelining with peer <*>	27
2474	namespaced env env name no_proxy value <*> metadata type multi separator merge_strategy append name NO_PROXY value <*> metadata type multi separator merge_strategy append	11
2475	<*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> stream MsgApp <*> reader	26
2476	HTTP_PROXY ansible_env.HTTP_PROXY	11
2477	level info time <*> <*> <*> caller node/manager.go <*> msg Successfully discovered node with nodeUUID <*> in vm VirtualMachine <*> VirtualCenterHost <*> UUID <*> Datacenter Datacenter Datacenter Datacenter <*> @ <*> VirtualCenterHost <*> TraceId <*>	33
2478	<*> <*> <*> <*> I | rafthttp stopped streaming with peer <*> stream Message reader	25
2479	HTTPS_PROXY ansible_env.HTTPS_PROXY	11
2480	<*> <*> <*> <*> I | etcdserver finished recovering cluster configuration	11
2481	level info time <*> <*> <*> caller node/manager.go <*> msg Successfully discovered node <*> with nodeUUID <*> TraceId <*>	33
2482	<*> <*> <*> <*> I | rafthttp stopped peer <*>	24
2483	id <name portworx > labels <key <*> value portworx > labels <key <*> value portworx >	33
2484	<*> <*> <*> <*> I | etcdserver removing old peers from network...	11
2485	END logs for container etcd of pod <*>	2
2486	https_proxy ansible_env.https_proxy	11
2487	<*> <*> <*> <*> I | rafthttp closed the TCP streaming connection with peer <*> stream MsgApp <*> writer	22
2488	<*> <*> <*> <*> I | rafthttp closed the TCP streaming connection with peer <*> stream Message writer	22
2489	NO_PROXY ansible_env.NO_PROXY	11
2490	id <namespace <*> name stork-account > labels <key <*> value stork-account >	143
2491	no_proxy ansible_env.no_proxy	11
2492	cluster env env name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace	11
2493	Executing command <*> <*> chroot <*> inventory playbook.yaml	11
2494	<*> <*> <*> <*> W | rafthttp <*> the TCP streaming connection with peer <*> stream MsgApp <*> reader	22
2495	id <namespace portworx name default > labels <key <*> value default >	143
2496	PLAY Configure chroot	11
2497	<*> <*> <*> <*> E | rafthttp failed to read <*> on stream MsgApp <*> context canceled	11
2498	<*> <*> <*> <*> I | rafthttp peer <*> became inactive message send to peer failed	22
2499	merged env merged env name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> metadata type multi separator merge_strategy append name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace	15
2500	TASK Gathering Facts gather_subset all gather_timeout <*>	11
2501	ok <*>	22
2502	ok <*> >	44
2503	msg Debian	11
2504	msg Ubuntu	11
2505	msg <*>	22
2506	TASK Include amazon os family changes <*> <*>	11
2507	skipping <*>	11
2508	TASK Include centos/debian os family changes <*> <*> ansible_os_family <*>	11
2509	<*> <*> <*> <*> W | rafthttp <*> the TCP streaming connection with peer <*> stream Message reader	22
2510	included <*> for <*>	11
2511	File exists <*> Copy over	11
2512	TASK Check version before upgrade <*> lsb_release <*>	11
2513	changed <*>	76
2514	<*> <*> <*> <*> I | rafthttp removed peer <*>	22
2515	the default service ipfamily for this cluster is IPv4	11
2516	TASK Remove <*> if it is installed <*> apt remove <*> <*>	11
2517	Health of component changed lastReport health.HealthReport Live true Ready false name async_calc_graph newReport health.HealthReport Live true Ready true	33
2518	fatal <*> FAILED! > changed true cmd apt remove <*> <*> delta 0 <*> <*> end <*> <*> <*> <*> msg <*> return code rc <*> start <*> <*> <*> <*> stderr nWARNING apt does not have a stable CLI interface. Use with caution in scripts. n nTerminated stderr_lines WARNING apt does not have a stable CLI interface. Use with caution in scripts. Terminated stdout Reading package lists... nBuilding dependency tree... nReading state information... nPackage <*> is not installed so not removed n0 upgraded 0 newly installed 0 to remove and <*> not upgraded. <*> not fully installed or removed. nAfter this operation 0 B of additional disk space will be used. nSetting up rpcbind <*> ... r nSetting up <*> <*> <*> ... r ndebconf unable to initialize frontend Dialog r ndebconf TERM is not set so the dialog frontend is not usable. r ndebconf falling back to frontend Readline r n r nCreating config file <*> with new version r ndebconf unable to initialize frontend Dialog r ndebconf TERM is not set so the dialog frontend is not usable. r ndebconf falling back to frontend Readline r nAdding system user `statd UID <*> ... r nAdding new user `statd UID <*> with group `nogroup ... r nNot creating home directory <*> . r nCreated symlink <*> → <*> r nCreated symlink <*> → <*> r <*> is a disabled or a static unit not starting it. r nSetting up <*> <*> <*> ... r ndebconf unable to initialize frontend Dialog r ndebconf TERM is not set so the dialog frontend is not usable. r ndebconf falling back to frontend Readline r nModified configuration file r <*> r n r nexports A new version <*> of r nconfiguration file <*> is available but the version installed r ncurrently has been locally modified. r n r n <*> install the package maintainer s version r n <*> keep the local version currently installed r n <*> show the differences between the versions r n <*> show a <*> difference between the versions r n <*> start a new shell to examine the situation r n r nWhat do you want to do about modified configuration file exports? stdout_lines Reading package lists... Building dependency tree... Reading state information... Package <*> is not installed so not removed 0 upgraded 0 newly installed 0 to remove and <*> not upgraded. <*> not fully installed or removed. After this operation 0 B of additional disk space will be used. Setting up rpcbind <*> ... Setting up <*> <*> <*> ... debconf unable to initialize frontend Dialog debconf TERM is not set so the dialog frontend is not usable. debconf falling back to frontend Readline Creating config file <*> with new version debconf unable to initialize frontend Dialog debconf TERM is not set so the dialog frontend is not usable. debconf falling back to frontend Readline Adding system user `statd UID <*> ... Adding new user `statd UID <*> with group `nogroup ... Not creating home directory <*> . Created symlink <*> → <*> Created symlink <*> → <*> <*> is a disabled or a static unit not starting it. Setting up <*> <*> <*> ... debconf unable to initialize frontend Dialog debconf TERM is not set so the dialog frontend is not usable. debconf falling back to frontend Readline Modified configuration file <*> exports A new version <*> of configuration file <*> is available but the version installed currently has been locally modified. <*> install the package maintainer s version <*> keep the local version currently installed <*> show the differences between the versions <*> show a <*> difference between the versions <*> start a new shell to examine the situation What do you want to do about modified configuration file exports?	11
2519	...ignoring	33
2520	<*> <*> <*> <*> I | etcdserver finished removing old peers from network	11
2521	level info time <*> <*> <*> caller <*> <*> msg ControllerGetCapabilities called with args XXX_NoUnkeyedLiteral XXX_unrecognized XXX_sizecache 0 TraceId <*>	33
2522	<*> <*> <*> <*> I | etcdserver adding peers from new cluster configuration into network...	11
2523	TASK Remove <*> if it is installed <*> sudo apt-key adv <*> <*> <*> <*>	22
2524	cluster env env name no_proxy value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append name USER_NO_PROXY value <*> <*> <*> metadata type multi separator merge_strategy append name HTTP_PROXY value http <*> <*> metadata type single separator merge_strategy replace name http_proxy value http <*> <*> metadata type single separator merge_strategy replace name HTTPS_PROXY value http <*> <*> metadata type single separator merge_strategy replace name https_proxy value http <*> <*> metadata type single separator merge_strategy replace name NO_PROXY value <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes localhost portworx-service <*> metadata type multi separator merge_strategy append	7
2525	<*> <*> <*> <*> I | etcdserver finished adding peers from new cluster configuration into network...	11
2526	<*> <*> <*> <*> I | etcdserver finished applying incoming snapshot at index <*>	11
2527	<*> <*> <*> <*> I | etcdserver published Name <*> ClientURLs https <*> <*> to cluster <*>	11
2528	<*> <*> <*> <*> I | embed ready to serve client requests	22
2529	<*> <*> <*> <*> I | embed serving client requests on <*> <*>	22
2530	<*> <*> <*> <*> I | embed rejected connection from <*> <*> error EOF ServerName	44
2531	fatal <*> FAILED! > changed true cmd sudo apt-key adv <*> <*> <*> <*> delta 0 <*> <*> end <*> <*> <*> <*> msg <*> return code rc <*> start <*> <*> <*> <*> stderr Warning apt-key output should not be parsed stdout is not a terminal ngpg keyserver receive failed Connection timed out stderr_lines Warning apt-key output should not be parsed stdout is not a terminal gpg keyserver receive failed Connection timed out stdout Executing <*> <*> <*> <*> <*> stdout_lines Executing <*> <*> <*> <*> <*>	22
2532	<*> systemd <*> Started libcontainer container <*>	374
2533	Hit error connecting to datastore <*> retry error etcdserver request timed out	11
2534	level info time <*> <*> <*> caller <*> <*> msg Starting container with operation mode METADATA_SYNC TraceId <*>	11
2535	<*> <*> <*> <*> I | mvcc store.index compact <*>	11
2536	<*> <*> <*> <*> I | mvcc finished scheduled compaction at <*> took <*>	11
2537	<*> <*> <*> <*> I | etcdserver/api/etcdhttp <*> OK status code <*>	208
2538	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result range_response_count 0 size <*> took too long <*> to execute	330
2539	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error context canceled took too long <*> to execute	88
2540	WARNING <*> <*> <*> <*> grpc <*> failed to write status connection error desc transport is closing	143
2541	<*> <*> <*> <*> W | wal sync duration of <*> expected less than <*>	88
2542	<*> <*> <*> <*> INFO <*> logterm <*> index <*> vote <*> ignored MsgVote from <*> logterm <*> index <*> at term <*> lease is not expired remaining ticks <*>	33
2543	<*> <*> <*> <*> INFO <*> is starting a new election at term <*>	44
2544	level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg Initializing MetadataSyncer	11
2545	level info time <*> <*> <*> caller <*> <*> msg k8s client using in-cluster config	22
2546	TASK Make a copy of security repos <*> cat <*> | grep secu > <*>	11
2547	TASK Wait for APT Lock before doing update <*> while fuser <*> <*> 2> <*> do sleep <*> done	11
2548	level info time <*> <*> <*> caller <*> <*> msg Setting client QPS to <*> and Burst to <*>	22
2549	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg Initializing k8sOrchestratorInstance	11
2550	<*> <*> <*> <*> INFO <*> received MsgVoteResp from <*> at term <*>	55
2551	TASK Update apt-get repo and cache update_cache yes force_apt_get yes cache_valid_time <*>	11
2552	<*> <*> <*> <*> INFO <*> logterm <*> index <*> sent MsgVote request to <*> at term <*>	44
2553	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg New internal feature states values stored successfully map <*> false	11
2554	level info time <*> <*> <*> caller k8sorchestrator/k8sorchestrator.go <*> msg k8sOrchestratorInstance initialized	11
2555	level info time <*> <*> <*> caller <*> <*> msg Defaulting timeout for vCenter Client to <*> minutes	11
2556	TASK List upgradable packages <*> apt-get <*> upgrade	11
2557	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Initializing defaultVirtualCenterManager...	11
2558	<*> <*> <*> <*> INFO <*> received MsgVoteResp rejection from <*> at term <*>	33
2559	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully initialized defaultVirtualCenterManager	11
2560	TASK Exclude kubeadm kubelet kubectl packages from upgrades <*> apt-mark hold kubeadm kubectl kubelet <*>	11
2561	level info time <*> <*> <*> caller vsphere/virtualcentermanager.go <*> msg Successfully registered VC <*>	11
2562	<*> <*> <*> <*> INFO <*> has received <*> MsgVoteResp votes and <*> vote rejections	33
2563	Version <*> Format %h	22
2564	<*> <*> <*> <*> INFO <*> term <*> received a MsgVote message with higher term from <*> term <*>	22
2565	level info time <*> <*> <*> caller vsphere/virtualcenter.go <*> msg New session ID for VSPHERE.LOCAL arvind <*>	11
2566	TASK Install security updates <*> apt-get upgrade <*> Dir Etc SourceList <*> <*> Dpkg Options <*> <*> Dpkg Options <*> <*>	11
2567	level info time <*> <*> <*> caller volume/manager.go <*> msg Initializing new volume.defaultManager...	11
2568	ReadCPIConfigYAML failed yaml unmarshal errors	22
2569	<*> <*> <*> <*> INFO <*> logterm <*> index <*> vote 0 cast MsgVote for <*> logterm <*> index <*> at term <*>	22
2570	level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg Adding watch on path <*>	11
2571	<*> systemd <*> <*> Consumed <*> <*> CPU time	11
2572	line <*> cannot unmarshal !!seq into config.CPIConfigYAML	22
2573	level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg Initialized metadata syncer	11
2574	ReadConfig INI succeeded. CPI <*> <*> is deprecated and will be removed in <*> Please use YAML based <*>	22
2575	TASK Check version after upgrade <*> lsb_release <*>	11
2576	level info time <*> <*> <*> caller syncer/metadatasyncer.go <*> msg fullSync is triggered TraceId <*>	11
2577	Config initialized	44
2578	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result range_response_count <*> size <*> took too long <*> to execute	2541
2579	level info time <*> <*> <*> caller <*> <*> msg FullSync start TraceId <*>	11
2580	ReadNsxtConfig failed user or vmc access token or client cert file must be set	22
2581	level warn time <*> <*> <*> caller <*> <*> msg could not find any volume which is present in both k8s and in CNS TraceId <*>	11
2582	Unmarshal failed yaml unmarshal errors	22
2583	PLAY RECAP	8
2584	level info time <*> <*> <*> caller <*> <*> msg FullSync fullSyncDeleteVolumes could not find any volume which is not present in k8s and needs to be checked for volume deletion. TraceId <*>	11
2585	<*> ok <*> changed <*> unreachable 0 failed 0 skipped <*> rescued 0 ignored <*>	7
2586	level info time <*> <*> <*> caller <*> <*> msg FullSync end TraceId <*>	11
2587	line <*> cannot unmarshal !!seq into config.LBConfigYAML	44
2588	ReadConfigYAML failed yaml unmarshal errors	22
2589	Successfully executed command chmod +x set-env.sh bash set-env.sh ansible-playbook <*> chroot <*> inventory playbook.yaml	5
2590	Executing post execution command cat <*> >> <*>	4
2591	ReadConfig INI succeeded. LoadBalancer <*> <*> is deprecated and will be removed in <*> Please use YAML based <*>	22
2592	<*> <*> <*> <*> W | etcdserver/api/etcdhttp <*> error QGET failed etcdserver request timed out status code <*>	33
2593	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error context deadline exceeded took too long <*> to execute	88
2594	Executed post execution command cat <*> >> <*>	3
2595	END logs for container node-agent of pod <*>	1
2596	Detected CSI driver <*>	11
2597	Supports migration from <*> plugin <*>	11
2598	Using saving PVs to API server in background	10
2599	new leader detected current leader <*>	57
2600	became leader starting	17
2601	Starting provisioner controller <*>	4
2602	Starting <*> volume queue	3
2603	Started provisioner controller <*>	2
2604	ReadRouteConfig failed router path is required	22
2605	loaded serving cert Generated self signed cert <*> serving validServingFor <*> localhost localhost issuer <*> <*> <*> <*> <*> <*> UTC to <*> <*> <*> <*> <*> UTC now <*> <*> <*> <*> <*> UTC	47
2606	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	11
2607	loaded SNI cert <*> self-signed loopback <*> serving validServingFor <*> issuer <*> <*> <*> <*> <*> <*> UTC to <*> <*> <*> <*> <*> UTC now <*> <*> <*> <*> <*> UTC	46
2608	<*> systemd <*> Created slice libcontainer container <*>	99
2609	loaded client CA <*> <*> <*> <*> <*> <*> <*> <*> <*> kubernetes issuer <self> <*> <*> <*> <*> <*> UTC to <*> <*> <*> <*> <*> UTC now <*> <*> <*> <*> <*> UTC	42
2610	Successfully loaded configuration. GOMAXPROCS 4 builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0xc0 AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	11
2611	... dropped 4 logs ...	11
2612	Could not construct reference to <*> TypeMeta <*> Kind APIVersion ObjectMeta <*> Name <*> GenerateName Namespace <*> SelfLink UID <*> ResourceVersion <*> Generation 0 CreationTimestamp <*> Time time.Time wall 0x0 ext <*> loc time.Location <*> DeletionTimestamp <*> nil DeletionGracePeriodSeconds <*> nil Labels map string string nil Annotations map string string nil OwnerReferences <*> nil Finalizers string nil ClusterName ManagedFields <*> <*> Manager <*> Operation Update APIVersion <*> Time <*> <*> FieldsType FieldsV1 FieldsV1 <*> <*> Spec <*> HolderIdentity string nil LeaseDurationSeconds <*> nil AcquireTime <*> nil RenewTime <*> nil LeaseTransitions <*> nil due to no kind is registered for the type <*> in scheme <*> <*> . Will not report event Normal LeaderElection <*> became leader	11
2613	<*> <*> <*> <*> W | etcdserver request header <ID <*> username <*> auth_revision <*> > txn <compare <target MOD key <*> mod_revision 0 > success <request_put <key <*> value_size <*> >> failure <>> with result size <*> took too long <*> to execute	11
2614	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> with result range_response_count <*> size <*> took too long <*> to execute	88
2615	<*> <*> <*> <*> W | etcdserver request header <ID <*> username <*> auth_revision <*> > txn <compare <target MOD key <*> mod_revision <*> > success <request_put <key <*> value_size <*> >> failure <request_range <key <*> > >> with result size <*> took too long <*> to execute	33
2616	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count 0 size <*> took too long <*> to execute	341
2617	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result range_response_count 0 size <*> took too long <*> to execute	770
2618	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> limit <*> with result range_response_count <*> size <*> took too long <*> to execute	231
2619	Event <*> Kind Endpoints Namespace <*> Name <*> UID <*> APIVersion <*> ResourceVersion <*> FieldPath type Normal reason LeaderElection <*> became leader	11
2620	Health of component changed lastReport health.HealthReport Live true Ready false name <*> newReport health.HealthReport Live true Ready true	33
2621	<*> Name tunl0 Addrs set.mapSet <*> set.empty	33
2622	Interface addrs changed. update <*> Name tunl0 Addrs set.mapSet <*> set.empty	33
2623	intdataplane.ifaceUpdate Name tunl0 State up Index <*>	33
2624	bird <*> Initializing	198
2625	Creating internal dataplane driver. config intdataplane.Config Hostname <*> IPv6Enabled false RuleRendererOverride rules.RuleRenderer nil IPIPMTU 0 VXLANMTU 0 VXLANPort <*> MaxIPSetSize <*> IptablesBackend auto IPSetsRefreshInterval <*> RouteRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckInterval <*> IptablesInsertMode insert IptablesLockFilePath <*> IptablesLockTimeout 0 IptablesLockProbeInterval <*> XDPRefreshInterval <*> Wireguard wireguard.Config Enabled false ListeningPort <*> FirewallMark 0 RoutingRulePriority <*> RoutingTableIndex <*> InterfaceName wireguard.cali MTU 0 NetlinkTimeout <*> RulesConfig rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0xc0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop IfaceMonitorConfig ifacemonitor.Config InterfaceExcludes regexp.Regexp regexp.Regexp <*> ResyncInterval <*> StatusReportingInterval 0 ConfigChangedRestartCallback func <*> FatalErrorRestartCallback func error <*> PostInSyncCallback func <*> HealthAggregator <*> <*> RouteTableManager <*> <*> DebugSimulateDataplaneHangAfter 0 ExternalNodesCidrs string nil BPFEnabled false BPFDisableUnprivileged true BPFKubeProxyIptablesCleanupEnabled true BPFLogLevel off BPFExtToServiceConnmark 0 BPFDataIfacePattern regexp.Regexp <*> XDPEnabled true XDPAllowGeneric false BPFConntrackTimeouts conntrack.Timeouts CreationGracePeriod <*> TCPPreEstablished <*> TCPEstablished <*> TCPFinsSeen <*> TCPResetSeen <*> UDPLastSeen <*> GenericIPLastSeen <*> ICMPLastSeen <*> BPFCgroupV2 BPFConnTimeLBEnabled true BPFMapRepin true BPFNodePortDSREnabled false KubeProxyMinSyncPeriod <*> KubeProxyEndpointSlicesEnabled false SidecarAccelerationEnabled false LookPathOverride func string string error nil KubeClientSet <*> <*> FeatureDetectOverrides map string string nil hostMTU 0 MTUIfacePattern regexp.Regexp <*>	11
2626	Creating rule renderer. config rules.Config IPSetConfigV4 ipsets.IPVersionConfig <*> IPSetConfigV6 ipsets.IPVersionConfig <*> WorkloadIfacePrefixes string cali IptablesMarkAccept <*> IptablesMarkPass <*> IptablesMarkScratch0 <*> IptablesMarkScratch1 <*> IptablesMarkEndpoint <*> IptablesMarkNonCaliEndpoint 0x0 KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName KubeIPVSSupportEnabled false OpenStackMetadataIP net.IP nil OpenStackMetadataPort <*> OpenStackSpecialCasesEnabled false VXLANEnabled false VXLANPort <*> VXLANVNI <*> IPIPEnabled true IPIPTunnelAddress net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> 0xc0 VXLANTunnelAddress net.IP nil AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false WireguardEnabled false WireguardInterfaceName wireguard.cali IptablesLogPrefix <*> EndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> DisableConntrackInvalid false NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName IptablesNATOutgoingInterfaceFilter NATOutgoingAddress net.IP nil BPFEnabled false ServiceLoopPrevention Drop	11
2627	bird <*> Starting	209
2628	bird <*> Connected to table master	209
2629	bird <*> State changed to feed	209
2630	bird Graceful restart started	66
2631	bird Graceful restart done	66
2632	bird Started	66
2633	bird <*> State changed to up	209
2634	Overall health status changed newStatus health.HealthReport Live true Ready true	33
2635	pickfirstBalancer HandleSubConnStateChange <*> CONNECTING <nil>	33
2636	grpc addrConn.createTransport failed to connect to <*> <nil> 0 <nil> . Err connection error desc transport Error while dialing dial tcp <*> connect connection refused . Reconnecting...	11
2637	pickfirstBalancer HandleSubConnStateChange <*> TRANSIENT_FAILURE connection error desc transport Error while dialing dial tcp <*> connect connection refused	11
2638	could not getversion rpc error code Unavailable desc connection error desc transport Error while dialing dial tcp <*> connect connection refused	11
2639	Successfully loaded configuration. GOMAXPROCS <*> builddate <*> <*> <*> config config.Config UseInternalDataplaneDriver true DataplaneDriver <*> WireguardEnabled false WireguardListeningPort <*> WireguardRoutingRulePriority <*> WireguardInterfaceName wireguard.cali WireguardMTU 0 BPFEnabled false BPFDisableUnprivileged true BPFLogLevel off BPFDataIfacePattern regexp.Regexp <*> BPFConnectTimeLoadBalancingEnabled true BPFExternalServiceMode tunnel BPFKubeProxyIptablesCleanupEnabled true BPFKubeProxyMinSyncPeriod <*> BPFKubeProxyEndpointSlicesEnabled false BPFExtToServiceConnmark 0 DebugBPFCgroupV2 DebugBPFMapRepinEnabled true DatastoreType kubernetes FelixHostname <*> EtcdAddr <*> <*> EtcdScheme http EtcdKeyFile EtcdCertFile EtcdCaFile EtcdEndpoints string nil TyphaAddr TyphaK8sServiceName TyphaK8sNamespace <*> TyphaReadTimeout <*> TyphaWriteTimeout <*> TyphaKeyFile TyphaCertFile TyphaCAFile TyphaCN TyphaURISAN Ipv6Support false IptablesBackend auto RouteRefreshInterval <*> InterfaceRefreshInterval <*> DeviceRouteSourceAddress net.IP nil DeviceRouteProtocol <*> RemoveExternalRoutes true IptablesRefreshInterval <*> IptablesPostWriteCheckIntervalSecs <*> IptablesLockFilePath <*> IptablesLockTimeoutSecs 0 IptablesLockProbeIntervalMillis <*> FeatureDetectOverride map string string nil IpsetsRefreshInterval <*> MaxIpsetSize <*> XDPRefreshInterval <*> PolicySyncPathPrefix NetlinkTimeoutSecs <*> MetadataAddr MetadataPort <*> OpenstackRegion InterfacePrefix cali InterfaceExclude regexp.Regexp regexp.Regexp <*> ChainInsertMode insert DefaultEndpointToHostAction ACCEPT IptablesFilterAllowAction ACCEPT IptablesMangleAllowAction ACCEPT LogPrefix <*> LogFilePath LogSeverityFile LogSeverityScreen INFO LogSeveritySys VXLANEnabled false VXLANPort <*> VXLANVNI <*> VXLANMTU 0 IPv4VXLANTunnelAddr net.IP nil VXLANTunnelMACAddr IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr net.IP 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0x0 0xff 0xff 0xc0 <*> <*> <*> AllowVXLANPacketsFromWorkloads false AllowIPIPPacketsFromWorkloads false AWSSrcDstCheck DoNothing ServiceLoopPrevention Drop ReportingIntervalSecs 0 ReportingTTLSecs <*> EndpointReportingEnabled false EndpointReportingDelaySecs <*> IptablesMarkMask <*> DisableConntrackInvalidCheck false HealthEnabled true HealthPort <*> HealthHost localhost PrometheusMetricsEnabled false PrometheusMetricsHost PrometheusMetricsPort <*> PrometheusGoMetricsEnabled true PrometheusProcessMetricsEnabled true FailsafeInboundHostPorts config.ProtoPort config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> FailsafeOutboundHostPorts config.ProtoPort config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol udp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> config.ProtoPort Net Protocol tcp Port <*> KubeNodePortRanges numorstring.Port numorstring.Port MinPort <*> MaxPort <*> PortName NATPortRange numorstring.Port MinPort 0x0 MaxPort 0x0 PortName NATOutgoingAddress net.IP nil UsageReportingEnabled true UsageReportingInitialDelaySecs <*> UsageReportingIntervalSecs <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd CalicoVersion <*> ExternalNodesCIDRList string nil DebugMemoryProfilePath DebugCPUProfilePath <*> DebugDisableLogDropping false DebugSimulateCalcGraphHangAfter 0 DebugSimulateDataplaneHangAfter 0 DebugPanicAfter 0 DebugSimulateDataRace false RouteSource CalicoIPAM RouteTableRange idalloc.IndexRange Min <*> Max <*> IptablesNATOutgoingInterfaceFilter SidecarAccelerationEnabled false XDPEnabled true GenericXDPEnabled false Variant Calico MTUIfacePattern regexp.Regexp <*> internalOverrides map string string sourceToRawConfig map config.Source map string string <*> map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd IpInIpEnabled true LogSeverityScreen Info ReportingIntervalSecs 0 <*> map string string IpInIpTunnelAddr <*> <*> map string string LogFilePath None LogSeverityFile None LogSeveritySys None MetadataAddr None <*> map string string datastoretype kubernetes defaultendpointtohostaction ACCEPT felixhostname <*> healthenabled true ipinipmtu 0 ipv6support false rawValues map string string CalicoVersion <*> ClusterGUID <*> ClusterType k8s bgp kubeadm kdd DatastoreType kubernetes DefaultEndpointToHostAction ACCEPT FelixHostname <*> HealthEnabled true IpInIpEnabled true IpInIpMtu 0 IpInIpTunnelAddr <*> Ipv6Support false LogFilePath None LogSeverityFile None LogSeverityScreen Info LogSeveritySys None MetadataAddr None ReportingIntervalSecs 0 Err error nil loadClientConfigFromEnvironment func apiconfig.CalicoAPIConfig error <*> useNodeResourceUpdates false gitcommit <*> version <*>	11
2640	<*> Name <*> Addrs set.mapSet	891
2641	Interface addrs changed. update <*> Name <*> Addrs set.mapSet	891
2642	intdataplane.ifaceUpdate Name <*> State up Index <*>	605
2643	END logs for container kube-vip of pod <*>	1
2644	bird Reconfiguration requested by SIGHUP	77
2645	bird Reconfiguring	66
2646	bird <*> Reconfigured	198
2647	bird Reconfigured	77
2648	Linux interface state changed. ifIndex 6 ifaceName <*> state up	33
2649	intdataplane.ifaceUpdate Name <*> State up Index 6	33
2650	Skipping API <*> because it has no resources.	77
2651	END logs for container portworx of pod <*>	11
2652	Netlink address update. addr fe80 ecee eeff feee eeee exists true ifIndex 6	22
2653	<*> Name <*> Addrs set.mapSet fe80 ecee eeff feee eeee set.empty	649
2654	Interface addrs changed. update <*> Name <*> Addrs set.mapSet fe80 ecee eeff feee eeee set.empty	649
2655	id <name <*> > labels <key control-plane value reach-manager > labels <key <*> value <*> > labels <key <*> value <*> > labels <key <*> value true >	33
2656	Starting AvailableConditionController	11
2657	Waiting for caches to sync for AvailableConditionController controller	11
2658	Starting OpenAPI AggregationController	11
2659	Starting APIServiceRegistrationController	11
2660	Waiting for caches to sync for APIServiceRegistrationController controller	11
2661	Starting API Priority and Fairness config controller	11
2662	pickfirstBalancer HandleSubConnStateChange <*> READY <nil>	22
2663	APIVersion <*>	11
2664	Adding NSXT secret listener failed %vconfig is not available for NSXT connector manager	11
2665	Starting route	11
2666	Will not configure cloud provider routes for <*> false <*> true.	11
2667	Starting cloud-node	11
2668	Starting autoregister controller	11
2669	Waiting for caches to sync for autoregister controller	11
2670	Starting OpenAPI controller	11
2671	Starting NamingConditionController	11
2672	Starting EstablishingController	11
2673	Starting KubernetesAPIApprovalPolicyConformantConditionController	11
2674	Unable to remove old endpoints from kubernetes service StorageError key not found Code <*> Key <*> ResourceVersion 0 AdditionalErrorMsg	11
2675	Caches are synced for autoregister controller	11
2676	Running API Priority and Fairness config worker	11
2677	Caches are synced for APIServiceRegistrationController controller	11
2678	Linux interface state changed. ifIndex 6 ifaceName <*> state down	11
2679	Started cloud-node	11
2680	Caches are synced for AvailableConditionController controller	11
2681	intdataplane.ifaceUpdate Name <*> State down Index 6	11
2682	all system priority classes are created successfully or already exist.	11
2683	Starting service	11
2684	OpenAPI AggregationController action for item Nothing removed from the queue .	11
2685	The vSphere cloud provider does not support load balancers	11
2686	OpenAPI AggregationController action for item <*> Nothing removed from the queue .	11
2687	Resetting endpoints for master service kubernetes to <*> <*>	11
2688	<*> <*> <*> <*> INFO <*> has received <*> MsgVoteResp votes and 0 vote rejections	11
2689	quota admission added evaluator for endpoints	11
2690	<*> <*> <*> <*> INFO <*> became leader at term <*>	11
2691	Netlink address update. addr fe80 ecee eeff feee eeee exists false ifIndex 6	11
2692	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> context deadline exceeded	44
2693	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error etcdserver leader changed took too long <*> to execute	77
2694	<*> Name <*> Addrs set.Set nil	330
2695	This node <*> is registered without the cloud taint. Will not process.	30
2696	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	319
2697	Interface addrs changed. update <*> Name <*> Addrs set.Set nil	330
2698	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result error etcdserver leader changed took too long <*> to execute	11
2699	Trace <*> <*> About to write a response <*> <*> <*> <*>	1144
2700	Recompute BGP peerings HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated HostBGPConfig node <*> name ip_addr_v4 updated HostBGPConfig node <*> name ip_addr_v6 updated HostBGPConfig node <*> name network_v4 updated HostBGPConfig node <*> name rr_cluster_id updated <*> updated	11
2701	Trace <*> GuaranteedUpdate etcd3 type apiregistration.APIService <*> <*> <*> <*> total time <*>	22
2702	Failed to create govmomi client. err ServerFaultCode Cannot complete login due to an incorrect user name or password.	8
2703	Trace <*> <*> Transaction committed <*> <*> <*> <*>	363
2704	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	143
2705	Trace <*> <*> Object stored in database <*> <*> <*> <*>	451
2706	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> dial tcp <*> <*> i/o timeout	33
2707	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	297
2708	Trace <*> GuaranteedUpdate etcd3 type coordination.Lease <*> <*> <*> <*> total time <*>	165
2709	intdataplane.ifaceUpdate Name <*> State down Index <*>	319
2710	<*> <*> <*> <*> W | etcdserver failed to send out heartbeat on time exceeded the <*> timeout for <*> to <*>	11
2711	<*> <*> <*> <*> W | etcdserver server is likely overloaded	11
2712	<*> failed with failing or missing response from https <*> <*> Get https <*> <*> <*> request canceled while waiting for connection Client.Timeout exceeded while awaiting headers	11
2713	<*> <*> <*> <*> W | etcdserver timed out waiting for read index response local node might have slow network	11
2714	<*> <*> <*> <*> W | etcdserver read-only range request key <*> range_end <*> count_only true with result error etcdserver request timed out took too long <*> to execute	77
2715	<*> <*> <*> <*> W | etcdserver read-only range request key <*> with result error etcdserver request timed out took too long <*> to execute	44
2716	quota admission added evaluator for serviceaccounts	11
2717	loading OpenAPI spec for <*> failed with failed to retrieve openAPI spec http error ResponseCode <*> Body error trying to reach service dial tcp <*> <*> i/o timeout	22
2718	Header map Content-Type text/plain charset utf-8 <*> nosniff	22
2719	OpenAPI AggregationController action for item <*> Rate Limited Requeue.	22
2720	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	77
2721	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	110
2722	Linux interface addrs changed. addrs set.mapSet <*> set.empty fe80 <*> <*> feb6 <*> set.empty ifaceName eth0	66
2723	Linux interface state changed. ifIndex 4 ifaceName <*> state up	11
2724	<*> failed with Operation cannot be fulfilled on <*> <*> the object has been modified please apply your changes to the latest version and try again	22
2725	intdataplane.ifaceUpdate Name <*> State up Index 4	11
2726	<*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> feb6 <*> set.empty	66
2727	<*> <*> <*> <*> E | rafthttp failed to read <*> on stream Message context canceled	11
2728	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet <*> set.empty fe80 <*> <*> feb6 <*> set.empty	66
2729	<*> <*> <*> <*> W | rafthttp rejected the stream from peer <*> since it was removed	66
2730	quota admission added evaluator for namespaces	11
2731	id <name wordpress > labels <key <*> value wordpress > labels <key <*> value wordpress >	33
2732	id <namespace wordpress name default > labels <key <*> value default >	385
2733	Trace <*> <*> Request completed <*> <*> <*> <*>	121
2734	Trace <*> GuaranteedUpdate etcd3 type <*> <*> <*> <*> <*> total time <*>	396
2735	Trace <*> Update url <*> user-agent manager/v0.0.0 linux/amd64 <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2736	Trace <*> List etcd3 key /autopilot.libopenstorage.org/autopilotruleobjects resourceVersion resourceVersionMatch limit <*> continue <*> <*> <*> <*> total time <*>	11
2737	Trace <*> List etcd3 key <*> resourceVersion 0 resourceVersionMatch limit <*> continue <*> <*> <*> <*> total time <*>	165
2738	Trace <*> List url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> as PartialObjectMetadataList g <*> v <*> <*> as PartialObjectMetadataList g <*> v <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	176
2739	Trace <*> <*> Listing from storage done <*> <*> <*> <*>	198
2740	Trace <*> <*> initial value restored <*> <*> <*> <*>	176
2741	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	209
2742	Trace <*> <*> About to apply patch <*> <*> <*> <*>	187
2743	watch of <*> ended with too old resource version <*> <*>	27
2744	END logs for container autopilot of pod <*>	1
2745	bird <*> State changed to start	88
2746	bird <*> State changed to wait	33
2747	watch of <*> ended with an error on the server unable to decode an event from the watch stream http2 client connection <*> has prevented the request from succeeding	9
2748	Trace <*> List etcd3 key /autopilot.libopenstorage.org/autopilotruleobjects resourceVersion 0 resourceVersionMatch limit <*> continue <*> <*> <*> <*> total time <*>	11
2749	Trace <*> List url <*> user-agent manager/v0.0.0 linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2750	Trace <*> Get url <*> user-agent manager/v0.0.0 linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	55
2751	Dataplane updates throttled	11
2752	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2753	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2754	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	77
2755	Dataplane updates no longer throttled	11
2756	Syncing routes found unexpected route ignoring due to grace period. dest <*> ifaceName <*> ifaceRegex ^cali. ipVersion <*>	2178
2757	Interface in cleanup grace period will retry after. ifaceName <*> ifaceRegex ^cali. ipVersion <*>	1089
2758	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> accept <*> as PartialObjectMetadata g <*> v <*> <*> as PartialObjectMetadata g <*> v <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	242
2759	Trace <*> Get url <*> user-agent manager/v0.0.0 linux/amd64 <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	110
2760	Trace <*> Get url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2761	apiserver was unable to write a JSON response http Handler timeout	99
2762	apiserver received an error that is not an <*> <*> s http Handler timeout http Handler timeout	99
2763	apiserver was unable to write a fallback JSON response http Handler timeout	99
2764	apiserver received an error that is not an <*> rpctypes.EtcdError code 0xe desc etcdserver leader changed etcdserver leader changed	77
2765	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	66
2766	apiserver received an error that is not an <*> <*> s context canceled context canceled	44
2767	apiserver received an error that is not an <*> rpctypes.EtcdError code 0xe desc etcdserver request timed out etcdserver request timed out	44
2768	Trace <*> GuaranteedUpdate etcd3 type policy.PodSecurityPolicy <*> <*> <*> <*> total time <*>	11
2769	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2770	Failed to report usage/get deprecation warnings. error Get https <*> false alp_policies 0 <*> <*> guid <*> heps 0 k8s_ver <*> policies 0 profiles <*> rev <*> size <*> type <*> version <*> weps <*> context deadline exceeded Client.Timeout exceeded while awaiting headers	66
2771	Resetting endpoints for master service kubernetes to <*>	11
2772	Auditing failed of request encoding failed policy.Eviction is not suitable for converting to <*> in scheme <*> <*>	209
2773	unable to encode watch object <*> write tcp <*> <*> <*> write connection reset by peer <*> writer http2.responseWriter <*> encoder versioning.codec <*> buf bytes.Buffer <*>	11
2774	Failed calling webhook failing closed <*> failed calling webhook <*> Post https <*> <*> <*> EOF	22
2775	Trace <*> Create url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	737
2776	timeout or abort while handling POST <*>	11
2777	Linux interface addrs changed. addrs set.mapSet fe80 <*> <*> feb6 <*> set.empty ifaceName eth0	11
2778	<*> Name eth0 Addrs set.mapSet fe80 <*> <*> feb6 <*> set.empty	11
2779	Interface addrs changed. update <*> Name eth0 Addrs set.mapSet fe80 <*> <*> feb6 <*> set.empty	11
2780	bird Adding protocol <*>	33
2781	Trace <*> Get url <*> user-agent <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	132
2782	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> endpoint-controller client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2783	Trace <*> GuaranteedUpdate etcd3 type discovery.EndpointSlice <*> <*> <*> <*> total time <*>	22
2784	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> endpointslice-controller client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2785	bird KIF Received address message for unknown interface <*>	66
2786	Trace <*> Patch url <*> user-agent <*> linux/amd64 <*> Format client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2787	Trace <*> Delete url <*> user-agent <*> linux/amd64 <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	22
2788	Trace <*> <*> Object deleted from database <*> <*> <*> <*>	22
2789	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2790	Trace <*> Update url <*> user-agent <*> linux/amd64 <*> serviceaccount <*> deployment-controller client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	11
2791	Trace <*> Get url <*> user-agent <*> <*> <*> client <*> accept <*> <*> protocol <*> <*> <*> <*> <*> total time <*>	4
2792	Trace <*> <*> Transformed response object <*> <*> <*> <*>	3
2793	Start NewCSISnapshotController with kubeconfig resyncPeriod <*>	33
2794	error retrieving resource lock <*> etcdserver leader changed	11
2795	error retrieving resource lock <*> etcdserver request timed out	22
2796	error retrieving resource lock <*> the server was unable to return a response in the time allotted but may still be processing the request get <*> <*>	22
2797	error retrieving resource lock <*> Get https <*> <*> http2 server sent GOAWAY and closed the connection LastStreamID <*> ErrCode NO_ERROR debug	11
2798	Reconfiguring	11
2799	Remove old route dest <*> ifaceName <*> ifaceRegex ^cali. ipVersion <*> routeProblems string unexpected route	88
2800	bird <*> State changed to stop	11
2801	bird <*> State changed to down	11
2802	failed to establish connection to CSI driver context deadline exceeded	11
2803	register maas provider <*>	23
2804	register aws provider <*>	19
2805	register azure provider <*>	21
2806	register vsphere provider	25
2807	register gcp provider <*>	27
2808	register generic provider	29
2809	register openstack provider	31
2810	detect env done spectrocluster Namespace <*> Name <*> env pilot	33581
2811	reconcile on pilot spectrocluster Namespace <*> Name <*>	4807
2812	downloading pack spectrocluster Namespace <*> Name <*> pack <*>	88
2813	create success spectrocluster Namespace <*> Name <*> <*> Pack name <*>	88
2814	pack downloaded spectrocluster Namespace <*> Name <*> <*> <*>	88
2815	skipping atop reconcile loop atop Namespace <*> Name <*> env pilot	4004
2816	create success spectrocluster Namespace <*> Name <*> name <*> <*> Secret	44
2817	Attempting to reconcile CloudFormation stack spectrocluster Namespace <*> Name <*> name <*>	22
2818	aws Error cloudformation spectrocluster Namespace <*> Name <*> code AccessDenied error AccessDenied User arn aws iam <*> <*> is not authorized to perform cloudformation DescribeStacks on resource arn aws cloudformation <*> <*> <*> with an explicit <*> n tstatus code <*> request id <*> region <*>	308
2819	aws Error cloudformation spectrocluster Namespace <*> Name <*> code ValidationError error ValidationError Stack with id <*> does not exist n tstatus code <*> request id <*> region <*>	44
2820	stack found in region spectrocluster Namespace <*> Name <*> region <*> stack <*>	22
2821	updating AWS CloudFormation stack spectrocluster Namespace <*> Name <*> stack <*>	22
2822	crd version info not found creating spectrocluster Namespace <*> Name <*> key Namespace <*> Name <*>	44
2823	installing crd from scopeDir spectrocluster Namespace <*> Name <*> scopeDir <*>	44
2824	starting clusterrolebinding role repair spectrocluster Namespace <*> Name <*> dir <*>	44
2825	applying dir spectrocluster Namespace <*> Name <*> dir <*>	44
2826	apply crd success spectrocluster Namespace <*> Name <*> provider capi	22
2827	unable to parse crd file continue to next error couldn t get version/kind json parse error json cannot unmarshal array into Go value of type struct APIVersion string json apiVersion omitempty Kind string json kind omitempty spectrocluster Namespace <*> Name <*> failed file <*>	22
2828	error spectrocluster Namespace <*> Name <*> message Warning kubectl apply should be used on resource created by either kubectl create <*> or kubectl apply	22
2829	apply crd success spectrocluster Namespace <*> Name <*> provider aws	22
2830	create AWSManagedCluster success spectrocluster Namespace <*> Name <*> name <*>	22
2831	create success spectrocluster Namespace <*> Name <*> <*> Cluster name <*>	22
2832	reconcileControlPlaneEndpoint spectrocluster Namespace <*> Name <*>	4796
2833	control plane endpoint reconcile done spectrocluster Namespace <*> Name <*>	4796
2834	creating or updating AWSManagedControlPlane spectrocluster Namespace <*> Name <*>	4796
2835	oidcIdentityProvider property value is not present in k8s pack spectrocluster Namespace <*> Name <*> packName <*>	4796
2836	should upgrade version in mcp spectrocluster Namespace <*> Name <*> desired version <*>	22
2837	reconcile mcp subnet tags spectrocluster Namespace <*> Name <*> cluster <*> mcp	22
2838	waiting for subnets in mcp network spec spectrocluster Namespace <*> Name <*>	22
2839	cluster security group not available yet skip ensure <*> port rule spectrocluster Namespace <*> Name <*>	4796
2840	create update operations spectrocluster Namespace <*> Name <*> mcp <*>	22
2841	create is triggered for ManagedControlPlane requeue after one minute	22
2842	AWSManagedCluster spec not changed spectrocluster Namespace <*> Name <*> name <*>	4774
2843	create update operations spectrocluster Namespace <*> Name <*> mcp 0	4774
2844	waiting for managed control plane to be ready spectrocluster Namespace <*> Name <*> name <*> namespace <*>	4774
2845	reconcile managed control plane done	4774
2846	begin reconcile for managed workers	4774
2847	creating or updating managed worker machine pool	4774
2848	creating or updating AWSManagedMachinePool spectrocluster Namespace <*> Name <*>	4774
2849	create success spectrocluster Namespace <*> Name <*> name <*> namespace <*>	22
2850	desired pool size for pool pool <*> size <*>	4774
2851	create update operations mmpOp <*> mpOp <*>	22
2852	create is triggered for worker MachinePool requeue after one minute	22
2853	check if rolling upgrade is required for AWSManagedMachinePool spectrocluster Namespace <*> Name <*> desired kind AWSManagedMachinePool apiVersion <*> metadata name <*> namespace <*> creationTimestamp null labels <*> <*> spec eksNodegroupName <*> availabilityZones <*> <*> <*> <*> subnetIDs <*> <*> additionalTags <*> spectro__tag spectro__ownerUid <*> <*> spectro__tag roleName <*> diskSize <*> instanceType t3.medium scaling minSize <*> maxSize <*> remoteAccess sshKeyName spectro capacityType spot status ready false replicas 0 existing kind AWSManagedMachinePool apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f labels . f <*> f spec . f additionalTags . f <*> f spectro__ownerUid f <*> f amiType f availabilityZones f capacityType f diskSize f eksNodegroupName f instanceType f remoteAccess . f sshKeyName f roleName f scaling . f maxSize f minSize f subnetIDs f status . f ready f replicas spec eksNodegroupName <*> availabilityZones <*> <*> <*> <*> subnetIDs <*> <*> additionalTags <*> spectro__tag spectro__ownerUid <*> <*> spectro__tag roleName <*> amiType <*> diskSize <*> instanceType t3.medium scaling minSize <*> maxSize <*> remoteAccess sshKeyName spectro capacityType spot status ready false replicas 0	22
2854	check if inline upgrade is required for AWSManagedMachinePool spectrocluster Namespace <*> Name <*> name <*> namespace <*>	4752
2855	check upgrade for existing machine pool MachinePool kind MachinePool apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> annotations <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f labels . f <*> f spec . f clusterName f replicas f template . f metadata f spec . f bootstrap . f dataSecretName f clusterName f infrastructureRef . f apiVersion f kind f name f namespace f version f status . f bootstrapReady f infrastructureReady f replicas spec clusterName <*> replicas <*> template metadata spec clusterName <*> bootstrap dataSecretName infrastructureRef kind AWSManagedMachinePool namespace <*> name <*> apiVersion <*> version <*> minReadySeconds 0 status replicas 0 bootstrapReady false infrastructureReady false	22
2856	create update operations mmpOp 0 mpOp 0	4752
2857	waiting for worker MachinePool replicas to reach target count name <*> namespace <*>	22
2858	check if rolling upgrade is required for AWSManagedMachinePool spectrocluster Namespace <*> Name <*> desired kind AWSManagedMachinePool apiVersion <*> metadata name <*> namespace <*> creationTimestamp null labels <*> <*> spec eksNodegroupName <*> availabilityZones <*> <*> <*> <*> subnetIDs <*> <*> additionalTags <*> spectro__tag spectro__ownerUid <*> <*> spectro__tag roleName <*> diskSize <*> instanceType t3.medium scaling minSize <*> maxSize <*> remoteAccess sshKeyName spectro capacityType spot status ready false replicas 0 existing kind AWSManagedMachinePool apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> ownerReferences apiVersion <*> kind MachinePool name <*> uid <*> controller true blockOwnerDeletion true managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f labels . f <*> f ownerReferences . k uid <*> . f apiVersion f blockOwnerDeletion f controller f kind f name f uid f spec . f additionalTags . f <*> f spectro__ownerUid f <*> f amiType f availabilityZones f capacityType f diskSize f eksNodegroupName f instanceType f remoteAccess . f sshKeyName f roleName f scaling . f maxSize f minSize f subnetIDs f status . f conditions f ready f replicas spec eksNodegroupName <*> availabilityZones <*> <*> <*> <*> subnetIDs <*> <*> additionalTags <*> spectro__tag spectro__ownerUid <*> <*> spectro__tag roleName <*> amiType <*> diskSize <*> instanceType t3.medium scaling minSize <*> maxSize <*> remoteAccess sshKeyName spectro capacityType spot status ready false replicas 0 conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForEKSControlPlane message 0 of <*> completed type EKSNodegroupReady status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForEKSControlPlane	4730
2859	check upgrade for existing machine pool MachinePool kind MachinePool apiVersion <*> metadata name <*> namespace <*> uid <*> resourceVersion <*> generation <*> creationTimestamp <*> <*> <*> labels <*> <*> annotations <*> ownerReferences apiVersion <*> kind Cluster name <*> uid <*> finalizers <*> managedFields manager manager operation Update apiVersion <*> time <*> <*> <*> fieldsType FieldsV1 fieldsV1 f metadata f annotations . f <*> f finalizers f labels . f <*> f ownerReferences f spec . f clusterName f replicas f template . f metadata f spec . f bootstrap . f dataSecretName f clusterName f infrastructureRef . f apiVersion f kind f name f namespace f version f status . f bootstrapReady f conditions f infrastructureReady f observedGeneration f phase f replicas spec clusterName <*> replicas <*> template metadata spec clusterName <*> bootstrap dataSecretName infrastructureRef kind AWSManagedMachinePool namespace <*> name <*> apiVersion <*> version <*> minReadySeconds 0 status replicas 0 phase Provisioning bootstrapReady true infrastructureReady false observedGeneration <*> conditions type Ready status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForEKSControlPlane message 0 of <*> completed type BootstrapReady status True lastTransitionTime <*> <*> <*> type InfrastructureReady status False severity Info lastTransitionTime <*> <*> <*> reason WaitingForEKSControlPlane message 0 of <*> completed type ReplicasReady status True lastTransitionTime <*> <*> <*>	4730
2860	waiting for worker MachinePool to be ready name <*> namespace <*>	4730
2861	reconcile mcp subnet tags spectrocluster Namespace <*> Name <*> cluster <*> mcp <*>	440
2862	update mcp subnets with lb tags done spectrocluster Namespace <*> Name <*> mcp <*>	440
2863	reconcile mmp tags spectrocluster Namespace <*> Name <*> mmp <*>	440
2864	mmp providerId list is empty skipping reconcile for mmp tags spectrocluster Namespace <*> Name <*> mmp <*>	440
2865	START logs for container mold-manager of pod <*>	11
2866	skipping mold reconcile for managed kubernetes cluster spectrocluster <*> clusterName <*> clusterNamespace <*>	989
2867	END logs for container mold-manager of pod <*>	1
